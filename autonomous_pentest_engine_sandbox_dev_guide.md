# Human-in-the-Loop Autonomous Web/API Pentest Engine
## Enterprise Web/API testing tool development guide

> **Purpose**: This guide defines how to design, build, and operate a **human-in-the-loop autonomous penetration testing engine** for **web and API applications**.
> **Audience**: Human developers, security engineers, and AI agents assisting with development.
> **Non-goals**: unauthorized exploitation, out of scope tests.

---

## 0) Base Framework: Gemini-CLI

### 0.1 Why Gemini-CLI as the Foundation

This engine is built on top of **[Gemini-CLI](https://github.com/google-gemini/gemini-cli)**, Google's open-source AI-powered CLI tool. Key advantages:

- **Native MCP Support**: First-class Model Context Protocol integration for tool discovery and execution
- **Built-in HITL Controls**: Confirmation dialogs, trust levels, and approval workflows
- **Extensible Architecture**: Skills, extensions, custom commands, and hooks system
- **Policy Engine**: Configurable approval modes (AUTOMATIC, INTERACTIVE, APPROVAL_REQUIRED)
- **Audit Trail**: Built-in telemetry and logging infrastructure
- **Multi-transport MCP**: Supports stdio, SSE, and HTTP streaming transports

### 0.2 Getting Started

```bash
# Clone the base framework
git clone https://github.com/google-gemini/gemini-cli.git
cd gemini-cli

# Install dependencies
npm install

# Build packages
npm run build

# The pentest engine extends this with custom MCP servers and skills
```

### 0.3 Project Structure (Extended)

```
pentest-engine/
├── gemini-cli/                    # Base framework (cloned)
├── .gemini/
│   ├── settings.json              # MCP server configurations
│   ├── config.yaml                # Project configuration
│   ├── skills/
│   │   ├── pentest-planner/       # Hypothesis generation skill
│   │   ├── vulnerability-validator/ # Finding validation skill
│   │   └── evidence-collector/    # Evidence bundling skill
│   └── commands/
│       ├── scope.toml             # /scope command
│       ├── engage.toml            # /engage command
│       └── killswitch.toml        # /killswitch command
├── mcp-servers/
│   ├── burp-mcp/                  # Burp Suite MCP server
│   ├── scope-guard-mcp/           # Scope enforcement MCP
│   ├── http-client-mcp/           # Rate-limited HTTP client
│   ├── openapi-mcp/               # OpenAPI parser/enumerator
│   ├── auth-tester-mcp/           # Auth differential testing
│   ├── evidence-mcp/              # Evidence bundler
│   └── world-model-mcp/           # Structured state store
├── scope/
│   └── engagement.yaml            # Scope definition file
├── evidence/                      # Evidence storage
└── logs/                          # Audit logs
```

---

## 1) Scope, Safety, and Operating Principles


### 1.2 Human-in-the-loop (HITL) principle
- The engine **MUST** place **approval gates** in front of actions that can:
  - change state (create/modify/delete),
  - cause denial-of-service risk,
  - trigger out-of-band interactions,
  - enumerate large object sets,
  - escalate privileges or attempt chaining beyond a threshold.

### 1.3 Deterministic safety (code > prompts)
Prompts are **not** safety controls. Safety controls must be enforced **in code**, including:
- scope allowlists / denylists,
- request budgets,
- rate limiting and concurrency limits,
- payload allow/deny policies,
- stopping conditions,
- evidence redaction rules,
- mandatory validation rules before findings are emitted.

### 1.4 “Engine owns execution”
- The LLM **suggests** actions and plans.
- The engine **decides** what is permissible and executes it via capability APIs.
- The LLM must never be able to run arbitrary commands or send raw network traffic without engine enforcement.

---

## 2) High-Level Architecture

### 2.1 Components (mapped to Gemini-CLI)

| Component | Implementation | Location |
|-----------|---------------|----------|
| **Orchestrator** | Gemini-CLI core engine | `gemini-cli/packages/core/` |
| **Scope & Safety Guard** | Custom MCP server | `mcp-servers/scope-guard-mcp/` |
| **World Model Store** | Custom MCP server + SQLite/JSON | `mcp-servers/world-model-mcp/` |
| **Planner / Reasoner (LLM)** | Gemini API via core | Built-in (configurable model) |
| **Capability Layer (Tools)** | MCP servers (see Section 17) | `mcp-servers/` |
| **Observation Normalizer** | Part of each MCP tool response | MCP tool implementations |
| **Validation Engine** | Custom MCP server | `mcp-servers/validator-mcp/` |
| **Audit & Evidence Logger** | Custom MCP + Gemini telemetry | `mcp-servers/evidence-mcp/` |
| **HITL Console** | Gemini-CLI confirmation bus | Built-in + custom commands |

### 2.2 Data flow (with Gemini-CLI)

```
┌─────────────────────────────────────────────────────────────────┐
│                      Gemini-CLI (Orchestrator)                   │
├─────────────────────────────────────────────────────────────────┤
│  User Input → Skills/Commands → Gemini API → Tool Selection     │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    MCP Tool Discovery Layer                      │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────────────────┐ │
│  │ scope-guard  │ │ burp-mcp    │ │ http-client-mcp          │ │
│  │ (validates)  │ │ (proxy/scan) │ │ (rate-limited requests)  │ │
│  └──────────────┘ └──────────────┘ └──────────────────────────┘ │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────────────────┐ │
│  │ openapi-mcp  │ │ auth-tester  │ │ world-model-mcp          │ │
│  │ (enumerate)  │ │ (BOLA/IDOR)  │ │ (state store)            │ │
│  └──────────────┘ └──────────────┘ └──────────────────────────┘ │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Confirmation Bus (HITL)                       │
│  - Tool-level trust settings                                     │
│  - Server-level allow-listing                                    │
│  - Risk-based approval gates                                     │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Evidence & Audit Layer                        │
│  - Correlation IDs (X-Engagement-ID, X-Action-ID)               │
│  - Request/response logging via Burp proxy                       │
│  - Finding validation and evidence bundling                      │
└─────────────────────────────────────────────────────────────────┘
```

### 2.3 Data flow (conceptual steps)
1. **Ingest**: scope + targets + identities + specs (OpenAPI).
2. **Plan**: LLM proposes hypothesis and action(s).
3. **Guard**: policy checks + risk scoring + gating via `scope-guard-mcp`.
4. **Execute**: MCP tools run under rate limits & budgets.
5. **Observe**: outputs normalized into structured facts via `world-model-mcp`.
6. **Validate**: re-tests and controls via `validator-mcp`. No validation = no finding.
7. **Report**: structured findings with evidence links via `evidence-mcp`.

### 2.4 Component Interface Contracts
All components MUST accept a shared run context and MUST emit structured outputs. This keeps audit trails consistent and enables strict validation at boundaries.

**Minimum run context (required everywhere):**
- `engagement_id`
- `run_id`
- `action_id`
- `timestamp` (RFC3339)
- `correlation_ids` (headers or tool-specific IDs)
- `identity_id` (optional, if identity-bound)
- `hypothesis_id` (optional)

**Contract summary (normative):**

| Component | Inputs | Outputs | Guarantees | Failure modes |
|-----------|--------|---------|------------|---------------|
| Orchestrator | Planner JSON, scope config, budgets | Action requests + approvals | No action executed without guard pass | Run abort, kill switch |
| Scope & Safety Guard | Target, budgets, risk | Allow/deny + rationale | Fail-closed on ambiguity | Deny + audit log |
| Capability Layer | Tool request envelope | Tool response envelope | Bounded execution + full logging | Error/blocked response |
| Observation Normalizer | Raw tool outputs | Observations w/ provenance | Deterministic normalization | Partial observations |
| Validation Engine | Action + evidence refs | Validation results | Repro + control requirements | Validation failed |
| Evidence Logger | Requests/responses + IDs | Evidence pack + hashes | Immutable evidence refs | Write failure |

---

## 3) Environment Setup (Enterprise Sandbox)

### 3.1 Required prerequisites
- **Node.js 20+** for Gemini-CLI
- **Gemini API Key** (set via `GEMINI_API_KEY` environment variable)
- A dedicated webapp/api for testing
- Test identities (multiple roles/tenants) with documented permissions.
- A designated **test proxy** (Burp Suite Professional recommended) and logging store.
- A secrets manager for credentials (no plaintext in repos).
- A stable set of sandbox targets and OpenAPI specs.

### 3.2 Strongly recommended
- A dedicated **testing gateway** that can hard-block non-allowlisted destinations.
- Read-only test data or synthetic fixtures.
- Separate "destructive" endpoints disabled unless explicitly enabled.
- **Burp Suite Professional** with REST API enabled (for Burp MCP integration).

### 3.3 Gemini-CLI Setup

```bash
# 1. Clone and build Gemini-CLI
git clone https://github.com/google-gemini/gemini-cli.git
cd gemini-cli
npm install && npm run build

# 2. Set up API key
export GEMINI_API_KEY="your-api-key"

# 3. Create project configuration directory
mkdir -p .gemini/skills .gemini/commands

# 4. Initialize settings.json with MCP servers (see Section 17)
cat > .gemini/settings.json << 'EOF'
{
  "mcpServers": {
    // Configure MCP servers here (see Section 17)
  }
}
EOF

# 5. Run the CLI
npm run start
# Or after global install: gemini
```

---

## 4) Scope Definition Format (Required)

### 4.1 Scope file (example schema)
Your scope file should be machine-validated. Recommended fields:

- `engagement_id`
- `allowlist`:
  - `domains`: exact domains or suffix patterns
  - `ip_ranges`: CIDR ranges
  - `services`: app identifiers / tags
- `denylist`:
  - production domains, known sensitive systems, external services
- `credentials`:
  - identity aliases (actual secrets stored elsewhere)
- `constraints`:
  - max requests per minute
  - max concurrent requests
  - max total requests
  - max object enumeration size
  - time window (optional)
- `forbidden_actions`:
  - e.g. “no data exfil”
- `approval_policy`:
  - which risk levels require human approval
- `evidence_policy`:
  - what raw data can be stored; redaction rules

### 4.2 Scope enforcement MUST
- Validate the file schema at startup.
- Compute a canonical allowlist set.
- Fail closed if anything is missing or inconsistent.

### 4.3 Scope JSON Schema (Normative)
The scope file MAY be authored in YAML, but MUST be validated against a JSON Schema at load time. Canonicalize after validation (sort lists, normalize CIDR blocks, and resolve domain suffixes).

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/engagement-scope.json",
  "type": "object",
  "required": [
    "schema_version",
    "engagement_id",
    "allowlist",
    "constraints",
    "approval_policy",
    "evidence_policy"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "engagement_id": { "type": "string", "minLength": 3 },
    "allowlist": {
      "type": "object",
      "required": ["domains", "ip_ranges"],
      "additionalProperties": false,
      "properties": {
        "domains": {
          "type": "array",
          "minItems": 1,
          "items": { "type": "string", "minLength": 1 }
        },
        "ip_ranges": {
          "type": "array",
          "minItems": 1,
          "items": { "type": "string", "pattern": "^([0-9]{1,3}\\.){3}[0-9]{1,3}/[0-9]{1,2}$" }
        },
        "services": {
          "type": "array",
          "items": { "type": "string", "minLength": 1 }
        }
      }
    },
    "denylist": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "domains": { "type": "array", "items": { "type": "string" } },
        "ip_ranges": { "type": "array", "items": { "type": "string" } },
        "services": { "type": "array", "items": { "type": "string" } }
      }
    },
    "credentials": {
      "type": "array",
      "items": { "type": "string", "minLength": 1 }
    },
    "constraints": {
      "type": "object",
      "required": ["max_rps", "max_concurrency", "max_total_requests", "max_object_enumeration"],
      "additionalProperties": false,
      "properties": {
        "max_rps": { "type": "integer", "minimum": 1 },
        "max_concurrency": { "type": "integer", "minimum": 1 },
        "max_total_requests": { "type": "integer", "minimum": 1 },
        "max_object_enumeration": { "type": "integer", "minimum": 1 },
        "time_window": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "start": { "type": "string", "format": "date-time" },
            "end": { "type": "string", "format": "date-time" }
          }
        }
      }
    },
    "forbidden_actions": {
      "type": "array",
      "items": { "type": "string", "minLength": 1 }
    },
    "approval_policy": {
      "type": "object",
      "required": ["risk_levels"],
      "additionalProperties": false,
      "properties": {
        "risk_levels": {
          "type": "object",
          "required": ["medium", "high"],
          "additionalProperties": false,
          "properties": {
            "low": { "type": "boolean" },
            "medium": { "type": "boolean" },
            "high": { "type": "boolean" }
          }
        }
      }
    },
    "evidence_policy": {
      "type": "object",
      "required": ["store_raw_bodies", "redaction_rules"],
      "additionalProperties": false,
      "properties": {
        "store_raw_bodies": { "type": "boolean" },
        "redaction_rules": {
          "type": "array",
          "items": { "type": "string", "minLength": 1 }
        },
        "retention_days": { "type": "integer", "minimum": 1 }
      }
    },
    "metadata": {
      "type": "object",
      "additionalProperties": true
    }
  }
}
```

---

## 5) Capability Layer (Tools) — MCP Implementation

> **Goal**: Provide safe, bounded "capabilities" as MCP servers that are hard to misuse.

### 5.1 Foundational capabilities (minimum) - MCP Mapping

| Capability | MCP Server | Key Tools |
|------------|------------|-----------|
| **HTTP Client** | `http-client-mcp` | `http_send`, `http_send_batch` |
| **OpenAPI Parser** | `openapi-mcp` | `openapi_ingest`, `openapi_list_endpoints` |
| **Auth Differential** | `auth-tester-mcp` | `auth_diff_test`, `auth_replay_with_identity` |
| **Evidence Bundler** | `evidence-mcp` | `evidence_bundle`, `evidence_export` |
| **Validator** | `validator-mcp` | `validate_repro`, `validate_negative_control` |
| **Scope Guard** | `scope-guard-mcp` | `scope_validate_target`, `scope_check_budget` |
| **World Model** | `world-model-mcp` | `wm_add_hypothesis`, `wm_add_finding` |

### 5.2 HTTP Client MCP (`http-client-mcp`)
```typescript
// Tools exposed:
// - http_send: Single request with scope validation + rate limiting
// - http_send_batch: Multiple requests with concurrency control
// - http_get_stats: Request statistics and remaining budget

// Key features:
// - Routes through Burp proxy for evidence capture
// - Validates all targets via scope-guard-mcp before sending
// - Enforces rate limits (max_rps, max_concurrent, max_total)
// - Adds correlation headers (X-Engagement-ID, X-Action-ID)
// - Exponential backoff on 429/503 responses
```

### 5.3 Additional capabilities (phase 2+)
- Token/session mutation and replay (`auth-tester-mcp`: `auth_mutate_replay`)
- Parameter discovery and schema-based fuzzing (`fuzzer-mcp`: `fuzz_schema_mutate`)
- GraphQL cost/depth testing (`graphql-mcp`: `graphql_cost_test`) if relevant
- Rate limit and lockout detection (`abuse-tester-mcp`: `abuse_rate_limit_probe`) with strict bounds
- Response diff and invariant extraction (`diff-mcp`: `diff_invariants`)
- Nuclei scanning (`nuclei-mcp`: `nuclei_scan_single`)
- ZAP passive scanning (`zap-mcp`: `zap_passive_scan`)

### 5.4 What NOT to expose as MCP tools
- Arbitrary shell execution (`bash`, `sh`, `cmd`) from the LLM.
- Raw socket access, port scanning without strict bounds.
- "Run any Burp scan" without scope-limited wrappers and budgets.
- Tools that can access production secrets or external internet by default.
- Active scanning tools without explicit `trust: false` and HITL gates.

### 5.5 Tool Request/Response Envelope (Normative)
All MCP tools MUST accept a common request envelope and return a common response envelope. Tool-specific parameters MUST live under `inputs`.

**Tool request schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/tool-request.json",
  "type": "object",
  "required": ["tool_name", "action_id", "engagement_id", "inputs"],
  "additionalProperties": false,
  "properties": {
    "tool_name": { "type": "string", "minLength": 1 },
    "action_id": { "type": "string", "minLength": 1 },
    "engagement_id": { "type": "string", "minLength": 1 },
    "run_id": { "type": "string" },
    "hypothesis_id": { "type": "string" },
    "identity_id": { "type": "string" },
    "risk_level": { "type": "string", "enum": ["low", "medium", "high"] },
    "budget": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "max_requests": { "type": "integer", "minimum": 1 },
        "timeout_ms": { "type": "integer", "minimum": 1 }
      }
    },
    "inputs": { "type": "object" }
  }
}
```

**Tool response schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/tool-response.json",
  "type": "object",
  "required": ["status", "observations"],
  "additionalProperties": false,
  "properties": {
    "status": { "type": "string", "enum": ["ok", "error", "blocked"] },
    "observations": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["type", "confidence", "data", "provenance"],
        "additionalProperties": false,
        "properties": {
          "type": { "type": "string", "minLength": 1 },
          "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
          "data": { "type": "object" },
          "provenance": {
            "type": "object",
            "required": ["tool_name", "timestamp"],
            "additionalProperties": false,
            "properties": {
              "tool_name": { "type": "string" },
              "timestamp": { "type": "string", "format": "date-time" },
              "request_id": { "type": "string" },
              "response_id": { "type": "string" }
            }
          }
        }
      }
    },
    "evidence_refs": {
      "type": "array",
      "items": { "type": "string" }
    },
    "errors": {
      "type": "array",
      "items": { "type": "string" }
    },
    "metrics": {
      "type": "object",
      "additionalProperties": true
    }
  }
}
```

**Tool input schemas (selected):**

`http_send` inputs:
```json
{
  "type": "object",
  "required": ["method", "url"],
  "additionalProperties": false,
  "properties": {
    "method": { "type": "string", "enum": ["GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"] },
    "url": { "type": "string", "format": "uri" },
    "headers": { "type": "object", "additionalProperties": { "type": "string" } },
    "body": { "type": ["string", "object"] },
    "timeout_ms": { "type": "integer", "minimum": 1 },
    "follow_redirects": { "type": "boolean" },
    "max_redirects": { "type": "integer", "minimum": 0 }
  }
}
```

`openapi_ingest` inputs:
```json
{
  "type": "object",
  "required": ["source_type", "source"],
  "additionalProperties": false,
  "properties": {
    "source_type": { "type": "string", "enum": ["file", "url", "text"] },
    "source": { "type": "string", "minLength": 1 },
    "base_url": { "type": "string", "format": "uri" }
  }
}
```

`auth_diff_test` inputs:
```json
{
  "type": "object",
  "required": ["request_template", "identities"],
  "additionalProperties": false,
  "properties": {
    "request_template": {
      "type": "object",
      "required": ["method", "url"],
      "additionalProperties": false,
      "properties": {
        "method": { "type": "string" },
        "url": { "type": "string", "format": "uri" },
        "headers": { "type": "object", "additionalProperties": { "type": "string" } },
        "body": { "type": ["string", "object"] }
      }
    },
    "identities": {
      "type": "array",
      "minItems": 2,
      "items": { "type": "string", "minLength": 1 }
    },
    "compare_fields": {
      "type": "array",
      "items": { "type": "string" }
    }
  }
}
```

`validate_repro` inputs:
```json
{
  "type": "object",
  "required": ["action_id", "attempts"],
  "additionalProperties": false,
  "properties": {
    "action_id": { "type": "string", "minLength": 1 },
    "attempts": { "type": "integer", "minimum": 1 },
    "negative_control": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "identity_id": { "type": "string" },
        "expected_status": { "type": "integer" }
      }
    },
    "cross_identity": { "type": "boolean" }
  }
}
```

### 5.6 MCP Tool Trust Configuration

```json
{
  "mcpServers": {
    "scope-guard": { "trust": true },      // Always safe
    "openapi": { "trust": true },          // Read-only parsing
    "world-model": { "trust": true },      // Internal state only
    "evidence": { "trust": true },         // Evidence collection

    "http-client": { "trust": false },     // Requires confirmation
    "auth-tester": { "trust": false },     // Requires confirmation
    "validator": { "trust": false },       // May send requests
    "burp": { "trust": false },            // External integration
    "nuclei": { "trust": false }           // Scanner
  }
}
```

---

## 6) Burp Suite Integration (MCP-Based)

### 6.1 Burp MCP Server Architecture

The Burp MCP server exposes Burp Suite functionality as MCP tools:

```
┌─────────────────────────────────────────────────────────────┐
│                    Burp Suite Professional                   │
│  ┌─────────────┐ ┌─────────────┐ ┌────────────────────────┐ │
│  │   Proxy     │ │   Scanner   │ │   Repeater/Intruder    │ │
│  └──────┬──────┘ └──────┬──────┘ └───────────┬────────────┘ │
│         │               │                     │              │
│         └───────────────┼─────────────────────┘              │
│                         │                                    │
│                    REST API (:1337)                          │
└─────────────────────────┬───────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                    Burp MCP Server                           │
│  ┌─────────────────┐ ┌─────────────────┐ ┌────────────────┐ │
│  │ burp.proxy_     │ │ burp.scan_      │ │ burp.get_      │ │
│  │ send_request    │ │ passive         │ │ findings       │ │
│  └─────────────────┘ └─────────────────┘ └────────────────┘ │
│  ┌─────────────────┐ ┌─────────────────┐ ┌────────────────┐ │
│  │ burp.get_       │ │ burp.export_    │ │ burp.scope_    │ │
│  │ history         │ │ evidence        │ │ check          │ │
│  └─────────────────┘ └─────────────────┘ └────────────────┘ │
└─────────────────────────┬───────────────────────────────────┘
                          │ MCP Protocol (stdio/SSE)
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                    Gemini-CLI                                │
└─────────────────────────────────────────────────────────────┘
```

### 6.2 Burp MCP Server Configuration

Add to `.gemini/settings.json`:

```json
{
  "mcpServers": {
    "burp": {
      "command": "node",
      "args": ["mcp-servers/burp-mcp/dist/server.js"],
      "env": {
        "BURP_API_URL": "http://127.0.0.1:1337",
        "BURP_API_KEY": "${BURP_API_KEY}"
      },
      "timeout": 60000,
      "trust": false,
      "includeTools": [
        "burp_proxy_send",
        "burp_get_history",
        "burp_get_findings",
        "burp_export_evidence"
      ],
      "excludeTools": [
        "burp_active_scan",
        "burp_intruder_attack"
      ]
    }
  }
}
```

### 6.3 Burp MCP Tools (Recommended)

| Tool | Purpose | Risk Level |
|------|---------|------------|
| `burp_proxy_send` | Send request through proxy with tagging | Low |
| `burp_get_history` | Retrieve proxy history (filtered) | Low |
| `burp_get_findings` | Get passive scanner findings | Low |
| `burp_export_evidence` | Export request/response for evidence | Low |
| `burp_scope_check` | Verify URL is in Burp scope | Low |
| `burp_passive_scan` | Run passive scan on history item | Medium |
| `burp_active_scan` | Run active scan (REQUIRES APPROVAL) | High |

### 6.4 Preferred: Burp as proxy + evidence capture
- Route all HTTP traffic through Burp proxy via `http-client-mcp`.
- Tag each request with custom headers:
  - `X-Engagement-ID`
  - `X-Action-ID`
  - `X-Identity-ID`
  - `X-Hypothesis-ID`
- Store via `burp_export_evidence`:
  - request/response bytes OR redacted versions
  - timestamps, status, sizes, hashes

### 6.5 Avoid: Direct Burp UI/Active Scanning
- Do not attempt to "drive" the Burp UI with the agent.
- Active scanning tools should be excluded or require explicit HITL approval.
- It reduces determinism and increases safety and audit risk.

---

## 7) World Model (Data Model) and RAG

### 7.1 World model is not “chat memory”
Maintain a structured, queryable model for:
- assets, endpoints, schemas
- identities and roles
- sessions/tokens
- observations (facts with evidence links)
- hypotheses (status, confidence)
- actions (approved/executed/blocked)
- findings (validated only)

### 7.2 RAG usage guidance
RAG is useful for:
- retrieving relevant endpoints and past observations
- searching previous test outcomes
- mapping patterns to remediation guidance

RAG is not a substitute for:
- authoritative scope policy enforcement
- finding validation
- storing evidence

**Rule**: RAG may inform reasoning; it must not be the single source of truth for execution decisions.

### 7.3 World Model Entity Schemas (Normative)
All world model entities MUST be validated on write. The schema below defines the minimal required fields for each entity.

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/world-model.json",
  "$defs": {
    "timestamp": { "type": "string", "format": "date-time" },
    "asset": {
      "type": "object",
      "required": ["asset_id", "kind", "name", "created_at"],
      "additionalProperties": false,
      "properties": {
        "asset_id": { "type": "string" },
        "kind": { "type": "string", "enum": ["domain", "ip", "service"] },
        "name": { "type": "string" },
        "tags": { "type": "array", "items": { "type": "string" } },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "endpoint": {
      "type": "object",
      "required": ["endpoint_id", "method", "path", "asset_id", "created_at"],
      "additionalProperties": false,
      "properties": {
        "endpoint_id": { "type": "string" },
        "method": { "type": "string" },
        "path": { "type": "string" },
        "asset_id": { "type": "string" },
        "openapi_ref": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "identity": {
      "type": "object",
      "required": ["identity_id", "label", "created_at"],
      "additionalProperties": false,
      "properties": {
        "identity_id": { "type": "string" },
        "label": { "type": "string" },
        "roles": { "type": "array", "items": { "type": "string" } },
        "tenant_id": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "session": {
      "type": "object",
      "required": ["session_id", "identity_id", "created_at"],
      "additionalProperties": false,
      "properties": {
        "session_id": { "type": "string" },
        "identity_id": { "type": "string" },
        "token_ref": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" },
        "expires_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "observation": {
      "type": "object",
      "required": ["observation_id", "action_id", "type", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "observation_id": { "type": "string" },
        "action_id": { "type": "string" },
        "type": { "type": "string" },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "data": { "type": "object" },
        "evidence_refs": { "type": "array", "items": { "type": "string" } },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "hypothesis": {
      "type": "object",
      "required": ["hypothesis_id", "description", "status", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "hypothesis_id": { "type": "string" },
        "description": { "type": "string" },
        "status": { "type": "string", "enum": ["new", "testing", "validated", "rejected"] },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "created_at": { "$ref": "#/$defs/timestamp" },
        "updated_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "action": {
      "type": "object",
      "required": ["action_id", "capability", "status", "requested_at"],
      "additionalProperties": false,
      "properties": {
        "action_id": { "type": "string" },
        "capability": { "type": "string" },
        "target": { "type": "object" },
        "status": { "type": "string", "enum": ["proposed", "approved", "blocked", "executed", "failed"] },
        "requested_at": { "$ref": "#/$defs/timestamp" },
        "approved_at": { "$ref": "#/$defs/timestamp" },
        "executed_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "finding": {
      "type": "object",
      "required": ["finding_id", "title", "severity", "status", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "finding_id": { "type": "string" },
        "title": { "type": "string" },
        "severity": { "type": "string", "enum": ["low", "medium", "high", "critical"] },
        "status": { "type": "string", "enum": ["draft", "validated", "rejected"] },
        "hypothesis_id": { "type": "string" },
        "evidence_refs": { "type": "array", "items": { "type": "string" } },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "remediation": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    }
  }
}
```

---

## 8) Agent Workflow (Plan → Act → Observe → Validate)

### 8.1 Standard loop
1. **Plan**
   - LLM proposes hypotheses and actions as structured JSON.
2. **Guard + Gate**
   - Policy checks + risk scoring + HITL approval where required.
3. **Execute**
   - Capabilities run under budgets.
4. **Observe**
   - Normalize outputs into facts with provenance.
5. **Validate**
   - Re-test + controls. No validation = no finding.
6. **Report**
   - Generate findings with evidence links and minimal sensitive data.

### 8.2 Mandatory structured output from LLM
Require the planner to output:
- `hypothesis_id`
- `action_id`
- `capability`
- `target`
- `inputs`
- `expected_signal`
- `validation_plan`
- `risk_level`

#### 8.2.1 Planner Output JSON Schema (Normative)
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/planner-output.json",
  "type": "object",
  "required": [
    "schema_version",
    "hypothesis_id",
    "action_id",
    "capability",
    "target",
    "inputs",
    "expected_signal",
    "validation_plan",
    "risk_level"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "hypothesis_id": { "type": "string", "minLength": 1 },
    "action_id": { "type": "string", "minLength": 1 },
    "capability": { "type": "string", "minLength": 1 },
    "target": {
      "oneOf": [
        {
          "type": "object",
          "required": ["endpoint_id"],
          "additionalProperties": false,
          "properties": {
            "endpoint_id": { "type": "string" },
            "method": { "type": "string" }
          }
        },
        {
          "type": "object",
          "required": ["url"],
          "additionalProperties": false,
          "properties": {
            "url": { "type": "string", "format": "uri" },
            "method": { "type": "string" }
          }
        }
      ]
    },
    "inputs": { "type": "object" },
    "expected_signal": { "type": "string", "minLength": 1 },
    "validation_plan": {
      "type": "object",
      "required": ["repro_attempts", "negative_control", "cross_identity"],
      "additionalProperties": false,
      "properties": {
        "repro_attempts": { "type": "integer", "minimum": 1 },
        "negative_control": { "type": "string", "minLength": 1 },
        "cross_identity": { "type": "boolean" }
      }
    },
    "risk_level": { "type": "string", "enum": ["low", "medium", "high"] },
    "notes": { "type": "string" }
  }
}
```

#### 8.2.2 Examples
Valid:
```json
{
  "schema_version": "1.0.0",
  "hypothesis_id": "H-042",
  "action_id": "A-112",
  "capability": "auth_diff_test",
  "target": { "endpoint_id": "ep-accounts-get", "method": "GET" },
  "inputs": { "request_template": { "method": "GET", "url": "https://app.test/api/accounts/123" }, "identities": ["user_a", "user_b"] },
  "expected_signal": "Identity B receives 403 while A receives 200 for the same object.",
  "validation_plan": { "repro_attempts": 3, "negative_control": "Use identity C with no access", "cross_identity": true },
  "risk_level": "medium"
}
```

Invalid (missing validation_plan and risk_level, includes raw shell):
```json
{
  "schema_version": "1.0.0",
  "hypothesis_id": "H-043",
  "action_id": "A-113",
  "capability": "shell.exec",
  "target": { "url": "https://app.test/api/users" },
  "inputs": { "cmd": "curl -k https://app.test/api/users" },
  "expected_signal": "Some response"
}
```

Reject non-conforming outputs.

### 8.3 Kill switch
- Provide a global stop:
  - immediate halt of new requests
  - graceful shutdown of in-flight tasks
  - lock the engagement state to prevent resumption without human review

### 8.4 Run Manifest + Action Ledger (Normative)
Each run MUST emit a `run_manifest.json` and an `action_ledger.jsonl`. These provide non-repudiable auditability for approvals and execution.

**`run_manifest.json` schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/run-manifest.json",
  "type": "object",
  "required": [
    "schema_version",
    "engagement_id",
    "run_id",
    "started_at",
    "scope_hash",
    "environment"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "engagement_id": { "type": "string" },
    "run_id": { "type": "string" },
    "started_at": { "type": "string", "format": "date-time" },
    "ended_at": { "type": "string", "format": "date-time" },
    "scope_hash": { "type": "string" },
    "environment": { "type": "string", "enum": ["SANDBOX", "STAGING"] },
    "operator": { "type": "string" },
    "tool_versions": { "type": "object", "additionalProperties": { "type": "string" } },
    "config_hash": { "type": "string" }
  }
}
```

**`action_ledger.jsonl` entry schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/action-ledger-entry.json",
  "type": "object",
  "required": [
    "schema_version",
    "action_id",
    "tool_name",
    "status",
    "requested_at"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "action_id": { "type": "string" },
    "hypothesis_id": { "type": "string" },
    "tool_name": { "type": "string" },
    "status": { "type": "string", "enum": ["proposed", "approved", "blocked", "executed", "failed"] },
    "requested_at": { "type": "string", "format": "date-time" },
    "approved_at": { "type": "string", "format": "date-time" },
    "executed_at": { "type": "string", "format": "date-time" },
    "correlation_ids": { "type": "object", "additionalProperties": { "type": "string" } },
    "request_hash": { "type": "string" },
    "response_hash": { "type": "string" },
    "error": { "type": "string" }
  }
}
```

---

## 9) Safety Guardrails (Hard Rules)

### 9.1 Scope checks
- Check every request destination against allowlist:
  - DNS resolved IP must be in allowlisted ranges
  - Host header must match allowlisted domain patterns
  - TLS SNI must match allowlist
- **Fail closed** if:
  - DNS resolution fails,
  - destination changes mid-run,
  - redirects go off-allowlist.

### 9.2 Budgets and throttling
Implement at least:
- `max_rps` (requests per second)
- `max_concurrency`
- `max_total_requests`
- `max_object_enumeration` (e.g., max 50 object IDs)
- exponential backoff on 429/503 responses

### 9.3 High-risk action gating (examples)
Require explicit approval for:
- password reset / recovery flows
- account lockout triggers
- large-scale enumeration
- file upload abuse testing
- out-of-band callbacks
- long-running fuzzing campaigns

### 9.4 Data minimisation & redaction
- Prefer storing:
  - hashes of sensitive fields,
  - field presence indicators,
  - invariant diffs,
  - minimal excerpts.
- If raw bodies are stored:
  - enforce encryption at rest,
  - strict access controls,
  - automatic expiry.

### 9.5 No production connectivity
- Block egress to public internet unless explicitly required and approved.
- Block known production domains at network layer.

---

## 10) Anti-Hallucination Rules (Validation Requirements)

### 10.1 Findings require evidence and controls
A finding is valid only if:
- **Reproducibility**: confirmed across N runs (recommend N=3).
- **Negative control**: same exploit attempt fails in a control scenario.
- **Cross-identity control**: A succeeds while B fails (or vice versa) per hypothesis.
- **Impact evidence**: unauthorized data or action is clearly shown via evidence links.

### 10.2 “Static indicators” are insufficient alone
- 500 errors, stack traces, or “odd responses” are not findings without exploitability proof.
- LLM confidence is not evidence.

### 10.3 Confidence scoring
Store confidence per hypothesis/finding:
- based on reproducibility, control strength, and signal quality.
Do not label anything “confirmed” below your defined threshold.

---

## 11) What To Do vs What Not To Do

### 11.1 Do
- Build capabilities around common web/API weakness classes:
  - BOLA/IDOR
  - broken auth/session management
  - role/tenant isolation failures
  - business logic bypass in sandbox-safe flows
- Keep actions narrow and bounded.
- Use multiple identities and controlled object sets.
- Produce evidence packs with correlation IDs.
- Add robust stop conditions and budget enforcement.

### 11.2 Do not
- Attempt exploitation outside scope allowlists.
- Run internet-wide recon, mass scans, or worm-like behavior.
- export large datasets.
- Let the agent execute arbitrary commands.
- Present unvalidated “findings” as confirmed vulnerabilities.

---

## 12) Implementation How-Tos

### 12.1 Correlation IDs everywhere
- Generate `action_id` for every step.
- Add headers like:
  - `X-Engagement-ID`, `X-Action-ID`, `X-Identity-ID`
- Ensure your proxy logs these values.

### 12.2 Evidence pack format
For each finding `F-###`, store:
- summary.json (finding metadata, confidence, timestamps)
- requests/ (request1.txt, response1.txt or redacted)
- artefacts/ (HAR, screenshots if relevant)
- invariants.json (diffs, extracted identifiers)
- validation.json (repro attempts + results)

### 12.3 Common web/API test workflows
#### Authorization differential testing (BOLA/IDOR)
1. Identify endpoint with object identifier.
2. Collect a small set of object IDs for identity A (<= budget).
3. Replay request with identity B.
4. Validate unauthorized access with controls and repetition.
5. Store evidence and mark as finding only if validated.

#### Session/token replay testing
1. Obtain token T for identity A (sandbox fixture).
2. Attempt replay in altered context (device/session binding checks) **only if allowed**.
3. Validate consistent behavior and controls.
4. Escalation attempts require approval.

#### Schema-based fuzzing (safe)
1. Use OpenAPI schema to generate valid-ish variants.
2. Mutate fields with strict bounds and stop conditions.
3. Log and triage signals; validate before reporting.

### 12.4 Evidence JSON Schemas (Normative)
Evidence files MUST be validated before persistence.

**summary.json schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-summary.json",
  "type": "object",
  "required": ["schema_version", "finding_id", "title", "severity", "confidence", "created_at"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "finding_id": { "type": "string" },
    "title": { "type": "string" },
    "severity": { "type": "string", "enum": ["low", "medium", "high", "critical"] },
    "status": { "type": "string", "enum": ["draft", "validated", "rejected"] },
    "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
    "created_at": { "type": "string", "format": "date-time" },
    "hypothesis_id": { "type": "string" },
    "impact": { "type": "string" },
    "remediation": { "type": "string" },
    "evidence_refs": { "type": "array", "items": { "type": "string" } }
  }
}
```

**validation.json schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-validation.json",
  "type": "object",
  "required": ["schema_version", "repro_attempts", "results"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "repro_attempts": { "type": "integer", "minimum": 1 },
    "negative_control": { "type": "string" },
    "cross_identity": { "type": "boolean" },
    "results": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["attempt", "status"],
        "additionalProperties": false,
        "properties": {
          "attempt": { "type": "integer", "minimum": 1 },
          "status": { "type": "string", "enum": ["pass", "fail"] },
          "notes": { "type": "string" }
        }
      }
    }
  }
}
```

**invariants.json schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-invariants.json",
  "type": "object",
  "required": ["schema_version", "invariants"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "invariants": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["field", "observation"],
        "additionalProperties": false,
        "properties": {
          "field": { "type": "string" },
          "observation": { "type": "string" },
          "evidence_ref": { "type": "string" }
        }
      }
    }
  }
}
```

---

## 13) Quality Gates for Merging Code

### 13.1 Mandatory checks
- Unit tests for:
  - allowlist enforcement
  - redirect handling
  - DNS/IP enforcement
  - budget/rate limit logic
  - HITL gating state machine
  - validator logic (repro + controls)
- Integration tests against a known sandbox service with seeded vulnerabilities.

### 13.2 Security reviews (internal)
- Review any new capability for:
  - scope bypass risk
  - destructive potential
  - data leakage potential
  - logging adequacy

### 13.3 Release safeguards
- Default configuration must be safe:
  - `environment=SANDBOX`
  - allowlist required
  - low budgets
  - approvals enabled
  - external egress disabled

### 13.4 Schema Versioning and Compatibility
- Every schema MUST include `schema_version` using semver (`MAJOR.MINOR.PATCH`).
- **PATCH**: fixes or clarifications with no structural change.
- **MINOR**: additive optional fields or relaxed constraints.
- **MAJOR**: breaking changes (removed fields, stricter validation, new required fields).
- Tools MUST reject unknown **MAJOR** versions and emit a blocking error.
- Tools SHOULD tolerate newer **MINOR** versions by ignoring unknown optional fields.

---

## 14) Operational Playbook (Sandbox)

### 14.1 Running an engagement (checklist)
1. Load scope file; validate schema.
2. Confirm allowlist resolution checks.
3. Load test identities (aliases only).
4. Ingest OpenAPI (if available).
5. Start proxy capture.
6. Run read-only mapping phase.
7. Generate hypotheses; approve a subset.
8. Execute bounded tests.
9. Validate findings.
10. Export evidence packs and report.

### 14.2 Incident handling
If the engine:
- hits unexpected targets,
- causes instability,
- triggers suspicious monitoring alerts,
- produces a large spike in traffic,

**Immediately kill switch**, then:
- preserve logs,
- notify the sandbox owner,
- conduct a post-run review before resuming.

---

## 15) Developer Notes for AI Agents Working in Development

### 15.1 Safe coding rules for AI agents
AI agents contributing code must:
- implement changes behind feature flags
- add tests for safety controls
- avoid adding any “execute arbitrary command” functionality
- preserve audit logging and correlation IDs
- never embed secrets in code or prompts

### 15.2 Prompting rules for AI agents (planner prompts)
- Planner prompts should:
  - require structured JSON outputs
  - remind that scope is sandbox-only
  - instruct the model to propose only capabilities, not raw commands
  - require validation plans for each proposed action

---

## 16) Development Phases (10-Phase Plan)

### Overview

| Phase | Name | Focus | Key Deliverables |
|-------|------|-------|------------------|
| 1 | Foundation | Gemini-CLI setup + project structure | Working CLI, config files |
| 2 | Scope Guard | Scope enforcement MCP | `scope-guard-mcp` with allowlist validation |
| 3 | HTTP Client | Rate-limited HTTP with safety | `http-client-mcp` with budgets + proxy |
| 4 | Burp Integration | Proxy + evidence capture | `burp-mcp` with history/export tools |
| 5 | OpenAPI & Discovery | Endpoint enumeration | `openapi-mcp` with spec parsing |
| 6 | World Model | Structured state store | `world-model-mcp` with SQLite backend |
| 7 | Auth Testing | BOLA/IDOR differential testing | `auth-tester-mcp` with identity replay |
| 8 | Validation Engine | Finding validation + controls | `validator-mcp` with repro logic |
| 9 | Evidence & Reporting | Evidence bundling + export | `evidence-mcp` + report generation |
| 10 | Advanced Tools | Nuclei, fuzzing, extended scanners | Additional MCP servers + skills |

---

### Phase 1: Foundation
**Goal**: Set up gemini-cli and project structure

**Tasks**:
- [ ] Clone gemini-cli from GitHub
- [ ] Install dependencies and build
- [ ] Set up Gemini API key
- [ ] Create project directory structure
- [ ] Create initial `.gemini/settings.json`
- [ ] Create scope file template (`scope/engagement.yaml`)
- [ ] Verify CLI runs and can call Gemini API

**Deliverables**:
```
pentest-engine/
├── gemini-cli/              # Cloned and built
├── .gemini/
│   ├── settings.json        # Empty mcpServers config
│   └── config.yaml
├── mcp-servers/             # Empty, ready for MCP servers
├── scope/
│   └── engagement.yaml      # Template scope file
└── package.json             # Project root config
```

**Exit Criteria**: `gemini` CLI starts, responds to prompts, no MCP servers yet.

---

### Phase 2: Scope Guard MCP
**Goal**: Implement scope enforcement as the first safety layer

**Tasks**:
- [ ] Create `mcp-servers/scope-guard-mcp/` project
- [ ] Implement scope file loader with JSON Schema validation
- [ ] Implement `scope_validate_target` tool (URL/IP check)
- [ ] Implement `scope_get_allowlist` tool
- [ ] Implement `scope_get_constraints` tool
- [ ] Implement `scope_check_budget` tool
- [ ] Add fail-closed behavior on validation errors
- [ ] Write unit tests for allowlist logic
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/scope-guard-mcp/
├── src/
│   ├── server.ts            # MCP server entry
│   ├── scope-loader.ts      # YAML/JSON loader + validation
│   └── validators.ts        # Domain/IP/CIDR validation
├── tests/
│   └── scope.test.ts
├── package.json
└── tsconfig.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `scope_validate_target` | Check if URL/IP is in scope |
| `scope_get_allowlist` | Return current allowlist |
| `scope_get_constraints` | Return rate limits and budgets |
| `scope_check_budget` | Check remaining request budget |

**Exit Criteria**: Scope guard correctly allows/denies targets based on scope file.

---

### Phase 3: HTTP Client MCP
**Goal**: Safe, rate-limited HTTP client with scope enforcement

**Tasks**:
- [ ] Create `mcp-servers/http-client-mcp/` project
- [ ] Implement `http_send` tool with rate limiting
- [ ] Integrate scope validation (call scope-guard before each request)
- [ ] Add proxy support (route through Burp)
- [ ] Add correlation headers (X-Engagement-ID, X-Action-ID)
- [ ] Implement request budget tracking
- [ ] Implement exponential backoff on 429/503
- [ ] Implement `http_send_batch` with concurrency limits
- [ ] Write unit tests for rate limiting
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/http-client-mcp/
├── src/
│   ├── server.ts
│   ├── rate-limiter.ts
│   ├── budget-tracker.ts
│   └── http-client.ts
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `http_send` | Send single HTTP request (rate-limited) |
| `http_send_batch` | Send multiple requests with concurrency control |
| `http_get_stats` | Get request statistics and remaining budget |

**Exit Criteria**: HTTP requests are rate-limited, scope-validated, and logged with correlation IDs.

---

### Phase 4: Burp Suite Integration
**Goal**: Integrate Burp as proxy and evidence capture layer

**Tasks**:
- [ ] Create `mcp-servers/burp-mcp/` project
- [ ] Implement Burp REST API client
- [ ] Implement `burp_proxy_send` tool
- [ ] Implement `burp_get_history` tool with filtering
- [ ] Implement `burp_get_findings` (passive scanner results)
- [ ] Implement `burp_export_evidence` tool
- [ ] Implement `burp_scope_check` tool
- [ ] Configure http-client-mcp to route through Burp proxy
- [ ] Test with Burp Suite Professional
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/burp-mcp/
├── src/
│   ├── server.ts
│   ├── burp-api-client.ts
│   └── evidence-exporter.ts
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `burp_proxy_send` | Send request through Burp proxy with tagging |
| `burp_get_history` | Retrieve proxy history (filtered) |
| `burp_get_findings` | Get passive scanner findings |
| `burp_export_evidence` | Export request/response for evidence |
| `burp_scope_check` | Check if URL is in Burp scope |

**Exit Criteria**: All HTTP traffic flows through Burp, can retrieve history and export evidence.

---

### Phase 5: OpenAPI & Discovery
**Goal**: Parse OpenAPI specs and enumerate endpoints

**Tasks**:
- [ ] Create `mcp-servers/openapi-mcp/` project
- [ ] Implement OpenAPI 3.x parser
- [ ] Implement `openapi_ingest` tool (file or URL)
- [ ] Implement `openapi_list_endpoints` with filtering
- [ ] Implement `openapi_get_schema` for endpoint details
- [ ] Implement `openapi_generate_request` for sample requests
- [ ] Store discovered endpoints in world model (Phase 6 integration)
- [ ] Write unit tests with sample OpenAPI specs
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/openapi-mcp/
├── src/
│   ├── server.ts
│   ├── openapi-parser.ts
│   └── request-generator.ts
├── tests/
│   └── fixtures/            # Sample OpenAPI specs
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `openapi_ingest` | Load and parse OpenAPI spec |
| `openapi_list_endpoints` | List all endpoints with methods |
| `openapi_get_schema` | Get request/response schema for endpoint |
| `openapi_generate_request` | Generate sample request from schema |

**Exit Criteria**: Can parse OpenAPI specs and list/query endpoints.

---

### Phase 6: World Model
**Goal**: Structured state store for assets, hypotheses, and findings

**Tasks**:
- [ ] Create `mcp-servers/world-model-mcp/` project
- [ ] Set up SQLite database with schema
- [ ] Implement entity CRUD operations (asset, endpoint, identity, session, observation, hypothesis, action, finding)
- [ ] Implement `wm_add_*` tools for each entity type
- [ ] Implement `wm_update_*` tools
- [ ] Implement `wm_query` tool with filtering
- [ ] Add JSON Schema validation on write
- [ ] Write migration scripts for schema changes
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/world-model-mcp/
├── src/
│   ├── server.ts
│   ├── database.ts
│   ├── entities/
│   │   ├── asset.ts
│   │   ├── endpoint.ts
│   │   ├── hypothesis.ts
│   │   └── finding.ts
│   └── validators.ts
├── migrations/
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `wm_add_endpoint` | Register discovered endpoint |
| `wm_add_hypothesis` | Create new hypothesis |
| `wm_update_hypothesis` | Update hypothesis status/confidence |
| `wm_add_observation` | Record observation with evidence |
| `wm_add_finding` | Record validated finding |
| `wm_query` | Query world model with filters |

**Exit Criteria**: Can store and query all entity types with validation.

---

### Phase 7: Auth Testing
**Goal**: BOLA/IDOR and authorization differential testing

**Tasks**:
- [ ] Create `mcp-servers/auth-tester-mcp/` project
- [ ] Implement identity store loader
- [ ] Implement `auth_get_identities` tool
- [ ] Implement `auth_diff_test` tool (multi-identity replay)
- [ ] Implement `auth_replay_with_identity` tool
- [ ] Add result comparison logic (status codes, response bodies)
- [ ] Integrate with http-client-mcp for requests
- [ ] Integrate with world-model-mcp for storing results
- [ ] Write unit tests with mock identities
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/auth-tester-mcp/
├── src/
│   ├── server.ts
│   ├── identity-store.ts
│   ├── diff-tester.ts
│   └── response-comparator.ts
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `auth_get_identities` | List available test identities |
| `auth_diff_test` | Test same request with multiple identities |
| `auth_replay_with_identity` | Replay specific request with different identity |

**Exit Criteria**: Can detect BOLA/IDOR by comparing responses across identities.

---

### Phase 8: Validation Engine
**Goal**: Finding validation with reproduction and controls

**Tasks**:
- [ ] Create `mcp-servers/validator-mcp/` project
- [ ] Implement `validate_repro` tool (N reproduction attempts)
- [ ] Implement `validate_negative_control` tool
- [ ] Implement `validate_cross_identity` tool
- [ ] Implement `validate_promote` tool (draft → validated)
- [ ] Add confidence scoring logic
- [ ] Integrate with http-client-mcp for re-testing
- [ ] Integrate with world-model-mcp for status updates
- [ ] Write unit tests for validation logic
- [ ] Configure in `.gemini/settings.json`

**Deliverables**:
```
mcp-servers/validator-mcp/
├── src/
│   ├── server.ts
│   ├── repro-runner.ts
│   ├── control-runner.ts
│   └── confidence-scorer.ts
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `validate_repro` | Reproduce finding N times |
| `validate_negative_control` | Run negative control test |
| `validate_cross_identity` | Cross-identity validation |
| `validate_promote` | Promote to confirmed finding |

**Exit Criteria**: Findings require successful validation before being marked confirmed.

---

### Phase 9: Evidence & Reporting
**Goal**: Evidence bundling, redaction, and report generation

**Tasks**:
- [ ] Create `mcp-servers/evidence-mcp/` project
- [ ] Implement evidence directory structure
- [ ] Implement `evidence_bundle` tool
- [ ] Implement `evidence_add_artifact` tool
- [ ] Implement redaction logic for sensitive data
- [ ] Implement `evidence_export` tool (ZIP, JSON)
- [ ] Implement report generation (Markdown, HTML)
- [ ] Add encryption at rest option
- [ ] Write unit tests for redaction
- [ ] Configure in `.gemini/settings.json`
- [ ] Create reporting skill (`.gemini/skills/reporter/`)

**Deliverables**:
```
mcp-servers/evidence-mcp/
├── src/
│   ├── server.ts
│   ├── bundler.ts
│   ├── redactor.ts
│   └── exporter.ts
├── templates/
│   ├── report.md.hbs
│   └── report.html.hbs
├── tests/
└── package.json
```

**MCP Tools**:
| Tool | Description |
|------|-------------|
| `evidence_bundle` | Create evidence pack for finding |
| `evidence_add_artifact` | Add artifact to bundle |
| `evidence_export` | Export evidence pack |
| `evidence_generate_report` | Generate finding report |

**Exit Criteria**: Complete evidence packs with redaction and exportable reports.

---

### Phase 10: Advanced Tools
**Goal**: Extended scanning capabilities and automation

**Tasks**:
- [ ] Create `mcp-servers/nuclei-mcp/` (Nuclei scanner)
- [ ] Create `mcp-servers/fuzzer-mcp/` (Schema-based fuzzing)
- [ ] Create `mcp-servers/zap-mcp/` (OWASP ZAP integration) - optional
- [ ] Create pentest planner skill (`.gemini/skills/pentest-planner/`)
- [ ] Create vulnerability validator skill
- [ ] Create custom commands (`/scope`, `/engage`, `/killswitch`)
- [ ] Implement run manifest generation
- [ ] Implement action ledger logging
- [ ] End-to-end integration testing
- [ ] Documentation and runbooks

**Deliverables**:
```
mcp-servers/
├── nuclei-mcp/
├── fuzzer-mcp/
└── zap-mcp/                 # Optional

.gemini/
├── skills/
│   ├── pentest-planner/
│   └── vulnerability-validator/
└── commands/
    ├── scope.toml
    ├── engage.toml
    └── killswitch.toml
```

**MCP Tools** (nuclei-mcp):
| Tool | Description |
|------|-------------|
| `nuclei_scan_single` | Scan single URL with specific template |
| `nuclei_scan_template` | Run template against target list |
| `nuclei_list_templates` | List available templates |

**Exit Criteria**: Full autonomous pentest workflow with planner, execution, validation, and reporting.

---

### Phase Summary Timeline

```
Phase 1  ████░░░░░░░░░░░░░░░░  Foundation
Phase 2  ░░░░████░░░░░░░░░░░░  Scope Guard
Phase 3  ░░░░░░░░████░░░░░░░░  HTTP Client
Phase 4  ░░░░░░░░░░░░████░░░░  Burp Integration
Phase 5  ░░░░░░░░░░░░░░░░████  OpenAPI Discovery
Phase 6  ████████░░░░░░░░░░░░  World Model
Phase 7  ░░░░░░░░████████░░░░  Auth Testing
Phase 8  ░░░░░░░░░░░░░░░░████  Validation Engine
Phase 9  ████████████░░░░░░░░  Evidence & Reporting
Phase 10 ░░░░░░░░░░░░████████  Advanced Tools
         ─────────────────────
         Weeks 1-2  3-4  5-6  7-8  9-10
```

**Dependencies**:
- Phase 2 (Scope Guard) → Required by Phase 3, 4, 7
- Phase 3 (HTTP Client) → Required by Phase 4, 7, 8
- Phase 6 (World Model) → Required by Phase 7, 8, 9
- Phase 7 (Auth Testing) → Required by Phase 8
- Phase 8 (Validation) → Required by Phase 9

---

### Legacy Roadmap: Safety Guardrails Maturity

### Phase A (MVP safety) - Covered in Phases 1-5
- strict allowlists
- budgets and rate limits
- approval for medium/high risk
- basic validation rules
- audit trail + evidence packs

### Phase B (advanced safety) - Covered in Phases 6-9
- environment attestation (sandbox-only proof)
- request anomaly detection (stop on suspicious behavior)
- automatic control selection (negative controls by default)
- PII detection + redaction automation
- per-endpoint risk profiles and adaptive throttling

### Phase C (enterprise hardening) - Phase 10+
- policy-as-code (versioned approvals)
- signed scope files and run manifests
- tamper-evident audit logs
- reproducible run replay tooling

---

## 16.1) Phase 1: Foundation - Detailed Implementation

### Objective
Set up the development environment with Gemini-CLI as the base framework and establish the project structure for the pentest engine.

### Prerequisites
- Node.js 20+ installed
- npm or yarn package manager
- Git
- Gemini API key from Google AI Studio
- Text editor / IDE (VS Code recommended)

### Step-by-Step Implementation

#### Step 1.1: Clone Gemini-CLI

```bash
# Create project root directory
mkdir pentest-engine
cd pentest-engine

# Clone Gemini-CLI
git clone https://github.com/google-gemini/gemini-cli.git

# Enter the directory and install dependencies
cd gemini-cli
npm install

# Build all packages
npm run build

# Verify installation
npm run start -- --version
```

#### Step 1.2: Set Up API Key

```bash
# Option 1: Environment variable (recommended for development)
export GEMINI_API_KEY="your-api-key-here"

# Option 2: Add to shell profile for persistence
echo 'export GEMINI_API_KEY="your-api-key-here"' >> ~/.bashrc
source ~/.bashrc

# Option 3: Use .env file (create in project root)
echo 'GEMINI_API_KEY=your-api-key-here' > .env
```

#### Step 1.3: Create Project Directory Structure

```bash
# Return to project root
cd ..

# Create directory structure
mkdir -p .gemini/skills
mkdir -p .gemini/commands
mkdir -p mcp-servers
mkdir -p scope
mkdir -p evidence
mkdir -p logs
mkdir -p data

# Create initial configuration files
touch .gemini/settings.json
touch .gemini/config.yaml
touch scope/engagement.yaml
```

#### Step 1.4: Initialize Project Configuration

Create `.gemini/settings.json`:

```json
{
  "mcpServers": {
  },
  "coreTools": [
    "read_file",
    "write_file",
    "glob",
    "grep"
  ],
  "approvalMode": "INTERACTIVE"
}
```

Create `.gemini/config.yaml`:

```yaml
# Pentest Engine Configuration
project:
  name: "pentest-engine"
  version: "0.1.0"
  environment: "SANDBOX"

# Default settings
defaults:
  max_rps: 10
  max_concurrency: 5
  max_total_requests: 1000

# Logging
logging:
  level: "info"
  directory: "./logs"
```

#### Step 1.5: Create Scope File Template

Create `scope/engagement.yaml`:

```yaml
# Engagement Scope Definition
# This file MUST be validated before any testing begins

schema_version: "1.0.0"
engagement_id: "ENG-001"

# Targets that ARE allowed
allowlist:
  domains:
    - "testapp.local"
    - "api.testapp.local"
    - "*.sandbox.example.com"
  ip_ranges:
    - "192.168.1.0/24"
    - "10.0.0.0/8"
  services:
    - "web-api"
    - "auth-service"

# Targets that are NEVER allowed (takes precedence)
denylist:
  domains:
    - "production.example.com"
    - "*.prod.example.com"
  ip_ranges:
    - "0.0.0.0/0"  # Block all by default, allowlist overrides
  services:
    - "payment-service"

# Test identity aliases (actual credentials stored in secrets manager)
credentials:
  - "user_admin"
  - "user_regular"
  - "user_readonly"
  - "user_guest"

# Rate limits and budgets
constraints:
  max_rps: 10
  max_concurrency: 5
  max_total_requests: 1000
  max_object_enumeration: 50
  time_window:
    start: "2024-01-01T00:00:00Z"
    end: "2024-12-31T23:59:59Z"

# Actions that are forbidden
forbidden_actions:
  - "password_reset_abuse"
  - "account_lockout"
  - "data_exfiltration"
  - "dos_testing"

# What risk levels require human approval
approval_policy:
  risk_levels:
    low: false      # Auto-approve low risk
    medium: true    # Require approval for medium
    high: true      # Require approval for high

# Evidence storage rules
evidence_policy:
  store_raw_bodies: true
  redaction_rules:
    - "password"
    - "token"
    - "api_key"
    - "secret"
    - "credential"
  retention_days: 90

# Optional metadata
metadata:
  client: "Internal Security Team"
  tester: "AI Pentest Engine"
  created_at: "2024-01-01T00:00:00Z"
```

#### Step 1.6: Create Root package.json

Create `package.json` in project root:

```json
{
  "name": "pentest-engine",
  "version": "0.1.0",
  "description": "Human-in-the-Loop Autonomous Web/API Pentest Engine",
  "private": true,
  "workspaces": [
    "mcp-servers/*"
  ],
  "scripts": {
    "start": "cd gemini-cli && npm run start",
    "build": "npm run build --workspaces",
    "test": "npm run test --workspaces",
    "lint": "npm run lint --workspaces"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0"
  }
}
```

#### Step 1.7: Verify Installation

```bash
# Start Gemini CLI and verify it works
cd gemini-cli
npm run start

# In the CLI, test basic functionality:
# > Hello, can you confirm you're working?
# > What tools do you have available?

# Exit with Ctrl+C or type /exit
```

### Directory Structure After Phase 1

```
pentest-engine/
├── gemini-cli/                    # Cloned and built
│   ├── packages/
│   │   ├── cli/
│   │   └── core/
│   ├── node_modules/
│   └── package.json
├── .gemini/
│   ├── settings.json              # MCP server configs (empty for now)
│   ├── config.yaml                # Project config
│   ├── skills/                    # Empty, for future skills
│   └── commands/                  # Empty, for future commands
├── mcp-servers/                   # Empty, for MCP server projects
├── scope/
│   └── engagement.yaml            # Scope template
├── evidence/                      # Empty, for evidence storage
├── logs/                          # Empty, for audit logs
├── data/                          # Empty, for databases
├── package.json                   # Root package.json
└── .env                           # API key (gitignored)
```

### Verification Checklist

- [ ] Gemini-CLI cloned and built successfully
- [ ] `npm run start` launches the CLI without errors
- [ ] API key is configured and CLI can communicate with Gemini API
- [ ] Project directory structure created
- [ ] `.gemini/settings.json` exists with valid JSON
- [ ] `scope/engagement.yaml` exists with template content
- [ ] Root `package.json` created for workspace management

### Common Issues and Solutions

| Issue | Solution |
|-------|----------|
| `npm install` fails | Ensure Node.js 20+ is installed: `node --version` |
| API key not recognized | Check env var: `echo $GEMINI_API_KEY` |
| Build errors | Delete `node_modules` and run `npm install` again |
| Permission errors | Check file permissions: `chmod -R 755 .` |

---

## 16.2) Phase 2: Scope Guard MCP - Detailed Implementation

### Objective
Build the first and most critical MCP server that enforces scope boundaries. Every other tool will depend on this for target validation.

### Prerequisites
- Phase 1 completed
- Understanding of MCP protocol basics
- TypeScript knowledge

### Architecture

```
┌─────────────────────────────────────────────────────────┐
│                    Scope Guard MCP                       │
├─────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────┐ │
│  │ Scope Loader │  │ Validators  │  │ Budget Tracker  │ │
│  │ (YAML/JSON)  │  │ (Domain/IP) │  │ (Request Count) │ │
│  └──────┬──────┘  └──────┬──────┘  └────────┬────────┘ │
│         │                │                   │          │
│         └────────────────┼───────────────────┘          │
│                          │                              │
│                    MCP Server                           │
│         ┌────────────────┼────────────────┐             │
│         │                │                │             │
│    scope_validate   scope_get_*    scope_check_budget   │
└─────────────────────────────────────────────────────────┘
```

### Step-by-Step Implementation

#### Step 2.1: Create MCP Server Project

```bash
cd pentest-engine

# Create the scope-guard-mcp directory
mkdir -p mcp-servers/scope-guard-mcp/src
mkdir -p mcp-servers/scope-guard-mcp/tests

cd mcp-servers/scope-guard-mcp

# Initialize package.json
cat > package.json << 'EOF'
{
  "name": "scope-guard-mcp",
  "version": "1.0.0",
  "description": "Scope enforcement MCP server for pentest engine",
  "main": "dist/server.js",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node src/server.ts",
    "test": "vitest run",
    "test:watch": "vitest"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "js-yaml": "^4.1.0",
    "ajv": "^8.12.0",
    "ajv-formats": "^2.1.1",
    "ipaddr.js": "^2.1.0"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0",
    "@types/js-yaml": "^4.0.9",
    "vitest": "^1.0.0",
    "ts-node": "^10.9.0"
  }
}
EOF

# Create tsconfig.json
cat > tsconfig.json << 'EOF'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "declaration": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "tests"]
}
EOF

# Install dependencies
npm install
```

#### Step 2.2: Create Scope Schema Validator

Create `src/schemas/scope-schema.ts`:

```typescript
// JSON Schema for scope file validation
export const scopeSchema = {
  $schema: "https://json-schema.org/draft/2020-12/schema",
  type: "object",
  required: [
    "schema_version",
    "engagement_id",
    "allowlist",
    "constraints",
    "approval_policy",
    "evidence_policy"
  ],
  additionalProperties: true,
  properties: {
    schema_version: {
      type: "string",
      pattern: "^[0-9]+\\.[0-9]+\\.[0-9]+$"
    },
    engagement_id: {
      type: "string",
      minLength: 1
    },
    allowlist: {
      type: "object",
      required: ["domains", "ip_ranges"],
      properties: {
        domains: {
          type: "array",
          items: { type: "string", minLength: 1 }
        },
        ip_ranges: {
          type: "array",
          items: { type: "string" }
        },
        services: {
          type: "array",
          items: { type: "string" }
        }
      }
    },
    denylist: {
      type: "object",
      properties: {
        domains: { type: "array", items: { type: "string" } },
        ip_ranges: { type: "array", items: { type: "string" } },
        services: { type: "array", items: { type: "string" } }
      }
    },
    credentials: {
      type: "array",
      items: { type: "string" }
    },
    constraints: {
      type: "object",
      required: ["max_rps", "max_concurrency", "max_total_requests", "max_object_enumeration"],
      properties: {
        max_rps: { type: "integer", minimum: 1 },
        max_concurrency: { type: "integer", minimum: 1 },
        max_total_requests: { type: "integer", minimum: 1 },
        max_object_enumeration: { type: "integer", minimum: 1 },
        time_window: {
          type: "object",
          properties: {
            start: { type: "string", format: "date-time" },
            end: { type: "string", format: "date-time" }
          }
        }
      }
    },
    forbidden_actions: {
      type: "array",
      items: { type: "string" }
    },
    approval_policy: {
      type: "object",
      required: ["risk_levels"],
      properties: {
        risk_levels: {
          type: "object",
          properties: {
            low: { type: "boolean" },
            medium: { type: "boolean" },
            high: { type: "boolean" }
          }
        }
      }
    },
    evidence_policy: {
      type: "object",
      required: ["store_raw_bodies", "redaction_rules"],
      properties: {
        store_raw_bodies: { type: "boolean" },
        redaction_rules: {
          type: "array",
          items: { type: "string" }
        },
        retention_days: { type: "integer", minimum: 1 }
      }
    },
    metadata: {
      type: "object",
      additionalProperties: true
    }
  }
};
```

#### Step 2.3: Create Scope Loader

Create `src/scope-loader.ts`:

```typescript
import * as fs from 'fs';
import * as yaml from 'js-yaml';
import Ajv from 'ajv';
import addFormats from 'ajv-formats';
import { scopeSchema } from './schemas/scope-schema.js';

export interface ScopeAllowlist {
  domains: string[];
  ip_ranges: string[];
  services?: string[];
}

export interface ScopeConstraints {
  max_rps: number;
  max_concurrency: number;
  max_total_requests: number;
  max_object_enumeration: number;
  time_window?: {
    start: string;
    end: string;
  };
}

export interface ScopeConfig {
  schema_version: string;
  engagement_id: string;
  allowlist: ScopeAllowlist;
  denylist?: ScopeAllowlist;
  credentials?: string[];
  constraints: ScopeConstraints;
  forbidden_actions?: string[];
  approval_policy: {
    risk_levels: {
      low?: boolean;
      medium: boolean;
      high: boolean;
    };
  };
  evidence_policy: {
    store_raw_bodies: boolean;
    redaction_rules: string[];
    retention_days?: number;
  };
  metadata?: Record<string, unknown>;
}

export class ScopeLoader {
  private ajv: Ajv;
  private scope: ScopeConfig | null = null;
  private scopeFilePath: string;

  constructor(scopeFilePath: string) {
    this.scopeFilePath = scopeFilePath;
    this.ajv = new Ajv({ allErrors: true, strict: false });
    addFormats(this.ajv);
  }

  load(): ScopeConfig {
    // Read file
    if (!fs.existsSync(this.scopeFilePath)) {
      throw new Error(`Scope file not found: ${this.scopeFilePath}`);
    }

    const fileContent = fs.readFileSync(this.scopeFilePath, 'utf-8');

    // Parse YAML or JSON
    let rawScope: unknown;
    if (this.scopeFilePath.endsWith('.yaml') || this.scopeFilePath.endsWith('.yml')) {
      rawScope = yaml.load(fileContent);
    } else {
      rawScope = JSON.parse(fileContent);
    }

    // Validate against schema
    const validate = this.ajv.compile(scopeSchema);
    const valid = validate(rawScope);

    if (!valid) {
      const errors = validate.errors?.map(e => `${e.instancePath} ${e.message}`).join('; ');
      throw new Error(`Scope validation failed: ${errors}`);
    }

    this.scope = rawScope as ScopeConfig;

    // Normalize domains (lowercase)
    this.scope.allowlist.domains = this.scope.allowlist.domains.map(d => d.toLowerCase());
    if (this.scope.denylist?.domains) {
      this.scope.denylist.domains = this.scope.denylist.domains.map(d => d.toLowerCase());
    }

    console.error(`[scope-guard] Loaded scope: ${this.scope.engagement_id}`);
    console.error(`[scope-guard] Allowed domains: ${this.scope.allowlist.domains.join(', ')}`);

    return this.scope;
  }

  getScope(): ScopeConfig {
    if (!this.scope) {
      throw new Error('Scope not loaded. Call load() first.');
    }
    return this.scope;
  }
}
```

#### Step 2.4: Create Target Validators

Create `src/validators.ts`:

```typescript
import * as ipaddr from 'ipaddr.js';
import { ScopeConfig } from './scope-loader.js';

export interface ValidationResult {
  valid: boolean;
  reason: string;
  details?: Record<string, unknown>;
}

export class TargetValidator {
  private scope: ScopeConfig;

  constructor(scope: ScopeConfig) {
    this.scope = scope;
  }

  /**
   * Validate a URL or IP against the scope
   */
  validateTarget(target: string): ValidationResult {
    try {
      // Try to parse as URL
      let hostname: string;
      let targetType: 'url' | 'ip' | 'domain';

      try {
        const url = new URL(target);
        hostname = url.hostname.toLowerCase();
        targetType = 'url';
      } catch {
        // Not a URL, treat as domain or IP
        hostname = target.toLowerCase();
        targetType = this.isIP(hostname) ? 'ip' : 'domain';
      }

      // Check denylist first (takes precedence)
      if (this.scope.denylist) {
        const denyResult = this.checkDenylist(hostname, targetType);
        if (denyResult.denied) {
          return {
            valid: false,
            reason: `Target is in denylist: ${denyResult.reason}`,
            details: { hostname, targetType, denyReason: denyResult.reason }
          };
        }
      }

      // Check allowlist
      const allowResult = this.checkAllowlist(hostname, targetType);
      if (!allowResult.allowed) {
        return {
          valid: false,
          reason: `Target not in allowlist: ${allowResult.reason}`,
          details: { hostname, targetType }
        };
      }

      return {
        valid: true,
        reason: `Target is in scope: ${allowResult.reason}`,
        details: { hostname, targetType, matchedRule: allowResult.matchedRule }
      };

    } catch (error) {
      return {
        valid: false,
        reason: `Validation error: ${error instanceof Error ? error.message : 'Unknown error'}`,
        details: { target }
      };
    }
  }

  private isIP(value: string): boolean {
    try {
      ipaddr.parse(value);
      return true;
    } catch {
      return false;
    }
  }

  private checkDenylist(hostname: string, targetType: string): { denied: boolean; reason: string } {
    const denylist = this.scope.denylist;
    if (!denylist) {
      return { denied: false, reason: '' };
    }

    // Check domain denylist
    if (targetType !== 'ip' && denylist.domains) {
      for (const pattern of denylist.domains) {
        if (this.matchesDomainPattern(hostname, pattern)) {
          return { denied: true, reason: `Matches denied domain pattern: ${pattern}` };
        }
      }
    }

    // Check IP denylist
    if (targetType === 'ip' && denylist.ip_ranges) {
      for (const range of denylist.ip_ranges) {
        if (this.ipInRange(hostname, range)) {
          return { denied: true, reason: `IP in denied range: ${range}` };
        }
      }
    }

    return { denied: false, reason: '' };
  }

  private checkAllowlist(hostname: string, targetType: string): { allowed: boolean; reason: string; matchedRule?: string } {
    const allowlist = this.scope.allowlist;

    // Check domain allowlist
    if (targetType !== 'ip') {
      for (const pattern of allowlist.domains) {
        if (this.matchesDomainPattern(hostname, pattern)) {
          return { allowed: true, reason: 'Domain in allowlist', matchedRule: pattern };
        }
      }
    }

    // Check IP allowlist
    if (targetType === 'ip') {
      for (const range of allowlist.ip_ranges) {
        if (this.ipInRange(hostname, range)) {
          return { allowed: true, reason: 'IP in allowed range', matchedRule: range };
        }
      }
    }

    // If it's a hostname, try to resolve and check IP
    // (In production, you'd do actual DNS resolution here)

    return { allowed: false, reason: 'No matching allowlist rule' };
  }

  /**
   * Match domain against pattern (supports wildcards like *.example.com)
   */
  private matchesDomainPattern(hostname: string, pattern: string): boolean {
    const lowerPattern = pattern.toLowerCase();

    // Exact match
    if (hostname === lowerPattern) {
      return true;
    }

    // Wildcard match (*.example.com)
    if (lowerPattern.startsWith('*.')) {
      const suffix = lowerPattern.slice(1); // .example.com
      return hostname.endsWith(suffix) || hostname === lowerPattern.slice(2);
    }

    // Subdomain match (allow subdomains of allowed domain)
    if (hostname.endsWith('.' + lowerPattern)) {
      return true;
    }

    return false;
  }

  /**
   * Check if IP is in CIDR range
   */
  private ipInRange(ip: string, cidr: string): boolean {
    try {
      const parsedIP = ipaddr.parse(ip);
      const [rangeIP, prefixLength] = ipaddr.parseCIDR(cidr);

      // Handle IPv4-mapped IPv6 addresses
      if (parsedIP.kind() !== rangeIP.kind()) {
        return false;
      }

      return parsedIP.match(rangeIP, parseInt(prefixLength.toString()));
    } catch {
      return false;
    }
  }
}
```

#### Step 2.5: Create Budget Tracker

Create `src/budget-tracker.ts`:

```typescript
import { ScopeConstraints } from './scope-loader.js';

export interface BudgetStatus {
  total_requests: number;
  remaining_requests: number;
  requests_this_second: number;
  max_rps: number;
  max_total: number;
  budget_exhausted: boolean;
  rate_limited: boolean;
}

export class BudgetTracker {
  private constraints: ScopeConstraints;
  private totalRequests: number = 0;
  private requestTimestamps: number[] = [];
  private identityBudgets: Map<string, number> = new Map();

  constructor(constraints: ScopeConstraints) {
    this.constraints = constraints;
  }

  /**
   * Record a request and check if within budget
   */
  recordRequest(identityId?: string): { allowed: boolean; reason: string } {
    const now = Date.now();

    // Check total budget
    if (this.totalRequests >= this.constraints.max_total_requests) {
      return {
        allowed: false,
        reason: `Total request budget exhausted (${this.totalRequests}/${this.constraints.max_total_requests})`
      };
    }

    // Check rate limit (requests per second)
    const oneSecondAgo = now - 1000;
    this.requestTimestamps = this.requestTimestamps.filter(t => t > oneSecondAgo);

    if (this.requestTimestamps.length >= this.constraints.max_rps) {
      return {
        allowed: false,
        reason: `Rate limit exceeded (${this.requestTimestamps.length}/${this.constraints.max_rps} rps)`
      };
    }

    // Check time window if specified
    if (this.constraints.time_window) {
      const windowStart = new Date(this.constraints.time_window.start).getTime();
      const windowEnd = new Date(this.constraints.time_window.end).getTime();

      if (now < windowStart || now > windowEnd) {
        return {
          allowed: false,
          reason: `Outside allowed time window (${this.constraints.time_window.start} - ${this.constraints.time_window.end})`
        };
      }
    }

    // Record the request
    this.totalRequests++;
    this.requestTimestamps.push(now);

    if (identityId) {
      const current = this.identityBudgets.get(identityId) || 0;
      this.identityBudgets.set(identityId, current + 1);
    }

    return { allowed: true, reason: 'Within budget' };
  }

  /**
   * Get current budget status
   */
  getStatus(identityId?: string): BudgetStatus {
    const now = Date.now();
    const oneSecondAgo = now - 1000;
    const recentRequests = this.requestTimestamps.filter(t => t > oneSecondAgo);

    return {
      total_requests: this.totalRequests,
      remaining_requests: Math.max(0, this.constraints.max_total_requests - this.totalRequests),
      requests_this_second: recentRequests.length,
      max_rps: this.constraints.max_rps,
      max_total: this.constraints.max_total_requests,
      budget_exhausted: this.totalRequests >= this.constraints.max_total_requests,
      rate_limited: recentRequests.length >= this.constraints.max_rps
    };
  }

  /**
   * Reset budget (for new engagement)
   */
  reset(): void {
    this.totalRequests = 0;
    this.requestTimestamps = [];
    this.identityBudgets.clear();
  }
}
```

#### Step 2.6: Create Main MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { ScopeLoader, ScopeConfig } from './scope-loader.js';
import { TargetValidator, ValidationResult } from './validators.js';
import { BudgetTracker, BudgetStatus } from './budget-tracker.js';

// Configuration from environment
const SCOPE_FILE = process.env.SCOPE_FILE || './scope/engagement.yaml';
const FAIL_CLOSED = process.env.FAIL_CLOSED !== 'false';

// Initialize components
let scopeConfig: ScopeConfig;
let validator: TargetValidator;
let budgetTracker: BudgetTracker;

try {
  const loader = new ScopeLoader(SCOPE_FILE);
  scopeConfig = loader.load();
  validator = new TargetValidator(scopeConfig);
  budgetTracker = new BudgetTracker(scopeConfig.constraints);
  console.error('[scope-guard] Initialization successful');
} catch (error) {
  console.error('[scope-guard] FATAL: Failed to initialize:', error);
  if (FAIL_CLOSED) {
    process.exit(1);
  }
}

// Create MCP Server
const server = new McpServer({
  name: 'scope-guard',
  version: '1.0.0',
});

// Tool: Validate a target URL or IP
server.tool(
  'scope_validate_target',
  'Check if a URL, domain, or IP address is within the engagement scope. Returns validation result with details.',
  {
    type: 'object',
    properties: {
      target: {
        type: 'string',
        description: 'URL, domain, or IP address to validate'
      }
    },
    required: ['target']
  },
  async ({ target }: { target: string }) => {
    if (!validator) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            valid: false,
            reason: 'Scope guard not initialized',
            fail_closed: true
          })
        }]
      };
    }

    const result: ValidationResult = validator.validateTarget(target);

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          target,
          in_scope: result.valid,
          reason: result.reason,
          details: result.details,
          engagement_id: scopeConfig.engagement_id
        }, null, 2)
      }]
    };
  }
);

// Tool: Get the current allowlist
server.tool(
  'scope_get_allowlist',
  'Retrieve the current engagement allowlist including allowed domains, IP ranges, and services.',
  {
    type: 'object',
    properties: {}
  },
  async () => {
    if (!scopeConfig) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'Scope not loaded' })
        }]
      };
    }

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          engagement_id: scopeConfig.engagement_id,
          allowlist: scopeConfig.allowlist,
          denylist: scopeConfig.denylist || { domains: [], ip_ranges: [] }
        }, null, 2)
      }]
    };
  }
);

// Tool: Get constraints (rate limits, budgets)
server.tool(
  'scope_get_constraints',
  'Retrieve the current rate limits, budget constraints, and approval policies.',
  {
    type: 'object',
    properties: {}
  },
  async () => {
    if (!scopeConfig) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'Scope not loaded' })
        }]
      };
    }

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          engagement_id: scopeConfig.engagement_id,
          constraints: scopeConfig.constraints,
          approval_policy: scopeConfig.approval_policy,
          forbidden_actions: scopeConfig.forbidden_actions || []
        }, null, 2)
      }]
    };
  }
);

// Tool: Check current budget status
server.tool(
  'scope_check_budget',
  'Check the current request budget status including remaining requests and rate limit status.',
  {
    type: 'object',
    properties: {
      identity_id: {
        type: 'string',
        description: 'Optional identity ID to check identity-specific budget'
      }
    }
  },
  async ({ identity_id }: { identity_id?: string }) => {
    if (!budgetTracker) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'Budget tracker not initialized' })
        }]
      };
    }

    const status: BudgetStatus = budgetTracker.getStatus(identity_id);

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          engagement_id: scopeConfig?.engagement_id,
          budget_status: status,
          identity_id: identity_id || null
        }, null, 2)
      }]
    };
  }
);

// Tool: Record a request (for budget tracking)
server.tool(
  'scope_record_request',
  'Record a request for budget tracking. Returns whether the request is allowed under current limits.',
  {
    type: 'object',
    properties: {
      identity_id: {
        type: 'string',
        description: 'Optional identity ID making the request'
      }
    }
  },
  async ({ identity_id }: { identity_id?: string }) => {
    if (!budgetTracker) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            allowed: false,
            reason: 'Budget tracker not initialized'
          })
        }]
      };
    }

    const result = budgetTracker.recordRequest(identity_id);

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          ...result,
          current_status: budgetTracker.getStatus(identity_id)
        }, null, 2)
      }]
    };
  }
);

// Tool: Get available test identities
server.tool(
  'scope_get_identities',
  'Get the list of available test identity aliases for the engagement.',
  {
    type: 'object',
    properties: {}
  },
  async () => {
    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          engagement_id: scopeConfig?.engagement_id,
          identities: scopeConfig?.credentials || []
        }, null, 2)
      }]
    };
  }
);

// Start the server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[scope-guard] MCP server started');
}

main().catch((error) => {
  console.error('[scope-guard] Fatal error:', error);
  process.exit(1);
});
```

#### Step 2.7: Create Unit Tests

Create `tests/validators.test.ts`:

```typescript
import { describe, it, expect, beforeEach } from 'vitest';
import { TargetValidator } from '../src/validators.js';
import { ScopeConfig } from '../src/scope-loader.js';

const mockScope: ScopeConfig = {
  schema_version: '1.0.0',
  engagement_id: 'TEST-001',
  allowlist: {
    domains: ['testapp.local', '*.sandbox.example.com', 'api.example.com'],
    ip_ranges: ['192.168.1.0/24', '10.0.0.0/8']
  },
  denylist: {
    domains: ['production.example.com', '*.prod.example.com'],
    ip_ranges: ['192.168.1.1/32']
  },
  constraints: {
    max_rps: 10,
    max_concurrency: 5,
    max_total_requests: 1000,
    max_object_enumeration: 50
  },
  approval_policy: {
    risk_levels: { low: false, medium: true, high: true }
  },
  evidence_policy: {
    store_raw_bodies: true,
    redaction_rules: ['password', 'token']
  }
};

describe('TargetValidator', () => {
  let validator: TargetValidator;

  beforeEach(() => {
    validator = new TargetValidator(mockScope);
  });

  describe('Domain validation', () => {
    it('should allow exact domain match', () => {
      const result = validator.validateTarget('https://testapp.local/api/users');
      expect(result.valid).toBe(true);
    });

    it('should allow wildcard domain match', () => {
      const result = validator.validateTarget('https://app.sandbox.example.com/test');
      expect(result.valid).toBe(true);
    });

    it('should allow subdomain of allowed domain', () => {
      const result = validator.validateTarget('https://v2.api.example.com/endpoint');
      expect(result.valid).toBe(true);
    });

    it('should deny domain not in allowlist', () => {
      const result = validator.validateTarget('https://malicious.com/hack');
      expect(result.valid).toBe(false);
    });

    it('should deny domain in denylist even if matches allowlist pattern', () => {
      const result = validator.validateTarget('https://production.example.com/api');
      expect(result.valid).toBe(false);
    });

    it('should deny wildcard denylist match', () => {
      const result = validator.validateTarget('https://api.prod.example.com/secret');
      expect(result.valid).toBe(false);
    });
  });

  describe('IP validation', () => {
    it('should allow IP in allowed range', () => {
      const result = validator.validateTarget('192.168.1.100');
      expect(result.valid).toBe(true);
    });

    it('should allow IP in large CIDR range', () => {
      const result = validator.validateTarget('10.255.255.255');
      expect(result.valid).toBe(true);
    });

    it('should deny IP not in any allowed range', () => {
      const result = validator.validateTarget('8.8.8.8');
      expect(result.valid).toBe(false);
    });

    it('should deny IP in denylist even if in allowlist range', () => {
      const result = validator.validateTarget('192.168.1.1');
      expect(result.valid).toBe(false);
    });
  });

  describe('URL parsing', () => {
    it('should handle URLs with ports', () => {
      const result = validator.validateTarget('https://testapp.local:8443/api');
      expect(result.valid).toBe(true);
    });

    it('should handle URLs with paths and query strings', () => {
      const result = validator.validateTarget('https://testapp.local/api/users?id=123&token=abc');
      expect(result.valid).toBe(true);
    });

    it('should be case-insensitive for domains', () => {
      const result = validator.validateTarget('https://TESTAPP.LOCAL/API');
      expect(result.valid).toBe(true);
    });
  });
});
```

#### Step 2.8: Build and Test

```bash
cd mcp-servers/scope-guard-mcp

# Build
npm run build

# Run tests
npm test

# Test manually with a simple script
node -e "
const { spawn } = require('child_process');
const server = spawn('node', ['dist/server.js'], {
  env: { ...process.env, SCOPE_FILE: '../../scope/engagement.yaml' }
});
server.stderr.on('data', d => console.log(d.toString()));
setTimeout(() => server.kill(), 2000);
"
```

#### Step 2.9: Configure in Gemini-CLI

Update `.gemini/settings.json`:

```json
{
  "mcpServers": {
    "scope-guard": {
      "command": "node",
      "args": ["mcp-servers/scope-guard-mcp/dist/server.js"],
      "env": {
        "SCOPE_FILE": "./scope/engagement.yaml",
        "FAIL_CLOSED": "true"
      },
      "timeout": 5000,
      "trust": true,
      "description": "Scope enforcement - validates all targets against allowlist"
    }
  },
  "approvalMode": "INTERACTIVE"
}
```

### Directory Structure After Phase 2

```
mcp-servers/scope-guard-mcp/
├── src/
│   ├── server.ts              # Main MCP server
│   ├── scope-loader.ts        # YAML/JSON loader + validation
│   ├── validators.ts          # Domain/IP validation logic
│   ├── budget-tracker.ts      # Request budget tracking
│   └── schemas/
│       └── scope-schema.ts    # JSON Schema definition
├── tests/
│   └── validators.test.ts     # Unit tests
├── dist/                      # Compiled output
├── package.json
└── tsconfig.json
```

### Verification Checklist

- [ ] `npm run build` completes without errors
- [ ] `npm test` passes all tests
- [ ] MCP server starts and loads scope file
- [ ] `scope_validate_target` correctly allows/denies targets
- [ ] `scope_get_allowlist` returns current allowlist
- [ ] `scope_check_budget` returns budget status
- [ ] Gemini-CLI can discover and use scope-guard tools
- [ ] Denylist takes precedence over allowlist

---

## 16.3) Phase 3: HTTP Client MCP - Detailed Implementation

### Objective
Build a safe, rate-limited HTTP client that enforces scope boundaries and integrates with Burp proxy for evidence capture.

### Prerequisites
- Phase 1 and Phase 2 completed
- scope-guard-mcp working
- Understanding of HTTP/HTTPS requests

### Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    HTTP Client MCP                           │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │ Rate Limiter │  │ Scope Check │  │ Correlation Headers │  │
│  │ (Token Bucket)│  │ (via MCP)   │  │ (X-Engagement-ID)   │  │
│  └──────┬──────┘  └──────┬──────┘  └──────────┬──────────┘  │
│         │                │                     │             │
│         └────────────────┼─────────────────────┘             │
│                          │                                   │
│                    ┌─────▼─────┐                             │
│                    │  Fetch    │                             │
│                    │  (Proxy)  │                             │
│                    └─────┬─────┘                             │
│                          │                                   │
└──────────────────────────┼───────────────────────────────────┘
                           │
                           ▼
                    ┌─────────────┐
                    │ Burp Proxy  │
                    │ (Optional)  │
                    └─────────────┘
```

### Step-by-Step Implementation

#### Step 3.1: Create MCP Server Project

```bash
cd pentest-engine

mkdir -p mcp-servers/http-client-mcp/src
mkdir -p mcp-servers/http-client-mcp/tests

cd mcp-servers/http-client-mcp

cat > package.json << 'EOF'
{
  "name": "http-client-mcp",
  "version": "1.0.0",
  "description": "Rate-limited HTTP client MCP server with scope enforcement",
  "main": "dist/server.js",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node src/server.ts",
    "test": "vitest run"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "undici": "^6.0.0",
    "https-proxy-agent": "^7.0.0",
    "uuid": "^9.0.0"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0",
    "@types/uuid": "^9.0.0",
    "vitest": "^1.0.0"
  }
}
EOF

cat > tsconfig.json << 'EOF'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "declaration": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "tests"]
}
EOF

npm install
```

#### Step 3.2: Create Rate Limiter

Create `src/rate-limiter.ts`:

```typescript
/**
 * Token Bucket Rate Limiter
 * Allows bursts up to bucket size, refills at constant rate
 */
export class RateLimiter {
  private tokens: number;
  private maxTokens: number;
  private refillRate: number; // tokens per second
  private lastRefill: number;

  constructor(maxRps: number) {
    this.maxTokens = maxRps;
    this.tokens = maxRps;
    this.refillRate = maxRps;
    this.lastRefill = Date.now();
  }

  /**
   * Try to acquire a token for making a request
   * Returns wait time in ms if rate limited, 0 if allowed
   */
  tryAcquire(): { allowed: boolean; waitMs: number } {
    this.refill();

    if (this.tokens >= 1) {
      this.tokens -= 1;
      return { allowed: true, waitMs: 0 };
    }

    // Calculate wait time until next token
    const waitMs = Math.ceil((1 - this.tokens) / this.refillRate * 1000);
    return { allowed: false, waitMs };
  }

  /**
   * Wait for a token to become available
   */
  async waitForToken(): Promise<void> {
    const { allowed, waitMs } = this.tryAcquire();
    if (!allowed) {
      await new Promise(resolve => setTimeout(resolve, waitMs));
      await this.waitForToken(); // Retry after wait
    }
  }

  private refill(): void {
    const now = Date.now();
    const elapsed = (now - this.lastRefill) / 1000;
    this.tokens = Math.min(this.maxTokens, this.tokens + elapsed * this.refillRate);
    this.lastRefill = now;
  }

  getStatus(): { tokens: number; maxTokens: number } {
    this.refill();
    return { tokens: Math.floor(this.tokens), maxTokens: this.maxTokens };
  }
}

/**
 * Concurrency Limiter
 * Limits number of concurrent in-flight requests
 */
export class ConcurrencyLimiter {
  private current: number = 0;
  private max: number;
  private queue: Array<() => void> = [];

  constructor(maxConcurrent: number) {
    this.max = maxConcurrent;
  }

  async acquire(): Promise<void> {
    if (this.current < this.max) {
      this.current++;
      return;
    }

    // Wait in queue
    return new Promise(resolve => {
      this.queue.push(() => {
        this.current++;
        resolve();
      });
    });
  }

  release(): void {
    this.current--;
    const next = this.queue.shift();
    if (next) {
      next();
    }
  }

  getStatus(): { current: number; max: number; queued: number } {
    return { current: this.current, max: this.max, queued: this.queue.length };
  }
}
```

#### Step 3.3: Create HTTP Client

Create `src/http-client.ts`:

```typescript
import { v4 as uuidv4 } from 'uuid';
import { RateLimiter, ConcurrencyLimiter } from './rate-limiter.js';

export interface HttpRequest {
  method: string;
  url: string;
  headers?: Record<string, string>;
  body?: string;
  timeout?: number;
}

export interface HttpResponse {
  status: number;
  statusText: string;
  headers: Record<string, string>;
  body: string;
  timing: {
    start: number;
    end: number;
    duration: number;
  };
}

export interface RequestResult {
  success: boolean;
  request_id: string;
  correlation_ids: {
    engagement_id: string;
    action_id: string;
    identity_id?: string;
  };
  request: {
    method: string;
    url: string;
    headers: Record<string, string>;
  };
  response?: HttpResponse;
  error?: string;
}

export interface HttpClientConfig {
  proxyUrl?: string;
  engagementId: string;
  maxRps: number;
  maxConcurrent: number;
  defaultTimeout: number;
}

export class HttpClient {
  private config: HttpClientConfig;
  private rateLimiter: RateLimiter;
  private concurrencyLimiter: ConcurrencyLimiter;
  private totalRequests: number = 0;
  private maxTotalRequests: number;

  constructor(config: HttpClientConfig, maxTotalRequests: number) {
    this.config = config;
    this.maxTotalRequests = maxTotalRequests;
    this.rateLimiter = new RateLimiter(config.maxRps);
    this.concurrencyLimiter = new ConcurrencyLimiter(config.maxConcurrent);
  }

  async send(
    request: HttpRequest,
    identityId?: string,
    actionId?: string
  ): Promise<RequestResult> {
    const requestId = uuidv4();
    const actualActionId = actionId || uuidv4();

    // Check total budget
    if (this.totalRequests >= this.maxTotalRequests) {
      return {
        success: false,
        request_id: requestId,
        correlation_ids: {
          engagement_id: this.config.engagementId,
          action_id: actualActionId,
          identity_id: identityId
        },
        request: {
          method: request.method,
          url: request.url,
          headers: request.headers || {}
        },
        error: `Total request budget exhausted (${this.totalRequests}/${this.maxTotalRequests})`
      };
    }

    // Wait for rate limit
    await this.rateLimiter.waitForToken();

    // Wait for concurrency slot
    await this.concurrencyLimiter.acquire();

    const correlationHeaders: Record<string, string> = {
      'X-Engagement-ID': this.config.engagementId,
      'X-Action-ID': actualActionId,
      'X-Request-ID': requestId,
    };

    if (identityId) {
      correlationHeaders['X-Identity-ID'] = identityId;
    }

    const finalHeaders = {
      ...request.headers,
      ...correlationHeaders
    };

    try {
      const startTime = Date.now();

      // Build fetch options
      const fetchOptions: RequestInit = {
        method: request.method,
        headers: finalHeaders,
        signal: AbortSignal.timeout(request.timeout || this.config.defaultTimeout),
      };

      if (request.body && ['POST', 'PUT', 'PATCH'].includes(request.method.toUpperCase())) {
        fetchOptions.body = request.body;
      }

      // Use proxy if configured
      let fetchUrl = request.url;
      if (this.config.proxyUrl) {
        // For Node.js, we'd use a proxy agent here
        // This is simplified - in production use https-proxy-agent
        process.env.HTTP_PROXY = this.config.proxyUrl;
        process.env.HTTPS_PROXY = this.config.proxyUrl;
      }

      const response = await fetch(fetchUrl, fetchOptions);
      const endTime = Date.now();

      // Read response body
      const responseBody = await response.text();

      // Convert headers to object
      const responseHeaders: Record<string, string> = {};
      response.headers.forEach((value, key) => {
        responseHeaders[key] = value;
      });

      this.totalRequests++;

      return {
        success: true,
        request_id: requestId,
        correlation_ids: {
          engagement_id: this.config.engagementId,
          action_id: actualActionId,
          identity_id: identityId
        },
        request: {
          method: request.method,
          url: request.url,
          headers: finalHeaders
        },
        response: {
          status: response.status,
          statusText: response.statusText,
          headers: responseHeaders,
          body: responseBody,
          timing: {
            start: startTime,
            end: endTime,
            duration: endTime - startTime
          }
        }
      };

    } catch (error) {
      this.totalRequests++;

      return {
        success: false,
        request_id: requestId,
        correlation_ids: {
          engagement_id: this.config.engagementId,
          action_id: actualActionId,
          identity_id: identityId
        },
        request: {
          method: request.method,
          url: request.url,
          headers: finalHeaders
        },
        error: error instanceof Error ? error.message : 'Unknown error'
      };

    } finally {
      this.concurrencyLimiter.release();
    }
  }

  getStats(): {
    totalRequests: number;
    remainingRequests: number;
    rateLimiter: { tokens: number; maxTokens: number };
    concurrency: { current: number; max: number; queued: number };
  } {
    return {
      totalRequests: this.totalRequests,
      remainingRequests: this.maxTotalRequests - this.totalRequests,
      rateLimiter: this.rateLimiter.getStatus(),
      concurrency: this.concurrencyLimiter.getStatus()
    };
  }
}
```

#### Step 3.4: Create Main MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { HttpClient, HttpRequest, RequestResult } from './http-client.js';

// Configuration from environment
const PROXY_URL = process.env.PROXY_URL || '';
const MAX_RPS = parseInt(process.env.MAX_RPS || '10');
const MAX_CONCURRENT = parseInt(process.env.MAX_CONCURRENT || '5');
const MAX_TOTAL_REQUESTS = parseInt(process.env.MAX_TOTAL_REQUESTS || '1000');
const DEFAULT_TIMEOUT = parseInt(process.env.DEFAULT_TIMEOUT || '30000');
const ENGAGEMENT_ID = process.env.ENGAGEMENT_ID || 'UNKNOWN';
const SCOPE_GUARD_ENABLED = process.env.SCOPE_GUARD_ENABLED !== 'false';

// Initialize HTTP client
const httpClient = new HttpClient({
  proxyUrl: PROXY_URL || undefined,
  engagementId: ENGAGEMENT_ID,
  maxRps: MAX_RPS,
  maxConcurrent: MAX_CONCURRENT,
  defaultTimeout: DEFAULT_TIMEOUT
}, MAX_TOTAL_REQUESTS);

console.error(`[http-client] Initialized with max_rps=${MAX_RPS}, max_concurrent=${MAX_CONCURRENT}, max_total=${MAX_TOTAL_REQUESTS}`);
if (PROXY_URL) {
  console.error(`[http-client] Proxy configured: ${PROXY_URL}`);
}

// Create MCP Server
const server = new McpServer({
  name: 'http-client',
  version: '1.0.0',
});

// Tool: Send a single HTTP request
server.tool(
  'http_send',
  'Send an HTTP request with rate limiting and scope enforcement. All requests are logged with correlation IDs.',
  {
    type: 'object',
    properties: {
      method: {
        type: 'string',
        description: 'HTTP method (GET, POST, PUT, DELETE, PATCH, etc.)',
        enum: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'HEAD', 'OPTIONS']
      },
      url: {
        type: 'string',
        description: 'Full URL to send the request to'
      },
      headers: {
        type: 'object',
        description: 'Optional HTTP headers as key-value pairs',
        additionalProperties: { type: 'string' }
      },
      body: {
        type: 'string',
        description: 'Optional request body (for POST, PUT, PATCH)'
      },
      identity_id: {
        type: 'string',
        description: 'Optional identity ID for auth context tracking'
      },
      action_id: {
        type: 'string',
        description: 'Optional action ID for correlation'
      },
      timeout: {
        type: 'number',
        description: 'Request timeout in milliseconds (default: 30000)'
      }
    },
    required: ['method', 'url']
  },
  async (args: {
    method: string;
    url: string;
    headers?: Record<string, string>;
    body?: string;
    identity_id?: string;
    action_id?: string;
    timeout?: number;
  }) => {
    const request: HttpRequest = {
      method: args.method,
      url: args.url,
      headers: args.headers,
      body: args.body,
      timeout: args.timeout
    };

    const result = await httpClient.send(request, args.identity_id, args.action_id);

    // Return structured response
    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          success: result.success,
          request_id: result.request_id,
          correlation_ids: result.correlation_ids,
          status: result.response?.status,
          status_text: result.response?.statusText,
          response_headers: result.response?.headers,
          response_body: result.response?.body,
          timing_ms: result.response?.timing.duration,
          error: result.error
        }, null, 2)
      }]
    };
  }
);

// Tool: Send multiple HTTP requests in batch
server.tool(
  'http_send_batch',
  'Send multiple HTTP requests with concurrency control. Useful for testing multiple endpoints.',
  {
    type: 'object',
    properties: {
      requests: {
        type: 'array',
        description: 'Array of request objects',
        items: {
          type: 'object',
          properties: {
            method: { type: 'string' },
            url: { type: 'string' },
            headers: { type: 'object', additionalProperties: { type: 'string' } },
            body: { type: 'string' }
          },
          required: ['method', 'url']
        }
      },
      identity_id: {
        type: 'string',
        description: 'Identity ID to use for all requests'
      }
    },
    required: ['requests']
  },
  async (args: {
    requests: HttpRequest[];
    identity_id?: string;
  }) => {
    const results: RequestResult[] = [];

    // Process requests sequentially to respect rate limits
    for (const request of args.requests) {
      const result = await httpClient.send(request, args.identity_id);
      results.push(result);
    }

    const summary = {
      total: results.length,
      successful: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length
    };

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          summary,
          results: results.map(r => ({
            request_id: r.request_id,
            url: r.request.url,
            success: r.success,
            status: r.response?.status,
            error: r.error
          }))
        }, null, 2)
      }]
    };
  }
);

// Tool: Get current HTTP client statistics
server.tool(
  'http_get_stats',
  'Get current HTTP client statistics including request counts, rate limiter status, and concurrency.',
  {
    type: 'object',
    properties: {}
  },
  async () => {
    const stats = httpClient.getStats();

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          engagement_id: ENGAGEMENT_ID,
          statistics: stats,
          configuration: {
            max_rps: MAX_RPS,
            max_concurrent: MAX_CONCURRENT,
            max_total_requests: MAX_TOTAL_REQUESTS,
            proxy_url: PROXY_URL || 'none',
            default_timeout_ms: DEFAULT_TIMEOUT
          }
        }, null, 2)
      }]
    };
  }
);

// Start the server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[http-client] MCP server started');
}

main().catch((error) => {
  console.error('[http-client] Fatal error:', error);
  process.exit(1);
});
```

#### Step 3.5: Build and Configure

```bash
# Build
npm run build

# Update .gemini/settings.json in project root
```

Update `.gemini/settings.json`:

```json
{
  "mcpServers": {
    "scope-guard": {
      "command": "node",
      "args": ["mcp-servers/scope-guard-mcp/dist/server.js"],
      "env": {
        "SCOPE_FILE": "./scope/engagement.yaml",
        "FAIL_CLOSED": "true"
      },
      "timeout": 5000,
      "trust": true,
      "description": "Scope enforcement - validates all targets against allowlist"
    },
    "http-client": {
      "command": "node",
      "args": ["mcp-servers/http-client-mcp/dist/server.js"],
      "env": {
        "PROXY_URL": "http://127.0.0.1:8080",
        "MAX_RPS": "10",
        "MAX_CONCURRENT": "5",
        "MAX_TOTAL_REQUESTS": "1000",
        "DEFAULT_TIMEOUT": "30000",
        "ENGAGEMENT_ID": "ENG-001"
      },
      "timeout": 60000,
      "trust": false,
      "description": "Rate-limited HTTP client with proxy support"
    }
  },
  "approvalMode": "INTERACTIVE"
}
```

### Verification Checklist

- [ ] `npm run build` completes without errors
- [ ] MCP server starts and shows configuration
- [ ] `http_send` sends requests with correlation headers
- [ ] Rate limiting works (requests are throttled)
- [ ] Concurrency limiting works
- [ ] `http_get_stats` returns accurate statistics
- [ ] Proxy routing works when configured
- [ ] Timeout handling works correctly

---

## 16.4) Phase 4: Burp Suite Integration - Detailed Implementation

### Objective
Integrate Burp Suite Professional as a proxy and evidence capture layer via its REST API.

### Prerequisites
- Phase 1-3 completed
- Burp Suite Professional installed
- Burp REST API enabled (User Options → Misc → REST API)

### Burp Suite Setup

#### Enable REST API in Burp

1. Open Burp Suite Professional
2. Go to **Settings** (gear icon) → **Suite** → **REST API**
3. Check **Service running**
4. Set port (default: 1337)
5. Generate or set API key
6. Note the URL: `http://127.0.0.1:1337`

### Step-by-Step Implementation

#### Step 4.1: Create MCP Server Project

```bash
cd pentest-engine

mkdir -p mcp-servers/burp-mcp/src
mkdir -p mcp-servers/burp-mcp/tests

cd mcp-servers/burp-mcp

cat > package.json << 'EOF'
{
  "name": "burp-mcp",
  "version": "1.0.0",
  "description": "Burp Suite MCP server for proxy and evidence capture",
  "main": "dist/server.js",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "test": "vitest run"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "undici": "^6.0.0"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0",
    "vitest": "^1.0.0"
  }
}
EOF

npm install
```

#### Step 4.2: Create Burp API Client

Create `src/burp-api-client.ts`:

```typescript
export interface BurpProxyHistoryItem {
  index: number;
  host: string;
  port: number;
  protocol: string;
  method: string;
  path: string;
  status: number;
  length: number;
  mime_type: string;
  comment: string;
  time: string;
}

export interface BurpIssue {
  serial_number: string;
  type: string;
  name: string;
  host: string;
  path: string;
  severity: string;
  confidence: string;
  issue_background: string;
  remediation_background: string;
  issue_detail: string;
  remediation_detail: string;
}

export interface BurpRequest {
  method: string;
  url: string;
  headers: string;
  body?: string;
}

export class BurpApiClient {
  private baseUrl: string;
  private apiKey: string;

  constructor(baseUrl: string, apiKey: string) {
    this.baseUrl = baseUrl.replace(/\/$/, '');
    this.apiKey = apiKey;
  }

  private async request(
    method: string,
    endpoint: string,
    body?: unknown
  ): Promise<unknown> {
    const url = `${this.baseUrl}${endpoint}`;

    const headers: Record<string, string> = {
      'Authorization': this.apiKey,
      'Content-Type': 'application/json'
    };

    const response = await fetch(url, {
      method,
      headers,
      body: body ? JSON.stringify(body) : undefined
    });

    if (!response.ok) {
      throw new Error(`Burp API error: ${response.status} ${response.statusText}`);
    }

    const text = await response.text();
    return text ? JSON.parse(text) : null;
  }

  /**
   * Get proxy history
   */
  async getProxyHistory(limit?: number): Promise<BurpProxyHistoryItem[]> {
    const history = await this.request('GET', '/v0.1/proxy/history') as BurpProxyHistoryItem[];

    if (limit && history.length > limit) {
      return history.slice(-limit);
    }

    return history;
  }

  /**
   * Get proxy history item details (request/response)
   */
  async getProxyHistoryItem(index: number): Promise<{
    request: string;
    response: string;
  }> {
    const [request, response] = await Promise.all([
      this.request('GET', `/v0.1/proxy/history/${index}/request`) as Promise<string>,
      this.request('GET', `/v0.1/proxy/history/${index}/response`) as Promise<string>
    ]);

    return { request, response };
  }

  /**
   * Get scanner issues
   */
  async getIssues(): Promise<BurpIssue[]> {
    return await this.request('GET', '/v0.1/scan/issues') as BurpIssue[];
  }

  /**
   * Send request to target via Burp
   */
  async sendRequest(request: {
    host: string;
    port: number;
    useHttps: boolean;
    request: string;
  }): Promise<{ response: string }> {
    return await this.request('POST', '/v0.1/send', request) as { response: string };
  }

  /**
   * Check if URL is in Burp scope
   */
  async isInScope(url: string): Promise<boolean> {
    try {
      const result = await this.request('GET', `/v0.1/scope/in?url=${encodeURIComponent(url)}`) as { in_scope: boolean };
      return result.in_scope;
    } catch {
      return false;
    }
  }

  /**
   * Add URL to Burp scope
   */
  async addToScope(url: string): Promise<void> {
    await this.request('PUT', `/v0.1/scope?url=${encodeURIComponent(url)}`);
  }

  /**
   * Get Burp version/status
   */
  async getVersion(): Promise<{ version: string }> {
    return await this.request('GET', '/v0.1/version') as { version: string };
  }
}
```

#### Step 4.3: Create Evidence Exporter

Create `src/evidence-exporter.ts`:

```typescript
import { BurpApiClient, BurpProxyHistoryItem } from './burp-api-client.js';

export interface EvidenceItem {
  history_index: number;
  host: string;
  method: string;
  path: string;
  status: number;
  timestamp: string;
  request_raw: string;
  response_raw: string;
  request_headers: Record<string, string>;
  response_headers: Record<string, string>;
  request_body?: string;
  response_body?: string;
  correlation_ids?: {
    engagement_id?: string;
    action_id?: string;
    identity_id?: string;
  };
}

export class EvidenceExporter {
  private client: BurpApiClient;

  constructor(client: BurpApiClient) {
    this.client = client;
  }

  /**
   * Export a single history item as evidence
   */
  async exportHistoryItem(index: number): Promise<EvidenceItem> {
    const history = await this.client.getProxyHistory();
    const item = history.find(h => h.index === index);

    if (!item) {
      throw new Error(`History item ${index} not found`);
    }

    const { request, response } = await this.client.getProxyHistoryItem(index);

    // Parse headers from raw request/response
    const requestHeaders = this.parseHeaders(request);
    const responseHeaders = this.parseHeaders(response);

    // Extract correlation IDs from request headers
    const correlationIds = {
      engagement_id: requestHeaders['x-engagement-id'],
      action_id: requestHeaders['x-action-id'],
      identity_id: requestHeaders['x-identity-id']
    };

    return {
      history_index: index,
      host: item.host,
      method: item.method,
      path: item.path,
      status: item.status,
      timestamp: item.time,
      request_raw: request,
      response_raw: response,
      request_headers: requestHeaders,
      response_headers: responseHeaders,
      request_body: this.extractBody(request),
      response_body: this.extractBody(response),
      correlation_ids: correlationIds
    };
  }

  /**
   * Export multiple history items filtered by criteria
   */
  async exportFiltered(filter: {
    host?: string;
    engagement_id?: string;
    status_codes?: number[];
    limit?: number;
  }): Promise<EvidenceItem[]> {
    const history = await this.client.getProxyHistory(filter.limit);
    const results: EvidenceItem[] = [];

    for (const item of history) {
      // Apply host filter
      if (filter.host && !item.host.includes(filter.host)) {
        continue;
      }

      // Apply status code filter
      if (filter.status_codes && !filter.status_codes.includes(item.status)) {
        continue;
      }

      try {
        const evidence = await this.exportHistoryItem(item.index);

        // Apply engagement_id filter
        if (filter.engagement_id &&
            evidence.correlation_ids?.engagement_id !== filter.engagement_id) {
          continue;
        }

        results.push(evidence);
      } catch (error) {
        console.error(`Failed to export item ${item.index}:`, error);
      }
    }

    return results;
  }

  private parseHeaders(raw: string): Record<string, string> {
    const headers: Record<string, string> = {};
    const lines = raw.split('\r\n');

    // Skip first line (request line or status line)
    for (let i = 1; i < lines.length; i++) {
      const line = lines[i];
      if (line === '') break; // End of headers

      const colonIndex = line.indexOf(':');
      if (colonIndex > 0) {
        const name = line.substring(0, colonIndex).trim().toLowerCase();
        const value = line.substring(colonIndex + 1).trim();
        headers[name] = value;
      }
    }

    return headers;
  }

  private extractBody(raw: string): string | undefined {
    const parts = raw.split('\r\n\r\n');
    if (parts.length > 1) {
      return parts.slice(1).join('\r\n\r\n');
    }
    return undefined;
  }
}
```

#### Step 4.4: Create Main MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { BurpApiClient } from './burp-api-client.js';
import { EvidenceExporter } from './evidence-exporter.js';

// Configuration
const BURP_API_URL = process.env.BURP_API_URL || 'http://127.0.0.1:1337';
const BURP_API_KEY = process.env.BURP_API_KEY || '';

// Initialize clients
const burpClient = new BurpApiClient(BURP_API_URL, BURP_API_KEY);
const evidenceExporter = new EvidenceExporter(burpClient);

// Verify connection on startup
(async () => {
  try {
    const version = await burpClient.getVersion();
    console.error(`[burp-mcp] Connected to Burp Suite ${version.version}`);
  } catch (error) {
    console.error(`[burp-mcp] Warning: Could not connect to Burp API at ${BURP_API_URL}`);
  }
})();

// Create MCP Server
const server = new McpServer({
  name: 'burp',
  version: '1.0.0',
});

// Tool: Get proxy history
server.tool(
  'burp_get_history',
  'Retrieve Burp Suite proxy history. Returns recent requests/responses captured by the proxy.',
  {
    type: 'object',
    properties: {
      limit: {
        type: 'number',
        description: 'Maximum number of history items to return (default: 50)'
      },
      host_filter: {
        type: 'string',
        description: 'Filter by host (partial match)'
      }
    }
  },
  async (args: { limit?: number; host_filter?: string }) => {
    try {
      let history = await burpClient.getProxyHistory(args.limit || 50);

      if (args.host_filter) {
        history = history.filter(h =>
          h.host.toLowerCase().includes(args.host_filter!.toLowerCase())
        );
      }

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            count: history.length,
            items: history.map(h => ({
              index: h.index,
              method: h.method,
              host: h.host,
              path: h.path,
              status: h.status,
              length: h.length,
              time: h.time
            }))
          }, null, 2)
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            error: error instanceof Error ? error.message : 'Unknown error',
            hint: 'Ensure Burp Suite is running with REST API enabled'
          })
        }]
      };
    }
  }
);

// Tool: Get scanner findings
server.tool(
  'burp_get_findings',
  'Retrieve passive scanner findings from Burp Suite.',
  {
    type: 'object',
    properties: {
      severity_filter: {
        type: 'string',
        description: 'Filter by severity (high, medium, low, information)',
        enum: ['high', 'medium', 'low', 'information']
      }
    }
  },
  async (args: { severity_filter?: string }) => {
    try {
      let issues = await burpClient.getIssues();

      if (args.severity_filter) {
        issues = issues.filter(i =>
          i.severity.toLowerCase() === args.severity_filter!.toLowerCase()
        );
      }

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            count: issues.length,
            issues: issues.map(i => ({
              serial: i.serial_number,
              name: i.name,
              host: i.host,
              path: i.path,
              severity: i.severity,
              confidence: i.confidence,
              detail: i.issue_detail?.substring(0, 200)
            }))
          }, null, 2)
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            error: error instanceof Error ? error.message : 'Unknown error'
          })
        }]
      };
    }
  }
);

// Tool: Export evidence
server.tool(
  'burp_export_evidence',
  'Export a proxy history item as evidence with full request/response details.',
  {
    type: 'object',
    properties: {
      history_index: {
        type: 'number',
        description: 'Index of the history item to export'
      }
    },
    required: ['history_index']
  },
  async (args: { history_index: number }) => {
    try {
      const evidence = await evidenceExporter.exportHistoryItem(args.history_index);

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            success: true,
            evidence: {
              ...evidence,
              // Truncate large bodies for display
              request_raw: evidence.request_raw.substring(0, 2000),
              response_raw: evidence.response_raw.substring(0, 5000)
            }
          }, null, 2)
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error'
          })
        }]
      };
    }
  }
);

// Tool: Check if URL is in Burp scope
server.tool(
  'burp_scope_check',
  'Check if a URL is in Burp Suite target scope.',
  {
    type: 'object',
    properties: {
      url: {
        type: 'string',
        description: 'URL to check'
      }
    },
    required: ['url']
  },
  async (args: { url: string }) => {
    try {
      const inScope = await burpClient.isInScope(args.url);

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            url: args.url,
            in_scope: inScope
          })
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            error: error instanceof Error ? error.message : 'Unknown error'
          })
        }]
      };
    }
  }
);

// Tool: Get Burp status
server.tool(
  'burp_get_status',
  'Get Burp Suite connection status and version.',
  {
    type: 'object',
    properties: {}
  },
  async () => {
    try {
      const version = await burpClient.getVersion();

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            connected: true,
            version: version.version,
            api_url: BURP_API_URL
          })
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            connected: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            api_url: BURP_API_URL
          })
        }]
      };
    }
  }
);

// Start the server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[burp-mcp] MCP server started');
}

main().catch((error) => {
  console.error('[burp-mcp] Fatal error:', error);
  process.exit(1);
});
```

#### Step 4.5: Update Configuration

Update `.gemini/settings.json` to include burp-mcp:

```json
{
  "mcpServers": {
    "scope-guard": {
      "command": "node",
      "args": ["mcp-servers/scope-guard-mcp/dist/server.js"],
      "env": {
        "SCOPE_FILE": "./scope/engagement.yaml",
        "FAIL_CLOSED": "true"
      },
      "timeout": 5000,
      "trust": true
    },
    "http-client": {
      "command": "node",
      "args": ["mcp-servers/http-client-mcp/dist/server.js"],
      "env": {
        "PROXY_URL": "http://127.0.0.1:8080",
        "MAX_RPS": "10",
        "MAX_CONCURRENT": "5",
        "MAX_TOTAL_REQUESTS": "1000",
        "ENGAGEMENT_ID": "ENG-001"
      },
      "timeout": 60000,
      "trust": false
    },
    "burp": {
      "command": "node",
      "args": ["mcp-servers/burp-mcp/dist/server.js"],
      "env": {
        "BURP_API_URL": "http://127.0.0.1:1337",
        "BURP_API_KEY": "${BURP_API_KEY}"
      },
      "timeout": 60000,
      "trust": false,
      "includeTools": [
        "burp_get_history",
        "burp_get_findings",
        "burp_export_evidence",
        "burp_scope_check",
        "burp_get_status"
      ]
    }
  }
}
```

### Verification Checklist

- [ ] Burp Suite REST API is enabled and accessible
- [ ] `burp_get_status` returns connected and version
- [ ] `burp_get_history` returns proxy history
- [ ] `burp_export_evidence` exports full request/response
- [ ] HTTP client requests appear in Burp history
- [ ] Correlation headers (X-Engagement-ID, etc.) visible in Burp

---

---

## 16.5) Phase 5: OpenAPI & Discovery - Detailed Implementation

### Objective
Parse OpenAPI specifications to enumerate and understand API endpoints, enabling structured testing of the target application.

### Prerequisites
- Phases 1-4 completed
- OpenAPI/Swagger specification for target application (optional but recommended)

### Step-by-Step Implementation

#### Step 5.1: Create MCP Server Project

```bash
cd pentest-engine
mkdir -p mcp-servers/openapi-mcp/src
cd mcp-servers/openapi-mcp

cat > package.json << 'EOF'
{
  "name": "openapi-mcp",
  "version": "1.0.0",
  "description": "OpenAPI parser and endpoint enumerator MCP server",
  "main": "dist/server.js",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "test": "vitest run"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "openapi-types": "^12.1.0",
    "js-yaml": "^4.1.0",
    "json-schema-faker": "^0.5.0"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0",
    "@types/js-yaml": "^4.0.9",
    "vitest": "^1.0.0"
  }
}
EOF

npm install
```

#### Step 5.2: Create OpenAPI Parser

Create `src/openapi-parser.ts`:

```typescript
import * as fs from 'fs';
import * as yaml from 'js-yaml';
import type { OpenAPIV3 } from 'openapi-types';

export interface ParsedEndpoint {
  endpoint_id: string;
  method: string;
  path: string;
  operation_id?: string;
  summary?: string;
  description?: string;
  tags: string[];
  parameters: ParsedParameter[];
  request_body?: ParsedRequestBody;
  responses: Record<string, ParsedResponse>;
  security: string[];
}

export interface ParsedParameter {
  name: string;
  in: 'query' | 'header' | 'path' | 'cookie';
  required: boolean;
  schema: unknown;
  description?: string;
}

export interface ParsedRequestBody {
  required: boolean;
  content_types: string[];
  schema: unknown;
}

export interface ParsedResponse {
  status_code: string;
  description: string;
  schema?: unknown;
}

export interface ParsedSpec {
  title: string;
  version: string;
  base_url: string;
  endpoints: ParsedEndpoint[];
  security_schemes: Record<string, unknown>;
}

export class OpenAPIParser {
  private spec: OpenAPIV3.Document | null = null;

  /**
   * Load and parse OpenAPI spec from file or URL
   */
  async load(source: string): Promise<ParsedSpec> {
    let rawSpec: string;

    if (source.startsWith('http://') || source.startsWith('https://')) {
      const response = await fetch(source);
      rawSpec = await response.text();
    } else {
      rawSpec = fs.readFileSync(source, 'utf-8');
    }

    // Parse YAML or JSON
    const spec = (source.endsWith('.yaml') || source.endsWith('.yml') || rawSpec.trim().startsWith('openapi:'))
      ? yaml.load(rawSpec) as OpenAPIV3.Document
      : JSON.parse(rawSpec) as OpenAPIV3.Document;

    this.spec = spec;

    return this.parse();
  }

  private parse(): ParsedSpec {
    if (!this.spec) {
      throw new Error('No spec loaded');
    }

    const endpoints: ParsedEndpoint[] = [];

    // Extract base URL from servers
    const baseUrl = this.spec.servers?.[0]?.url || '';

    // Parse all paths
    for (const [path, pathItem] of Object.entries(this.spec.paths || {})) {
      if (!pathItem) continue;

      const methods = ['get', 'post', 'put', 'delete', 'patch', 'head', 'options'] as const;

      for (const method of methods) {
        const operation = pathItem[method];
        if (!operation) continue;

        const endpointId = `${method.toUpperCase()}-${path.replace(/[^a-zA-Z0-9]/g, '-')}`;

        endpoints.push({
          endpoint_id: endpointId,
          method: method.toUpperCase(),
          path,
          operation_id: operation.operationId,
          summary: operation.summary,
          description: operation.description,
          tags: operation.tags || [],
          parameters: this.parseParameters([
            ...(pathItem.parameters || []),
            ...(operation.parameters || [])
          ]),
          request_body: this.parseRequestBody(operation.requestBody),
          responses: this.parseResponses(operation.responses),
          security: this.parseSecurity(operation.security || this.spec!.security || [])
        });
      }
    }

    return {
      title: this.spec.info.title,
      version: this.spec.info.version,
      base_url: baseUrl,
      endpoints,
      security_schemes: this.spec.components?.securitySchemes || {}
    };
  }

  private parseParameters(params: (OpenAPIV3.ParameterObject | OpenAPIV3.ReferenceObject)[]): ParsedParameter[] {
    return params
      .filter((p): p is OpenAPIV3.ParameterObject => !('$ref' in p))
      .map(p => ({
        name: p.name,
        in: p.in as 'query' | 'header' | 'path' | 'cookie',
        required: p.required || false,
        schema: p.schema,
        description: p.description
      }));
  }

  private parseRequestBody(body?: OpenAPIV3.RequestBodyObject | OpenAPIV3.ReferenceObject): ParsedRequestBody | undefined {
    if (!body || '$ref' in body) return undefined;

    return {
      required: body.required || false,
      content_types: Object.keys(body.content || {}),
      schema: body.content?.['application/json']?.schema
    };
  }

  private parseResponses(responses: OpenAPIV3.ResponsesObject): Record<string, ParsedResponse> {
    const result: Record<string, ParsedResponse> = {};

    for (const [code, response] of Object.entries(responses)) {
      if ('$ref' in response) continue;

      result[code] = {
        status_code: code,
        description: response.description,
        schema: response.content?.['application/json']?.schema
      };
    }

    return result;
  }

  private parseSecurity(security: OpenAPIV3.SecurityRequirementObject[]): string[] {
    return security.flatMap(req => Object.keys(req));
  }

  /**
   * Generate a sample request for an endpoint
   */
  generateSampleRequest(endpoint: ParsedEndpoint, baseUrl: string): {
    method: string;
    url: string;
    headers: Record<string, string>;
    body?: string;
  } {
    let path = endpoint.path;
    const headers: Record<string, string> = {};
    const queryParams: string[] = [];

    // Fill path parameters
    for (const param of endpoint.parameters) {
      if (param.in === 'path') {
        path = path.replace(`{${param.name}}`, this.generateSampleValue(param.schema, param.name));
      } else if (param.in === 'query') {
        queryParams.push(`${param.name}=${this.generateSampleValue(param.schema, param.name)}`);
      } else if (param.in === 'header') {
        headers[param.name] = this.generateSampleValue(param.schema, param.name);
      }
    }

    let url = `${baseUrl}${path}`;
    if (queryParams.length > 0) {
      url += `?${queryParams.join('&')}`;
    }

    const result: {
      method: string;
      url: string;
      headers: Record<string, string>;
      body?: string;
    } = {
      method: endpoint.method,
      url,
      headers
    };

    // Generate request body if needed
    if (endpoint.request_body?.schema) {
      headers['Content-Type'] = 'application/json';
      result.body = JSON.stringify(this.generateSampleObject(endpoint.request_body.schema));
    }

    return result;
  }

  private generateSampleValue(schema: unknown, name: string): string {
    if (!schema || typeof schema !== 'object') return 'example';

    const s = schema as { type?: string; format?: string; example?: unknown; enum?: unknown[] };

    if (s.example !== undefined) return String(s.example);
    if (s.enum && s.enum.length > 0) return String(s.enum[0]);

    switch (s.type) {
      case 'integer': return '1';
      case 'number': return '1.0';
      case 'boolean': return 'true';
      case 'string':
        if (s.format === 'uuid') return '550e8400-e29b-41d4-a716-446655440000';
        if (s.format === 'email') return 'test@example.com';
        if (s.format === 'date') return '2024-01-01';
        if (s.format === 'date-time') return '2024-01-01T00:00:00Z';
        if (name.toLowerCase().includes('id')) return '123';
        return 'example';
      default: return 'example';
    }
  }

  private generateSampleObject(schema: unknown): unknown {
    if (!schema || typeof schema !== 'object') return {};

    const s = schema as {
      type?: string;
      properties?: Record<string, unknown>;
      items?: unknown;
      example?: unknown;
    };

    if (s.example !== undefined) return s.example;

    if (s.type === 'array' && s.items) {
      return [this.generateSampleObject(s.items)];
    }

    if (s.type === 'object' && s.properties) {
      const result: Record<string, unknown> = {};
      for (const [key, prop] of Object.entries(s.properties)) {
        result[key] = this.generateSampleValue(prop, key);
      }
      return result;
    }

    return {};
  }
}
```

#### Step 5.3: Create MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { OpenAPIParser, ParsedSpec, ParsedEndpoint } from './openapi-parser.js';

// State
let loadedSpec: ParsedSpec | null = null;
const parser = new OpenAPIParser();

// Create MCP Server
const server = new McpServer({
  name: 'openapi',
  version: '1.0.0',
});

// Tool: Ingest OpenAPI spec
server.tool(
  'openapi_ingest',
  'Load and parse an OpenAPI specification from a file path or URL.',
  {
    type: 'object',
    properties: {
      source: {
        type: 'string',
        description: 'File path or URL to the OpenAPI spec (YAML or JSON)'
      }
    },
    required: ['source']
  },
  async (args: { source: string }) => {
    try {
      loadedSpec = await parser.load(args.source);

      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            success: true,
            title: loadedSpec.title,
            version: loadedSpec.version,
            base_url: loadedSpec.base_url,
            endpoint_count: loadedSpec.endpoints.length,
            security_schemes: Object.keys(loadedSpec.security_schemes)
          }, null, 2)
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error'
          })
        }]
      };
    }
  }
);

// Tool: List endpoints
server.tool(
  'openapi_list_endpoints',
  'List all endpoints from the loaded OpenAPI spec with optional filtering.',
  {
    type: 'object',
    properties: {
      method_filter: {
        type: 'string',
        description: 'Filter by HTTP method (GET, POST, etc.)'
      },
      tag_filter: {
        type: 'string',
        description: 'Filter by tag'
      },
      path_contains: {
        type: 'string',
        description: 'Filter paths containing this string'
      }
    }
  },
  async (args: { method_filter?: string; tag_filter?: string; path_contains?: string }) => {
    if (!loadedSpec) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'No spec loaded. Use openapi_ingest first.' })
        }]
      };
    }

    let endpoints = loadedSpec.endpoints;

    if (args.method_filter) {
      endpoints = endpoints.filter(e => e.method === args.method_filter!.toUpperCase());
    }
    if (args.tag_filter) {
      endpoints = endpoints.filter(e => e.tags.includes(args.tag_filter!));
    }
    if (args.path_contains) {
      endpoints = endpoints.filter(e => e.path.includes(args.path_contains!));
    }

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          count: endpoints.length,
          endpoints: endpoints.map(e => ({
            endpoint_id: e.endpoint_id,
            method: e.method,
            path: e.path,
            summary: e.summary,
            tags: e.tags,
            requires_auth: e.security.length > 0
          }))
        }, null, 2)
      }]
    };
  }
);

// Tool: Get endpoint schema
server.tool(
  'openapi_get_schema',
  'Get detailed schema information for a specific endpoint.',
  {
    type: 'object',
    properties: {
      endpoint_id: {
        type: 'string',
        description: 'Endpoint ID from openapi_list_endpoints'
      },
      method: {
        type: 'string',
        description: 'HTTP method (alternative to endpoint_id)'
      },
      path: {
        type: 'string',
        description: 'Path (alternative to endpoint_id)'
      }
    }
  },
  async (args: { endpoint_id?: string; method?: string; path?: string }) => {
    if (!loadedSpec) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'No spec loaded. Use openapi_ingest first.' })
        }]
      };
    }

    let endpoint: ParsedEndpoint | undefined;

    if (args.endpoint_id) {
      endpoint = loadedSpec.endpoints.find(e => e.endpoint_id === args.endpoint_id);
    } else if (args.method && args.path) {
      endpoint = loadedSpec.endpoints.find(
        e => e.method === args.method!.toUpperCase() && e.path === args.path
      );
    }

    if (!endpoint) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'Endpoint not found' })
        }]
      };
    }

    return {
      content: [{
        type: 'text',
        text: JSON.stringify(endpoint, null, 2)
      }]
    };
  }
);

// Tool: Generate sample request
server.tool(
  'openapi_generate_request',
  'Generate a sample HTTP request for an endpoint based on its schema.',
  {
    type: 'object',
    properties: {
      endpoint_id: {
        type: 'string',
        description: 'Endpoint ID from openapi_list_endpoints'
      },
      base_url: {
        type: 'string',
        description: 'Override base URL (optional)'
      }
    },
    required: ['endpoint_id']
  },
  async (args: { endpoint_id: string; base_url?: string }) => {
    if (!loadedSpec) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'No spec loaded. Use openapi_ingest first.' })
        }]
      };
    }

    const endpoint = loadedSpec.endpoints.find(e => e.endpoint_id === args.endpoint_id);
    if (!endpoint) {
      return {
        content: [{
          type: 'text',
          text: JSON.stringify({ error: 'Endpoint not found' })
        }]
      };
    }

    const baseUrl = args.base_url || loadedSpec.base_url;
    const sampleRequest = parser.generateSampleRequest(endpoint, baseUrl);

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          endpoint_id: endpoint.endpoint_id,
          sample_request: sampleRequest
        }, null, 2)
      }]
    };
  }
);

// Start server
async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[openapi-mcp] MCP server started');
}

main().catch(console.error);
```

### Verification Checklist

- [ ] Can load OpenAPI spec from file
- [ ] Can load OpenAPI spec from URL
- [ ] `openapi_list_endpoints` returns all endpoints
- [ ] Filtering by method, tag, path works
- [ ] `openapi_generate_request` creates valid sample requests

---

## 16.6) Phase 6: World Model - Detailed Implementation

### Objective
Create a structured state store to track assets, endpoints, hypotheses, observations, and findings throughout the engagement.

### Step-by-Step Implementation

#### Step 6.1: Create MCP Server Project

```bash
cd pentest-engine
mkdir -p mcp-servers/world-model-mcp/src
cd mcp-servers/world-model-mcp

cat > package.json << 'EOF'
{
  "name": "world-model-mcp",
  "version": "1.0.0",
  "description": "World model state store MCP server",
  "main": "dist/server.js",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "test": "vitest run"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "better-sqlite3": "^9.0.0",
    "uuid": "^9.0.0"
  },
  "devDependencies": {
    "typescript": "^5.3.0",
    "@types/node": "^20.0.0",
    "@types/better-sqlite3": "^7.6.0",
    "@types/uuid": "^9.0.0",
    "vitest": "^1.0.0"
  }
}
EOF

npm install
```

#### Step 6.2: Create Database Schema

Create `src/database.ts`:

```typescript
import Database from 'better-sqlite3';
import { v4 as uuidv4 } from 'uuid';

export interface Asset {
  asset_id: string;
  kind: 'domain' | 'ip' | 'service';
  name: string;
  tags: string[];
  created_at: string;
}

export interface Endpoint {
  endpoint_id: string;
  asset_id: string;
  method: string;
  path: string;
  openapi_ref?: string;
  created_at: string;
}

export interface Identity {
  identity_id: string;
  label: string;
  roles: string[];
  tenant_id?: string;
  created_at: string;
}

export interface Hypothesis {
  hypothesis_id: string;
  description: string;
  status: 'new' | 'testing' | 'validated' | 'rejected';
  confidence: number;
  created_at: string;
  updated_at: string;
}

export interface Observation {
  observation_id: string;
  action_id: string;
  type: string;
  confidence: number;
  data: Record<string, unknown>;
  evidence_refs: string[];
  created_at: string;
}

export interface Finding {
  finding_id: string;
  title: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  status: 'draft' | 'validated' | 'rejected';
  hypothesis_id?: string;
  evidence_refs: string[];
  confidence: number;
  remediation?: string;
  created_at: string;
}

export class WorldModelDatabase {
  private db: Database.Database;

  constructor(dbPath: string) {
    this.db = new Database(dbPath);
    this.initSchema();
  }

  private initSchema(): void {
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS assets (
        asset_id TEXT PRIMARY KEY,
        kind TEXT NOT NULL,
        name TEXT NOT NULL,
        tags TEXT DEFAULT '[]',
        created_at TEXT NOT NULL
      );

      CREATE TABLE IF NOT EXISTS endpoints (
        endpoint_id TEXT PRIMARY KEY,
        asset_id TEXT,
        method TEXT NOT NULL,
        path TEXT NOT NULL,
        openapi_ref TEXT,
        created_at TEXT NOT NULL,
        FOREIGN KEY (asset_id) REFERENCES assets(asset_id)
      );

      CREATE TABLE IF NOT EXISTS identities (
        identity_id TEXT PRIMARY KEY,
        label TEXT NOT NULL,
        roles TEXT DEFAULT '[]',
        tenant_id TEXT,
        created_at TEXT NOT NULL
      );

      CREATE TABLE IF NOT EXISTS hypotheses (
        hypothesis_id TEXT PRIMARY KEY,
        description TEXT NOT NULL,
        status TEXT DEFAULT 'new',
        confidence REAL DEFAULT 0,
        created_at TEXT NOT NULL,
        updated_at TEXT NOT NULL
      );

      CREATE TABLE IF NOT EXISTS observations (
        observation_id TEXT PRIMARY KEY,
        action_id TEXT NOT NULL,
        type TEXT NOT NULL,
        confidence REAL DEFAULT 0,
        data TEXT DEFAULT '{}',
        evidence_refs TEXT DEFAULT '[]',
        created_at TEXT NOT NULL
      );

      CREATE TABLE IF NOT EXISTS findings (
        finding_id TEXT PRIMARY KEY,
        title TEXT NOT NULL,
        severity TEXT NOT NULL,
        status TEXT DEFAULT 'draft',
        hypothesis_id TEXT,
        evidence_refs TEXT DEFAULT '[]',
        confidence REAL DEFAULT 0,
        remediation TEXT,
        created_at TEXT NOT NULL,
        FOREIGN KEY (hypothesis_id) REFERENCES hypotheses(hypothesis_id)
      );

      CREATE INDEX IF NOT EXISTS idx_endpoints_asset ON endpoints(asset_id);
      CREATE INDEX IF NOT EXISTS idx_findings_status ON findings(status);
      CREATE INDEX IF NOT EXISTS idx_hypotheses_status ON hypotheses(status);
    `);
  }

  // Asset methods
  addAsset(asset: Omit<Asset, 'asset_id' | 'created_at'>): Asset {
    const id = uuidv4();
    const now = new Date().toISOString();
    const fullAsset: Asset = { ...asset, asset_id: id, created_at: now };

    this.db.prepare(`
      INSERT INTO assets (asset_id, kind, name, tags, created_at)
      VALUES (?, ?, ?, ?, ?)
    `).run(id, asset.kind, asset.name, JSON.stringify(asset.tags || []), now);

    return fullAsset;
  }

  getAssets(filter?: { kind?: string }): Asset[] {
    let query = 'SELECT * FROM assets';
    const params: unknown[] = [];

    if (filter?.kind) {
      query += ' WHERE kind = ?';
      params.push(filter.kind);
    }

    return this.db.prepare(query).all(...params).map(row => ({
      ...(row as Record<string, unknown>),
      tags: JSON.parse((row as Record<string, string>).tags)
    })) as Asset[];
  }

  // Endpoint methods
  addEndpoint(endpoint: Omit<Endpoint, 'endpoint_id' | 'created_at'>): Endpoint {
    const id = uuidv4();
    const now = new Date().toISOString();

    this.db.prepare(`
      INSERT INTO endpoints (endpoint_id, asset_id, method, path, openapi_ref, created_at)
      VALUES (?, ?, ?, ?, ?, ?)
    `).run(id, endpoint.asset_id, endpoint.method, endpoint.path, endpoint.openapi_ref, now);

    return { ...endpoint, endpoint_id: id, created_at: now };
  }

  getEndpoints(filter?: { asset_id?: string; method?: string }): Endpoint[] {
    let query = 'SELECT * FROM endpoints WHERE 1=1';
    const params: unknown[] = [];

    if (filter?.asset_id) {
      query += ' AND asset_id = ?';
      params.push(filter.asset_id);
    }
    if (filter?.method) {
      query += ' AND method = ?';
      params.push(filter.method);
    }

    return this.db.prepare(query).all(...params) as Endpoint[];
  }

  // Hypothesis methods
  addHypothesis(hypothesis: Omit<Hypothesis, 'hypothesis_id' | 'created_at' | 'updated_at'>): Hypothesis {
    const id = `H-${Date.now()}`;
    const now = new Date().toISOString();

    this.db.prepare(`
      INSERT INTO hypotheses (hypothesis_id, description, status, confidence, created_at, updated_at)
      VALUES (?, ?, ?, ?, ?, ?)
    `).run(id, hypothesis.description, hypothesis.status, hypothesis.confidence, now, now);

    return { ...hypothesis, hypothesis_id: id, created_at: now, updated_at: now };
  }

  updateHypothesis(id: string, updates: Partial<Hypothesis>): boolean {
    const now = new Date().toISOString();
    const setClauses: string[] = ['updated_at = ?'];
    const params: unknown[] = [now];

    if (updates.status !== undefined) {
      setClauses.push('status = ?');
      params.push(updates.status);
    }
    if (updates.confidence !== undefined) {
      setClauses.push('confidence = ?');
      params.push(updates.confidence);
    }

    params.push(id);

    const result = this.db.prepare(`
      UPDATE hypotheses SET ${setClauses.join(', ')} WHERE hypothesis_id = ?
    `).run(...params);

    return result.changes > 0;
  }

  getHypotheses(filter?: { status?: string }): Hypothesis[] {
    let query = 'SELECT * FROM hypotheses';
    const params: unknown[] = [];

    if (filter?.status) {
      query += ' WHERE status = ?';
      params.push(filter.status);
    }

    return this.db.prepare(query).all(...params) as Hypothesis[];
  }

  // Finding methods
  addFinding(finding: Omit<Finding, 'finding_id' | 'created_at'>): Finding {
    const id = `F-${Date.now()}`;
    const now = new Date().toISOString();

    this.db.prepare(`
      INSERT INTO findings (finding_id, title, severity, status, hypothesis_id, evidence_refs, confidence, remediation, created_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    `).run(
      id, finding.title, finding.severity, finding.status,
      finding.hypothesis_id, JSON.stringify(finding.evidence_refs || []),
      finding.confidence, finding.remediation, now
    );

    return { ...finding, finding_id: id, created_at: now };
  }

  getFindings(filter?: { status?: string; severity?: string }): Finding[] {
    let query = 'SELECT * FROM findings WHERE 1=1';
    const params: unknown[] = [];

    if (filter?.status) {
      query += ' AND status = ?';
      params.push(filter.status);
    }
    if (filter?.severity) {
      query += ' AND severity = ?';
      params.push(filter.severity);
    }

    return this.db.prepare(query).all(...params).map(row => ({
      ...(row as Record<string, unknown>),
      evidence_refs: JSON.parse((row as Record<string, string>).evidence_refs)
    })) as Finding[];
  }

  updateFinding(id: string, updates: Partial<Finding>): boolean {
    const setClauses: string[] = [];
    const params: unknown[] = [];

    if (updates.status !== undefined) {
      setClauses.push('status = ?');
      params.push(updates.status);
    }
    if (updates.confidence !== undefined) {
      setClauses.push('confidence = ?');
      params.push(updates.confidence);
    }
    if (updates.evidence_refs !== undefined) {
      setClauses.push('evidence_refs = ?');
      params.push(JSON.stringify(updates.evidence_refs));
    }

    if (setClauses.length === 0) return false;

    params.push(id);

    const result = this.db.prepare(`
      UPDATE findings SET ${setClauses.join(', ')} WHERE finding_id = ?
    `).run(...params);

    return result.changes > 0;
  }

  // Observation methods
  addObservation(observation: Omit<Observation, 'observation_id' | 'created_at'>): Observation {
    const id = uuidv4();
    const now = new Date().toISOString();

    this.db.prepare(`
      INSERT INTO observations (observation_id, action_id, type, confidence, data, evidence_refs, created_at)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `).run(
      id, observation.action_id, observation.type, observation.confidence,
      JSON.stringify(observation.data), JSON.stringify(observation.evidence_refs || []), now
    );

    return { ...observation, observation_id: id, created_at: now };
  }

  // Statistics
  getStats(): {
    assets: number;
    endpoints: number;
    hypotheses: { total: number; by_status: Record<string, number> };
    findings: { total: number; by_status: Record<string, number>; by_severity: Record<string, number> };
  } {
    const assetCount = (this.db.prepare('SELECT COUNT(*) as count FROM assets').get() as { count: number }).count;
    const endpointCount = (this.db.prepare('SELECT COUNT(*) as count FROM endpoints').get() as { count: number }).count;

    const hypothesisStats = this.db.prepare(`
      SELECT status, COUNT(*) as count FROM hypotheses GROUP BY status
    `).all() as { status: string; count: number }[];

    const findingStatsByStatus = this.db.prepare(`
      SELECT status, COUNT(*) as count FROM findings GROUP BY status
    `).all() as { status: string; count: number }[];

    const findingStatsBySeverity = this.db.prepare(`
      SELECT severity, COUNT(*) as count FROM findings GROUP BY severity
    `).all() as { severity: string; count: number }[];

    return {
      assets: assetCount,
      endpoints: endpointCount,
      hypotheses: {
        total: hypothesisStats.reduce((sum, s) => sum + s.count, 0),
        by_status: Object.fromEntries(hypothesisStats.map(s => [s.status, s.count]))
      },
      findings: {
        total: findingStatsByStatus.reduce((sum, s) => sum + s.count, 0),
        by_status: Object.fromEntries(findingStatsByStatus.map(s => [s.status, s.count])),
        by_severity: Object.fromEntries(findingStatsBySeverity.map(s => [s.severity, s.count]))
      }
    };
  }
}
```

#### Step 6.3: Create MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { WorldModelDatabase } from './database.js';

const DB_PATH = process.env.DB_PATH || './data/world-model.db';
const db = new WorldModelDatabase(DB_PATH);

console.error(`[world-model] Database initialized at ${DB_PATH}`);

const server = new McpServer({
  name: 'world-model',
  version: '1.0.0',
});

// Tool: Add endpoint
server.tool(
  'wm_add_endpoint',
  'Register a discovered endpoint in the world model.',
  {
    type: 'object',
    properties: {
      method: { type: 'string' },
      path: { type: 'string' },
      asset_id: { type: 'string' },
      openapi_ref: { type: 'string' }
    },
    required: ['method', 'path']
  },
  async (args) => {
    const endpoint = db.addEndpoint(args as any);
    return { content: [{ type: 'text', text: JSON.stringify(endpoint, null, 2) }] };
  }
);

// Tool: Add hypothesis
server.tool(
  'wm_add_hypothesis',
  'Create a new security hypothesis to test.',
  {
    type: 'object',
    properties: {
      description: { type: 'string' },
      status: { type: 'string', enum: ['new', 'testing', 'validated', 'rejected'] },
      confidence: { type: 'number' }
    },
    required: ['description']
  },
  async (args: { description: string; status?: string; confidence?: number }) => {
    const hypothesis = db.addHypothesis({
      description: args.description,
      status: (args.status as any) || 'new',
      confidence: args.confidence || 0
    });
    return { content: [{ type: 'text', text: JSON.stringify(hypothesis, null, 2) }] };
  }
);

// Tool: Update hypothesis
server.tool(
  'wm_update_hypothesis',
  'Update a hypothesis status or confidence.',
  {
    type: 'object',
    properties: {
      hypothesis_id: { type: 'string' },
      status: { type: 'string', enum: ['new', 'testing', 'validated', 'rejected'] },
      confidence: { type: 'number' }
    },
    required: ['hypothesis_id']
  },
  async (args: { hypothesis_id: string; status?: string; confidence?: number }) => {
    const success = db.updateHypothesis(args.hypothesis_id, {
      status: args.status as any,
      confidence: args.confidence
    });
    return { content: [{ type: 'text', text: JSON.stringify({ success }) }] };
  }
);

// Tool: Add finding
server.tool(
  'wm_add_finding',
  'Record a validated security finding.',
  {
    type: 'object',
    properties: {
      title: { type: 'string' },
      severity: { type: 'string', enum: ['low', 'medium', 'high', 'critical'] },
      status: { type: 'string', enum: ['draft', 'validated', 'rejected'] },
      hypothesis_id: { type: 'string' },
      evidence_refs: { type: 'array', items: { type: 'string' } },
      confidence: { type: 'number' },
      remediation: { type: 'string' }
    },
    required: ['title', 'severity']
  },
  async (args) => {
    const finding = db.addFinding(args as any);
    return { content: [{ type: 'text', text: JSON.stringify(finding, null, 2) }] };
  }
);

// Tool: Query world model
server.tool(
  'wm_query',
  'Query the world model for endpoints, hypotheses, or findings.',
  {
    type: 'object',
    properties: {
      entity_type: { type: 'string', enum: ['endpoints', 'hypotheses', 'findings', 'stats'] },
      filter: { type: 'object' }
    },
    required: ['entity_type']
  },
  async (args: { entity_type: string; filter?: Record<string, unknown> }) => {
    let result: unknown;

    switch (args.entity_type) {
      case 'endpoints':
        result = db.getEndpoints(args.filter as any);
        break;
      case 'hypotheses':
        result = db.getHypotheses(args.filter as any);
        break;
      case 'findings':
        result = db.getFindings(args.filter as any);
        break;
      case 'stats':
        result = db.getStats();
        break;
      default:
        result = { error: 'Unknown entity type' };
    }

    return { content: [{ type: 'text', text: JSON.stringify(result, null, 2) }] };
  }
);

async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[world-model] MCP server started');
}

main().catch(console.error);
```

### Verification Checklist

- [ ] Database file created successfully
- [ ] Can add and query endpoints
- [ ] Can add and update hypotheses
- [ ] Can add and query findings
- [ ] Statistics returned correctly

---

## 16.7) Phase 7: Auth Testing - Detailed Implementation

### Objective
Implement authorization differential testing to detect BOLA/IDOR vulnerabilities by replaying requests with different identities.

### Key Concepts

**BOLA (Broken Object Level Authorization)**: When an API allows access to objects that should be restricted based on user identity.

**IDOR (Insecure Direct Object Reference)**: When an application exposes internal object references without proper authorization checks.

### Step-by-Step Implementation

#### Step 7.1: Create MCP Server

```bash
cd pentest-engine
mkdir -p mcp-servers/auth-tester-mcp/src
cd mcp-servers/auth-tester-mcp
# ... (similar setup as previous phases)
```

#### Step 7.2: Create Identity Store

Create `src/identity-store.ts`:

```typescript
import * as fs from 'fs';
import * as yaml from 'js-yaml';

export interface TestIdentity {
  identity_id: string;
  label: string;
  roles: string[];
  tenant_id?: string;
  auth_header: string;  // e.g., "Bearer <token>" or "Basic <base64>"
  auth_type: 'bearer' | 'basic' | 'api_key' | 'cookie';
  cookies?: Record<string, string>;
}

export class IdentityStore {
  private identities: Map<string, TestIdentity> = new Map();

  loadFromFile(filePath: string): void {
    const content = fs.readFileSync(filePath, 'utf-8');
    const data = yaml.load(content) as { identities: TestIdentity[] };

    for (const identity of data.identities) {
      this.identities.set(identity.identity_id, identity);
    }

    console.error(`[auth-tester] Loaded ${this.identities.size} identities`);
  }

  get(identityId: string): TestIdentity | undefined {
    return this.identities.get(identityId);
  }

  list(): TestIdentity[] {
    return Array.from(this.identities.values());
  }

  getAuthHeaders(identityId: string): Record<string, string> {
    const identity = this.get(identityId);
    if (!identity) return {};

    const headers: Record<string, string> = {};

    switch (identity.auth_type) {
      case 'bearer':
      case 'basic':
        headers['Authorization'] = identity.auth_header;
        break;
      case 'api_key':
        headers['X-API-Key'] = identity.auth_header;
        break;
      case 'cookie':
        if (identity.cookies) {
          headers['Cookie'] = Object.entries(identity.cookies)
            .map(([k, v]) => `${k}=${v}`)
            .join('; ');
        }
        break;
    }

    return headers;
  }
}
```

#### Step 7.3: Create Differential Tester

Create `src/diff-tester.ts`:

```typescript
export interface DiffTestRequest {
  method: string;
  url: string;
  headers?: Record<string, string>;
  body?: string;
}

export interface DiffTestResult {
  identity_id: string;
  status_code: number;
  response_length: number;
  response_hash: string;
  contains_target_data: boolean;
  timing_ms: number;
  error?: string;
}

export interface DiffTestSummary {
  request: DiffTestRequest;
  results: DiffTestResult[];
  analysis: {
    status_codes_differ: boolean;
    response_lengths_differ: boolean;
    potential_bola: boolean;
    potential_idor: boolean;
    recommendation: string;
  };
}

export class DifferentialTester {
  /**
   * Analyze results from multiple identity tests
   */
  analyzeResults(request: DiffTestRequest, results: DiffTestResult[]): DiffTestSummary {
    const statusCodes = new Set(results.map(r => r.status_code));
    const responseLengths = results.map(r => r.response_length);
    const avgLength = responseLengths.reduce((a, b) => a + b, 0) / responseLengths.length;
    const lengthVariance = responseLengths.some(l => Math.abs(l - avgLength) > avgLength * 0.1);

    // Detect potential BOLA/IDOR patterns
    const successfulResults = results.filter(r => r.status_code >= 200 && r.status_code < 300);
    const failedResults = results.filter(r => r.status_code >= 400);

    // Pattern: Multiple users can access same object (potential BOLA)
    const potentialBola = successfulResults.length > 1 &&
                          new Set(successfulResults.map(r => r.response_hash)).size === 1;

    // Pattern: Different response content for same object ID (potential IDOR)
    const potentialIdor = successfulResults.length > 1 &&
                          new Set(successfulResults.map(r => r.response_hash)).size > 1;

    let recommendation = 'No authorization issues detected.';

    if (potentialBola) {
      recommendation = 'POTENTIAL BOLA: Multiple identities can access the same object. Verify if this is expected authorization behavior.';
    } else if (potentialIdor) {
      recommendation = 'POTENTIAL IDOR: Different identities receive different data for the same object reference. Investigate data isolation.';
    } else if (statusCodes.size === 1 && successfulResults.length === results.length) {
      recommendation = 'All identities received successful responses. May need manual review of response content.';
    }

    return {
      request,
      results,
      analysis: {
        status_codes_differ: statusCodes.size > 1,
        response_lengths_differ: lengthVariance,
        potential_bola: potentialBola,
        potential_idor: potentialIdor,
        recommendation
      }
    };
  }

  /**
   * Generate hash for response comparison
   */
  hashResponse(body: string): string {
    // Simple hash for comparison (in production, use crypto)
    let hash = 0;
    for (let i = 0; i < body.length; i++) {
      const char = body.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash;
    }
    return hash.toString(16);
  }
}
```

#### Step 7.4: Create MCP Server

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { IdentityStore } from './identity-store.js';
import { DifferentialTester, DiffTestRequest, DiffTestResult } from './diff-tester.js';

const IDENTITY_FILE = process.env.IDENTITY_FILE || './scope/identities.yaml';
const identityStore = new IdentityStore();
const diffTester = new DifferentialTester();

try {
  identityStore.loadFromFile(IDENTITY_FILE);
} catch (error) {
  console.error('[auth-tester] Warning: Could not load identities file');
}

const server = new McpServer({
  name: 'auth-tester',
  version: '1.0.0',
});

// Tool: Get available identities
server.tool(
  'auth_get_identities',
  'List available test identities.',
  { type: 'object', properties: {} },
  async () => {
    const identities = identityStore.list().map(i => ({
      identity_id: i.identity_id,
      label: i.label,
      roles: i.roles,
      auth_type: i.auth_type
    }));
    return { content: [{ type: 'text', text: JSON.stringify(identities, null, 2) }] };
  }
);

// Tool: Differential test
server.tool(
  'auth_diff_test',
  'Test the same request with multiple identities to detect authorization issues.',
  {
    type: 'object',
    properties: {
      method: { type: 'string' },
      url: { type: 'string' },
      headers: { type: 'object', additionalProperties: { type: 'string' } },
      body: { type: 'string' },
      identity_ids: {
        type: 'array',
        items: { type: 'string' },
        description: 'List of identity IDs to test with'
      }
    },
    required: ['method', 'url', 'identity_ids']
  },
  async (args: {
    method: string;
    url: string;
    headers?: Record<string, string>;
    body?: string;
    identity_ids: string[];
  }) => {
    const request: DiffTestRequest = {
      method: args.method,
      url: args.url,
      headers: args.headers,
      body: args.body
    };

    const results: DiffTestResult[] = [];

    for (const identityId of args.identity_ids) {
      const authHeaders = identityStore.getAuthHeaders(identityId);

      try {
        const startTime = Date.now();
        const response = await fetch(args.url, {
          method: args.method,
          headers: { ...args.headers, ...authHeaders },
          body: args.body
        });
        const endTime = Date.now();

        const responseBody = await response.text();

        results.push({
          identity_id: identityId,
          status_code: response.status,
          response_length: responseBody.length,
          response_hash: diffTester.hashResponse(responseBody),
          contains_target_data: responseBody.length > 0,
          timing_ms: endTime - startTime
        });
      } catch (error) {
        results.push({
          identity_id: identityId,
          status_code: 0,
          response_length: 0,
          response_hash: '',
          contains_target_data: false,
          timing_ms: 0,
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }

    const summary = diffTester.analyzeResults(request, results);

    return { content: [{ type: 'text', text: JSON.stringify(summary, null, 2) }] };
  }
);

async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error('[auth-tester] MCP server started');
}

main().catch(console.error);
```

### Verification Checklist

- [ ] Can load identity file
- [ ] `auth_get_identities` returns configured identities
- [ ] `auth_diff_test` sends requests with different auth headers
- [ ] Analysis correctly identifies BOLA/IDOR patterns

---

## 16.8) Phase 8: Validation Engine - Summary

### Objective
Implement finding validation with reproduction, negative controls, and cross-identity verification.

### Key Features
- **Reproduction**: Run the same test N times to confirm consistency
- **Negative Control**: Verify the vulnerability doesn't exist in control scenarios
- **Cross-Identity**: Confirm different users get different results
- **Confidence Scoring**: Calculate confidence based on validation results

### MCP Tools
| Tool | Purpose |
|------|---------|
| `validate_repro` | Reproduce finding N times |
| `validate_negative_control` | Run negative control test |
| `validate_cross_identity` | Cross-identity validation |
| `validate_promote` | Promote to confirmed finding |

---

## 16.9) Phase 9: Evidence & Reporting - Summary

### Objective
Bundle evidence with correlation IDs, apply redaction rules, and generate reports.

### Key Features
- **Evidence Bundling**: Collect request/response pairs with metadata
- **Redaction**: Remove sensitive data (passwords, tokens) before storage
- **Report Generation**: Generate Markdown/HTML reports
- **Export**: Create ZIP archives of evidence packs

### MCP Tools
| Tool | Purpose |
|------|---------|
| `evidence_bundle` | Create evidence pack for finding |
| `evidence_add_artifact` | Add artifact to bundle |
| `evidence_export` | Export as ZIP |
| `evidence_generate_report` | Generate finding report |

---

## 16.10) Phase 10: Advanced Tools - Summary

### Objective
Add advanced scanning capabilities and automation skills.

### Components

#### Nuclei MCP Server
- Wrapper around Nuclei vulnerability scanner
- Template-based scanning with rate limits
- Scope enforcement before scanning

#### Fuzzer MCP Server
- Schema-based fuzzing using OpenAPI specs
- Parameter mutation with bounds
- Signal detection and triage

#### Skills
- **pentest-planner**: Generates structured test hypotheses
- **vulnerability-validator**: Validates findings with controls

#### Custom Commands
- `/scope`: Display current scope
- `/engage`: Start engagement
- `/killswitch`: Emergency stop

### Final Configuration

After Phase 10, your `.gemini/settings.json` should include all MCP servers:

```json
{
  "mcpServers": {
    "scope-guard": { ... },
    "http-client": { ... },
    "burp": { ... },
    "openapi": { ... },
    "world-model": { ... },
    "auth-tester": { ... },
    "validator": { ... },
    "evidence": { ... },
    "nuclei": { ... }
  }
}
```

---

## 17) MCP Server Configurations (Complete Reference)

### 17.1 Full settings.json Example

Create `.gemini/settings.json` with the following MCP server configurations:

```json
{
  "mcpServers": {
    "scope-guard": {
      "command": "node",
      "args": ["mcp-servers/scope-guard-mcp/dist/server.js"],
      "env": {
        "SCOPE_FILE": "./scope/engagement.yaml",
        "FAIL_CLOSED": "true"
      },
      "timeout": 5000,
      "trust": true,
      "description": "Validates all targets against scope allowlist"
    },

    "burp": {
      "command": "node",
      "args": ["mcp-servers/burp-mcp/dist/server.js"],
      "env": {
        "BURP_API_URL": "http://127.0.0.1:1337",
        "BURP_API_KEY": "${BURP_API_KEY}"
      },
      "timeout": 60000,
      "trust": false,
      "includeTools": [
        "burp_proxy_send",
        "burp_get_history",
        "burp_get_findings",
        "burp_export_evidence",
        "burp_scope_check"
      ],
      "excludeTools": [
        "burp_active_scan",
        "burp_intruder_attack",
        "burp_collaborator"
      ],
      "description": "Burp Suite proxy and passive scanning"
    },

    "http-client": {
      "command": "node",
      "args": ["mcp-servers/http-client-mcp/dist/server.js"],
      "env": {
        "PROXY_URL": "http://127.0.0.1:8080",
        "MAX_RPS": "10",
        "MAX_CONCURRENT": "5",
        "MAX_TOTAL_REQUESTS": "1000",
        "SCOPE_MCP": "scope-guard"
      },
      "timeout": 30000,
      "trust": false,
      "description": "Rate-limited HTTP client with scope enforcement"
    },

    "openapi": {
      "command": "node",
      "args": ["mcp-servers/openapi-mcp/dist/server.js"],
      "timeout": 15000,
      "trust": true,
      "description": "OpenAPI spec parser and endpoint enumerator"
    },

    "auth-tester": {
      "command": "node",
      "args": ["mcp-servers/auth-tester-mcp/dist/server.js"],
      "env": {
        "IDENTITY_STORE": "./scope/identities.yaml",
        "HTTP_MCP": "http-client"
      },
      "timeout": 60000,
      "trust": false,
      "description": "Authorization differential testing (BOLA/IDOR)"
    },

    "world-model": {
      "command": "node",
      "args": ["mcp-servers/world-model-mcp/dist/server.js"],
      "env": {
        "DB_PATH": "./data/world-model.db"
      },
      "timeout": 10000,
      "trust": true,
      "description": "Structured state store for assets, hypotheses, findings"
    },

    "evidence": {
      "command": "node",
      "args": ["mcp-servers/evidence-mcp/dist/server.js"],
      "env": {
        "EVIDENCE_DIR": "./evidence",
        "REDACT_SECRETS": "true",
        "ENCRYPT_AT_REST": "true"
      },
      "timeout": 15000,
      "trust": true,
      "description": "Evidence bundler with redaction"
    },

    "validator": {
      "command": "node",
      "args": ["mcp-servers/validator-mcp/dist/server.js"],
      "env": {
        "REPRO_COUNT": "3",
        "REQUIRE_NEGATIVE_CONTROL": "true"
      },
      "timeout": 120000,
      "trust": false,
      "description": "Finding validation with repro and controls"
    },

    "nuclei": {
      "command": "node",
      "args": ["mcp-servers/nuclei-mcp/dist/server.js"],
      "env": {
        "NUCLEI_PATH": "/usr/local/bin/nuclei",
        "TEMPLATES_DIR": "./nuclei-templates",
        "PROXY_URL": "http://127.0.0.1:8080",
        "RATE_LIMIT": "10"
      },
      "timeout": 300000,
      "trust": false,
      "excludeTools": [
        "nuclei_scan_all",
        "nuclei_scan_cves"
      ],
      "description": "Nuclei vulnerability scanner (bounded)"
    }
  }
}
```

### 17.2 MCP Server Tool Reference

#### scope-guard-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `scope_validate_target` | Check if URL/IP is in scope | `target: string` |
| `scope_get_allowlist` | Get current allowlist | - |
| `scope_get_constraints` | Get rate limits and budgets | - |
| `scope_check_budget` | Check remaining request budget | `identity_id?: string` |

#### burp-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `burp_proxy_send` | Send request through proxy | `request: object, tags: object` |
| `burp_get_history` | Get proxy history | `filter?: object, limit?: number` |
| `burp_get_findings` | Get passive scan findings | `severity?: string` |
| `burp_export_evidence` | Export req/res for evidence | `history_id: number` |
| `burp_scope_check` | Check if URL in Burp scope | `url: string` |

#### http-client-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `http_send` | Send HTTP request (rate-limited) | `method, url, headers?, body?` |
| `http_send_batch` | Send multiple requests | `requests: array, concurrency?: number` |
| `http_get_stats` | Get request statistics | - |

#### openapi-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `openapi_ingest` | Load and parse OpenAPI spec | `spec_path: string` or `spec_url: string` |
| `openapi_list_endpoints` | List all endpoints | `filter?: object` |
| `openapi_get_schema` | Get schema for endpoint | `path: string, method: string` |
| `openapi_generate_request` | Generate sample request | `path: string, method: string` |

#### auth-tester-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `auth_diff_test` | Test authorization differential | `request: object, identities: array` |
| `auth_get_identities` | List available test identities | - |
| `auth_replay_with_identity` | Replay request with different identity | `request_id, identity_id` |

#### world-model-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `wm_add_endpoint` | Register discovered endpoint | `endpoint: object` |
| `wm_add_hypothesis` | Create new hypothesis | `hypothesis: object` |
| `wm_update_hypothesis` | Update hypothesis status | `id, status, confidence?` |
| `wm_add_observation` | Record observation/fact | `observation: object` |
| `wm_add_finding` | Record validated finding | `finding: object` |
| `wm_query` | Query world model | `query: object` |

#### evidence-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `evidence_bundle` | Create evidence pack | `finding_id, artifacts: array` |
| `evidence_add_artifact` | Add artifact to bundle | `bundle_id, artifact: object` |
| `evidence_export` | Export evidence pack | `bundle_id, format?: string` |

#### validator-mcp Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `validate_repro` | Reproduce finding N times | `finding_id, count?: number` |
| `validate_negative_control` | Run negative control test | `finding_id, control_config` |
| `validate_cross_identity` | Cross-identity validation | `finding_id, identities: array` |
| `validate_promote` | Promote to confirmed finding | `finding_id` |

### 17.3 Additional Security MCP Servers

#### nuclei-mcp (Vulnerability Scanner)

```json
{
  "nuclei": {
    "command": "python",
    "args": ["-m", "nuclei_mcp"],
    "env": {
      "NUCLEI_PATH": "/usr/local/bin/nuclei",
      "RATE_LIMIT": "10",
      "PROXY": "http://127.0.0.1:8080"
    },
    "timeout": 300000,
    "trust": false,
    "includeTools": ["nuclei_scan_single", "nuclei_scan_template"],
    "excludeTools": ["nuclei_scan_all"]
  }
}
```

#### zap-mcp (OWASP ZAP)

```json
{
  "zap": {
    "command": "node",
    "args": ["mcp-servers/zap-mcp/dist/server.js"],
    "env": {
      "ZAP_API_URL": "http://127.0.0.1:8081",
      "ZAP_API_KEY": "${ZAP_API_KEY}"
    },
    "timeout": 60000,
    "trust": false,
    "includeTools": ["zap_spider", "zap_passive_scan", "zap_get_alerts"],
    "excludeTools": ["zap_active_scan", "zap_attack"]
  }
}
```

#### sqlmap-mcp (SQL Injection Testing)

```json
{
  "sqlmap": {
    "command": "python",
    "args": ["-m", "sqlmap_mcp"],
    "env": {
      "SQLMAP_PATH": "/usr/local/bin/sqlmap",
      "PROXY": "http://127.0.0.1:8080",
      "LEVEL": "1",
      "RISK": "1"
    },
    "timeout": 180000,
    "trust": false
  }
}
```

### 17.4 Creating Custom MCP Servers

Each MCP server should follow this structure:

```typescript
// mcp-servers/my-tool-mcp/src/server.ts
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';

const server = new McpServer({
  name: 'my-tool',
  version: '1.0.0',
});

// Register tools with schemas
server.tool(
  'my_tool_action',
  'Description of what this tool does',
  {
    type: 'object',
    properties: {
      target: { type: 'string', description: 'Target URL' },
      options: { type: 'object', description: 'Additional options' }
    },
    required: ['target']
  },
  async (args) => {
    // 1. Validate inputs
    // 2. Check scope (call scope-guard if needed)
    // 3. Execute bounded action
    // 4. Return structured result

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          success: true,
          data: { /* results */ },
          correlation_id: generateCorrelationId()
        })
      }]
    };
  }
);

// Start server
const transport = new StdioServerTransport();
await server.connect(transport);
```

### 17.5 MCP Trust and Approval Configuration

```json
{
  "mcpServers": {
    "safe-tool": {
      "command": "...",
      "trust": true  // No confirmation dialogs
    },
    "risky-tool": {
      "command": "...",
      "trust": false  // Requires confirmation for each call
    }
  }
}
```

**Trust Levels:**
- `trust: true` - Tool executes without user confirmation
- `trust: false` (default) - Each invocation shows confirmation dialog
- User can allow-list tools/servers during runtime via confirmation dialog options

---

## 18) Skills for Pentest Workflows

### 18.1 Pentest Planner Skill

Create `.gemini/skills/pentest-planner/SKILL.md`:

```markdown
---
name: pentest-planner
description: Generates structured hypotheses and test plans for web/API security testing
---

# Pentest Planner

You are a security testing planner. Generate structured test hypotheses.

## Output Format

Always output JSON with this structure:
\`\`\`json
{
  "hypothesis_id": "H-001",
  "action_id": "A-001",
  "capability": "auth_diff_test",
  "target": "endpoint path",
  "inputs": {},
  "expected_signal": "description",
  "validation_plan": "how to validate",
  "risk_level": "low|medium|high"
}
\`\`\`

## Constraints
- Only propose capabilities from the available MCP tools
- Never propose raw commands or arbitrary code execution
- Always include a validation plan
- Flag high-risk actions explicitly
```

### 18.2 Vulnerability Validator Skill

Create `.gemini/skills/vulnerability-validator/SKILL.md`:

```markdown
---
name: vulnerability-validator
description: Validates potential vulnerabilities with reproduction and controls
---

# Vulnerability Validator

You validate security findings with rigorous controls.

## Validation Requirements
1. Reproduce the finding at least 3 times
2. Run negative control (should fail in control scenario)
3. Run cross-identity control (different user should get different result)
4. Document evidence with correlation IDs

## Output
Only mark findings as CONFIRMED if all validation passes.
```

---

## 19) Custom Commands

### 19.1 /scope Command

Create `.gemini/commands/scope.toml`:

```toml
prompt = """
Load and display the current engagement scope.
Use the scope-guard MCP to:
1. Load the scope file
2. Display allowlisted domains and IPs
3. Show current constraints (rate limits, budgets)
4. List available test identities

{{args}}
"""
description = "Display current engagement scope"
```

### 19.2 /engage Command

Create `.gemini/commands/engage.toml`:

```toml
prompt = """
Start a new pentest engagement session.
1. Validate scope file exists and is valid
2. Initialize world model
3. Start evidence logging
4. Display engagement summary

Engagement target: {{args}}
"""
description = "Start a pentest engagement"
```

### 19.3 /killswitch Command

Create `.gemini/commands/killswitch.toml`:

```toml
prompt = """
EMERGENCY STOP - Immediately halt all testing activities.
1. Stop all pending requests
2. Close all MCP connections
3. Lock engagement state
4. Export current evidence

Reason: {{args}}
"""
description = "Emergency stop all testing"
```

---

## Appendix A: Example "Forbidden Actions" List (Sandbox Defaults)
- Password reset or recovery abuse testing without explicit approval
- Account lockout testing without explicit approval
- Bulk data extraction or enumeration beyond small samples
- Out-of-band callbacks (unless explicitly authorized)
- Long fuzzing campaigns without approval

---

## Appendix B: Definitions
- **Capability**: A bounded, safe tool function exposed to the agent (e.g., `auth_diff_test`).
- **Action**: A single invocation of a capability with specific inputs and constraints.
- **Observation**: Normalized output facts with provenance and confidence.
- **Finding**: A validated, evidenced vulnerability with repro steps and remediation.
- **MCP (Model Context Protocol)**: Protocol for exposing tools to LLMs with structured schemas.
- **MCP Server**: A process that implements the MCP protocol and exposes tools.
- **MCP Transport**: Communication mechanism (stdio, SSE, HTTP streaming).
- **Trust Level**: MCP server setting that determines if user confirmation is required.
- **Gemini-CLI**: Google's open-source AI CLI tool used as the base framework.
- **Skill**: A SKILL.md file that provides context-aware instructions to the LLM.
- **Custom Command**: A TOML file defining a reusable prompt accessible via `/command`.

---

## Appendix C: Minimal "Definition of Done" for an OC2-credible Prototype (Internal)
- Demonstrates:
  - structured hypotheses and actions,
  - HITL approvals,
  - bounded execution under budgets,
  - validation with controls,
  - evidence packs with correlation IDs.
- Produces at least one validated sandbox finding without manual tool driving.

---

## Appendix D: Quick Start - Minimal MCP Setup

### Step 1: Clone and Build Base Framework

```bash
git clone https://github.com/google-gemini/gemini-cli.git
cd gemini-cli
npm install && npm run build
```

### Step 2: Create Minimal MCP Server (scope-guard)

```bash
mkdir -p mcp-servers/scope-guard-mcp/src
cd mcp-servers/scope-guard-mcp
npm init -y
npm install @modelcontextprotocol/sdk
```

Create `src/server.ts`:

```typescript
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import * as fs from 'fs';
import * as yaml from 'js-yaml';

interface Scope {
  allowlist: { domains: string[]; ip_ranges: string[] };
  constraints: { max_rps: number; max_total_requests: number };
}

const scopeFile = process.env.SCOPE_FILE || './scope/engagement.yaml';
let scope: Scope;

try {
  scope = yaml.load(fs.readFileSync(scopeFile, 'utf8')) as Scope;
} catch (e) {
  console.error('Failed to load scope file:', e);
  process.exit(1);
}

const server = new McpServer({
  name: 'scope-guard',
  version: '1.0.0',
});

server.tool(
  'scope_validate_target',
  'Check if a URL or IP is within the engagement scope',
  {
    type: 'object',
    properties: {
      target: { type: 'string', description: 'URL or IP to validate' }
    },
    required: ['target']
  },
  async ({ target }) => {
    const url = new URL(target);
    const isAllowed = scope.allowlist.domains.some(d =>
      url.hostname === d || url.hostname.endsWith('.' + d)
    );

    return {
      content: [{
        type: 'text',
        text: JSON.stringify({
          target,
          in_scope: isAllowed,
          reason: isAllowed ? 'Domain in allowlist' : 'Domain NOT in allowlist'
        })
      }]
    };
  }
);

server.tool(
  'scope_get_constraints',
  'Get current rate limits and budget constraints',
  { type: 'object', properties: {} },
  async () => {
    return {
      content: [{
        type: 'text',
        text: JSON.stringify(scope.constraints)
      }]
    };
  }
);

const transport = new StdioServerTransport();
await server.connect(transport);
```

### Step 3: Configure MCP in Gemini-CLI

Create `.gemini/settings.json`:

```json
{
  "mcpServers": {
    "scope-guard": {
      "command": "npx",
      "args": ["ts-node", "mcp-servers/scope-guard-mcp/src/server.ts"],
      "env": {
        "SCOPE_FILE": "./scope/engagement.yaml"
      },
      "trust": true
    }
  }
}
```

### Step 4: Create Scope File

Create `scope/engagement.yaml`:

```yaml
engagement_id: "TEST-001"
allowlist:
  domains:
    - "testapp.local"
    - "api.testapp.local"
  ip_ranges:
    - "192.168.1.0/24"
constraints:
  max_rps: 10
  max_concurrent: 5
  max_total_requests: 1000
```

### Step 5: Run

```bash
cd gemini-cli
npm run start

# In the CLI, test the MCP tool:
# > Check if https://testapp.local/api/users is in scope
```

---

## Appendix E: Available MCP Tool Repositories

### Security-Focused MCP Servers

| Repository | Description | Status |
|------------|-------------|--------|
| [anthropic/mcp-servers](https://github.com/anthropics/mcp-servers) | Reference MCP implementations | Official |
| [AshwinSanthanam/mcp-security-tools](https://github.com/AshwinSanthanam/mcp-security-tools) | Security scanner integrations | Community |
| Custom (this project) | Pentest-specific MCP servers | Build |

### Recommended Third-Party MCP Servers

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@anthropic/mcp-server-filesystem", "./evidence"],
      "trust": true,
      "description": "Read/write evidence files"
    },
    "sqlite": {
      "command": "npx",
      "args": ["-y", "@anthropic/mcp-server-sqlite", "./data/world-model.db"],
      "trust": true,
      "description": "World model database"
    }
  }
}
```

---

## Appendix F: Gemini-CLI Key Configuration Reference

### Model Selection

```json
{
  "model": "gemini-2.0-flash",
  "embeddingModel": "text-embedding-004"
}
```

### Approval Modes

```json
{
  "approvalMode": "INTERACTIVE"
}
```

Options:
- `AUTOMATIC` - No confirmations (dangerous for pentest)
- `INTERACTIVE` - Confirm risky actions (recommended)
- `APPROVAL_REQUIRED` - Confirm all actions

### Tool Filtering (Global)

```json
{
  "coreTools": ["read_file", "write_file", "shell"],
  "excludeTools": ["dangerous_tool"]
}
```

---

## Appendix G: Canonical JSON Schemas

### G.1 Scope Schema
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/engagement-scope.json",
  "type": "object",
  "required": [
    "schema_version",
    "engagement_id",
    "allowlist",
    "constraints",
    "approval_policy",
    "evidence_policy"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "engagement_id": { "type": "string", "minLength": 3 },
    "allowlist": {
      "type": "object",
      "required": ["domains", "ip_ranges"],
      "additionalProperties": false,
      "properties": {
        "domains": { "type": "array", "minItems": 1, "items": { "type": "string" } },
        "ip_ranges": { "type": "array", "minItems": 1, "items": { "type": "string" } },
        "services": { "type": "array", "items": { "type": "string" } }
      }
    },
    "denylist": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "domains": { "type": "array", "items": { "type": "string" } },
        "ip_ranges": { "type": "array", "items": { "type": "string" } },
        "services": { "type": "array", "items": { "type": "string" } }
      }
    },
    "credentials": { "type": "array", "items": { "type": "string" } },
    "constraints": {
      "type": "object",
      "required": ["max_rps", "max_concurrency", "max_total_requests", "max_object_enumeration"],
      "additionalProperties": false,
      "properties": {
        "max_rps": { "type": "integer", "minimum": 1 },
        "max_concurrency": { "type": "integer", "minimum": 1 },
        "max_total_requests": { "type": "integer", "minimum": 1 },
        "max_object_enumeration": { "type": "integer", "minimum": 1 },
        "time_window": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "start": { "type": "string", "format": "date-time" },
            "end": { "type": "string", "format": "date-time" }
          }
        }
      }
    },
    "forbidden_actions": { "type": "array", "items": { "type": "string" } },
    "approval_policy": {
      "type": "object",
      "required": ["risk_levels"],
      "additionalProperties": false,
      "properties": {
        "risk_levels": {
          "type": "object",
          "required": ["medium", "high"],
          "additionalProperties": false,
          "properties": {
            "low": { "type": "boolean" },
            "medium": { "type": "boolean" },
            "high": { "type": "boolean" }
          }
        }
      }
    },
    "evidence_policy": {
      "type": "object",
      "required": ["store_raw_bodies", "redaction_rules"],
      "additionalProperties": false,
      "properties": {
        "store_raw_bodies": { "type": "boolean" },
        "redaction_rules": { "type": "array", "items": { "type": "string" } },
        "retention_days": { "type": "integer", "minimum": 1 }
      }
    },
    "metadata": { "type": "object", "additionalProperties": true }
  }
}
```

### G.2 Planner Output Schema
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/planner-output.json",
  "type": "object",
  "required": [
    "schema_version",
    "hypothesis_id",
    "action_id",
    "capability",
    "target",
    "inputs",
    "expected_signal",
    "validation_plan",
    "risk_level"
  ],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "hypothesis_id": { "type": "string" },
    "action_id": { "type": "string" },
    "capability": { "type": "string" },
    "target": {
      "oneOf": [
        {
          "type": "object",
          "required": ["endpoint_id"],
          "additionalProperties": false,
          "properties": {
            "endpoint_id": { "type": "string" },
            "method": { "type": "string" }
          }
        },
        {
          "type": "object",
          "required": ["url"],
          "additionalProperties": false,
          "properties": {
            "url": { "type": "string", "format": "uri" },
            "method": { "type": "string" }
          }
        }
      ]
    },
    "inputs": { "type": "object" },
    "expected_signal": { "type": "string" },
    "validation_plan": {
      "type": "object",
      "required": ["repro_attempts", "negative_control", "cross_identity"],
      "additionalProperties": false,
      "properties": {
        "repro_attempts": { "type": "integer", "minimum": 1 },
        "negative_control": { "type": "string" },
        "cross_identity": { "type": "boolean" }
      }
    },
    "risk_level": { "type": "string", "enum": ["low", "medium", "high"] },
    "notes": { "type": "string" }
  }
}
```

### G.3 Tool Request/Response Schemas
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/tool-request.json",
  "type": "object",
  "required": ["tool_name", "action_id", "engagement_id", "inputs"],
  "additionalProperties": false,
  "properties": {
    "tool_name": { "type": "string" },
    "action_id": { "type": "string" },
    "engagement_id": { "type": "string" },
    "run_id": { "type": "string" },
    "hypothesis_id": { "type": "string" },
    "identity_id": { "type": "string" },
    "risk_level": { "type": "string", "enum": ["low", "medium", "high"] },
    "budget": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "max_requests": { "type": "integer", "minimum": 1 },
        "timeout_ms": { "type": "integer", "minimum": 1 }
      }
    },
    "inputs": { "type": "object" }
  }
}
```

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/tool-response.json",
  "type": "object",
  "required": ["status", "observations"],
  "additionalProperties": false,
  "properties": {
    "status": { "type": "string", "enum": ["ok", "error", "blocked"] },
    "observations": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["type", "confidence", "data", "provenance"],
        "additionalProperties": false,
        "properties": {
          "type": { "type": "string" },
          "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
          "data": { "type": "object" },
          "provenance": {
            "type": "object",
            "required": ["tool_name", "timestamp"],
            "additionalProperties": false,
            "properties": {
              "tool_name": { "type": "string" },
              "timestamp": { "type": "string", "format": "date-time" },
              "request_id": { "type": "string" },
              "response_id": { "type": "string" }
            }
          }
        }
      }
    },
    "evidence_refs": { "type": "array", "items": { "type": "string" } },
    "errors": { "type": "array", "items": { "type": "string" } },
    "metrics": { "type": "object", "additionalProperties": true }
  }
}
```

### G.4 World Model Schema
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/world-model.json",
  "$defs": {
    "timestamp": { "type": "string", "format": "date-time" },
    "asset": {
      "type": "object",
      "required": ["asset_id", "kind", "name", "created_at"],
      "additionalProperties": false,
      "properties": {
        "asset_id": { "type": "string" },
        "kind": { "type": "string", "enum": ["domain", "ip", "service"] },
        "name": { "type": "string" },
        "tags": { "type": "array", "items": { "type": "string" } },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "endpoint": {
      "type": "object",
      "required": ["endpoint_id", "method", "path", "asset_id", "created_at"],
      "additionalProperties": false,
      "properties": {
        "endpoint_id": { "type": "string" },
        "method": { "type": "string" },
        "path": { "type": "string" },
        "asset_id": { "type": "string" },
        "openapi_ref": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "identity": {
      "type": "object",
      "required": ["identity_id", "label", "created_at"],
      "additionalProperties": false,
      "properties": {
        "identity_id": { "type": "string" },
        "label": { "type": "string" },
        "roles": { "type": "array", "items": { "type": "string" } },
        "tenant_id": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "session": {
      "type": "object",
      "required": ["session_id", "identity_id", "created_at"],
      "additionalProperties": false,
      "properties": {
        "session_id": { "type": "string" },
        "identity_id": { "type": "string" },
        "token_ref": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" },
        "expires_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "observation": {
      "type": "object",
      "required": ["observation_id", "action_id", "type", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "observation_id": { "type": "string" },
        "action_id": { "type": "string" },
        "type": { "type": "string" },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "data": { "type": "object" },
        "evidence_refs": { "type": "array", "items": { "type": "string" } },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "hypothesis": {
      "type": "object",
      "required": ["hypothesis_id", "description", "status", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "hypothesis_id": { "type": "string" },
        "description": { "type": "string" },
        "status": { "type": "string", "enum": ["new", "testing", "validated", "rejected"] },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "created_at": { "$ref": "#/$defs/timestamp" },
        "updated_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "action": {
      "type": "object",
      "required": ["action_id", "capability", "status", "requested_at"],
      "additionalProperties": false,
      "properties": {
        "action_id": { "type": "string" },
        "capability": { "type": "string" },
        "target": { "type": "object" },
        "status": { "type": "string", "enum": ["proposed", "approved", "blocked", "executed", "failed"] },
        "requested_at": { "$ref": "#/$defs/timestamp" },
        "approved_at": { "$ref": "#/$defs/timestamp" },
        "executed_at": { "$ref": "#/$defs/timestamp" }
      }
    },
    "finding": {
      "type": "object",
      "required": ["finding_id", "title", "severity", "status", "confidence", "created_at"],
      "additionalProperties": false,
      "properties": {
        "finding_id": { "type": "string" },
        "title": { "type": "string" },
        "severity": { "type": "string", "enum": ["low", "medium", "high", "critical"] },
        "status": { "type": "string", "enum": ["draft", "validated", "rejected"] },
        "hypothesis_id": { "type": "string" },
        "evidence_refs": { "type": "array", "items": { "type": "string" } },
        "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
        "remediation": { "type": "string" },
        "created_at": { "$ref": "#/$defs/timestamp" }
      }
    }
  }
}
```

### G.5 Run Manifest and Action Ledger
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/run-manifest.json",
  "type": "object",
  "required": ["schema_version", "engagement_id", "run_id", "started_at", "scope_hash", "environment"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "engagement_id": { "type": "string" },
    "run_id": { "type": "string" },
    "started_at": { "type": "string", "format": "date-time" },
    "ended_at": { "type": "string", "format": "date-time" },
    "scope_hash": { "type": "string" },
    "environment": { "type": "string", "enum": ["SANDBOX", "STAGING"] },
    "operator": { "type": "string" },
    "tool_versions": { "type": "object", "additionalProperties": { "type": "string" } },
    "config_hash": { "type": "string" }
  }
}
```

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/action-ledger-entry.json",
  "type": "object",
  "required": ["schema_version", "action_id", "tool_name", "status", "requested_at"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "action_id": { "type": "string" },
    "hypothesis_id": { "type": "string" },
    "tool_name": { "type": "string" },
    "status": { "type": "string", "enum": ["proposed", "approved", "blocked", "executed", "failed"] },
    "requested_at": { "type": "string", "format": "date-time" },
    "approved_at": { "type": "string", "format": "date-time" },
    "executed_at": { "type": "string", "format": "date-time" },
    "correlation_ids": { "type": "object", "additionalProperties": { "type": "string" } },
    "request_hash": { "type": "string" },
    "response_hash": { "type": "string" },
    "error": { "type": "string" }
  }
}
```

### G.6 Evidence Schemas
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-summary.json",
  "type": "object",
  "required": ["schema_version", "finding_id", "title", "severity", "confidence", "created_at"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "finding_id": { "type": "string" },
    "title": { "type": "string" },
    "severity": { "type": "string", "enum": ["low", "medium", "high", "critical"] },
    "status": { "type": "string", "enum": ["draft", "validated", "rejected"] },
    "confidence": { "type": "number", "minimum": 0, "maximum": 1 },
    "created_at": { "type": "string", "format": "date-time" },
    "hypothesis_id": { "type": "string" },
    "impact": { "type": "string" },
    "remediation": { "type": "string" },
    "evidence_refs": { "type": "array", "items": { "type": "string" } }
  }
}
```

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-validation.json",
  "type": "object",
  "required": ["schema_version", "repro_attempts", "results"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "repro_attempts": { "type": "integer", "minimum": 1 },
    "negative_control": { "type": "string" },
    "cross_identity": { "type": "boolean" },
    "results": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["attempt", "status"],
        "additionalProperties": false,
        "properties": {
          "attempt": { "type": "integer", "minimum": 1 },
          "status": { "type": "string", "enum": ["pass", "fail"] },
          "notes": { "type": "string" }
        }
      }
    }
  }
}
```

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://example.local/schemas/evidence-invariants.json",
  "type": "object",
  "required": ["schema_version", "invariants"],
  "additionalProperties": false,
  "properties": {
    "schema_version": { "type": "string" },
    "invariants": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["field", "observation"],
        "additionalProperties": false,
        "properties": {
          "field": { "type": "string" },
          "observation": { "type": "string" },
          "evidence_ref": { "type": "string" }
        }
      }
    }
  }
}
```
