# AutoPentest Setup Guide

## Prerequisites

- **Python 3.10+** (required by the `mcp` SDK and asyncpg)
- **Docker Engine + Docker Compose** (for the full stack)
- **An MCP-compatible AI client** (Claude Code, Claude Desktop, Gemini CLI, etc.)

---

## Option 1: MCP Server Only (Standalone)

Use this when you just want to connect the MCP server to your AI client without the web dashboard or database.

```bash
cd AutoPentest

# Make the launcher executable
chmod +x start_mcp.sh

# Run it (creates venv, installs deps, starts the MCP server)
./start_mcp.sh
```

The script will:
1. Create a Python venv at `backend/venv/` if missing
2. Install all dependencies from `backend/requirements.txt`
3. Test the MCP import
4. Launch the server on stdio (logs to `/tmp/autopentest_mcp.log`)

### Connect Your AI Client

Add to your MCP client configuration (e.g. `~/.claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "autopentest": {
      "command": "/bin/bash",
      "args": ["/absolute/path/to/AutoPentest/start_mcp.sh"]
    }
  }
}
```

---

## Option 2: Full Stack (Docker Compose)

Use this for the complete platform with PostgreSQL, REST API, Kali container, and web dashboard.

### 1. Configure Environment

```bash
cp backend/.env.example backend/.env
```

Edit `backend/.env` and change at minimum:
- `POSTGRES_PASSWORD` - set a secure password
- `DEFAULT_CONTAINER_NAME` - defaults to `kali-autopentest`

### 2. Start Services

```bash
docker-compose up -d
```

This starts 4 containers:

| Service | Container | Port | Purpose |
|---------|-----------|------|---------|
| postgres | `autopentest_postgres` | 5432 | PostgreSQL 16 + pgvector database |
| backend | `autopentest_backend` | 8000 | FastAPI REST API + MCP server |
| kali | `kali-autopentest` | -- | Kali Linux with security tools |
| frontend | `autopentest_frontend` | 5173 | React web dashboard |

### 3. Verify

```bash
# Check all containers are running
docker-compose ps

# Test backend health
curl http://localhost:8000/health

# Test Kali container has tools
docker exec kali-autopentest which nmap ffuf nuclei sqlmap

# Test database connection
docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "SELECT version();"

# Open the web dashboard
# http://localhost:5173
```

---

## Python Dependencies

All dependencies are in `backend/requirements.txt`:

### Core
| Package | Purpose |
|---------|---------|
| `fastapi` | REST API framework |
| `uvicorn` | ASGI server |
| `sqlalchemy` + `asyncpg` | PostgreSQL ORM + async driver |
| `pgvector` | PostgreSQL vector similarity search |
| `pydantic` + `pydantic-settings` | Data validation and settings |
| `httpx` | Async HTTP client |
| `mcp>=1.0.0` | Model Context Protocol SDK |
| `structlog` | Structured logging |

### AutoPentest MCP Tools
| Package | Purpose |
|---------|---------|
| `pyyaml` | Scope YAML file parsing |
| `jsonschema` | Scope schema validation |
| `playwright` | Browser automation (15 browser tools) |
| `jinja2` | Evidence report templates |
| `beautifulsoup4` + `lxml` | Web crawling and parsing |
| `python-multipart` | File upload support |

### Install Playwright Browsers (if using browser tools)

```bash
source backend/venv/bin/activate
playwright install chromium
```

---

## Database Migration

The project uses **PostgreSQL with pgvector** for:
- Cards (findings, observations, hypotheses)
- Recon data (assets, endpoints, services)
- World model (10 `wm_*` tables with per-assessment isolation)
- Scope configuration (per-assessment allowlists and constraints)
- Activity logs and request tracking

### Initialize Database

On first run, the backend automatically creates all tables. To manually run migrations:

```bash
# Check if pgvector extension is installed
docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Verify world model tables exist
docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "\dt wm_*"
```

---

## Zen Features (v2)

The following features were adapted from [Zen-Ai-Pentest](https://github.com/SHAdd0WTAka/Zen-Ai-Pentest):

### Risk Engine (`risk_score`, `risk_assess`)
CVSS v3.1 base score calculation, EPSS estimation, business impact scoring, and unified risk prioritization. Use `risk_score` for individual findings and `risk_assess` for batch assessment.

**New:** CVSS scores are auto-computed from vectors when creating/updating findings.

### PoC Generation (`poc_generate`)
Generates proof-of-concept scripts (curl + Python) for confirmed findings. Supports SQLi, XSS, IDOR, SSRF, LFI, and command injection. PoC-level only — demonstrates the vulnerability exists without deep exploitation.

### Exploit Safety Levels
4-tier safety classification (SAFE → CAUTION → DANGEROUS → BLOCKED) applied automatically to commands executed via `execute_command`. Blocked commands are refused; dangerous commands show warnings.

### SARIF Output
Export findings as SARIF 2.1.0 JSON via `evidence_export(format="sarif")` for CI/CD integration (GitHub Code Scanning, Azure DevOps, etc.).

### Plan-and-Execute with Reflection
Plan persistence in the world model via `wm_add_plan` and `wm_update_plan`. Create multi-step testing plans, track step completion, and add reflections on findings.

### DB-Aware SQL Injection Payloads
DB-specific SQLi payloads for MySQL, PostgreSQL, MSSQL, Oracle, SQLite with WAF bypass variants. The payload registry contains 300+ payloads across 46 vulnerability classes.

---

## Coverage Engine & Testing Engine

### Automated Vulnerability Testing
- **Coverage Matrix**: Systematic endpoint × vulnerability class testing grid
- **Testing Engine**: 7 tools for automated security testing (`testing_build_matrix`, `testing_next`, `testing_status`, etc.)
- **Pentest Tools**: 8 LLM-in-the-loop tools for manual testing (`recon_endpoint`, `inject_payload`, `inject_batch`, `record_finding`, etc.)
- **Endpoint Analysis**: LLM-driven probing with adaptive payloads
- **Recon Pipeline**: Automated subdomain enumeration and service discovery

### Exchange Analysis
Every HTTP request/response is analyzed for 25 risk signal types:
- Missing security headers (CSP, HSTS, X-Frame-Options)
- Insecure cookies (missing HttpOnly, Secure, SameSite)
- CORS misconfigurations
- Template injection indicators
- SQL error messages
- XSS reflection patterns
- JWT tokens detected
- And 18 more...

Risk signals are **automatically persisted as findings** with CVSS vectors, attack scenarios, and remediation guidance.

---

## Finding Fields & Evidence

Every finding includes:
- **Title** - Brief vulnerability description
- **CVSS v3.1 Vector & Score** - Auto-computed from vector string
- **Affected Endpoints** - Comma-separated or JSON array of URLs
- **Description** - Detailed explanation (supports Markdown)
- **Attack Scenario** - Step-by-step exploitation walkthrough (supports Markdown)
- **Evidence** - Structured JSON with HTTP request/response/payload
- **Recommendation** - Remediation guidance (supports Markdown)
- **Status** - `confirmed`, `probable`, `observation`, etc.

### Evidence Format

Evidence is stored as JSON and displayed with formatted HTTP panels:

```json
{
  "request": {
    "method": "POST",
    "url": "https://api.example.com/login",
    "headers": {"Content-Type": "application/json"},
    "body": "{\"username\":\"admin' OR '1'='1\"}"
  },
  "response": {
    "status": 500,
    "headers": {"Content-Type": "text/html"},
    "body": "MySQL error: You have an error in your SQL syntax..."
  },
  "payload": "admin' OR '1'='1",
  "description": "Confirmed SQL injection via error message"
}
```

### Markdown Rendering

All text fields (description, attack_scenario, recommendation) support **GitHub Flavored Markdown**:
- `**bold**`, `*italic*`, `` `code` ``
- Fenced code blocks with syntax highlighting
- Bullet lists, numbered lists
- Tables, links, images

---

## Optional Configuration

### Scope File (Hybrid DB + File)

AutoPentest uses a **hybrid scope approach**:
1. **Primary**: Per-assessment scope stored in PostgreSQL (`wm_scope_config` table)
2. **Fallback**: `./scope/engagement.yaml` file (for development/testing)

Create a YAML scope file as fallback:

```bash
mkdir -p scope
```

Create `scope/engagement.yaml`:

```yaml
engagement:
  id: "eng-2024-001"
  name: "Example Corp Pentest"
  client: "Example Corp"

allowlist:
  domains:
    - "*.example.com"
  ip_ranges:
    - "10.0.0.0/24"
  ports:
    - 80
    - 443
    - 8080

denylist:
  domains:
    - "prod.example.com"
  keywords:
    - "production"

constraints:
  rate_limits:
    max_requests_per_second: 10.0  # Rate limiting only (no hard cap on total requests)
  timeout:
    default_timeout_ms: 30000

credentials:
  - id: "admin"
    type: "bearer"
    scope: "admin"
    token_env: "ADMIN_TOKEN"

approval_policy:
  require_approval_for:
    - "destructive_actions"
```

Set in `.env`:
```
SCOPE_FILE=./scope/engagement.yaml
```

**Migration to Database:**

```bash
# Migrate scope file to database for assessment ID 1
cd backend
./venv/bin/python scripts/migrate_scope_to_db.py --assessment-id 1 --scope-file ../scope/engagement.yaml
```

---

## Project Structure

```
AutoPentest/
├── backend/
│   ├── mcp/
│   │   ├── autopentest_server.py          # MCP entry point (118 tools)
│   │   └── modules/
│   │       ├── service.py                 # AutoPentestService + scope provider
│   │       ├── resources.py               # 9 MCP resources (workflow guides)
│   │       ├── tools_assessment.py        # 4 tools (load, create, update, list)
│   │       ├── tools_cards.py             # 4 tools (add, update, list, delete)
│   │       ├── tools_recon.py             # 2 tools (subdomain_enum, whois)
│   │       ├── tools_execution.py         # 1 tool (execute + safety classifier)
│   │       ├── tools_scanning.py          # 5 tools (nmap, masscan, Nuclei wrappers)
│   │       ├── tools_credentials.py       # 2 tools (add, list)
│   │       ├── tools_scope.py             # 6 tools (validate, allowlist, tracking, etc.)
│   │       ├── tools_http.py              # 3 tools (send, batch, stats)
│   │       ├── tools_fuzzer.py            # 3 tools (DEPRECATED - mock mode only)
│   │       ├── tools_nuclei.py            # 3 tools (scan, list, config)
│   │       ├── tools_openapi.py           # 6 tools (parse, validate, fuzz, diff, etc.)
│   │       ├── tools_validator.py         # 4 tools (repro, control, promote, cross-identity)
│   │       ├── tools_evidence.py          # 4 tools (bundle, add, export, generate)
│   │       ├── tools_auth_tester.py       # 3 tools (diff, test, fuzz)
│   │       ├── tools_world_model.py       # 16 tools (add/query/search endpoints, hypotheses, plans, etc.)
│   │       ├── tools_risk.py              # 3 tools (score, assess, poc_generate)
│   │       ├── tools_browser.py           # 15 tools (navigate, click, fill, screenshot, etc.)
│   │       ├── tools_coverage.py          # 6 tools (init, discover, mark, next, status, build_matrix)
│   │       ├── tools_recon_pipeline.py    # 3 tools (run, status, cancel)
│   │       ├── tools_endpoint_analysis.py # 3 tools (probe, analyze, test)
│   │       ├── tools_crawler.py           # 3 tools (start, status, results)
│   │       ├── tools_sequences.py         # 4 tools (data_ownership, create, execute, fuzz)
│   │       ├── tools_testing_engine.py    # 7 tools (build_matrix, next, execute, mark, status, etc.)
│   │       ├── tools_pentest.py           # 8 tools (recon_endpoint, inject_*, record_finding, etc.)
│   │       └── lib/                       # 43 supporting libraries
│   │           ├── world_model_db.py      # PostgreSQL world model (10 wm_* tables)
│   │           ├── scope_loader.py        # Hybrid DB + file scope loading
│   │           ├── scope_loader_db.py     # Database scope persistence
│   │           ├── scope_validator.py     # Target validation (CIDR, wildcards)
│   │           ├── budget_tracker.py      # Request tracking (unlimited)
│   │           ├── http_client.py         # Rate-limited HTTP client
│   │           ├── http_client_factory.py # Per-assessment HTTP client factory
│   │           ├── exchange_analyzer.py   # 25 risk signal detection
│   │           ├── risk_engine.py         # CVSS v3.1 + EPSS scoring
│   │           ├── payload_registry.py    # 300+ payloads, 46 vuln classes
│   │           ├── phase_orchestrator.py  # 5-phase lifecycle gates
│   │           ├── coverage_graph.py      # Endpoint × vuln class matrix
│   │           ├── web_crawler.py         # Async web crawler
│   │           ├── sequence_runner.py     # Multi-step business logic testing
│   │           └── ...                    # 30 more libraries
│   ├── api/                               # REST API endpoints
│   │   ├── cards.py                       # CRUD for findings/observations
│   │   ├── assessments.py                 # Assessment management
│   │   ├── activity_log.py                # Activity feed
│   │   └── ...
│   ├── models/                            # SQLAlchemy database models
│   ├── schemas/                           # Pydantic validation schemas
│   ├── services/                          # Business logic
│   ├── scripts/                           # Migration and utility scripts
│   ├── tests/                             # 324 passing tests
│   ├── config.py                          # Pydantic settings
│   └── requirements.txt                   # Python dependencies
├── frontend/                              # React dashboard (Ant Design 5.x)
│   ├── src/
│   │   ├── components/
│   │   │   ├── assessment/
│   │   │   │   ├── CardsTable.jsx         # Findings table (Markdown + Evidence)
│   │   │   │   ├── ActivityFeed.jsx       # Real-time activity log
│   │   │   │   ├── PhaseTimeline.jsx      # Phase progress visualization
│   │   │   │   └── ...
│   │   │   └── common/
│   │   │       ├── MarkdownContent.jsx    # React Markdown wrapper
│   │   │       └── ...
│   │   ├── pages/
│   │   │   ├── Dashboard.jsx              # Main dashboard
│   │   │   ├── AssessmentDetail.jsx       # Per-assessment view
│   │   │   └── ...
│   │   └── App.jsx
│   ├── package.json                       # Node.js dependencies
│   └── package-lock.json                  # Dependency lock file
├── docker-compose.yml                     # 4-service orchestration
├── Dockerfile.kali                        # Kali Linux container
├── start_mcp.sh                           # MCP server launcher
├── README.md                              # Project overview
├── SETUP.md                               # This file
├── CLAUDE.md                              # LLM agent workflow guide
└── AGENTS.md                              # Agent development guide
```

---

## Frontend Dependencies

The web dashboard is built with React 19 and Ant Design 5.x:

| Package | Purpose |
|---------|---------|
| `react` + `react-dom` | UI framework |
| `react-router-dom` | Client-side routing |
| `antd` | Ant Design component library (buttons, tables, modals, forms, etc.) |
| `@ant-design/icons` | Ant Design icon set |
| `axios` | HTTP client |
| `lucide-react` | Supplementary icon library |
| `react-markdown` | GitHub Flavored Markdown rendering |
| `remark-gfm` | GFM plugin for react-markdown (tables, strikethrough, task lists) |
| `tailwindcss` | Utility CSS (layout, spacing, custom styles) |

### Install & Run Frontend

```bash
cd frontend
npm install
npm run dev   # Starts Vite dev server on http://localhost:5173
```

**Note:** Do NOT delete `package.json` or `package-lock.json` from the frontend directory - they are essential for the React app. The legacy TypeScript MCP servers have been migrated to Python and removed.

---

## Testing

Run the test suite:

```bash
cd backend
source venv/bin/activate

# Run all tests (324 tests)
pytest tests/ -v

# Run specific test file
pytest tests/test_risk_signal_alignment.py -v

# Run with coverage
pytest tests/ --cov=mcp/modules --cov-report=html
```

---

## Troubleshooting

### MCP server fails to start
- Check logs: `cat /tmp/autopentest_mcp.log`
- Verify Python 3.10+: `python3 --version`
- Reinstall deps: `rm -rf backend/venv && ./start_mcp.sh`

### Docker containers won't start
- Check Docker is running: `docker info`
- Check logs: `docker-compose logs -f backend`
- Rebuild: `docker-compose build --no-cache`

### Kali container missing tools
- Rebuild: `docker-compose build kali`
- Check manually: `docker exec kali-autopentest apt list --installed`

### Browser tools not working
- Install Playwright browsers: `playwright install chromium`
- Check Playwright version: `pip show playwright`

### Scope validation errors
- Verify scope exists: `docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "SELECT assessment_id FROM wm_scope_config WHERE is_active = TRUE;"`
- Check YAML fallback: `cat scope/engagement.yaml`
- Test YAML syntax: `python3 -c "import yaml; yaml.safe_load(open('scope/engagement.yaml'))"`

### Database connection errors
- Check PostgreSQL is running: `docker ps | grep postgres`
- Verify credentials in `.env` match `docker-compose.yml`
- Test connection: `docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "SELECT 1;"`

### World model errors
- Check tables exist: `docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "\dt wm_*"`
- Verify pgvector: `docker exec autopentest_postgres psql -U autopentest -d autopentest_db -c "SELECT * FROM pg_extension WHERE extname = 'vector';"`

### Frontend build errors
- Clear node_modules: `rm -rf frontend/node_modules && cd frontend && npm install`
- Check Node.js version: `node --version` (should be 18+)
- Rebuild frontend container: `docker-compose build frontend`

---

## Key Statistics

- **118 Tools** across 23 modules
- **324 Tests** (100% pass rate)
- **43 Library Modules** for support functionality
- **300+ Payloads** across 46 vulnerability classes
- **25 Risk Signals** auto-detected in HTTP responses
- **10 World Model Tables** with per-assessment isolation
- **9 MCP Resources** providing workflow guidance
- **5 Phase Gates** for structured testing lifecycle

---

## Architecture Highlights

### Per-Assessment Isolation
- Each assessment has its own world model data (`wm_*` tables filtered by `assessment_id`)
- Separate scope configuration, request tracking, and credential stores
- HTTP client cache isolation prevents cross-assessment data leaks

### Hybrid Scope System
- **Primary**: Database-stored scope (per-assessment, version-controlled)
- **Fallback**: YAML file (`./scope/engagement.yaml`) for development
- Automatic validation before every HTTP request

### Risk Signal Auto-Persistence
- Exchange analyzer detects 25 risk signal types
- Signals automatically converted to findings with CVSS vectors
- Attack scenarios and remediation guidance included
- Deduplication by signal type within assessment

### Evidence-Based Testing
- Structured JSON evidence storage (request/response/payload)
- Markdown rendering for all documentation fields
- CVSS auto-computation from vector strings
- PoC generation for confirmed findings

---

## Next Steps

1. **Read CLAUDE.md** - LLM agent testing workflow and tool usage guide
2. **Read AGENTS.md** - Agent development and tool creation guide
3. **Browse tool modules** - Explore `backend/mcp/modules/tools_*.py` for tool implementations
4. **Check MCP resources** - Read `backend/mcp/modules/resources.py` for workflow guidance
5. **Run tests** - Verify your setup with `pytest tests/ -v`
6. **Create an assessment** - Use the web UI or MCP `load_assessment()` tool
7. **Start testing** - Follow the 8-step pentest workflow in CLAUDE.md
