"""
Tests for autonomous execution mode tool.

20 tests validating the orchestration_auto_run tool with runbook state machine,
approval gates, repeatable steps, and error handling.
"""

import sys
import os
import json
import unittest
from unittest.mock import AsyncMock, MagicMock, patch
from pathlib import Path

# Add modules to path (avoid pip mcp package shadowing)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../mcp/modules'))

from tools_auto_run import (
    get_auto_run_tools,
    handle_auto_run_tool,
    RUNBOOK_PLAN_TITLE,
    RUNBOOK_STEPS,
    _get_step_def_by_id,
    _compute_progress,
)


class TestAutoRunTool(unittest.IsolatedAsyncioTestCase):
    """Test suite for autonomous execution tool."""

    def setUp(self):
        """Set up test fixtures."""
        # Mock MCP service
        self.mcp_service = MagicMock()
        self.mcp_service.current_assessment_id = 1
        self.mcp_service.current_base_url = "https://example.com"
        self.mcp_service.activity_logger = None

        # Mock world model DB
        self.db_mock = AsyncMock()

    async def test_requires_assessment_loaded(self):
        """Test that tool requires assessment to be loaded."""
        self.mcp_service.current_assessment_id = None

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertIn("error", data)
        self.assertIn("No assessment loaded", data["error"])

    async def test_status_returns_progress(self):
        """Test status action returns runbook progress."""
        # Mock plan with some steps done
        plan = {
            "id": "plan-1",
            "title": RUNBOOK_PLAN_TITLE,
            "steps": [
                {"description": "1.1", "status": "done"},
                {"description": "1.2", "status": "done"},
                {"description": "1.3", "status": "in_progress"},
                {"description": "1.4", "status": "pending"},
            ],
        }
        self.db_mock.query.return_value = [plan]

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "status"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["runbook"]["phase"], 1)
        self.assertEqual(data["runbook"]["step"], 3)
        self.assertEqual(data["runbook"]["steps_done"], 2)
        self.assertEqual(data["runbook"]["steps_total"], 4)

    async def test_next_returns_first_step(self):
        """Test next action returns first step when starting fresh."""
        # Mock plan with all pending steps
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = []  # No plan exists
        self.db_mock.add_plan = AsyncMock(return_value=plan)
        self.db_mock.update_plan = AsyncMock()

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "1.1")
        self.assertEqual(data["next_step"]["tool"], "scope_get_allowlist")
        self.assertEqual(data["next_step"]["args"], {})

    async def test_step_done_advances_state(self):
        """Test step_done marks current step done and returns next."""
        # Mock plan with first step in_progress
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})
        all_steps[0]["status"] = "in_progress"

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        # Mock update_plan to actually update the step status
        async def mock_update_plan(plan_id, step_index, step_status, **kwargs):
            all_steps[step_index]["status"] = step_status
        self.db_mock.update_plan = AsyncMock(side_effect=mock_update_plan)
        self.db_mock.get_by_id = AsyncMock(return_value=plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Allowlist retrieved"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "1.2")
        self.assertEqual(data["next_step"]["tool"], "subdomain_enum")
        # Verify update_plan was called
        self.db_mock.update_plan.assert_called()

    async def test_step_failed_with_retry(self):
        """Test step_failed with retry policy returns same step."""
        # Step 4.5 (testing_next) has on_failure=retry (6-phase structure)
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 4.5 to in_progress
        step_45_index = None
        for i, s in enumerate(all_steps):
            if s["description"] == "4.5":
                s["status"] = "in_progress"
                step_45_index = i
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]
        self.db_mock.get_by_id = AsyncMock(return_value=plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_failed", "error": "Test failed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertIn("Retrying", data["message"])
        self.assertEqual(data["next_step"]["id"], "4.5")

    async def test_step_failed_with_skip(self):
        """Test step_failed with skip policy advances to next step."""
        # Step 1.2 (subdomain_enum) has on_failure=skip
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 1.1 to done and 1.2 to in_progress
        for s in all_steps:
            if s["description"] < "1.2":
                s["status"] = "done"
            elif s["description"] == "1.2":
                s["status"] = "in_progress"
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        # Mock update_plan to actually update the step status
        async def mock_update_plan(plan_id, step_index, step_status, **kwargs):
            all_steps[step_index]["status"] = step_status
        self.db_mock.update_plan = AsyncMock(side_effect=mock_update_plan)
        self.db_mock.get_by_id = AsyncMock(return_value=plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_failed", "error": "Subdomain enum failed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "1.3")

    async def test_step_failed_with_halt(self):
        """Test step_failed with halt policy stops runbook."""
        # Step 1.1 (scope_get_allowlist) has on_failure=halt
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})
        all_steps[0]["status"] = "in_progress"

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]
        self.db_mock.update_plan = AsyncMock()
        self.db_mock.get_by_id = AsyncMock(return_value=plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_failed", "error": "Scope check failed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "halted")
        self.assertIn("critical step failure", data["message"])

    async def test_approval_gate_blocks(self):
        """Test step with approval_required returns awaiting_approval."""
        # Step 4.4 (testing_build_matrix) requires approval in 6-phase structure
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set steps up to 4.4 to in_progress
        for s in all_steps:
            if s["description"] == "4.4":
                s["status"] = "pending"  # NOT in_progress yet
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        # Make it look like we're at 4.4
        for i, s in enumerate(all_steps):
            if s["description"] < "4.4":
                s["status"] = "done"

        self.db_mock.query.return_value = [plan]

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "awaiting_approval")
        self.assertIn("approval", data["message"])
        self.assertEqual(data["step"]["id"], "4.4")

    async def test_approval_gate_proceeds_after_done(self):
        """Test step_done proceeds past approval gate when in_progress."""
        # Step 4.4 in_progress means approved (6-phase structure)
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Mark all steps before 4.4 as done
        for s in all_steps:
            if s["description"] < "4.4":
                s["status"] = "done"
            elif s["description"] == "4.4":
                s["status"] = "in_progress"  # Approved
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        # Mock update_plan to actually update the step status
        async def mock_update_plan(plan_id, step_index, step_status, **kwargs):
            all_steps[step_index]["status"] = step_status
        self.db_mock.update_plan = AsyncMock(side_effect=mock_update_plan)
        self.db_mock.get_by_id = AsyncMock(return_value=plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Matrix built"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "4.5")

    async def test_reset_clears_all_steps(self):
        """Test reset action marks all steps as pending."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "done"})

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]
        self.db_mock.update_plan = AsyncMock()

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "reset"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertIn("reset", data["message"])
        # Verify all steps reset to pending
        for step in all_steps:
            self.assertEqual(step["status"], "pending")

    async def test_runbook_complete(self):
        """Test status=complete when all steps done."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "done"})

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "complete")
        self.assertIn("complete", data["message"])

    async def test_arg_resolution_target_domain(self):
        """Test {target_domain} resolution from base_url."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})
        # Set to step 1.2 (subdomain_enum)
        for s in all_steps:
            if s["description"] == "1.2":
                s["status"] = "pending"
            elif s["description"] < "1.2":
                s["status"] = "done"

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]
        self.db_mock.update_plan = AsyncMock()
        self.mcp_service.current_base_url = "https://api.example.com/v1"

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["args"]["domain"], "api.example.com")

    async def test_arg_resolution_finding_id(self):
        """Test {next_unvalidated_finding} resolution from DB query."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set to step 5.2 (validate_repro) - mark prior steps as done (6-phase structure)
        for s in all_steps:
            if s["description"] < "5.2":
                s["status"] = "done"
            elif s["description"] == "5.2":
                break  # Leave 5.2 as pending

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}

        # Note: Step 5.2 (validate_repro) requires approval, so it will return awaiting_approval
        # We need to mark it as in_progress to simulate approval
        for s in all_steps:
            if s["description"] == "5.2":
                s["status"] = "in_progress"  # Simulate approval
                break

        self.db_mock.query.side_effect = [
            [plan],  # First call: get plan
            [{"id": "finding-123", "status": "potential"}],  # Second call: get finding
        ]
        self.db_mock.update_plan = AsyncMock()

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["args"]["card_id"], "finding-123")

    async def test_gate_check_blocks_advance(self):
        """Test gate check blocks phase advance when gates not met."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 1.6 (gate check) to done with gates_met=false
        for s in all_steps:
            if s["description"] == "1.6":
                s["status"] = "done"
                s["result"] = json.dumps({
                    "gates_met": False,
                    "unmet_conditions": ["needs 3 assets", "needs 5 endpoints"]
                })
            elif s["description"] < "1.6":
                s["status"] = "done"

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "blocked")
        self.assertIn("Gate requirements not met", data["message"])
        self.assertIn("needs 3 assets", data["unmet_conditions"])

    async def test_gate_check_allows_advance(self):
        """Test gate check allows phase advance when gates are met."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 1.6 (gate check) to done with gates_met=true
        for s in all_steps:
            if s["description"] == "1.6":
                s["status"] = "done"
                s["result"] = json.dumps({"gates_met": True})
            elif s["description"] < "1.6":
                s["status"] = "done"

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]
        self.db_mock.update_plan = AsyncMock()

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "next"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "1.7")
        self.assertEqual(data["next_step"]["tool"], "orchestration_advance")

    async def test_repeatable_step_repeats(self):
        """Test repeatable step repeats when conditions not met."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 4.5 (testing_next) to in_progress (6-phase structure)
        for s in all_steps:
            if s["description"] < "4.5":
                s["status"] = "done"
            elif s["description"] == "4.5":
                s["status"] = "in_progress"
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        # Mock PhaseOrchestrator.get_metrics to return low values
        mock_metrics = {"coverage_pct": 10, "findings": 1}

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock), \
             patch('lib.phase_orchestrator.PhaseOrchestrator.get_metrics', return_value=mock_metrics):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Test completed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertIn("repeating", data["message"])
        self.assertEqual(data["next_step"]["id"], "4.5")
        self.assertEqual(data["next_step"]["tool"], "testing_next")

    async def test_repeatable_step_advances(self):
        """Test repeatable step advances when conditions are met."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 4.5 (testing_next) to in_progress (6-phase structure)
        for s in all_steps:
            if s["description"] < "4.5":
                s["status"] = "done"
            elif s["description"] == "4.5":
                s["status"] = "in_progress"
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.return_value = [plan]

        # Mock PhaseOrchestrator.get_metrics to return high values (above thresholds)
        mock_metrics = {"coverage_pct": 30, "findings": 5}

        # Mock update_plan to actually update the step status
        async def mock_update_plan(plan_id, step_index, step_status, **kwargs):
            all_steps[step_index]["status"] = step_status
            if "step_result" in kwargs:
                all_steps[step_index]["result"] = kwargs["step_result"]
        self.db_mock.update_plan = AsyncMock(side_effect=mock_update_plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock), \
             patch('lib.phase_orchestrator.PhaseOrchestrator.get_metrics', return_value=mock_metrics):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Test completed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "4.6")
        self.assertEqual(data["next_step"]["tool"], "get_test_progress")


    async def test_code_audit_repeat_condition_repeats(self):
        """Test code_audit_all_reviewed repeats when unreviewed items exist."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 3.8 (code_audit_get_next) to in_progress
        for s in all_steps:
            if s["description"] < "3.8":
                s["status"] = "done"
            elif s["description"] == "3.8":
                s["status"] = "in_progress"
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.side_effect = [
            [plan],  # First call: get plan
            # Second call: code_audit_queue items (unreviewed exist)
            [
                {"id": "q1", "category": "code_audit_queue", "metadata": {"reviewed": True}},
                {"id": "q2", "category": "code_audit_queue", "metadata": {"reviewed": False}},
                {"id": "q3", "category": "code_audit_queue", "metadata": {"reviewed": False}},
            ],
        ]

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Function reviewed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertIn("repeating", data["message"])
        self.assertEqual(data["next_step"]["id"], "3.8")
        self.assertEqual(data["next_step"]["tool"], "code_audit_get_next")

    async def test_code_audit_repeat_condition_advances(self):
        """Test code_audit_all_reviewed advances when all items reviewed."""
        all_steps = []
        for phase_num in range(1, 7):
            for step_def in RUNBOOK_STEPS.get(phase_num, []):
                all_steps.append({"description": step_def["id"], "status": "pending"})

        # Set step 3.8 (code_audit_get_next) to in_progress
        for s in all_steps:
            if s["description"] < "3.8":
                s["status"] = "done"
            elif s["description"] == "3.8":
                s["status"] = "in_progress"
                break

        plan = {"id": "plan-1", "title": RUNBOOK_PLAN_TITLE, "steps": all_steps}
        self.db_mock.query.side_effect = [
            [plan],  # First call: get plan
            # Second call: code_audit_queue items (all reviewed)
            [
                {"id": "q1", "category": "code_audit_queue", "metadata": {"reviewed": True}},
                {"id": "q2", "category": "code_audit_queue", "metadata": {"reviewed": True}},
            ],
        ]

        # Mock update_plan to actually update the step status
        async def mock_update_plan(plan_id, step_index, step_status, **kwargs):
            all_steps[step_index]["status"] = step_status
            if "step_result" in kwargs:
                all_steps[step_index]["result"] = kwargs["step_result"]
        self.db_mock.update_plan = AsyncMock(side_effect=mock_update_plan)

        with patch('lib.world_model_db.get_world_model_db', return_value=self.db_mock):
            result = await handle_auto_run_tool(
                "orchestration_auto_run",
                {"action": "step_done", "result_summary": "Function reviewed"},
                self.mcp_service
            )

        data = json.loads(result[0].text)
        self.assertEqual(data["status"], "ok")
        self.assertEqual(data["next_step"]["id"], "3.9")
        self.assertEqual(data["next_step"]["tool"], "code_audit_progress")


class TestAutoRunMetadata(unittest.TestCase):
    """Test tool metadata and registration."""

    def test_tool_definition(self):
        """Test tool is defined correctly."""
        tools = get_auto_run_tools()
        self.assertEqual(len(tools), 1)
        self.assertEqual(tools[0].name, "orchestration_auto_run")
        self.assertIn("autonomous", tools[0].description.lower())
        self.assertIn("runbook", tools[0].description.lower())

    def test_in_core_tools(self):
        """Test orchestration_auto_run is in CORE_TOOLS."""
        from lib.tool_metadata import CORE_TOOLS
        self.assertIn("orchestration_auto_run", CORE_TOOLS)

    def test_in_tool_metadata(self):
        """Test orchestration_auto_run has metadata entry."""
        from lib.tool_metadata import TOOL_METADATA
        self.assertIn("orchestration_auto_run", TOOL_METADATA)
        metadata = TOOL_METADATA["orchestration_auto_run"]
        self.assertEqual(metadata["category"], "assessment")
        self.assertEqual(metadata["phase"], "recon")
        self.assertEqual(metadata["risk_level"], "caution")

    def test_visible_all_phases(self):
        """Test tool is visible in all phases (CORE_TOOLS)."""
        from lib.tool_metadata import get_visible_tools_for_phase
        for phase in range(1, 7):
            visible = get_visible_tools_for_phase(phase)
            self.assertIn("orchestration_auto_run", visible, f"Missing in phase {phase}")


class TestRunbookDefinition(unittest.TestCase):
    """Test runbook step definitions."""

    def test_runbook_has_all_phases(self):
        """Test runbook has all 6 phases defined."""
        self.assertEqual(len(RUNBOOK_STEPS), 6)
        for phase in range(1, 7):
            self.assertIn(phase, RUNBOOK_STEPS)

    def test_step_id_format(self):
        """Test all step IDs follow phase.step format."""
        for phase_num, steps in RUNBOOK_STEPS.items():
            for step in steps:
                self.assertIn("id", step)
                self.assertRegex(step["id"], r"^\d+\.\d+$")
                phase_part = int(step["id"].split(".")[0])
                self.assertEqual(phase_part, phase_num)

    def test_all_steps_have_required_fields(self):
        """Test all steps have required fields."""
        required = ["id", "name", "tool", "args_template", "description", "approval_required", "on_failure"]
        for phase_num, steps in RUNBOOK_STEPS.items():
            for step in steps:
                for field in required:
                    self.assertIn(field, step, f"Step {step.get('id')} missing {field}")

    def test_on_failure_valid_values(self):
        """Test on_failure only uses valid values."""
        valid = ["retry", "skip", "halt"]
        for phase_num, steps in RUNBOOK_STEPS.items():
            for step in steps:
                self.assertIn(step["on_failure"], valid, f"Step {step['id']} has invalid on_failure")

    def test_get_step_def_by_id(self):
        """Test _get_step_def_by_id helper."""
        step = _get_step_def_by_id("1.1")
        self.assertIsNotNone(step)
        self.assertEqual(step["id"], "1.1")
        self.assertEqual(step["tool"], "scope_get_allowlist")

        step = _get_step_def_by_id("4.5")
        self.assertIsNotNone(step)
        self.assertEqual(step["id"], "4.5")
        self.assertEqual(step["tool"], "testing_next")
        self.assertTrue(step["repeatable"])

    def test_compute_progress(self):
        """Test _compute_progress helper."""
        steps = [
            {"description": "1.1", "status": "done"},
            {"description": "1.2", "status": "done"},
            {"description": "1.3", "status": "in_progress"},
            {"description": "1.4", "status": "pending"},
        ]
        progress = _compute_progress(steps)
        self.assertEqual(progress["phase"], 1)
        self.assertEqual(progress["step"], 3)
        self.assertEqual(progress["steps_done"], 2)
        self.assertEqual(progress["steps_total"], 4)
        self.assertEqual(progress["progress_pct"], 50)
        self.assertFalse(progress["is_complete"])


if __name__ == "__main__":
    unittest.main()
