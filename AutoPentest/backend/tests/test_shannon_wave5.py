"""Tests for Shannon Wave 5 features: Hallucination filter, Recon report, Privesc framework."""
import sys
import types
import unittest
import json
from unittest.mock import AsyncMock, MagicMock, patch

sys.path.insert(0, 'mcp/modules')

# Mock mcp.types to avoid import errors on system Python
mcp_mod = types.ModuleType('mcp')
mcp_types = types.ModuleType('mcp.types')
mcp_types.Tool = type('Tool', (), {'__init__': lambda s, **k: None})
mcp_types.TextContent = type('TextContent', (), {'__init__': lambda s, **k: None})
sys.modules.setdefault('mcp', mcp_mod)
sys.modules.setdefault('mcp.types', mcp_types)


# ============================================================================
# Hallucination Filter Tests
# ============================================================================

class TestValidateFinding(unittest.TestCase):
    """Test hallucination_filter.py: validate_finding function."""

    def test_valid_finding(self):
        from lib.hallucination_filter import validate_finding
        finding = {
            "id": "f-1",
            "title": "SQL Injection in /api/users",
            "description": "The id parameter is vulnerable to SQL injection.",
            "severity": "high",
            "evidence_ids": ["e-1"],
        }
        artifacts = [{"id": "e-1"}]
        result = validate_finding(finding, artifacts)
        self.assertTrue(result.is_valid)
        self.assertEqual(result.issues, [])
        self.assertEqual(result.confidence, 1.0)

    def test_no_title_or_description(self):
        from lib.hallucination_filter import validate_finding
        finding = {"id": "f-1", "severity": "low"}
        result = validate_finding(finding)
        self.assertFalse(result.is_valid)
        self.assertIn("no title or description", result.issues[0].lower())

    def test_high_severity_no_evidence(self):
        from lib.hallucination_filter import validate_finding
        finding = {
            "id": "f-1",
            "title": "Critical RCE",
            "severity": "critical",
        }
        result = validate_finding(finding)
        self.assertFalse(result.is_valid)
        self.assertTrue(any("evidence" in i.lower() for i in result.issues))

    def test_high_severity_with_metadata_evidence_is_ok(self):
        from lib.hallucination_filter import validate_finding
        finding = {
            "id": "f-1",
            "title": "SQLi Found",
            "severity": "high",
            "metadata": {"evidence": {"request": "GET /api?id=1' OR 1=1--"}},
        }
        result = validate_finding(finding)
        self.assertTrue(result.is_valid)

    def test_speculative_content_detected(self):
        from lib.hallucination_filter import validate_finding
        # Title and description must consist ENTIRELY of speculative phrases
        # (no substantive words remain after stripping). "vulnerable" is
        # substantive, so use only speculative phrases.
        finding = {
            "id": "f-1",
            "title": "might be",
            "description": "could be possibly",
        }
        result = validate_finding(finding)
        self.assertFalse(result.is_valid)
        self.assertTrue(any("speculative" in i.lower() for i in result.issues))

    def test_missing_evidence_ids(self):
        from lib.hallucination_filter import validate_finding
        finding = {
            "id": "f-1",
            "title": "XSS Found",
            "severity": "medium",
            "evidence_ids": ["e-1", "e-2"],
        }
        artifacts = [{"id": "e-1"}]  # e-2 is missing
        result = validate_finding(finding, artifacts)
        self.assertFalse(result.is_valid)
        self.assertTrue(any("e-2" in i for i in result.issues))

    def test_confidence_decreases_with_issues(self):
        from lib.hallucination_filter import validate_finding
        finding = {"id": "f-1", "severity": "high"}
        result = validate_finding(finding)
        self.assertLessEqual(result.confidence, 0.5)

    def test_low_severity_no_evidence_ok(self):
        from lib.hallucination_filter import validate_finding
        finding = {
            "id": "f-1",
            "title": "Missing X-Frame-Options header",
            "severity": "low",
        }
        result = validate_finding(finding)
        self.assertTrue(result.is_valid)


class TestFilterSpeculativeContent(unittest.TestCase):
    """Test hallucination_filter.py: filter_speculative_content function."""

    def test_removes_speculative_sentences(self):
        from lib.hallucination_filter import filter_speculative_content
        text = "The endpoint is vulnerable. This might be exploitable. Evidence confirms injection."
        filtered = filter_speculative_content(text)
        self.assertIn("vulnerable", filtered)
        self.assertNotIn("might be", filtered)
        self.assertIn("Evidence confirms", filtered)

    def test_preserves_non_speculative_text(self):
        from lib.hallucination_filter import filter_speculative_content
        text = "SQL injection confirmed. Payload returned all users."
        filtered = filter_speculative_content(text)
        self.assertEqual(filtered, text)

    def test_empty_string_returns_empty(self):
        from lib.hallucination_filter import filter_speculative_content
        self.assertEqual(filter_speculative_content(""), "")

    def test_none_returns_none(self):
        from lib.hallucination_filter import filter_speculative_content
        self.assertIsNone(filter_speculative_content(None))

    def test_all_speculative_returns_empty(self):
        from lib.hallucination_filter import filter_speculative_content
        text = "This might be vulnerable. It could be exploitable. Further testing needed."
        filtered = filter_speculative_content(text)
        self.assertEqual(filtered, "")

    def test_speculative_phrases_list(self):
        from lib.hallucination_filter import SPECULATIVE_PHRASES
        self.assertGreaterEqual(len(SPECULATIVE_PHRASES), 10)
        self.assertIn("might be", SPECULATIVE_PHRASES)
        self.assertIn("could be", SPECULATIVE_PHRASES)
        self.assertIn("needs confirmation", SPECULATIVE_PHRASES)


class TestVerifyEvidenceIntegrity(unittest.IsolatedAsyncioTestCase):
    """Test hallucination_filter.py: verify_evidence_integrity async function."""

    async def test_finding_not_found(self):
        from lib.hallucination_filter import verify_evidence_integrity
        mock_db = AsyncMock()
        mock_db.get_by_id.return_value = None
        result = await verify_evidence_integrity("f-missing", mock_db)
        self.assertFalse(result.is_valid)
        self.assertEqual(result.confidence, 0.0)

    async def test_high_finding_no_evidence_ids(self):
        from lib.hallucination_filter import verify_evidence_integrity
        mock_db = AsyncMock()
        mock_db.get_by_id.return_value = {
            "id": "f-1", "severity": "high", "evidence_ids": []
        }
        result = await verify_evidence_integrity("f-1", mock_db)
        self.assertFalse(result.is_valid)

    async def test_evidence_ids_found_in_knowledge(self):
        from lib.hallucination_filter import verify_evidence_integrity
        mock_db = AsyncMock()
        mock_db.get_by_id.side_effect = lambda table, id: {
            ("findings", "f-1"): {"id": "f-1", "severity": "high", "evidence_ids": ["e-1"]},
            ("knowledge", "e-1"): {"id": "e-1", "content": "proof"},
        }.get((table, id))
        result = await verify_evidence_integrity("f-1", mock_db)
        self.assertTrue(result.is_valid)

    async def test_evidence_ids_found_in_observations(self):
        from lib.hallucination_filter import verify_evidence_integrity
        mock_db = AsyncMock()
        mock_db.get_by_id.side_effect = lambda table, id: {
            ("findings", "f-1"): {"id": "f-1", "severity": "medium", "evidence_ids": ["o-1"]},
            ("knowledge", "o-1"): None,
            ("observations", "o-1"): {"id": "o-1", "content": "observed"},
        }.get((table, id))
        result = await verify_evidence_integrity("f-1", mock_db)
        self.assertTrue(result.is_valid)

    async def test_missing_evidence_reference(self):
        from lib.hallucination_filter import verify_evidence_integrity
        mock_db = AsyncMock()
        mock_db.get_by_id.side_effect = lambda table, id: {
            ("findings", "f-1"): {"id": "f-1", "severity": "medium", "evidence_ids": ["e-missing"]},
            ("knowledge", "e-missing"): None,
            ("observations", "e-missing"): None,
        }.get((table, id))
        result = await verify_evidence_integrity("f-1", mock_db)
        self.assertFalse(result.is_valid)
        self.assertTrue(any("e-missing" in i for i in result.issues))


# ============================================================================
# Recon Report Tests
# ============================================================================

class TestReconReport(unittest.IsolatedAsyncioTestCase):
    """Test recon_report.py: structured 9-section report generator."""

    def _make_mock_db(self):
        mock_db = AsyncMock()
        mock_db.query.side_effect = lambda table, limit=100: {
            "assets": [
                {"name": "target.com", "type": "domain", "metadata": {"technologies": ["nginx"]}},
                {"name": "192.168.1.1", "type": "ip"},
            ],
            "endpoints": [
                {"path": "/api/users", "method": "GET", "parameters": [{"name": "id", "in": "query"}]},
                {"path": "/api/login", "method": "POST", "parameters": [{"name": "username"}, {"name": "password"}]},
            ],
            "identities": [
                {"name": "admin", "auth_type": "session", "metadata": {"role": "admin"}},
                {"name": "user1", "auth_type": "session", "metadata": {"role": "user"}},
            ],
            "relationships": [
                {"source_id": "target.com", "target_id": "192.168.1.1", "type": "resolves_to"},
            ],
            "hypotheses": [
                {"title": "IDOR on /api/users", "status": "untested", "confidence": 0.7},
            ],
        }.get(table, [])
        return mock_db

    async def test_generates_all_sections(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("Section 0", report)
        self.assertIn("Section 1", report)
        self.assertIn("Section 2", report)
        self.assertIn("Section 3", report)
        self.assertIn("Section 4", report)
        self.assertIn("Section 5", report)
        self.assertIn("Section 6", report)
        self.assertIn("Section 7", report)
        self.assertIn("Section 8", report)

    async def test_section_1_includes_domains(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("target.com", report)

    async def test_section_2_includes_tech_stack(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("nginx", report)

    async def test_section_4_includes_endpoints(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("/api/users", report)
        self.assertIn("/api/login", report)

    async def test_section_5_input_vectors(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("Input Vectors", report)
        self.assertIn("username", report)

    async def test_section_7_roles(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("admin", report)
        self.assertIn("user", report)

    async def test_section_8_hypotheses(self):
        from lib.recon_report import generate_recon_report
        mock_db = self._make_mock_db()
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("IDOR", report)

    async def test_empty_data_shows_guidance(self):
        from lib.recon_report import generate_recon_report
        mock_db = AsyncMock()
        mock_db.query.return_value = []
        report = await generate_recon_report(mock_db, assessment_id=1)
        self.assertIn("No assets", report)


# ============================================================================
# Privilege Escalation Framework Tests
# ============================================================================

class TestPrivescFramework(unittest.IsolatedAsyncioTestCase):
    """Test privesc_framework.py: escalation candidate discovery."""

    def _make_mock_db(self, identities=None, endpoints=None):
        mock_db = AsyncMock()
        mock_db.query.side_effect = lambda table, limit=100: {
            "identities": identities or [
                {"name": "admin", "metadata": {"role": "admin"}},
                {"name": "user1", "metadata": {"role": "user"}},
            ],
            "endpoints": endpoints or [
                {"path": "/admin/settings", "method": "GET", "auth_required": True},
                {"path": "/api/users", "method": "GET", "parameters": [{"name": "user_id"}]},
                {"path": "/api/submit", "method": "POST", "auth_required": False},
            ],
        }.get(table, [])
        return mock_db

    async def test_discovers_vertical_escalation(self):
        from lib.privesc_framework import discover_privesc_candidates, EscalationType
        mock_db = self._make_mock_db()
        candidates = await discover_privesc_candidates(mock_db, assessment_id=1)
        vertical = [c for c in candidates if c.escalation_type == EscalationType.VERTICAL]
        self.assertGreater(len(vertical), 0)
        admin_paths = [c for c in vertical if "/admin" in c.endpoint]
        self.assertGreater(len(admin_paths), 0)

    async def test_discovers_horizontal_escalation(self):
        from lib.privesc_framework import discover_privesc_candidates, EscalationType
        mock_db = self._make_mock_db(
            identities=[
                {"name": "user1", "metadata": {"role": "user"}},
                {"name": "user2", "metadata": {"role": "user"}},
            ],
            endpoints=[
                {"path": "/api/profile", "method": "GET", "parameters": [{"name": "user_id"}]},
            ],
        )
        candidates = await discover_privesc_candidates(mock_db, assessment_id=1)
        horizontal = [c for c in candidates if c.escalation_type == EscalationType.HORIZONTAL]
        self.assertGreater(len(horizontal), 0)

    async def test_discovers_workflow_bypass(self):
        from lib.privesc_framework import discover_privesc_candidates, EscalationType
        mock_db = self._make_mock_db()
        candidates = await discover_privesc_candidates(mock_db, assessment_id=1)
        bypass = [c for c in candidates if c.escalation_type == EscalationType.WORKFLOW_BYPASS]
        self.assertGreater(len(bypass), 0)
        submit = [c for c in bypass if "/api/submit" in c.endpoint]
        self.assertGreater(len(submit), 0)

    async def test_empty_data_returns_empty(self):
        from lib.privesc_framework import discover_privesc_candidates
        mock_db = AsyncMock()
        mock_db.query.return_value = []
        candidates = await discover_privesc_candidates(mock_db, assessment_id=1)
        self.assertEqual(candidates, [])

    async def test_candidates_sorted_by_confidence(self):
        from lib.privesc_framework import discover_privesc_candidates
        mock_db = self._make_mock_db()
        candidates = await discover_privesc_candidates(mock_db, assessment_id=1)
        if len(candidates) > 1:
            confidences = [c.confidence for c in candidates]
            self.assertEqual(confidences, sorted(confidences, reverse=True))

    async def test_candidate_to_dict(self):
        from lib.privesc_framework import PrivEscCandidate, EscalationType
        c = PrivEscCandidate(
            source_role="user", target_role="admin",
            escalation_type=EscalationType.VERTICAL,
            endpoint="/admin", parameter="",
            confidence=0.8, reason="test"
        )
        d = c.to_dict()
        self.assertEqual(d["escalation_type"], "vertical")
        self.assertEqual(d["confidence"], 0.8)


class TestPrivescTestPlans(unittest.TestCase):
    """Test privesc_framework.py: test plan generation."""

    def test_generate_vertical_test_plan(self):
        from lib.privesc_framework import PrivEscCandidate, EscalationType, generate_privesc_tests
        candidates = [PrivEscCandidate(
            source_role="user", target_role="admin",
            escalation_type=EscalationType.VERTICAL,
            endpoint="/admin/settings", parameter="",
            confidence=0.8, method="GET"
        )]
        plans = generate_privesc_tests(candidates)
        self.assertEqual(len(plans), 1)
        self.assertGreater(len(plans[0]["test_steps"]), 0)
        self.assertGreater(len(plans[0]["success_criteria"]), 0)

    def test_generate_horizontal_test_plan(self):
        from lib.privesc_framework import PrivEscCandidate, EscalationType, generate_privesc_tests
        candidates = [PrivEscCandidate(
            source_role="user", target_role="user",
            escalation_type=EscalationType.HORIZONTAL,
            endpoint="/api/profile", parameter="user_id",
            confidence=0.65, method="GET"
        )]
        plans = generate_privesc_tests(candidates)
        self.assertEqual(len(plans), 1)
        self.assertTrue(any("inject_payload" in s.get("tool", "") for s in plans[0]["test_steps"]))

    def test_generate_workflow_bypass_test_plan(self):
        from lib.privesc_framework import PrivEscCandidate, EscalationType, generate_privesc_tests
        candidates = [PrivEscCandidate(
            source_role="anonymous", target_role="user",
            escalation_type=EscalationType.WORKFLOW_BYPASS,
            endpoint="/api/submit", parameter="",
            confidence=0.5, method="POST"
        )]
        plans = generate_privesc_tests(candidates)
        self.assertEqual(len(plans), 1)
        self.assertTrue(any("recon_endpoint" in s.get("tool", "") for s in plans[0]["test_steps"]))

    def test_empty_candidates_empty_plans(self):
        from lib.privesc_framework import generate_privesc_tests
        plans = generate_privesc_tests([])
        self.assertEqual(plans, [])


class TestRoleLevel(unittest.TestCase):
    """Test _role_level helper for role hierarchy."""

    def test_guest_is_low(self):
        from lib.privesc_framework import _role_level
        self.assertLess(_role_level("guest"), _role_level("admin"))

    def test_admin_is_high(self):
        from lib.privesc_framework import _role_level
        self.assertGreater(_role_level("admin"), _role_level("user"))

    def test_unknown_defaults_to_user(self):
        from lib.privesc_framework import _role_level
        self.assertEqual(_role_level("custom_role"), 3)


if __name__ == '__main__':
    unittest.main()
