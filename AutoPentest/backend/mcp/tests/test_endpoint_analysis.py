"""
Tests for the Endpoint Analysis Engine.

Covers:
- ResponseClassifier: per-vuln-class detection (sqli, xss, ssti, path_traversal, etc.)
- TestPlanExecutor: library loading, budget tracking, suspicious signals, payload injection
- CoverageTracker: per-parameter matrix building, ssti classification
"""

from __future__ import annotations

import asyncio
import json
import os
import sys
import unittest
from unittest.mock import AsyncMock, MagicMock, patch

# Add modules to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "modules"))

# Mock mcp.types before importing anything that depends on it
import types as pytypes
mock_mcp = pytypes.ModuleType("mcp")
mock_mcp_types = pytypes.ModuleType("mcp.types")

class MockTool:
    def __init__(self, name="", description="", inputSchema=None):
        self.name = name
        self.description = description
        self.inputSchema = inputSchema or {}

class MockTextContent:
    def __init__(self, type="text", text=""):
        self.type = type
        self.text = text

mock_mcp_types.Tool = MockTool
mock_mcp_types.TextContent = MockTextContent
sys.modules["mcp"] = mock_mcp
sys.modules["mcp.types"] = mock_mcp_types


def run_async(coro):
    """Helper to run async code in sync tests."""
    return asyncio.get_event_loop().run_until_complete(coro)


# ---------------------------------------------------------------------------
# In-memory mock pool for WorldModelDatabase (replaces SQLite test databases)
# ---------------------------------------------------------------------------

class MockRecord(dict):
    """Dict subclass that supports both dict['key'] and dict.key access, like asyncpg.Record."""
    def __getattr__(self, name):
        try:
            return self[name]
        except KeyError:
            raise AttributeError(name)


class MockConnection:
    """Simulates an asyncpg connection backed by in-memory tables."""

    def __init__(self, tables):
        self._tables = tables
        self._in_transaction = False

    async def execute(self, sql, *params):
        sql_lower = sql.strip().lower()
        if sql_lower.startswith("insert into"):
            self._handle_insert(sql, params)
        elif sql_lower.startswith("update"):
            self._handle_update(sql, params)
        elif sql_lower.startswith("delete"):
            self._handle_delete(sql, params)
        return "OK"

    async def fetchrow(self, sql, *params):
        rows = await self.fetch(sql, *params)
        return rows[0] if rows else None

    async def fetch(self, sql, *params):
        return self._handle_select(sql, params)

    def transaction(self):
        return MockTransaction(self)

    def _handle_insert(self, sql, params):
        sql_lower = sql.lower()
        table = None
        if "insert into" in sql_lower:
            after_into = sql[sql_lower.index("insert into") + len("insert into"):].strip()
            table = after_into.split()[0].strip()
        if not table:
            return
        if table not in self._tables:
            self._tables[table] = []

        cols_start = sql.index("(", sql_lower.index(table) + len(table))
        cols_end = sql.index(")", cols_start)
        columns = [c.strip() for c in sql[cols_start+1:cols_end].split(",")]

        record = MockRecord()
        for i, col in enumerate(columns):
            if i < len(params):
                val = params[i]
                if isinstance(val, str) and col in ('metadata', 'tags', 'parameters',
                    'permissions', 'evidence', 'evidence_ids', 'steps', 'tool_args'):
                    try:
                        val = json.loads(val)
                    except (json.JSONDecodeError, TypeError):
                        pass
                record[col] = val

        if "on conflict" in sql_lower and "do nothing" in sql_lower:
            existing = self._tables.get(table, [])
            if self._check_unique_conflict(table, record, existing):
                return

        self._tables.setdefault(table, []).append(record)

    def _check_unique_conflict(self, table, record, existing):
        if table == "wm_coverage_matrix":
            for r in existing:
                if (r.get("assessment_id") == record.get("assessment_id") and
                    r.get("endpoint_id") == record.get("endpoint_id") and
                    r.get("vuln_class") == record.get("vuln_class") and
                    r.get("parameter") == record.get("parameter")):
                    return True
        return False

    def _handle_update(self, sql, params):
        sql_lower = sql.lower()
        table = sql[sql_lower.index("update") + 6:sql_lower.index("set")].strip()
        if table not in self._tables:
            return
        set_clause = sql[sql_lower.index("set") + 3:sql_lower.index("where")].strip()
        where_clause = sql[sql_lower.index("where") + 5:].strip()
        param_map = {f"${i+1}": p for i, p in enumerate(params)}

        set_assignments = {}
        for part in set_clause.split(","):
            part = part.strip()
            if "=" in part:
                col, val_placeholder = part.split("=", 1)
                col = col.strip()
                val_placeholder = val_placeholder.strip()
                if val_placeholder in param_map:
                    val = param_map[val_placeholder]
                    if isinstance(val, str) and col in ('metadata', 'evidence', 'steps', 'tool_args'):
                        try:
                            val = json.loads(val)
                        except (json.JSONDecodeError, TypeError):
                            pass
                    set_assignments[col] = val

        where_conditions = {}
        for part in where_clause.split(" AND "):
            part = part.strip()
            if "=" in part:
                col, val_placeholder = part.split("=", 1)
                col = col.strip()
                val_placeholder = val_placeholder.strip()
                if val_placeholder in param_map:
                    where_conditions[col] = param_map[val_placeholder]

        for row in self._tables.get(table, []):
            if all(row.get(k) == v for k, v in where_conditions.items()):
                row.update(set_assignments)

    def _handle_delete(self, sql, params):
        sql_lower = sql.lower()
        table_start = sql_lower.index("from") + 4
        table_end = sql_lower.index("where") if "where" in sql_lower else len(sql)
        table = sql[table_start:table_end].strip()
        if table not in self._tables:
            return
        if "where" not in sql_lower:
            self._tables[table] = []
            return
        where_clause = sql[sql_lower.index("where") + 5:].strip()
        param_map = {f"${i+1}": p for i, p in enumerate(params)}
        where_conditions = {}
        for part in where_clause.split(" AND "):
            part = part.strip()
            if "=" in part:
                col, val_placeholder = part.split("=", 1)
                col = col.strip()
                val_placeholder = val_placeholder.strip()
                if val_placeholder in param_map:
                    where_conditions[col] = param_map[val_placeholder]
        self._tables[table] = [
            r for r in self._tables[table]
            if not all(r.get(k) == v for k, v in where_conditions.items())
        ]

    def _handle_select(self, sql, params):
        sql_lower = sql.lower()
        param_map = {f"${i+1}": p for i, p in enumerate(params)}

        if "from" not in sql_lower:
            return []

        from_part = sql_lower.split("from")[1]
        for kw in ("where", "group by", "order by", "limit"):
            if kw in from_part:
                from_part = from_part[:from_part.index(kw)]

        main_table = from_part.strip().split()[0].strip()
        rows = list(self._tables.get(main_table, []))

        if "count(*)" in sql_lower:
            rows = self._filter_rows(rows, sql, param_map)
            if "group by" in sql_lower:
                return self._handle_group_by(sql, rows, param_map)
            return [MockRecord({"cnt": len(rows)})]

        if "group by" in sql_lower:
            rows = self._filter_rows(rows, sql, param_map)
            return self._handle_group_by(sql, rows, param_map)

        rows = self._filter_rows(rows, sql, param_map)

        if "order by" in sql_lower:
            order_part = sql_lower.split("order by")[1]
            for kw in ("limit", "offset"):
                if kw in order_part:
                    order_part = order_part[:order_part.index(kw)]
            desc = "desc" in order_part
            order_col = order_part.strip().split()[0].strip()
            if "." in order_col:
                order_col = order_col.split(".")[-1]
            rows.sort(key=lambda r: r.get(order_col, ""), reverse=desc)

        if "limit" in sql_lower:
            limit_part = sql_lower.split("limit")[-1].strip()
            limit_val = limit_part.split()[0].strip()
            if limit_val.startswith("$"):
                limit_num = param_map.get(limit_val, 100)
            else:
                try:
                    limit_num = int(limit_val)
                except ValueError:
                    limit_num = 100
            rows = rows[:limit_num]

        return [MockRecord(r) if not isinstance(r, MockRecord) else r for r in rows]

    def _filter_rows(self, rows, sql, param_map):
        sql_lower = sql.lower()
        if "where" not in sql_lower:
            return rows
        where_start = sql_lower.index("where") + 5
        where_end = len(sql_lower)
        for kw in ("group by", "order by", "limit", "having"):
            if kw in sql_lower[where_start:]:
                where_end = min(where_end, sql_lower.index(kw, where_start))
        where_clause = sql[where_start:where_end].strip()
        return [r for r in rows if self._matches_where(r, where_clause, param_map)]

    def _matches_where(self, row, where_clause, param_map):
        conditions = where_clause.split(" AND ")
        for cond in conditions:
            cond = cond.strip()
            if not cond:
                continue
            if not self._eval_condition(row, cond, param_map):
                return False
        return True

    def _eval_condition(self, row, cond, param_map):
        cond = cond.strip()
        if "=" in cond and "!" not in cond:
            parts = cond.split("=", 1)
            col = parts[0].strip()
            if "." in col:
                col = col.split(".")[-1]
            val = parts[1].strip()
            if val.startswith("$"):
                val = param_map.get(val)
            elif val.startswith("'") and val.endswith("'"):
                val = val[1:-1]
            return row.get(col) == val
        return True

    def _handle_group_by(self, sql, rows, param_map):
        sql_lower = sql.lower()
        gb_idx = sql_lower.index("group by") + 8
        gb_end = len(sql_lower)
        for kw in ("order by", "limit", "having"):
            if kw in sql_lower[gb_idx:]:
                gb_end = min(gb_end, sql_lower.index(kw, gb_idx))
        group_cols = [c.strip().split(".")[-1] for c in sql[gb_idx:gb_end].strip().split(",")]

        groups = {}
        for row in rows:
            key = tuple(row.get(col) for col in group_cols)
            groups.setdefault(key, []).append(row)

        results = []
        for key, group_rows in groups.items():
            result = MockRecord()
            for i, col in enumerate(group_cols):
                result[col] = key[i]
            result["cnt"] = len(group_rows)
            result["count"] = len(group_rows)
            results.append(result)
        return results


class MockTransaction:
    def __init__(self, conn):
        self.conn = conn

    async def __aenter__(self):
        self.conn._in_transaction = True
        return self

    async def __aexit__(self, *args):
        self.conn._in_transaction = False


class MockPool:
    """In-memory mock of asyncpg pool for testing."""

    def __init__(self):
        self._tables = {}
        self._conn = MockConnection(self._tables)

    def acquire(self):
        return MockPoolAcquire(self._conn)


class MockPoolAcquire:
    def __init__(self, conn):
        self.conn = conn

    async def __aenter__(self):
        return self.conn

    async def __aexit__(self, *args):
        pass


def _make_test_db(assessment_id=1):
    """Create a WorldModelDatabase backed by in-memory mock pool."""
    from lib.world_model_db import WorldModelDatabase
    pool = MockPool()
    db = WorldModelDatabase(pool=pool, assessment_id=assessment_id)
    run_async(db.init())
    return db


# ---------------------------------------------------------------------------
# ResponseClassifier Tests
# ---------------------------------------------------------------------------

class TestResponseClassifier(unittest.TestCase):
    """Test deterministic vulnerability classification."""

    def setUp(self):
        from lib.response_classifier import ResponseClassifier
        self.classifier = ResponseClassifier()
        self.baseline = {
            "status": 200,
            "body_hash": "abcdef1234567890",
            "body_length": 500,
            "timing_ms": 50,
        }

    def test_classify_sqli_error_based(self):
        """MySQL syntax error in body -> vulnerable, confidence >= 0.8."""
        response = {
            "status": 500,
            "headers": {},
            "body": 'Error: You have an error in your SQL syntax near "test"',
            "timing": {"duration_ms": 60},
        }
        result = self.classifier.classify("sqli", response, self.baseline, "' OR 1=1--", "name")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)
        self.assertEqual(result.vuln_class, "sqli")
        self.assertTrue(any("SQL error" in e for e in result.evidence))

    def test_classify_sqli_time_based(self):
        """5s response vs 50ms baseline -> vulnerable."""
        response = {
            "status": 200,
            "headers": {},
            "body": "Normal response",
            "timing": {"duration_ms": 5000},
        }
        result = self.classifier.classify("sqli", response, self.baseline, "' AND SLEEP(5)--", "name")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)

    def test_classify_sqli_clean(self):
        """Normal 200 response -> not vulnerable."""
        response = {
            "status": 200,
            "headers": {},
            "body": "Normal search results page",
            "timing": {"duration_ms": 55},
        }
        result = self.classifier.classify("sqli", response, self.baseline, "' OR 1=1--", "name")
        self.assertFalse(result.is_vulnerable)

    def test_classify_xss_reflected(self):
        """<script>alert(1)</script> in body -> vulnerable."""
        payload = "<script>alert(1)</script>"
        response = {
            "status": 200,
            "headers": {},
            "body": f'<div>Results for: {payload}</div>',
            "timing": {"duration_ms": 45},
        }
        result = self.classifier.classify("xss", response, self.baseline, payload, "q")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)

    def test_classify_xss_encoded(self):
        """HTML-encoded payload -> not vulnerable."""
        payload = "<script>alert(1)</script>"
        response = {
            "status": 200,
            "headers": {},
            "body": '<div>Results for: &lt;script&gt;alert(1)&lt;/script&gt;</div>',
            "timing": {"duration_ms": 45},
        }
        result = self.classifier.classify("xss", response, self.baseline, payload, "q")
        self.assertFalse(result.is_vulnerable)

    def test_classify_ssti_computation(self):
        """49 in response after {{7*7}} -> vulnerable."""
        response = {
            "status": 200,
            "headers": {},
            "body": "Hello, 49! Welcome.",
            "timing": {"duration_ms": 50},
        }
        result = self.classifier.classify("ssti", response, self.baseline, "{{7*7}}", "name")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)

    def test_classify_path_traversal(self):
        """root:x:0:0: in body -> vulnerable."""
        response = {
            "status": 200,
            "headers": {},
            "body": "root:x:0:0:root:/root:/bin/bash\ndaemon:x:1:1:",
            "timing": {"duration_ms": 40},
        }
        result = self.classifier.classify(
            "path_traversal", response, self.baseline, "../../../../etc/passwd", "file"
        )
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)

    def test_classify_ssrf_metadata(self):
        """ami-id in body -> vulnerable."""
        response = {
            "status": 200,
            "headers": {},
            "body": '{"ami-id": "ami-12345", "instance-id": "i-abcdef"}',
            "timing": {"duration_ms": 100},
        }
        result = self.classifier.classify(
            "ssrf", response, self.baseline, "http://169.254.169.254/latest/meta-data/", "url"
        )
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.8)

    def test_classify_info_disclosure(self):
        """Server version header -> vulnerable."""
        response = {
            "status": 200,
            "headers": {"Server": "Apache/2.4.41 (Ubuntu)", "X-Powered-By": "PHP/7.4"},
            "body": "OK",
            "timing": {"duration_ms": 30},
        }
        result = self.classifier.classify("info_disclosure", response, self.baseline, "", "")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.7)

    def test_classify_misconfig_cors(self):
        """Access-Control-Allow-Origin: * -> vulnerable."""
        response = {
            "status": 200,
            "headers": {"Access-Control-Allow-Origin": "*"},
            "body": "OK",
            "timing": {"duration_ms": 30},
        }
        result = self.classifier.classify("misconfig", response, self.baseline, "", "")
        self.assertTrue(result.is_vulnerable)
        self.assertGreaterEqual(result.confidence, 0.7)


# ---------------------------------------------------------------------------
# TestPlanExecutor Tests
# ---------------------------------------------------------------------------

class TestPlanExecutorBasic(unittest.TestCase):
    """Test TestPlanExecutor with mocked HttpClient."""

    def setUp(self):
        self.db = _make_test_db()

        # Mock HTTP client
        self.mock_http = MagicMock()
        self.mock_http.send = AsyncMock()

        # Default: return a normal 200 response
        self._set_http_response(200, "Normal response", 50)

    def tearDown(self):
        run_async(self.db.close())

    def _set_http_response(self, status, body, timing_ms=50, headers=None):
        """Configure mock HTTP client to return a specific response."""
        self.mock_http.send.return_value = {
            "success": True,
            "correlation_ids": {},
            "request": {"method": "GET", "url": "http://test", "headers": {}},
            "response": {
                "status": status,
                "headers": headers or {},
                "body": body,
                "timing": {"duration_ms": timing_ms},
            },
        }

    def _make_executor(self):
        from lib.test_plan_executor import TestPlanExecutor
        return TestPlanExecutor(http_client=self.mock_http, db=self.db)

    def _make_test_plan(self, tests, max_payloads=20):
        return {
            "endpoint_id": "",
            "base_url": "http://test.local",
            "method": "GET",
            "path": "/search",
            "headers": {},
            "base_body": "",
            "max_payloads": max_payloads,
            "tests": tests,
        }

    def test_execute_plan_all_pass(self):
        """Mock returns 200 OK for all payloads -> all passed."""
        executor = self._make_executor()
        plan = self._make_test_plan([
            {"vuln_class": "xss", "parameter": "q", "location": "query",
             "payloads": ["<script>test</script>", "test payload"]},
        ])
        result = run_async(executor.execute(plan))
        self.assertEqual(result["total_tests"], 1)
        # The payloads don't match XSS dangerous patterns reflected in "Normal response"
        self.assertEqual(result["vulnerable_count"], 0)
        self.assertGreaterEqual(result["passed_count"], 0)

    def test_execute_plan_finds_sqli(self):
        """Mock returns SQL error -> finding created."""
        self._set_http_response(
            500,
            'Error: You have an error in your SQL syntax near "test"',
            60,
        )
        executor = self._make_executor()
        plan = self._make_test_plan([
            {"vuln_class": "sqli", "parameter": "name", "location": "query",
             "payloads": ["' OR 1=1--"]},
        ])
        result = run_async(executor.execute(plan))
        self.assertEqual(result["vulnerable_count"], 1)
        self.assertEqual(result["results_by_test"][0]["status"], "vulnerable")

    def test_execute_plan_safety_block(self):
        """DROP TABLE payload -> skipped by safety classifier."""
        executor = self._make_executor()
        plan = self._make_test_plan([
            {"vuln_class": "sqli", "parameter": "name", "location": "query",
             "payloads": ["'; DROP DATABASE production;--"]},
        ])
        result = run_async(executor.execute(plan))
        # Should be skipped (all payloads blocked)
        self.assertIn(result["results_by_test"][0]["status"], ("skipped", "clean"))

    def test_execute_plan_loads_library(self):
        """use_library=True -> payloads loaded from library."""
        executor = self._make_executor()
        plan = self._make_test_plan([
            {"vuln_class": "xss", "parameter": "q", "location": "query",
             "use_library": True},
        ])
        result = run_async(executor.execute(plan))
        # Should have sent some payloads
        self.assertGreater(result["payloads_used"], 0)

    def test_budget_tracking(self):
        """Execute with budget of 5 -> only 5 payloads sent."""
        executor = self._make_executor()
        plan = self._make_test_plan(
            [
                {"vuln_class": "xss", "parameter": "q", "location": "query",
                 "payloads": [f"payload_{i}" for i in range(10)],
                 "max_payloads": 5},
            ],
            max_payloads=5,
        )
        result = run_async(executor.execute(plan))
        # Should not exceed budget (5 from test + 1 baseline)
        self.assertLessEqual(result["results_by_test"][0]["payloads_sent"], 5)

    def test_budget_refuses_over_limit(self):
        """Budget of 3, send 10 payloads -> only 3 sent."""
        executor = self._make_executor()
        plan = self._make_test_plan(
            [
                {"vuln_class": "sqli", "parameter": "name", "location": "query",
                 "payloads": [f"' OR {i}={i}--" for i in range(10)],
                 "max_payloads": 3},
            ],
            max_payloads=3,
        )
        result = run_async(executor.execute(plan))
        self.assertLessEqual(result["results_by_test"][0]["payloads_sent"], 3)


class TestPlanExecutorSignals(unittest.TestCase):
    """Test suspicious signal tracking and adaptive hints."""

    def setUp(self):
        self.db = _make_test_db()

        self.mock_http = MagicMock()
        self.mock_http.send = AsyncMock()

    def tearDown(self):
        run_async(self.db.close())

    def _make_executor(self):
        from lib.test_plan_executor import TestPlanExecutor
        return TestPlanExecutor(http_client=self.mock_http, db=self.db)

    def test_suspicious_signal_tracking(self):
        """500 for single-quote payload -> status 'suspicious', signal recorded."""
        call_count = [0]

        async def mock_send(request, **kwargs):
            call_count[0] += 1
            if call_count[0] == 1:
                # Baseline
                return {
                    "success": True,
                    "correlation_ids": {},
                    "request": request,
                    "response": {
                        "status": 200, "headers": {},
                        "body": "Normal", "timing": {"duration_ms": 50},
                    },
                }
            else:
                # Test payload -> 500 but no SQL error string
                return {
                    "success": True,
                    "correlation_ids": {},
                    "request": request,
                    "response": {
                        "status": 500, "headers": {},
                        "body": "Internal Server Error",
                        "timing": {"duration_ms": 60},
                    },
                }

        self.mock_http.send = mock_send
        executor = self._make_executor()

        plan = {
            "endpoint_id": "", "base_url": "http://test.local",
            "method": "GET", "path": "/search", "headers": {}, "base_body": "",
            "max_payloads": 20,
            "tests": [
                {"vuln_class": "sqli", "parameter": "q", "location": "query",
                 "payloads": ["'"]},
            ],
        }
        result = run_async(executor.execute(plan))
        test_result = result["results_by_test"][0]
        self.assertEqual(test_result["status"], "suspicious")
        self.assertGreater(len(test_result["suspicious_signals"]), 0)

    def test_clean_status_no_signals(self):
        """All payloads return normal 200 -> status 'clean'."""
        self.mock_http.send.return_value = {
            "success": True,
            "correlation_ids": {},
            "request": {"method": "GET", "url": "http://test", "headers": {}},
            "response": {
                "status": 200, "headers": {},
                "body": "Normal search results",
                "timing": {"duration_ms": 50},
            },
        }
        executor = self._make_executor()

        plan = {
            "endpoint_id": "", "base_url": "http://test.local",
            "method": "GET", "path": "/search", "headers": {}, "base_body": "",
            "max_payloads": 20,
            "tests": [
                {"vuln_class": "sqli", "parameter": "q", "location": "query",
                 "payloads": ["test_value", "another_value"]},
            ],
        }
        result = run_async(executor.execute(plan))
        test_result = result["results_by_test"][0]
        self.assertEqual(test_result["status"], "clean")
        self.assertEqual(len(test_result["suspicious_signals"]), 0)

    def test_adaptive_hints_generation(self):
        """Suspicious signals -> hints string mentions the pattern."""
        call_count = [0]

        async def mock_send(request, **kwargs):
            call_count[0] += 1
            if call_count[0] == 1:
                return {
                    "success": True, "correlation_ids": {},
                    "request": request,
                    "response": {
                        "status": 200, "headers": {},
                        "body": "Normal", "timing": {"duration_ms": 50},
                    },
                }
            else:
                return {
                    "success": True, "correlation_ids": {},
                    "request": request,
                    "response": {
                        "status": 500, "headers": {},
                        "body": "Server Error",
                        "timing": {"duration_ms": 2100},
                    },
                }

        self.mock_http.send = mock_send
        executor = self._make_executor()

        plan = {
            "endpoint_id": "", "base_url": "http://test.local",
            "method": "GET", "path": "/search", "headers": {}, "base_body": "",
            "max_payloads": 20,
            "tests": [
                {"vuln_class": "sqli", "parameter": "name", "location": "query",
                 "payloads": ["' OR 1=1--"]},
            ],
        }
        result = run_async(executor.execute(plan))
        self.assertIn("suspicious", result["adaptive_hints"].lower() if result["adaptive_hints"] else "")


# ---------------------------------------------------------------------------
# Payload Injection Tests
# ---------------------------------------------------------------------------

class TestPayloadInjection(unittest.TestCase):
    """Test _inject_payload for all location types."""

    def setUp(self):
        from lib.test_plan_executor import TestPlanExecutor
        self.inject = TestPlanExecutor._inject_payload

    def test_inject_query(self):
        url, body, headers = self.inject(
            "http://test.local/search?q=hello",
            "GET", {}, "", "q", "query", "' OR 1=1--"
        )
        self.assertIn("q=%27+OR+1%3D1--", url)

    def test_inject_body_json(self):
        url, body, headers = self.inject(
            "http://test.local/api",
            "POST", {"Content-Type": "application/json"},
            '{"name": "test"}', "name", "body", "injected"
        )
        parsed = json.loads(body)
        self.assertEqual(parsed["name"], "injected")

    def test_inject_body_form(self):
        url, body, headers = self.inject(
            "http://test.local/api",
            "POST", {}, "name=test&age=25", "name", "body", "injected"
        )
        self.assertIn("name=injected", body)

    def test_inject_path(self):
        url, body, headers = self.inject(
            "http://test.local/users/{id}/profile",
            "GET", {}, "", "id", "path", "999"
        )
        self.assertIn("/users/999/profile", url)

    def test_inject_header(self):
        url, body, headers = self.inject(
            "http://test.local/api", "GET", {}, "",
            "X-Custom", "header", "injected_value"
        )
        self.assertEqual(headers["X-Custom"], "injected_value")

    def test_inject_cookie(self):
        url, body, headers = self.inject(
            "http://test.local/api", "GET", {}, "",
            "session", "cookie", "abc123"
        )
        self.assertIn("session=abc123", headers["Cookie"])


# ---------------------------------------------------------------------------
# Per-Parameter Coverage Tests
# ---------------------------------------------------------------------------

class TestPerParameterCoverage(unittest.TestCase):
    """Test CoverageTracker per-parameter matrix building."""

    def test_build_matrix_per_parameter(self):
        """3 params x sqli = 3 rows."""
        from lib.coverage_tracker import CoverageTracker
        endpoints = [{
            "id": "ep1",
            "method": "GET",
            "path": "/search",
            "parameters": {"query": {"q": "string", "lang": "string", "page": "string"}},
            "auth_required": False,
        }]
        rows = CoverageTracker.build_matrix(endpoints, "http://test.local", vuln_classes=["sqli"])
        # Should have 3 rows (one per param)
        sqli_rows = [r for r in rows if r["vuln_class"] == "sqli"]
        self.assertEqual(len(sqli_rows), 3)
        params = {r["parameter"] for r in sqli_rows}
        self.assertEqual(params, {"q", "lang", "page"})

    def test_build_matrix_ssti_class(self):
        """ssti included for endpoint with params."""
        from lib.coverage_tracker import CoverageTracker
        endpoints = [{
            "id": "ep2",
            "method": "POST",
            "path": "/render",
            "parameters": {"body": {"template": "string"}},
            "auth_required": False,
        }]
        rows = CoverageTracker.build_matrix(endpoints, "http://test.local")
        vuln_classes = {r["vuln_class"] for r in rows}
        self.assertIn("ssti", vuln_classes)

    def test_build_matrix_non_param_class_single_row(self):
        """info_disclosure should have single row with parameter=''."""
        from lib.coverage_tracker import CoverageTracker
        endpoints = [{
            "id": "ep3",
            "method": "GET",
            "path": "/status",
            "parameters": {"query": {"q": "string"}},
            "auth_required": False,
        }]
        rows = CoverageTracker.build_matrix(endpoints, "http://test.local", vuln_classes=["info_disclosure"])
        self.assertEqual(len(rows), 1)
        self.assertEqual(rows[0]["parameter"], "")

    def test_classify_endpoint_includes_ssti(self):
        """classify_endpoint includes ssti when endpoint has params."""
        from lib.coverage_tracker import CoverageTracker
        endpoint = {
            "method": "POST",
            "path": "/api/template",
            "parameters": {"body": {"input": "string"}},
            "auth_required": False,
        }
        classes = CoverageTracker.classify_endpoint(endpoint)
        self.assertIn("ssti", classes)


# ---------------------------------------------------------------------------
# ResponseAnalyzer Tests
# ---------------------------------------------------------------------------

class TestResponseAnalyzer(unittest.TestCase):
    """Test the response analyzer module."""

    def test_detect_reflected_params(self):
        from lib.response_analyzer import detect_reflected_params
        request = {"url": "http://test.local/search?q=testvalue&page=1", "method": "GET"}
        response = {"body": "Results for: testvalue"}
        reflected = detect_reflected_params(request, response)
        self.assertIn("q", reflected)

    def test_detect_response_type_json(self):
        from lib.response_analyzer import detect_response_type
        response = {"headers": {"Content-Type": "application/json"}, "body": "{}"}
        self.assertEqual(detect_response_type(response), "json")

    def test_detect_response_type_html(self):
        from lib.response_analyzer import detect_response_type
        response = {"headers": {"Content-Type": "text/html"}, "body": "<html>"}
        self.assertEqual(detect_response_type(response), "html")

    def test_extract_security_headers(self):
        from lib.response_analyzer import extract_security_headers
        headers = {"Content-Security-Policy": "default-src 'self'"}
        result = extract_security_headers(headers)
        self.assertIn("Content-Security-Policy", result["present"])
        self.assertIn("X-Frame-Options", result["missing"])

    def test_detect_error_indicators(self):
        from lib.response_analyzer import detect_error_indicators
        response = {"body": "Error: SQL syntax error near 'test'"}
        indicators = detect_error_indicators(response)
        self.assertGreater(len(indicators), 0)
        self.assertEqual(indicators[0]["category"], "sql")

    def test_fingerprint_response(self):
        from lib.response_analyzer import fingerprint_response
        response = {
            "status": 200,
            "headers": {"Content-Type": "text/html"},
            "body": "Hello World",
            "timing": {"duration_ms": 100},
        }
        fp = fingerprint_response(response)
        self.assertEqual(fp["status"], 200)
        self.assertEqual(fp["body_length"], 11)
        self.assertEqual(fp["timing_ms"], 100)
        self.assertIsNotNone(fp["body_hash"])

    def test_analyze_response_full(self):
        from lib.response_analyzer import analyze_response
        request = {
            "url": "http://test.local/search?q=hello",
            "method": "GET",
            "headers": {},
            "body": "",
        }
        response = {
            "status": 200,
            "headers": {
                "Content-Type": "text/html",
                "Server": "nginx/1.21",
            },
            "body": "<html><body>Results for: hello</body></html>",
            "timing": {"duration_ms": 50},
        }
        result = analyze_response(request, response)
        self.assertIn("parameters", result)
        self.assertIn("reflected_params", result)
        self.assertIn("response_indicators", result)
        self.assertIn("fingerprint", result)
        self.assertIn("q", result["reflected_params"])
        self.assertEqual(result["response_indicators"]["server_tech"], "nginx/1.21")


# ---------------------------------------------------------------------------
# World Model DB Migration Test
# ---------------------------------------------------------------------------

class TestCoverageMatrixMigration(unittest.TestCase):
    """Test that the parameter column migration works correctly."""

    def test_coverage_init_with_parameter(self):
        """coverage_init_rows with parameter field."""
        db = _make_test_db()

        rows = [
            {"endpoint_id": "ep1", "vuln_class": "sqli", "parameter": "name",
             "tool_name": "fuzz_parameter", "tool_args": {}, "priority": 70},
            {"endpoint_id": "ep1", "vuln_class": "sqli", "parameter": "email",
             "tool_name": "fuzz_parameter", "tool_args": {}, "priority": 65},
            {"endpoint_id": "ep1", "vuln_class": "info_disclosure", "parameter": "",
             "tool_name": "http_send", "tool_args": {}, "priority": 40},
        ]
        result = run_async(db.coverage_init_rows(rows))
        self.assertEqual(result["created"], 3)

        # Verify uniqueness: same endpoint + vuln_class but different parameter
        report = run_async(db.coverage_report(endpoint_id="ep1"))
        self.assertEqual(report["total_cells"], 3)

        run_async(db.close())


if __name__ == "__main__":
    unittest.main()
