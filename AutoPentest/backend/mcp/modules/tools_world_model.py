"""
World Model Tools - wm_add_asset, wm_add_endpoint, wm_add_identity,
wm_add_hypothesis, wm_update_hypothesis, wm_add_finding, wm_update_finding,
wm_add_observation, wm_query, wm_store, wm_recall, wm_add_plan, wm_update_plan.

Ported from the world-model-mcp TypeScript server to Python, following the
same pattern as tools_evidence.py and tools_scope.py.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Dict, List

from mcp.types import Tool, TextContent

logger = logging.getLogger("autopentest-mcp")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

from lib.tool_helpers import _json_content, _error_content, _get_db


# ---------------------------------------------------------------------------
# Tool definitions
# ---------------------------------------------------------------------------

def get_world_model_tools() -> List[Tool]:
    """Return the sixteen world-model tools (13 original + 3 graph)."""
    return [
        # 1 ---- wm_add_asset -----------------------------------------------
        Tool(
            name="wm_add_asset",
            description=(
                "Add target asset (domain, subdomain, IP, service, application) to world model inventory. Assets "
                "are top-level entities representing attack surface components. Serves as parent container for "
                "endpoints (via wm_add_endpoint) and target for hypotheses. Supports metadata and tagging for "
                "organization. Foundation of structured asset tracking and relationship mapping. "

                "**When to use:** Phase 1 (Recon) when discovering new assets via subdomain_enum(), scan(), or "
                "manual identification. Create domain asset first, then subdomains, IPs, services. One asset per "
                "unique entity (example.com = domain, api.example.com = subdomain, 10.0.0.1 = IP). Use before "
                "wm_add_endpoint() to establish parent-child relationships. "

                "**Dependencies:** None - entry point tool for world model. Get asset_id from return value for "
                "wm_add_endpoint(asset_id=...). Query existing assets with wm_query(table='assets') before creating "
                "to avoid duplicates. Follow with wm_add_endpoint() to register discovered endpoints, "
                "wm_add_relationship() to link assets (domain → subdomain → IP chains). "

                "**Budget impact:** LOW - local database insert, no network requests. Completes <50ms. No request "
                "budget impact. Create hundreds of assets efficiently during recon. "

                "**Failure modes:** Duplicate name+kind returns existing asset_id (idempotent). Invalid kind enum "
                "rejected by schema. Empty name causes validation error. Metadata JSON serialization errors if "
                "complex objects provided (flatten first). "

                "**Risk level:** SAFE - local inventory management only, no network activity or target interaction. "
                "Documentation tool for organizing discovered attack surface. "

                "**Returns:** Asset creation result with asset_id (UUID for wm_add_endpoint reference), kind, name, "
                "metadata, tags, created_at. Use asset_id in wm_add_endpoint(), wm_add_hypothesis(target_id), "
                "wm_query(filters={'asset_id': ...}), wm_add_relationship(source_id). Automatically indexed for "
                "full-text search via wm_recall()."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "kind": {
                        "type": "string",
                        "enum": ["domain", "subdomain", "ip", "service", "application"],
                        "description": "Kind of asset",
                    },
                    "name": {
                        "type": "string",
                        "description": "Asset name or identifier (e.g. 'example.com', '10.0.0.1')",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata (JSON object)",
                        "additionalProperties": True,
                    },
                    "tags": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Optional tags for categorisation",
                    },
                },
                "required": ["kind", "name"],
            },
        ),

        # 2 ---- wm_add_endpoint --------------------------------------------
        Tool(
            name="wm_add_endpoint",
            description=(
                "Add an API endpoint to an existing asset in the world model. Registers HTTP endpoints "
                "discovered through crawling, API spec parsing, or manual identification. Endpoints become "
                "targets for coverage matrix initialization, vulnerability testing, and authorization checks. "
                "Tracks method, path, parameters, authentication requirements, and metadata for systematic testing. "

                "**When to use:** Phase 2 (Mapping) after discovering endpoints via crawler_start(), "
                "openapi_parse(), browser_discover_forms(), or manual browsing. Call for each unique "
                "method+path combination (GET /api/users and POST /api/users are separate endpoints). "
                "Essential for building comprehensive testing coverage matrix and tracking endpoint inventory. "

                "**Dependencies:** Requires wm_add_asset() to have created parent asset first (get asset_id "
                "from wm_add_asset or wm_query(table='assets')). Typically called after discovery tools populate "
                "initial data. Follow with coverage_init() to build test matrix, or wm_add_hypothesis() to "
                "propose vulnerability theories for specific endpoints. "

                "**Budget impact:** LOW - Local database insert, no HTTP requests. Completes in <50ms. "
                "Does NOT count against request budget. Can add hundreds of endpoints efficiently. "

                "**Failure modes:** 'Asset not found' if asset_id doesn't exist - call wm_query(table='assets') "
                "to find valid IDs or wm_add_asset() to create one. 'Duplicate endpoint' if method+path already "
                "exists for this asset (safe to ignore, returns existing endpoint_id). Invalid method name "
                "(should be GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS). Missing path returns validation error. "

                "**Risk level:** SAFE - Local data storage only, no network activity or target interaction. "
                "Builds knowledge base for planning testing strategy. Persistent across assessment sessions "
                "for progress tracking and resumption. "

                "**Returns:** Endpoint creation result with endpoint_id (UUID for later reference), asset_id "
                "(parent), method, path, auth_required flag, and parameters schema. Use endpoint_id with "
                "coverage_init(), endpoint_probe(), wm_add_hypothesis(target_id=...), and wm_query(table='endpoints', "
                "filters={'endpoint_id': ...}). Automatically linked to parent asset in world model graph for "
                "relationship queries."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "asset_id": {
                        "type": "string",
                        "description": "ID of the parent asset",
                    },
                    "method": {
                        "type": "string",
                        "description": "HTTP method (GET, POST, PUT, DELETE, etc.)",
                    },
                    "path": {
                        "type": "string",
                        "description": "URL path (e.g. '/api/v1/users')",
                    },
                    "parameters": {
                        "type": "object",
                        "description": "Parameter schema or examples (JSON object)",
                        "additionalProperties": True,
                    },
                    "auth_required": {
                        "type": "boolean",
                        "description": "Whether the endpoint requires authentication (default: false)",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata (JSON object)",
                        "additionalProperties": True,
                    },
                },
                "required": ["asset_id", "method", "path"],
            },
        ),

        # 3 ---- wm_add_identity --------------------------------------------
        Tool(
            name="wm_add_identity",
            description=(
                "Add test identity or credential profile to world model for authorization testing. Represents user "
                "accounts, API keys, or service credentials with defined scope/permissions. Used for differential "
                "authorization testing (auth_diff_test), cross-identity validation, and privilege escalation detection. "
                "Tracks authentication type, role/scope, and capabilities for systematic access control testing. "

                "**When to use:** Phase 2-3 (Mapping/Assessment) when you have multiple test accounts or discovered "
                "credentials. Create identity for each permission level (admin, user, readonly, anonymous). Use before "
                "auth_diff_test() to test authorization boundaries. Common after credentials_add() stores actual tokens "
                "(this tracks permission levels, credentials_add stores actual auth values). "

                "**Dependencies:** None for creation. Used by auth_diff_test(), auth_replay_with_identity(), "
                "validate_cross_identity(), sequence_credential_reuse(). Query with wm_query(table='identities') "
                "or auth_get_identities() to see available test accounts. Reference identity_id in authorization tests. "

                "**Budget impact:** LOW - local database insert, no network requests. Completes <50ms. No request "
                "budget impact. Create multiple identities for comprehensive authz testing. "

                "**Failure modes:** Duplicate name silently returns existing (idempotent). Invalid auth_type enum "
                "rejected by schema. Missing scope causes validation error. Permissions array can be empty. "

                "**Risk level:** SAFE - local test account registry, no network activity or target interaction. "
                "Metadata for organizing authorization test matrix. "

                "**Returns:** Identity creation result with identity_id (for auth tests), name, auth_type, scope, "
                "permissions[], metadata, created_at. Use identity_id in auth_diff_test(identity_ids=[...]), "
                "crawler_start(identity_id), http_send(identity_id), sequence_execute(identity_id) for testing "
                "with specific permission levels."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "name": {
                        "type": "string",
                        "description": "Identity name (e.g. 'admin-user', 'api-key-readonly')",
                    },
                    "auth_type": {
                        "type": "string",
                        "description": "Authentication type (e.g. 'bearer', 'basic', 'cookie', 'api_key')",
                    },
                    "scope": {
                        "type": "string",
                        "description": "Scope or role of the identity (e.g. 'admin', 'user', 'readonly')",
                    },
                    "permissions": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "List of permissions or capabilities",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata (JSON object)",
                        "additionalProperties": True,
                    },
                },
                "required": ["name", "auth_type", "scope"],
            },
        ),

        # 4 ---- wm_add_hypothesis -------------------------------------------
        Tool(
            name="wm_add_hypothesis",
            description=(
                "Create a security hypothesis to test. Hypotheses represent vulnerability theories that drive "
                "targeted testing and provide structured workflow for confirmation. Tracks suspected "
                "vulnerabilities from initial observation through testing to confirmed finding or rejection. "
                "Status progression: proposed → testing → confirmed/rejected. Essential for organizing testing "
                "methodology and linking evidence to specific vulnerability theories. "

                "**When to use:** Phase 2-3 (Mapping/Assessment) when you suspect a vulnerability based on "
                "observations (error messages, suspicious parameters, missing auth checks, tech stack patterns). "
                "Create hypothesis BEFORE testing to document your reasoning. Use for: suspected IDOR on endpoints "
                "with ID parameters, potential SQLi on search/filter parameters, possible XSS on reflection points, "
                "auth bypass opportunities, SSRF on URL parameters. One hypothesis per vulnerability type per endpoint. "

                "**Dependencies:** Optionally reference target_id from wm_add_endpoint() or wm_add_asset() to link "
                "hypothesis to specific target. Follow with wm_update_hypothesis(status='testing') when starting "
                "tests, then add_card(type='finding') if confirmed, or wm_update_hypothesis(status='rejected') if "
                "ruled out. Use wm_add_observation() to attach test results and evidence to hypothesis. "

                "**Budget impact:** LOW - Local database insert, no HTTP requests. Completes in <50ms. "
                "Does NOT count against request budget. Create liberally for all suspected vulnerabilities to "
                "maintain organized testing approach. "

                "**Failure modes:** 'Invalid severity' if not in [info, low, medium, high, critical]. 'Target not "
                "found' if target_id provided but doesn't exist (verify with wm_query). No other expected failures - "
                "hypothesis creation always succeeds for valid inputs. Duplicate hypotheses allowed (testing same "
                "vulnerability twice with different approaches). "

                "**Risk level:** SAFE - Local knowledge base documentation only, no network activity or target "
                "interaction. Pure planning and organization tool. Persistent across sessions for long-term "
                "assessment tracking. "

                "**Returns:** Hypothesis creation result with hypothesis_id (UUID for later reference), title, "
                "description, severity (expected if confirmed), status (initially 'proposed'), target_id (if linked), "
                "created_at timestamp. Use hypothesis_id with wm_update_hypothesis(), wm_add_observation(), "
                "wm_add_finding(), and wm_query(table='hypotheses'). Automatically creates 'proposed' status - "
                "update to 'testing' when beginning validation, 'confirmed' when validated (usually via wm_add_finding), "
                "or 'rejected' when ruled out."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "title": {
                        "type": "string",
                        "description": "Short title (e.g. 'IDOR on /api/users/{id}')",
                    },
                    "description": {
                        "type": "string",
                        "description": "Detailed description of the hypothesis",
                    },
                    "severity": {
                        "type": "string",
                        "enum": ["info", "low", "medium", "high", "critical"],
                        "description": "Expected severity if confirmed",
                    },
                    "target_id": {
                        "type": "string",
                        "description": "Optional ID of the target asset or endpoint",
                    },
                },
                "required": ["title", "description", "severity"],
            },
        ),

        # 5 ---- wm_update_hypothesis ----------------------------------------
        Tool(
            name="wm_update_hypothesis",
            description=(
                "Update hypothesis status (proposed→testing→confirmed/rejected) and append evidence references. "
                "Tracks testing lifecycle progress and links observations/artifacts to vulnerability theories. Status "
                "changes document workflow: 'testing' when starting validation, 'confirmed' when creating finding "
                "(via wm_add_finding), 'rejected' when ruled out. Evidence array grows as testing progresses. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) to track hypothesis progress. Pattern: "
                "wm_add_hypothesis (creates 'proposed') → wm_update_hypothesis(status='testing') when starting tests → "
                "wm_add_observation (attach test results) → wm_update_hypothesis(status='confirmed', evidence=[obs_ids]) "
                "if vulnerable, or status='rejected' if ruled out. Essential for maintaining organized test methodology. "

                "**Dependencies:** Requires hypothesis_id from wm_add_hypothesis(). Evidence IDs from "
                "wm_add_observation(), evidence_add_artifact(), or observation_id from validate_* tools. Typically "
                "updated multiple times during testing lifecycle. Query wm_query(table='hypotheses', filters={'status': "
                "'testing'}) to see active testing. "

                "**Budget impact:** LOW - local database update, no network requests. Completes <50ms. No request "
                "budget impact. Update frequently to track progress. "

                "**Failure modes:** 'Hypothesis not found' if ID invalid. Invalid status enum rejected by schema. "
                "Evidence IDs not validated (can reference non-existent IDs). Status transitions not enforced (can "
                "skip states). Appending same evidence ID multiple times creates duplicates. "

                "**Risk level:** SAFE - local status tracking only, no network activity or target interaction. "
                "Workflow management tool. "

                "**Returns:** Simple confirmation 'Hypothesis {ID} updated'. Updated status immediately visible in "
                "wm_query(table='hypotheses'). Use to maintain audit trail of testing process: when started, evidence "
                "collected, outcome (confirmed/rejected)."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "Hypothesis ID to update",
                    },
                    "status": {
                        "type": "string",
                        "enum": ["proposed", "testing", "confirmed", "rejected"],
                        "description": "New status",
                    },
                    "evidence": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Evidence IDs to append (observation IDs, artifact IDs, etc.)",
                    },
                },
                "required": ["id"],
            },
        ),

        # 6 ---- wm_add_finding ----------------------------------------------
        Tool(
            name="wm_add_finding",
            description=(
                "Record confirmed security finding linked to hypothesis in world model. Represents validated "
                "vulnerabilities with confidence scores (0.0-1.0), severity, evidence references, and remediation "
                "guidance. Creates 'confirms' relationship between hypothesis and finding in graph. Alternative to "
                "add_card() for world-model-centric workflow. Findings persist in structured database for reporting "
                "and analysis. "

                "**When to use:** Phase 4 (Exploitation) after validate_promote() confirms vulnerability with high "
                "confidence (>0.67). Use when following hypothesis-driven testing workflow (wm_add_hypothesis → test → "
                "wm_add_finding if confirmed). Prefer this over add_card() when working extensively with world model "
                "(auto-creates graph relationships). One finding per validated vulnerability per hypothesis. "

                "**Dependencies:** Requires hypothesis_id from wm_add_hypothesis(). Evidence IDs from "
                "wm_add_observation(), evidence_add_artifact(), or observation references. Follow with "
                "wm_update_hypothesis(status='confirmed') to close loop. Automatically creates 'confirms' relationship "
                "in graph (query with wm_get_neighbors). Use risk_score() to calculate CVSS/business impact. "

                "**Budget impact:** LOW - local database insert, no network requests. Completes <50ms. No request "
                "budget impact. Creates permanent record with graph relationships. "

                "**Failure modes:** 'Hypothesis not found' if hypothesis_id invalid. Confidence outside [0.0, 1.0] "
                "rejected. Invalid severity enum rejected. Evidence IDs not validated (can reference missing). Missing "
                "remediation allowed but reduces report quality. Duplicate findings allowed (intentional for tracking). "

                "**Risk level:** SAFE - local finding documentation, no network activity or target interaction. Creates "
                "permanent validated vulnerability record. "

                "**Returns:** Finding result with finding_id (for references), hypothesis_id, title, severity, "
                "confidence, evidence_ids[], remediation, metadata, status (initially 'draft'), created_at. Use "
                "finding_id in wm_update_finding(), evidence_bundle(finding_id), coverage_mark(finding_id), "
                "wm_add_relationship(). Graph relationship auto-created: hypothesis → confirms → finding."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "hypothesis_id": {
                        "type": "string",
                        "description": "ID of the hypothesis this finding confirms",
                    },
                    "title": {
                        "type": "string",
                        "description": "Finding title (e.g. 'SQL Injection in login form')",
                    },
                    "severity": {
                        "type": "string",
                        "enum": ["info", "low", "medium", "high", "critical"],
                        "description": "Finding severity",
                    },
                    "confidence": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1,
                        "description": "Confidence level from 0.0 to 1.0",
                    },
                    "evidence_ids": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "IDs of supporting evidence (observations, artifacts)",
                    },
                    "remediation": {
                        "type": "string",
                        "description": "Recommended remediation steps",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata (CVSS, CWE, references, etc.)",
                        "additionalProperties": True,
                    },
                    "proof_level": {
                        "type": "string",
                        "enum": ["theoretical", "partial", "bypass", "takeover"],
                        "description": "Evidence strength: theoretical (unverified), partial (some evidence), bypass (security control bypassed), takeover (full exploitation). Critical severity requires bypass or takeover.",
                    },
                    "verdict": {
                        "type": "string",
                        "enum": ["exploited", "blocked_by_security", "out_of_scope", "false_positive"],
                        "description": "Final classification of the finding after validation.",
                    },
                },
                "required": ["hypothesis_id", "title", "severity", "confidence"],
            },
        ),

        # 7 ---- wm_update_finding -------------------------------------------
        Tool(
            name="wm_update_finding",
            description=(
                "Update finding status (draft→confirmed→reported→remediated), refine confidence score, or enhance "
                "remediation guidance. Tracks finding lifecycle from initial discovery through reporting and fix "
                "verification. Status progression documents vulnerability management workflow. Confidence adjustments "
                "based on additional validation or follow-up testing. "

                "**When to use:** Phase 4-5 (Exploitation/Reporting) to track finding maturity. Pattern: "
                "wm_add_finding (creates 'draft') → wm_update_finding(status='confirmed', confidence=0.9) after "
                "validation → status='reported' when delivered to client → status='remediated' after fix verified. "
                "Update confidence after validate_negative_control(), validate_cross_identity() provide more data. "
                "Enhance remediation with specific fix guidance. "

                "**Dependencies:** Requires finding_id from wm_add_finding(). No follow-up required - updates in place. "
                "Query wm_query(table='findings', filters={'status': 'draft'}) to see unconfirmed. Use with "
                "risk_assess() to calculate prioritization after confidence updates. "

                "**Budget impact:** LOW - local database update, no network requests. Completes <50ms. No request "
                "budget impact. Update freely as findings mature. "

                "**Failure modes:** 'Finding not found' if ID invalid. Invalid status enum rejected. Confidence "
                "outside [0.0, 1.0] rejected. Status transitions not enforced (can skip states or regress). Empty "
                "remediation allowed. Partial updates (only status, only confidence) supported. "

                "**Risk level:** SAFE - local finding status management, no network activity or target interaction. "
                "Tracks vulnerability lifecycle. "

                "**Returns:** Simple confirmation 'Finding {ID} updated'. Updated values immediately visible in "
                "wm_query(table='findings'). Use to maintain finding maturity tracking: draft (new), confirmed "
                "(validated), reported (delivered), remediated (fixed and verified)."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "Finding ID to update",
                    },
                    "status": {
                        "type": "string",
                        "enum": ["draft", "confirmed", "reported", "remediated"],
                        "description": "New finding status",
                    },
                    "confidence": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1,
                        "description": "Updated confidence level",
                    },
                    "remediation": {
                        "type": "string",
                        "description": "Updated remediation steps",
                    },
                    "proof_level": {
                        "type": "string",
                        "enum": ["theoretical", "partial", "bypass", "takeover"],
                        "description": "Evidence strength: theoretical (unverified), partial (some evidence), bypass (security control bypassed), takeover (full exploitation). Critical severity requires bypass or takeover.",
                    },
                    "verdict": {
                        "type": "string",
                        "enum": ["exploited", "blocked_by_security", "out_of_scope", "false_positive"],
                        "description": "Final classification of the finding after validation.",
                    },
                },
                "required": ["id"],
            },
        ),

        # 8 ---- wm_add_observation ------------------------------------------
        Tool(
            name="wm_add_observation",
            description=(
                "Add observation (request, response, behavior, anomaly) to hypothesis as supporting evidence. "
                "Observations are test artifacts documenting hypothesis validation attempts: HTTP exchanges showing "
                "vulnerability trigger, application behaviors indicating security issue, anomalous responses suggesting "
                "flaw. Builds evidence chain for hypothesis confirmation or rejection. Multiple observations per hypothesis. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) during hypothesis testing to document evidence. "
                "Pattern: wm_add_hypothesis → wm_update_hypothesis(status='testing') → perform tests → "
                "wm_add_observation (type='request', content=payload) → wm_add_observation (type='response', content=result) → "
                "analyze → wm_update_hypothesis(evidence=[obs_ids]). Use type='request' for payloads sent, "
                "type='response' for server replies, type='behavior' for application actions, type='anomaly' for "
                "unexpected results. "

                "**Dependencies:** Requires hypothesis_id from wm_add_hypothesis(). Use returned observation_id in "
                "wm_update_hypothesis(evidence=[...]). Observations link to hypothesis, hypothesis links to finding "
                "if confirmed. Query with wm_query(table='observations', filters={'hypothesis_id': ...}). "

                "**Budget impact:** LOW - local database insert, no network requests. Completes <50ms. No request "
                "budget impact. Create many observations per hypothesis for comprehensive evidence. "

                "**Failure modes:** 'Hypothesis not found' if hypothesis_id invalid. Invalid type enum rejected. "
                "Empty content allowed but useless. Large content (>1MB) may cause performance issues (consider "
                "wm_store for large payloads and reference ID here). Metadata JSON serialization errors. "

                "**Risk level:** SAFE - local evidence documentation, no network activity or target interaction. "
                "Creates audit trail of testing activities. "

                "**Returns:** Observation result with observation_id (for evidence references), hypothesis_id, type, "
                "content, metadata, created_at. Use observation_id in wm_update_hypothesis(evidence=[obs_id, ...]), "
                "evidence_add_artifact(), wm_query. Builds evidence chain from hypothesis through observations to finding."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "hypothesis_id": {
                        "type": "string",
                        "description": "ID of the hypothesis this observation belongs to",
                    },
                    "type": {
                        "type": "string",
                        "enum": ["request", "response", "behavior", "anomaly"],
                        "description": "Type of observation",
                    },
                    "content": {
                        "type": "string",
                        "description": "Observation content (raw data, description, etc.)",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata (JSON object)",
                        "additionalProperties": True,
                    },
                },
                "required": ["hypothesis_id", "type", "content"],
            },
        ),

        # 9 ---- wm_query ---------------------------------------------------
        Tool(
            name="wm_query",
            description=(
                "Query the world model database. Search any table (assets, endpoints, identities, hypotheses, "
                "observations, findings, plans) with optional filters, pagination, and statistics. Essential for "
                "retrieving discovered assets, querying endpoint inventory, reviewing hypothesis status, and "
                "analyzing findings. Supports column=value filters, single record fetch by ID, and aggregate "
                "statistics across all tables. "

                "**When to use:** Phase 1-5 (All phases) to retrieve data from world model. Common use cases: "
                "wm_query(table='assets') to list all discovered domains/IPs, wm_query(table='endpoints', "
                "filters={'auth_required': true}) to find authenticated endpoints, wm_query(table='hypotheses', "
                "filters={'status': 'proposed'}) to see untested theories, wm_query(table='findings', "
                "filters={'severity': 'high'}) for critical vulnerabilities, wm_query(table='endpoints', id='<uuid>') "
                "for specific endpoint details, wm_query(table='assets', stats=true) for inventory counts. "

                "**Dependencies:** Requires prior data population via wm_add_asset(), wm_add_endpoint(), "
                "wm_add_hypothesis(), wm_add_finding(), etc. Returns empty results if no matching records (not an "
                "error). Follow query results with additional wm_* operations to update or enhance records. Use "
                "with coverage_init() to build test matrix from queried endpoints. "

                "**Budget impact:** LOW - Local database query, no HTTP requests. Completes in <100ms for small "
                "result sets, <500ms for large tables (1000+ rows). Does NOT count against request budget. "
                "Pagination (limit/offset) recommended for large tables to avoid overwhelming output. "

                "**Failure modes:** 'Invalid table' if table not in allowed list. 'Invalid filter column' if "
                "filtering on non-existent column (table schemas: assets(kind,name,tags), endpoints(method,path,"
                "auth_required,asset_id), hypotheses(title,status,severity,target_id), findings(severity,confidence,"
                "status,hypothesis_id)). 'Record not found' if querying by ID that doesn't exist (returns empty, "
                "not error). Large result sets without limit may return truncated results with warning. "

                "**Risk level:** SAFE - Read-only database query, no network activity or target interaction. "
                "No side effects or modifications. Query-only introspection of knowledge base. "

                "**Returns:** Query results array with matching records (each record includes id, created_at, "
                "updated_at, and table-specific fields). If stats=true, returns counts object with rows per table "
                "(assets_count, endpoints_count, hypotheses_count, findings_count). If id provided, returns single "
                "record object (not array). Empty array if no matches (valid response). Use results to: build lists "
                "for UI display, retrieve asset_ids/endpoint_ids for tool parameters, analyze testing progress, "
                "generate reports, resume assessment from previous state."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "table": {
                        "type": "string",
                        "enum": [
                            "assets", "endpoints", "identities",
                            "hypotheses", "observations", "findings",
                            "plans",
                        ],
                        "description": "Table to query",
                    },
                    "filters": {
                        "type": "object",
                        "description": (
                            "Column=value filters (e.g. {\"kind\": \"domain\"}, "
                            "{\"status\": \"confirmed\"})"
                        ),
                        "additionalProperties": True,
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Maximum rows to return (default: 100)",
                    },
                    "offset": {
                        "type": "integer",
                        "description": "Number of rows to skip (default: 0)",
                    },
                    "id": {
                        "type": "string",
                        "description": "If provided, fetch a single record by ID (ignores filters/limit/offset)",
                    },
                    "stats": {
                        "type": "boolean",
                        "description": "If true, return row counts for all tables (ignores other params)",
                    },
                },
                "required": ["table"],
            },
        ),

        # 10 ---- wm_store --------------------------------------------------
        Tool(
            name="wm_store",
            description=(
                "Store knowledge artifacts in world model RAG (Retrieval-Augmented Generation) system for later "
                "retrieval. Captures scan output, page content, HTTP exchanges, command results, fuzz results, errors, "
                "or any testing data worth preserving. Content auto-chunked if large (>10KB) and full-text indexed "
                "via PostgreSQL tsvector + semantic embeddings (pgvector). Essential for building institutional memory "
                "across sessions and enabling context-aware testing decisions. "

                "**When to use:** Phase 1-5 (All phases) after tool executions produce valuable output. Auto-called by "
                "many tools (scan, fuzz_endpoint, crawler_start) to preserve results. Manually call for: command outputs "
                "(execute results), interesting HTTP exchanges (http_send responses), error messages worth analyzing, "
                "page content for later reference, form data discovered, navigation traces. Use before wm_recall to "
                "enable context retrieval. "

                "**Dependencies:** None for storage. Retrieved with wm_recall(query, category, target). Auto-chunked "
                "for large content: 10KB chunks with overlap, indexed independently but retrievable together. Use "
                "source_tool for filtering (e.g., wm_recall(source_tool='nmap')). Tag for categorization (tags=['critical', "
                "'database']). "

                "**Budget impact:** LOW - local database insert with FTS/vector indexing. Completes <200ms for typical "
                "content (<100KB). Large content (>1MB) takes <2 seconds to chunk and index. No network requests. "
                "Storage unlimited - PostgreSQL handles GB-scale knowledge stores. "

                "**Failure modes:** Empty content allowed but useless. Very large content (>10MB) may timeout during "
                "embedding generation (chunk manually first). Invalid category enum rejected. Metadata JSON serialization "
                "errors if complex objects. Duplicate content creates multiple entries (intentional - timestamps matter). "

                "**Risk level:** SAFE - local knowledge storage, no network activity or target interaction. Builds "
                "persistent memory across sessions. "

                "**Returns:** Storage result with knowledge_id (for wm_recall(id=...) retrieval), source_tool, category, "
                "title, content_length, chunk_count (if chunked), tags[], target, created_at. Use knowledge_id for "
                "precise retrieval or rely on wm_recall search. Content immediately searchable via full-text and semantic "
                "similarity."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "source_tool": {
                        "type": "string",
                        "description": "Name of the tool that produced this content",
                    },
                    "category": {
                        "type": "string",
                        "enum": [
                            "scan_output", "page_content", "http_exchange",
                            "fuzz_result", "command_output", "error",
                            "form_data", "navigation", "timing", "other",
                        ],
                        "description": "Knowledge category for filtering",
                    },
                    "title": {
                        "type": "string",
                        "description": "Short descriptive title",
                    },
                    "content": {
                        "type": "string",
                        "description": "The content to store",
                    },
                    "target": {
                        "type": "string",
                        "description": "Target identifier (URL, IP, domain, etc.)",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Additional metadata (JSON object)",
                        "additionalProperties": True,
                    },
                    "tags": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Tags for filtering",
                    },
                },
                "required": ["source_tool", "category", "title", "content"],
            },
        ),

        # 11 ---- wm_recall -------------------------------------------------
        Tool(
            name="wm_recall",
            description=(
                "Search and retrieve stored knowledge from world model RAG system using full-text search (PostgreSQL "
                "FTS with tsvector), semantic search (pgvector embeddings), and metadata filters. Queries knowledge "
                "stored via wm_store() or auto-captured by tools. Returns relevant scan outputs, page content, HTTP "
                "exchanges, command results, errors - anything previously stored. Essential for context-aware testing: "
                "\"have we seen similar endpoint before?\", \"what did nmap find?\", \"recall error messages\". "

                "**When to use:** Phase 2-5 (Mapping onwards) to leverage institutional memory. Use before testing "
                "endpoints: wm_recall(query='similar endpoint sql injection', category='fuzz_result') to see prior "
                "findings. Use after errors: wm_recall(query='database error messages', category='error') for context. "
                "Use for reports: wm_recall(target='example.com') to gather all discoveries. Use "
                "wm_recall(source_tool='nmap', since='2024-01-15') for recent scan results. "

                "**Dependencies:** Requires wm_store() to have captured content first. Returns empty if no matches "
                "(expected early in assessment). Use query parameter for keyword/semantic search, filters "
                "(category, target, source_tool, tags, since) for precision. Set include_content=false for metadata-only "
                "results (faster). Set stats=true for knowledge store statistics. "

                "**Budget impact:** ZERO - local database query with FTS/vector search. Returns instantly for typical "
                "queries (<100ms). Complex semantic queries may take <500ms. No network requests. Pagination via "
                "limit/offset for large result sets. "

                "**Failure modes:** Empty results if: (1) no matching content stored, (2) query too specific, (3) "
                "filters too restrictive. Semantic search requires query text (empty query with filters works for "
                "metadata-only search). Since timestamp format must be ISO-8601. Invalid category enum rejected. "

                "**Risk level:** SAFE - read-only knowledge retrieval, no network activity or target interaction. "
                "Enables LLM context awareness. "

                "**Returns:** Search results array with: knowledge_id, source_tool, category, title, content (if "
                "include_content=true), target, tags[], created_at, relevance_score (FTS + semantic combined). Use "
                "content for context, knowledge_id for precise retrieval via wm_recall(id=...). Results sorted by "
                "relevance descending. Use for building context before endpoint testing or generating comprehensive reports."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search query (FTS5 full-text search + semantic similarity)",
                    },
                    "category": {
                        "type": "string",
                        "enum": [
                            "scan_output", "page_content", "http_exchange",
                            "fuzz_result", "command_output", "error",
                            "form_data", "navigation", "timing", "other",
                        ],
                        "description": "Filter by category",
                    },
                    "target": {
                        "type": "string",
                        "description": "Filter by target (URL, IP, domain)",
                    },
                    "source_tool": {
                        "type": "string",
                        "description": "Filter by source tool name",
                    },
                    "tags": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Filter by tags (any match)",
                    },
                    "since": {
                        "type": "string",
                        "description": "Filter by creation time (ISO-8601, e.g. '2024-01-01T00:00:00')",
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Maximum results to return (default: 20)",
                    },
                    "offset": {
                        "type": "integer",
                        "description": "Number of results to skip (default: 0)",
                    },
                    "full_chunks": {
                        "type": "boolean",
                        "description": "Include all chunks (default: false, head chunks only)",
                    },
                    "include_content": {
                        "type": "boolean",
                        "description": "Include full content in results (default: true)",
                    },
                    "id": {
                        "type": "string",
                        "description": "Retrieve a specific knowledge entry by ID (with all chunks)",
                    },
                    "stats": {
                        "type": "boolean",
                        "description": "Return knowledge store statistics (ignores other params)",
                    },
                },
            },
        ),

        # 12 ---- wm_add_plan -----------------------------------------------
        Tool(
            name="wm_add_plan",
            description=(
                "Create structured testing plan with ordered steps for multi-step attack sequences or complex testing "
                "workflows. Plans track progress through structured methodology: each step has status (pending/in_progress/done/skipped) "
                "and optional result. Used for systematic exploitation chains, privilege escalation paths, or organized "
                "testing campaigns. Alternative to ad-hoc testing for maintaining clear methodology documentation. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) before complex multi-tool attack chains. Use for: "
                "privilege escalation sequences (recon → foothold → lateral movement → escalation), SQL injection "
                "exploitation (detection → extraction → file access → RCE), comprehensive endpoint testing campaigns. "
                "Create plan with all steps upfront, update progress with wm_update_plan() as you execute. "

                "**Dependencies:** None for creation. Use wm_update_plan(step_index, step_status) to track progress. "
                "Query wm_query(table='plans', filters={'status': 'active'}) to see in-progress. Plan persists across "
                "sessions for long-term assessment tracking. Use for organizing testing when coverage matrix insufficient "
                "(e.g., exploit chains not representable as endpoint × vuln_class). "

                "**Budget impact:** LOW - local database insert, no network requests. Completes <50ms. No request "
                "budget impact. Create multiple plans for parallel testing tracks. "

                "**Failure modes:** Empty steps array rejected (must have at least 1 step). Duplicate titles allowed "
                "(can have multiple plans with same name). Very long plans (>50 steps) may be unwieldy (consider "
                "breaking into multiple plans). "

                "**Risk level:** SAFE - local planning and documentation, no network activity or target interaction. "
                "Organizational tool for complex testing. "

                "**Returns:** Plan creation result with plan_id (for wm_update_plan reference), title, goal, steps[] "
                "(all initially status='pending'), status (initially 'active'), created_at. Use plan_id with "
                "wm_update_plan() to mark step progress. Query wm_query(table='plans') to review. Use for maintaining "
                "structured methodology documentation and progress tracking in complex assessments."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "title": {
                        "type": "string",
                        "description": "Plan title (e.g. 'SQL Injection testing on /api/login')",
                    },
                    "goal": {
                        "type": "string",
                        "description": "What this plan aims to achieve",
                    },
                    "steps": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "description": {
                                    "type": "string",
                                    "description": "Step description",
                                },
                            },
                            "required": ["description"],
                        },
                        "description": "Ordered list of steps to execute",
                    },
                },
                "required": ["title", "goal", "steps"],
            },
        ),

        # 13 ---- wm_update_plan --------------------------------------------
        Tool(
            name="wm_update_plan",
            description=(
                "Update plan step status (pending→in_progress→done/skipped) and record step results or reflections. "
                "Tracks execution progress through structured testing plan. Step results document what happened, "
                "reflections capture lessons learned. Overall plan status (active→completed/abandoned) marks campaign "
                "lifecycle. Essential for maintaining audit trail of complex attack sequences. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) during plan execution. Pattern: wm_add_plan → "
                "wm_update_plan(step_index=0, step_status='in_progress') when starting step → execute step → "
                "wm_update_plan(step_index=0, step_status='done', step_result='found SQLi') → proceed to next step. "
                "Use step_status='skipped' when step unnecessary. Use reflection parameter at key milestones to document "
                "insights. Set status='completed' when all steps done, 'abandoned' if stopping early. "

                "**Dependencies:** Requires plan_id from wm_add_plan(). Step_index is 0-based (first step = 0). Query "
                "wm_query(table='plans', filters={'plan_id': ...}) to see current state. All parameters optional except "
                "plan_id - can update just status, just one step, or multiple fields at once. "

                "**Budget impact:** LOW - local database update, no network requests. Completes <50ms. No request "
                "budget impact. Update frequently to maintain progress visibility. "

                "**Failure modes:** 'Plan not found' if plan_id invalid. step_index out of range returns error (verify "
                "with wm_query first). Invalid step_status/status enums rejected. Multiple updates to same step allowed "
                "(last status wins). Can update step status without result (optional). "

                "**Risk level:** SAFE - local progress tracking, no network activity or target interaction. Workflow "
                "documentation tool. "

                "**Returns:** Simple confirmation 'Plan {ID} updated'. Updated status/results immediately visible in "
                "wm_query(table='plans'). Use to maintain clear progress documentation: which steps completed, which "
                "failed, what was learned, why plan abandoned. Reflection field builds institutional knowledge for "
                "future assessments."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "Plan ID",
                    },
                    "step_index": {
                        "type": "integer",
                        "description": "Step index to update (0-based)",
                    },
                    "step_status": {
                        "type": "string",
                        "enum": ["pending", "in_progress", "done", "skipped"],
                        "description": "New status for the step",
                    },
                    "step_result": {
                        "type": "string",
                        "description": "Result or output of the step",
                    },
                    "reflection": {
                        "type": "string",
                        "description": "Reflection on what was learned (appended to plan)",
                    },
                    "status": {
                        "type": "string",
                        "enum": ["active", "completed", "abandoned"],
                        "description": "Overall plan status",
                    },
                },
                "required": ["id"],
            },
        ),

        # 14 ---- wm_add_relationship ----------------------------------------
        Tool(
            name="wm_add_relationship",
            description=(
                "Add typed directional edge between entities in attack-surface graph (assets, endpoints, identities, "
                "hypotheses, findings). Creates structured relationships: domain has subdomain, subdomain resolves to IP, "
                "asset has endpoint, endpoint has finding, identity tested endpoint, hypothesis targets asset, hypothesis "
                "confirms finding. Enables graph queries (wm_get_neighbors, wm_find_path) for attack chain analysis and "
                "relationship discovery. Idempotent - duplicate edges silently ignored. "

                "**When to use:** Phase 1-5 (All phases) to build attack-surface knowledge graph. Auto-created by many "
                "tools (wm_add_endpoint creates has_endpoint, wm_add_finding creates confirms, coverage_mark creates "
                "has_finding). Manually create for: domain→subdomain chains (domain_has_subdomain), IP resolution "
                "(resolves_to), identity testing (tested_by), hypothesis targeting (targets). Essential for visualizing "
                "attack surface structure and finding lateral movement paths. "

                "**Dependencies:** Requires source_id and target_id from wm_add_* tools. Entities must exist before "
                "linking (verify with wm_query). Query relationships with wm_get_neighbors(entity_id, rel_types=[...]) "
                "or wm_find_path(from, to). Use metadata for edge attributes (e.g., metadata={'timestamp': '...', "
                "'confidence': 0.9}). "

                "**Budget impact:** LOW - local graph edge insert, no network requests. Completes <50ms. No request "
                "budget impact. Create thousands of relationships efficiently. "

                "**Failure modes:** 'Entity not found' if source/target IDs invalid (verify with wm_query first). "
                "Invalid entity types or rel_type enum rejected. Duplicate relationships silently ignored (idempotent - "
                "INSERT OR IGNORE). Circular relationships allowed (asset → endpoint → finding → hypothesis → asset cycles "
                "possible). Metadata JSON serialization errors. "

                "**Risk level:** SAFE - local graph construction, no network activity or target interaction. Builds "
                "structured knowledge representation. "

                "**Returns:** Relationship result with source (type, id), target (type, id), rel_type, metadata, "
                "created_at. If duplicate: returns existing relationship. Use with wm_get_neighbors to traverse graph: "
                "find all endpoints for asset, all findings for endpoint, all hypotheses targeting asset. Use wm_find_path "
                "to discover attack chains: domain → subdomain → IP → service → endpoint → vulnerability → exploit."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "source_type": {
                        "type": "string",
                        "enum": ["asset", "endpoint", "identity", "hypothesis", "finding"],
                        "description": "Type of the source entity",
                    },
                    "source_id": {
                        "type": "string",
                        "description": "ID of the source entity",
                    },
                    "target_type": {
                        "type": "string",
                        "enum": ["asset", "endpoint", "identity", "hypothesis", "finding"],
                        "description": "Type of the target entity",
                    },
                    "target_id": {
                        "type": "string",
                        "description": "ID of the target entity",
                    },
                    "rel_type": {
                        "type": "string",
                        "enum": [
                            "domain_has_subdomain", "resolves_to", "has_endpoint",
                            "has_finding", "tested_by", "targets", "confirms",
                        ],
                        "description": "Relationship type",
                    },
                    "metadata": {
                        "type": "object",
                        "description": "Optional metadata for the edge",
                        "additionalProperties": True,
                    },
                },
                "required": ["source_type", "source_id", "target_type", "target_id", "rel_type"],
            },
        ),

        # 15 ---- wm_get_neighbors -------------------------------------------
        Tool(
            name="wm_get_neighbors",
            description=(
                "BFS (Breadth-First Search) graph traversal from starting entity returning connected nodes and edges "
                "up to specified depth. Discovers: all endpoints for an asset (depth=1), all findings for endpoints "
                "(depth=2), attack chains from domain to vulnerabilities (depth=3+). Filter by relationship types "
                "(rel_types=['has_endpoint', 'has_finding']) and direction (outgoing/incoming/both). Essential for "
                "understanding attack surface structure and entity relationships. "

                "**When to use:** Phase 2-5 (Mapping onwards) to explore graph structure. Use cases: from asset find "
                "all endpoints (wm_get_neighbors(entity_type='asset', entity_id, rel_types=['has_endpoint'], direction='outgoing', "
                "depth=1)), from endpoint find findings (rel_types=['has_finding']), from hypothesis find confirmed "
                "findings (rel_types=['confirms']), discover subdomain chains (domain → subdomains, depth=2). Use for "
                "impact analysis: which assets affected by finding, which endpoints share vulnerability pattern. "

                "**Dependencies:** Requires entity_id from wm_add_* tools. Entity must exist (verify with wm_query). "
                "Relationships must exist via wm_add_relationship or auto-created by tools. Empty result if no "
                "relationships (isolated entity). Use rel_types filter for focused traversal. Max depth=4 prevents "
                "excessive computation. "

                "**Budget impact:** LOW - local graph traversal query, no network requests. Completes <200ms for "
                "typical graphs (depth=2, <100 nodes). Deep traversals (depth=4, large graphs) may take <1 second. "
                "No request budget impact. "

                "**Failure modes:** 'Entity not found' if entity_id/type invalid. Empty results if entity isolated "
                "(no relationships). Direction='incoming' with no inbound edges returns empty. Deep traversals (depth=4) "
                "on dense graphs may timeout (reduce depth or add rel_types filter). Invalid rel_types silently filtered. "

                "**Risk level:** SAFE - read-only graph query, no network activity or target interaction. Knowledge "
                "discovery tool. "

                "**Returns:** Graph traversal result with: nodes[] (discovered entities with type, id, metadata), "
                "edges[] (relationships with source, target, rel_type), depth_reached (actual BFS depth). Nodes grouped "
                "by entity type. Use to visualize attack surface, find lateral movement opportunities, analyze finding "
                "impact radius, discover related vulnerabilities. Combine with wm_find_path for targeted chain discovery."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "entity_type": {
                        "type": "string",
                        "enum": ["asset", "endpoint", "identity", "hypothesis", "finding"],
                        "description": "Type of the starting entity",
                    },
                    "entity_id": {
                        "type": "string",
                        "description": "ID of the starting entity",
                    },
                    "rel_types": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Filter to specific relationship types (optional)",
                    },
                    "direction": {
                        "type": "string",
                        "enum": ["outgoing", "incoming", "both"],
                        "description": "Edge direction to follow (default: both)",
                    },
                    "depth": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 4,
                        "description": "BFS depth (default: 1, max: 4)",
                    },
                },
                "required": ["entity_type", "entity_id"],
            },
        ),

        # 16 ---- wm_find_path -----------------------------------------------
        Tool(
            name="wm_find_path",
            description=(
                "Find shortest path between two entities in attack-surface graph using bidirectional BFS. "
                "Returns ordered list of relationship edges forming the path. Answers: 'How did attack chain "
                "reach this finding?', 'What links domain to vulnerability?', 'Which endpoints connect two "
                "hypotheses?'. Essential for attack chain analysis, pivot documentation, and understanding "
                "exploitation dependencies. Maximum depth 8 hops prevents infinite searches. Returns empty if "
                "no path exists (entities are disconnected subgraphs). "

                "**When to use:** Phase 4-5 (Exploitation/Reporting) for attack chain documentation and pivot "
                "analysis. Use when: documenting how auth bypass led to IDOR finding (from_type='finding' "
                "finding_id_A, to_type='finding' finding_id_B), analyzing which hypotheses target same asset "
                "(path between hypothesis_1 and hypothesis_2 through shared asset), reporting full attack path "
                "from initial recon to critical finding (from_type='asset' domain, to_type='finding' critical_vuln). "
                "Essential for SARIF output generation and evidence export where tool path provenance matters. "

                "**Dependencies:** Requires prior use of wm_add_relationship() to create graph edges. Empty "
                "graph returns 'no path found' for all queries. Use wm_query(table='assets'), "
                "wm_query(table='endpoints'), wm_query(table='findings') to get entity IDs before calling. "
                "Combine with wm_get_neighbors() for broader exploration if path search fails (may indicate "
                "missing intermediate relationships). Use evidence_bundle() after finding path for structured "
                "attack chain documentation. "

                "**Budget impact:** ZERO - local PostgreSQL graph query, no network requests. Bidirectional BFS "
                "is efficient even for large graphs (>1000 nodes). Returns instantly for typical engagements "
                "(<100 assets, <500 endpoints, <50 findings). Max depth 8 prevents runaway queries. "

                "**Failure modes:** Returns 'no path found' if entities disconnected (expected - not all entities "
                "relate). 'Entity not found' if from_id/to_id invalid (verify IDs with wm_query first). Empty "
                "path [] if from and to are same entity (valid result). Max depth exceeded returns shortest path "
                "within 8 hops or empty (increase max_depth to 8 max if needed). Type mismatch (from_type != actual "
                "entity type) returns error - verify entity types before calling. "

                "**Risk level:** SAFE - read-only graph traversal, no network activity or target interaction. Pure "
                "graph algorithm on local PostgreSQL data. "

                "**Returns:** JSON with: path[] (ordered list of edges), path_length (number of hops), from_entity "
                "(source details), to_entity (target details), relationship_types[] (edge types in path). Each edge "
                "in path contains: {source_type, source_id, target_type, target_id, rel_type, metadata}. Empty path "
                "[] indicates no connection found. Use path to generate attack narratives: 'Discovered domain example.com "
                "(wm_add_asset) → resolved to IP 10.0.0.1 (resolves_to edge) → found /api/users endpoint (has_endpoint) "
                "→ hypothesis IDOR vulnerability (targets) → confirmed as finding #42 (confirms).' Essential for "
                "visual attack chain diagrams and report generation."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "from_type": {
                        "type": "string",
                        "enum": ["asset", "endpoint", "identity", "hypothesis", "finding"],
                        "description": "Type of the starting entity",
                    },
                    "from_id": {
                        "type": "string",
                        "description": "ID of the starting entity",
                    },
                    "to_type": {
                        "type": "string",
                        "enum": ["asset", "endpoint", "identity", "hypothesis", "finding"],
                        "description": "Type of the target entity",
                    },
                    "to_id": {
                        "type": "string",
                        "description": "ID of the target entity",
                    },
                    "max_depth": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 8,
                        "description": "Maximum search depth (default: 8)",
                    },
                },
                "required": ["from_type", "from_id", "to_type", "to_id"],
            },
        ),
    ]


# ---------------------------------------------------------------------------
# Tool handler dispatch
# ---------------------------------------------------------------------------

async def handle_world_model_tool(
    name: str,
    arguments: dict,
    mcp_service: Any = None,
) -> List[TextContent]:
    """Dispatch a world-model tool call to the appropriate handler.

    Parameters
    ----------
    name : str
        Tool name (one of the nine wm_* tools).
    arguments : dict
        Arguments supplied by the caller.
    mcp_service :
        The MCP service instance (unused by world-model tools but kept
        for interface parity with other tool modules).
    """
    try:
        if name == "wm_add_asset":
            return await _handle_add_asset(arguments, mcp_service)
        elif name == "wm_add_endpoint":
            return await _handle_add_endpoint(arguments, mcp_service)
        elif name == "wm_add_identity":
            return await _handle_add_identity(arguments, mcp_service)
        elif name == "wm_add_hypothesis":
            return await _handle_add_hypothesis(arguments, mcp_service)
        elif name == "wm_update_hypothesis":
            return await _handle_update_hypothesis(arguments, mcp_service)
        elif name == "wm_add_finding":
            return await _handle_add_finding(arguments, mcp_service)
        elif name == "wm_update_finding":
            return await _handle_update_finding(arguments, mcp_service)
        elif name == "wm_add_observation":
            return await _handle_add_observation(arguments, mcp_service)
        elif name == "wm_query":
            return await _handle_query(arguments, mcp_service)
        elif name == "wm_store":
            return await _handle_wm_store(arguments, mcp_service)
        elif name == "wm_recall":
            return await _handle_wm_recall(arguments, mcp_service)
        elif name == "wm_add_plan":
            return await _handle_add_plan(arguments, mcp_service)
        elif name == "wm_update_plan":
            return await _handle_update_plan(arguments, mcp_service)
        elif name == "wm_add_relationship":
            return await _handle_add_relationship(arguments, mcp_service)
        elif name == "wm_get_neighbors":
            return await _handle_get_neighbors(arguments, mcp_service)
        elif name == "wm_find_path":
            return await _handle_find_path(arguments, mcp_service)
    except ValueError:
        return _error_content(
            "No assessment loaded. Use 'load_assessment' first before using world model tools."
        )
    except Exception as exc:
        logger.error("World-model tool %s failed: %s", name, exc, exc_info=True)
        return _error_content(f"Error in {name}: {exc}")

    return _error_content(f"Unknown world-model tool: {name}")


# ---------------------------------------------------------------------------
# Lazy database initialisation
# ---------------------------------------------------------------------------

# (db + json helpers imported from lib.tool_helpers above; _get_db raises ValueError)


# ---------------------------------------------------------------------------
# Individual handlers
# ---------------------------------------------------------------------------

async def _handle_add_asset(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_asset."""
    kind = arguments.get("kind")
    if not kind or not isinstance(kind, str):
        return _error_content("kind is required and must be a string")

    name = arguments.get("name")
    if not name or not isinstance(name, str):
        return _error_content("name is required and must be a string")

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    tags = arguments.get("tags") or []
    if not isinstance(tags, list):
        tags = []

    db = await _get_db(mcp_service)
    asset = await db.add_asset(kind=kind, name=name, metadata=metadata, tags=tags)

    # Sync asset to backend recon
    if mcp_service:
        _ASSET_TYPE_MAP = {
            "domain": "subdomain", "subdomain": "subdomain",
            "ip": "service", "service": "service", "application": "technology",
        }
        await mcp_service.safe_add_recon(
            data_type=_ASSET_TYPE_MAP.get(kind, kind),
            name=name,
            details={"kind": kind, "tags": tags, "wm_id": asset.get("id", "")},
            phase="reconnaissance",
        )

    return _json_content({
        "success": True,
        "asset": asset,
        "message": f"Asset '{name}' ({kind}) added to world model.",
    })


async def _handle_add_endpoint(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_endpoint."""
    asset_id = arguments.get("asset_id")
    if not asset_id or not isinstance(asset_id, str):
        return _error_content("asset_id is required and must be a string")

    method = arguments.get("method")
    if not method or not isinstance(method, str):
        return _error_content("method is required and must be a string")

    path = arguments.get("path")
    if not path or not isinstance(path, str):
        return _error_content("path is required and must be a string")

    parameters = arguments.get("parameters") or {}
    if not isinstance(parameters, dict):
        parameters = {}

    auth_required = arguments.get("auth_required") is True

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    db = await _get_db(mcp_service)
    endpoint = await db.add_endpoint(
        asset_id=asset_id,
        method=method.upper(),
        path=path,
        parameters=parameters,
        auth_required=auth_required,
        metadata=metadata,
    )

    # Sync endpoint to backend recon
    if mcp_service:
        await mcp_service.safe_add_recon(
            data_type="endpoint",
            name=f"{method.upper()} {path}",
            details={
                "method": method.upper(),
                "path": path,
                "auth_required": auth_required,
                "wm_id": endpoint.get("id", ""),
            },
            phase="reconnaissance",
        )

    # Auto-create graph edge: asset → endpoint
    try:
        await db.add_relationship(
            source_type="asset", source_id=asset_id,
            target_type="endpoint", target_id=endpoint["id"],
            rel_type="has_endpoint",
        )
    except Exception as rel_exc:
        logger.warning("Auto-relationship (has_endpoint) failed: %s", rel_exc)

    return _json_content({
        "success": True,
        "endpoint": endpoint,
        "message": f"Endpoint {method.upper()} {path} added to asset {asset_id}.",
    })


async def _handle_add_identity(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_identity."""
    name = arguments.get("name")
    if not name or not isinstance(name, str):
        return _error_content("name is required and must be a string")

    auth_type = arguments.get("auth_type")
    if not auth_type or not isinstance(auth_type, str):
        return _error_content("auth_type is required and must be a string")

    scope = arguments.get("scope")
    if not scope or not isinstance(scope, str):
        return _error_content("scope is required and must be a string")

    permissions = arguments.get("permissions") or []
    if not isinstance(permissions, list):
        permissions = []

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    db = await _get_db(mcp_service)
    identity = await db.add_identity(
        name=name,
        auth_type=auth_type,
        scope=scope,
        permissions=permissions,
        metadata=metadata,
    )

    return _json_content({
        "success": True,
        "identity": identity,
        "message": f"Identity '{name}' ({auth_type}, scope={scope}) added.",
    })


async def _handle_add_hypothesis(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_hypothesis."""
    title = arguments.get("title")
    if not title or not isinstance(title, str):
        return _error_content("title is required and must be a string")

    description = arguments.get("description")
    if not description or not isinstance(description, str):
        return _error_content("description is required and must be a string")

    severity = arguments.get("severity")
    if not severity or not isinstance(severity, str):
        return _error_content("severity is required and must be a string")

    target_id = arguments.get("target_id")
    if target_id is not None and not isinstance(target_id, str):
        target_id = None

    db = await _get_db(mcp_service)
    hypothesis = await db.add_hypothesis(
        title=title,
        description=description,
        severity=severity,
        target_id=target_id,
    )

    # Auto-create graph edge: hypothesis → target (if target_id provided)
    if target_id:
        try:
            await db.add_relationship(
                source_type="hypothesis", source_id=hypothesis["id"],
                target_type="endpoint", target_id=target_id,
                rel_type="targets",
            )
        except Exception as rel_exc:
            logger.warning("Auto-relationship (targets) failed: %s", rel_exc)

    return _json_content({
        "success": True,
        "hypothesis": hypothesis,
        "message": f"Hypothesis '{title}' created with status 'proposed'.",
    })


async def _handle_update_hypothesis(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_update_hypothesis."""
    hypothesis_id = arguments.get("id")
    if not hypothesis_id or not isinstance(hypothesis_id, str):
        return _error_content("id is required and must be a string")

    status = arguments.get("status")
    if status is not None and not isinstance(status, str):
        return _error_content("status must be a string")

    evidence = arguments.get("evidence")
    if evidence is not None and not isinstance(evidence, list):
        return _error_content("evidence must be an array of strings")

    if status is None and evidence is None:
        return _error_content("At least one of status or evidence must be provided")

    db = await _get_db(mcp_service)
    hypothesis = await db.update_hypothesis(
        hypothesis_id=hypothesis_id,
        status=status,
        evidence=evidence,
    )

    return _json_content({
        "success": True,
        "hypothesis": hypothesis,
        "message": f"Hypothesis {hypothesis_id} updated.",
    })


async def _handle_add_finding(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_finding."""
    hypothesis_id = arguments.get("hypothesis_id")
    if not hypothesis_id or not isinstance(hypothesis_id, str):
        return _error_content("hypothesis_id is required and must be a string")

    title = arguments.get("title")
    if not title or not isinstance(title, str):
        return _error_content("title is required and must be a string")

    severity = arguments.get("severity")
    if not severity or not isinstance(severity, str):
        return _error_content("severity is required and must be a string")

    confidence = arguments.get("confidence")
    if confidence is None or not isinstance(confidence, (int, float)):
        return _error_content("confidence is required and must be a number (0.0 - 1.0)")

    evidence_ids = arguments.get("evidence_ids") or []
    if not isinstance(evidence_ids, list):
        evidence_ids = []

    remediation = arguments.get("remediation")
    if remediation is not None and not isinstance(remediation, str):
        remediation = None

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    proof_level = arguments.get("proof_level")
    if proof_level is not None and not isinstance(proof_level, str):
        proof_level = None

    verdict = arguments.get("verdict")
    if verdict is not None and not isinstance(verdict, str):
        verdict = None

    db = await _get_db(mcp_service)
    finding = await db.add_finding(
        hypothesis_id=hypothesis_id,
        title=title,
        severity=severity,
        confidence=float(confidence),
        evidence_ids=evidence_ids,
        remediation=remediation,
        metadata=metadata,
        proof_level=proof_level,
        verdict=verdict,
    )

    # Auto-create graph edge: finding → hypothesis
    try:
        await db.add_relationship(
            source_type="finding", source_id=finding["id"],
            target_type="hypothesis", target_id=hypothesis_id,
            rel_type="confirms",
        )
    except Exception as rel_exc:
        logger.warning("Auto-relationship (confirms) failed: %s", rel_exc)

    # Sync finding to backend as a card
    if mcp_service:
        if mcp_service.current_assessment_id:
            _SEV_MAP = {"critical": "CRITICAL", "high": "HIGH", "medium": "MEDIUM", "low": "LOW", "info": "INFO"}
            sync_result = await mcp_service.safe_add_card(
                card_type="finding",
                title=title,
                severity=_SEV_MAP.get(severity, "INFO"),
                status="confirmed" if float(confidence) >= 0.7 else "potential",
                technical_analysis=f"Hypothesis: {hypothesis_id}\nConfidence: {confidence}",
                notes=remediation or "",
                context=f"Source: world_model, WM ID: {finding.get('id', '')}",
            )
            if sync_result.skipped:
                logger.warning(
                    f"Finding '{title}' created in world model but NOT synced to cards table. "
                    f"Reason: {sync_result.reason}. Finding will not be visible in dashboard."
                )
            elif not sync_result.ok:
                logger.error(
                    f"Failed to sync finding '{title}' to cards table: {sync_result.reason}. "
                    f"Finding exists in world model but not in dashboard."
                )
            else:
                logger.info(f"Finding '{title}' synced to cards table successfully (ID: {finding.get('id')})")
        else:
            logger.error(
                f"Cannot sync finding '{title}' to cards - no assessment loaded in mcp_service. "
                f"Finding exists in world model (ID: {finding.get('id')}) but NOT visible in dashboard."
            )
    else:
        logger.warning(
            f"Finding '{title}' created in world model (ID: {finding.get('id')}) but mcp_service is None - "
            f"cannot sync to cards table. Finding will NOT be visible in dashboard."
        )

    return _json_content({
        "success": True,
        "finding": finding,
        "message": f"Finding '{title}' ({severity}, confidence={confidence}) recorded.",
    })


async def _handle_update_finding(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_update_finding."""
    finding_id = arguments.get("id")
    if not finding_id or not isinstance(finding_id, str):
        return _error_content("id is required and must be a string")

    status = arguments.get("status")
    if status is not None and not isinstance(status, str):
        return _error_content("status must be a string")

    confidence = arguments.get("confidence")
    if confidence is not None and not isinstance(confidence, (int, float)):
        return _error_content("confidence must be a number (0.0 - 1.0)")

    remediation = arguments.get("remediation")
    if remediation is not None and not isinstance(remediation, str):
        return _error_content("remediation must be a string")

    proof_level = arguments.get("proof_level")
    if proof_level is not None and not isinstance(proof_level, str):
        return _error_content("proof_level must be a string")

    verdict = arguments.get("verdict")
    if verdict is not None and not isinstance(verdict, str):
        return _error_content("verdict must be a string")

    if status is None and confidence is None and remediation is None and proof_level is None and verdict is None:
        return _error_content("At least one of status, confidence, remediation, proof_level, or verdict must be provided")

    db = await _get_db(mcp_service)
    finding = await db.update_finding(
        finding_id=finding_id,
        status=status,
        confidence=float(confidence) if confidence is not None else None,
        remediation=remediation,
        proof_level=proof_level,
        verdict=verdict,
    )

    return _json_content({
        "success": True,
        "finding": finding,
        "message": f"Finding {finding_id} updated.",
    })


async def _handle_add_observation(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_observation."""
    hypothesis_id = arguments.get("hypothesis_id")
    if not hypothesis_id or not isinstance(hypothesis_id, str):
        return _error_content("hypothesis_id is required and must be a string")

    obs_type = arguments.get("type")
    if not obs_type or not isinstance(obs_type, str):
        return _error_content("type is required and must be a string")

    content = arguments.get("content")
    if not content or not isinstance(content, str):
        return _error_content("content is required and must be a string")

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    db = await _get_db(mcp_service)
    observation = await db.add_observation(
        hypothesis_id=hypothesis_id,
        obs_type=obs_type,
        content=content,
        metadata=metadata,
    )

    return _json_content({
        "success": True,
        "observation": observation,
        "message": f"Observation ({obs_type}) added to hypothesis {hypothesis_id}.",
    })


async def _handle_query(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_query - flexible querying of the world model."""
    # Check for stats mode first
    if arguments.get("stats") is True:
        db = await _get_db(mcp_service)
        stats = await db.get_stats()
        return _json_content({
            "success": True,
            "stats": stats,
            "message": "World model statistics.",
        })

    table = arguments.get("table")
    if not table or not isinstance(table, str):
        return _error_content("table is required and must be a string")

    # Check for single-record lookup by ID
    record_id = arguments.get("id")
    if record_id and isinstance(record_id, str):
        db = await _get_db(mcp_service)
        record = await db.get_by_id(table, record_id)
        if record is None:
            return _error_content(f"Record not found: {record_id} in {table}")
        return _json_content({
            "success": True,
            "table": table,
            "record": record,
        })

    # General query with filters
    filters = arguments.get("filters") or {}
    if not isinstance(filters, dict):
        filters = {}

    limit = arguments.get("limit", 100)
    if not isinstance(limit, int) or limit < 1:
        limit = 100

    offset = arguments.get("offset", 0)
    if not isinstance(offset, int) or offset < 0:
        offset = 0

    db = await _get_db(mcp_service)
    results = await db.query(table=table, filters=filters, limit=limit, offset=offset)

    return _json_content({
        "success": True,
        "table": table,
        "count": len(results),
        "limit": limit,
        "offset": offset,
        "filters": filters,
        "results": results,
    })


async def _handle_wm_store(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_store - store knowledge in the world model."""
    source_tool = arguments.get("source_tool")
    if not source_tool or not isinstance(source_tool, str):
        return _error_content("source_tool is required and must be a string")

    category = arguments.get("category")
    if not category or not isinstance(category, str):
        return _error_content("category is required and must be a string")

    title = arguments.get("title")
    if not title or not isinstance(title, str):
        return _error_content("title is required and must be a string")

    content = arguments.get("content")
    if not content or not isinstance(content, str):
        return _error_content("content is required and must be a string")

    target = arguments.get("target", "")
    if not isinstance(target, str):
        target = ""

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    tags = arguments.get("tags") or []
    if not isinstance(tags, list):
        tags = []

    db = await _get_db(mcp_service)

    # Generate embedding (best-effort)
    embedding = None
    try:
        from lib.embedder import get_embedder
        embedder = get_embedder()
        embed_text = f"{title}\n{content[:512]}" if len(content) > 512 else f"{title}\n{content}"
        embedding = embedder.embed(embed_text)
    except Exception:
        pass

    result = await db.store_knowledge(
        source_tool=source_tool,
        category=category,
        title=title,
        content=content,
        target=target,
        metadata=metadata,
        tags=tags,
        embedding=embedding,
    )

    return _json_content({
        "success": True,
        **result,
        "message": f"Knowledge stored: '{title}' ({category}, {result['chunk_count']} chunk(s), {result['content_size']} bytes)",
    })


async def _handle_wm_recall(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_recall - search and retrieve stored knowledge."""
    # Check for stats mode
    if arguments.get("stats") is True:
        db = await _get_db(mcp_service)
        stats = await db.knowledge_stats()
        return _json_content({
            "success": True,
            "stats": stats,
            "message": "Knowledge store statistics.",
        })

    # Check for single-record lookup by ID
    record_id = arguments.get("id")
    if record_id and isinstance(record_id, str):
        db = await _get_db(mcp_service)
        chunks = await db.get_knowledge_chunks(record_id)
        if not chunks:
            return _error_content(f"Knowledge entry not found: {record_id}")

        # Reassemble content from chunks
        full_content = "".join(c.get("content", "") for c in chunks)
        head = chunks[0].copy()
        head["content"] = full_content
        head.pop("embedding", None)

        return _json_content({
            "success": True,
            "entry": head,
            "chunk_count": len(chunks),
        })

    # Search / browse mode
    query = arguments.get("query")
    if query is not None and not isinstance(query, str):
        query = str(query)

    category = arguments.get("category")
    target = arguments.get("target")
    source_tool = arguments.get("source_tool")
    tags = arguments.get("tags")
    since = arguments.get("since")
    limit = arguments.get("limit", 20)
    offset = arguments.get("offset", 0)
    full_chunks = arguments.get("full_chunks", False)
    include_content = arguments.get("include_content", True)

    if not isinstance(limit, int) or limit < 1:
        limit = 20
    if not isinstance(offset, int) or offset < 0:
        offset = 0

    db = await _get_db(mcp_service)

    # Generate query embedding for semantic search
    query_embedding = None
    if query:
        try:
            from lib.embedder import get_embedder
            embedder = get_embedder()
            query_embedding = embedder.embed(query)
        except Exception:
            pass

    results = await db.recall_knowledge(
        query=query,
        query_embedding=query_embedding,
        category=category,
        target=target,
        source_tool=source_tool,
        tags=tags,
        since=since,
        limit=limit,
        offset=offset,
        full_chunks=full_chunks,
        include_content=include_content,
    )

    return _json_content({
        "success": True,
        "query": query,
        "count": len(results),
        "limit": limit,
        "offset": offset,
        "results": results,
    })


async def _handle_add_plan(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_plan - create a structured testing plan."""
    title = arguments.get("title")
    if not title or not isinstance(title, str):
        return _error_content("title is required and must be a string")

    goal = arguments.get("goal")
    if not goal or not isinstance(goal, str):
        return _error_content("goal is required and must be a string")

    steps = arguments.get("steps")
    if not steps or not isinstance(steps, list) or len(steps) == 0:
        return _error_content("steps is required and must be a non-empty array")

    db = await _get_db(mcp_service)
    plan = await db.add_plan(title=title, goal=goal, steps=steps)

    return _json_content({
        "success": True,
        "plan": plan,
        "message": f"Plan '{title}' created with {len(plan['steps'])} steps.",
    })


async def _handle_update_plan(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_update_plan - update step status or add reflection."""
    plan_id = arguments.get("id")
    if not plan_id or not isinstance(plan_id, str):
        return _error_content("id is required and must be a string")

    step_index = arguments.get("step_index")
    if step_index is not None and not isinstance(step_index, int):
        return _error_content("step_index must be an integer")

    step_status = arguments.get("step_status")
    if step_status is not None and not isinstance(step_status, str):
        return _error_content("step_status must be a string")

    step_result = arguments.get("step_result")
    if step_result is not None and not isinstance(step_result, str):
        return _error_content("step_result must be a string")

    reflection = arguments.get("reflection")
    if reflection is not None and not isinstance(reflection, str):
        return _error_content("reflection must be a string")

    status = arguments.get("status")
    if status is not None and not isinstance(status, str):
        return _error_content("status must be a string")

    # Must provide at least one update field
    if all(v is None for v in [step_index, reflection, status]):
        return _error_content(
            "At least one of step_index, reflection, or status must be provided"
        )

    db = await _get_db(mcp_service)
    plan = await db.update_plan(
        plan_id=plan_id,
        step_index=step_index,
        step_status=step_status,
        step_result=step_result,
        reflection=reflection,
        status=status,
    )

    return _json_content({
        "success": True,
        "plan": plan,
        "message": f"Plan {plan_id} updated.",
    })


# ---------------------------------------------------------------------------
# Graph tool handlers
# ---------------------------------------------------------------------------

async def _handle_add_relationship(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_add_relationship - add a typed edge between entities."""
    source_type = arguments.get("source_type")
    if not source_type or not isinstance(source_type, str):
        return _error_content("source_type is required and must be a string")

    source_id = arguments.get("source_id")
    if not source_id or not isinstance(source_id, str):
        return _error_content("source_id is required and must be a string")

    target_type = arguments.get("target_type")
    if not target_type or not isinstance(target_type, str):
        return _error_content("target_type is required and must be a string")

    target_id = arguments.get("target_id")
    if not target_id or not isinstance(target_id, str):
        return _error_content("target_id is required and must be a string")

    rel_type = arguments.get("rel_type")
    if not rel_type or not isinstance(rel_type, str):
        return _error_content("rel_type is required and must be a string")

    metadata = arguments.get("metadata") or {}
    if not isinstance(metadata, dict):
        metadata = {}

    db = await _get_db(mcp_service)
    rel = await db.add_relationship(
        source_type=source_type,
        source_id=source_id,
        target_type=target_type,
        target_id=target_id,
        rel_type=rel_type,
        metadata=metadata,
    )

    return _json_content({
        "success": True,
        "relationship": rel,
        "message": f"Relationship {source_type}:{source_id} --[{rel_type}]--> {target_type}:{target_id} added.",
    })


async def _handle_get_neighbors(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_get_neighbors - BFS traversal from an entity."""
    entity_type = arguments.get("entity_type")
    if not entity_type or not isinstance(entity_type, str):
        return _error_content("entity_type is required and must be a string")

    entity_id = arguments.get("entity_id")
    if not entity_id or not isinstance(entity_id, str):
        return _error_content("entity_id is required and must be a string")

    rel_types = arguments.get("rel_types")
    if rel_types is not None and not isinstance(rel_types, list):
        rel_types = None

    direction = arguments.get("direction", "both")
    if direction not in ("outgoing", "incoming", "both"):
        direction = "both"

    depth = arguments.get("depth", 1)
    if not isinstance(depth, int) or depth < 1:
        depth = 1

    db = await _get_db(mcp_service)
    result = await db.get_neighbors(
        entity_type=entity_type,
        entity_id=entity_id,
        rel_types=rel_types,
        direction=direction,
        depth=depth,
    )

    return _json_content({
        "success": True,
        "node_count": len(result["nodes"]),
        "edge_count": len(result["edges"]),
        **result,
        "message": f"Found {len(result['nodes'])} neighbors, {len(result['edges'])} edges at depth {depth}.",
    })


async def _handle_find_path(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle wm_find_path - shortest path between two entities."""
    from_type = arguments.get("from_type")
    if not from_type or not isinstance(from_type, str):
        return _error_content("from_type is required and must be a string")

    from_id = arguments.get("from_id")
    if not from_id or not isinstance(from_id, str):
        return _error_content("from_id is required and must be a string")

    to_type = arguments.get("to_type")
    if not to_type or not isinstance(to_type, str):
        return _error_content("to_type is required and must be a string")

    to_id = arguments.get("to_id")
    if not to_id or not isinstance(to_id, str):
        return _error_content("to_id is required and must be a string")

    max_depth = arguments.get("max_depth", 8)
    if not isinstance(max_depth, int) or max_depth < 1:
        max_depth = 8

    db = await _get_db(mcp_service)
    path = await db.get_attack_path(
        from_type=from_type,
        from_id=from_id,
        to_type=to_type,
        to_id=to_id,
        max_depth=max_depth,
    )

    if path is None:
        return _json_content({
            "success": True,
            "found": False,
            "path": [],
            "length": 0,
            "message": f"No path found from {from_type}:{from_id} to {to_type}:{to_id} (max depth {max_depth}).",
        })

    return _json_content({
        "success": True,
        "found": True,
        "path": path,
        "length": len(path),
        "message": f"Path found: {len(path)} hop(s) from {from_type}:{from_id} to {to_type}:{to_id}.",
    })
