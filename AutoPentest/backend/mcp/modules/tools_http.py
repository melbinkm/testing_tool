"""
HTTP Client Tools - http_send, http_send_batch, http_get_stats

Ports the http-client-mcp TypeScript server's 3 tools to Python.
Provides rate-limited, proxy-aware HTTP request capabilities with
correlation headers and concurrency control.
"""
import json
import os
from typing import List
from urllib.parse import urlparse

from mcp.types import Tool, TextContent
from lib.http_client import HttpClient


# NOTE: Module-level singleton REMOVED - now using per-assessment HTTP client
# via mcp_service with assessment-specific scope validation


def _get_http_client(mcp_service) -> HttpClient:
    """Get or create HTTP client with per-assessment scope.

    Parameters
    ----------
    mcp_service : AutoPentestService
        Service instance providing assessment_id and scope_provider.

    Returns
    -------
    HttpClient
        HTTP client configured with per-assessment scope validation.
    """
    # Fix C1: Cache HTTP client per assessment to preserve budget/rate counters
    # Invalidate cache if assessment changed
    cache_key = mcp_service.current_assessment_id
    if hasattr(mcp_service, '_http_client_cache') and \
       hasattr(mcp_service, '_http_client_cache_key') and \
       mcp_service._http_client_cache_key == cache_key and \
       mcp_service._http_client_cache is not None:
        return mcp_service._http_client_cache

    # Build exchange logger callback for audit trail
    async def _log_exchange(request, response, correlation_ids, timing):
        if hasattr(mcp_service, 'activity_logger') and mcp_service.activity_logger:
            await mcp_service.activity_logger.log_http_exchange(
                url=request.get("url", ""),
                method=request.get("method", ""),
                status_code=response.get("status", 0),
                request_headers=request.get("headers", {}),
                response_headers=response.get("headers", {}),
                response_body_preview=(response.get("body") or "")[:2048],
                correlation_id=correlation_ids.get("request_id", ""),
                timing_ms=timing.get("duration_ms", 0),
            )

    # Create new HTTP client with assessment context
    client = HttpClient(
        config={
            "engagement_id": os.environ.get("ENGAGEMENT_ID", "default"),
            "proxy_url": os.environ.get("PROXY_URL"),
            "max_rps": float(os.environ.get("MAX_RPS", "10")),
            "max_concurrent": int(os.environ.get("MAX_CONCURRENT", "5")),
            "default_timeout": float(os.environ.get("DEFAULT_TIMEOUT", "30000")),
            "max_total_requests": int(os.environ.get("MAX_TOTAL_REQUESTS", "10000")),
        },
        assessment_id=mcp_service.current_assessment_id,
        scope_provider=mcp_service.scope_provider,
        exchange_logger=_log_exchange,
    )

    # Cache for reuse
    mcp_service._http_client_cache = client
    mcp_service._http_client_cache_key = cache_key
    return client


def _validate_url(url: str) -> bool:
    """Validate that a URL has a valid format with scheme and netloc."""
    try:
        parsed = urlparse(url)
        return parsed.scheme in ("http", "https") and bool(parsed.netloc)
    except Exception:
        return False


def get_http_tools() -> List[Tool]:
    """Get HTTP client tool definitions."""
    return [
        Tool(
            name="http_send",
            description=(
                "Send a single HTTP request with automatic rate limiting, budget tracking, and correlation "
                "headers. Supports proxy routing through tools like Burp Suite (via PROXY_URL env var) for "
                "request inspection and modification. Automatically validates target is in scope and enforces "
                "MAX_RPS and MAX_TOTAL_REQUESTS constraints. Essential for manual vulnerability testing. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) for surgical testing of specific "
                "vulnerabilities. Use when you need precise control over request construction (custom headers, "
                "specific payloads, timing). Ideal for testing authentication bypasses, session handling, CSRF, "
                "header injection, and manual parameter manipulation. For multiple similar requests, use "
                "http_send_batch() instead for better performance. "

                "**Dependencies:** Requires scope_validate_target() to confirm URL is in allowlist (automatic "
                "if scope configured). Check scope_check_budget() before expensive operations. Follow with "
                "validate_repro() if response indicates vulnerability. Use wm_store() to save interesting "
                "responses for later analysis. "

                "**Budget impact:** LOW - 1 request per call. Respects MAX_RPS rate limit (default 10/sec) "
                "and MAX_TOTAL_REQUESTS budget (default 10000). Each request automatically tracked and "
                "counted against total budget. Use http_get_stats() to check remaining budget. "

                "**Failure modes:** 'Out of scope' error if target not in allowlist - verify with "
                "scope_validate_target() first. 'Budget exceeded' if MAX_TOTAL_REQUESTS reached - check "
                "scope_check_budget() and prioritize high-value tests. 'Rate limited' if exceeding MAX_RPS "
                "(queued automatically, no retry needed). 'Timeout' if endpoint slow - increase timeout "
                "parameter or verify endpoint is reachable. 'Connection refused' may indicate WAF/firewall "
                "blocking, IP ban, or service down. "

                "**Risk level:** CAUTION - Sends user-controlled requests to target. Risk depends on method "
                "and payload: GET with benign parameters = low risk, POST with malicious payloads = high risk. "
                "All requests logged with correlation headers (X-AutoPentest-Request-ID) for audit trail. "
                "Detectable in target logs and by IDS/IPS if payloads are aggressive. "

                "**Returns:** HTTP response with status code, headers (dict), body (string), timing "
                "information (duration_ms), correlation_id, and request metadata. Full request/response pair "
                "suitable for evidence_add_artifact(). If proxy configured, request also routed through proxy "
                "for manual inspection in Burp/OWASP ZAP. Use response for differential analysis, error "
                "detection, and validation workflows."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "method": {
                        "type": "string",
                        "enum": ["GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"],
                        "description": "HTTP method to use"
                    },
                    "url": {
                        "type": "string",
                        "description": "Target URL (must include http:// or https://)"
                    },
                    "headers": {
                        "type": "object",
                        "description": "Optional HTTP headers as key-value pairs"
                    },
                    "body": {
                        "type": "string",
                        "description": "Optional request body"
                    },
                    "timeout": {
                        "type": "number",
                        "description": "Request timeout in milliseconds (overrides default)"
                    },
                    "identity_id": {
                        "type": "string",
                        "description": "Optional identity ID for correlation tracking"
                    },
                    "analyze": {
                        "type": "boolean",
                        "description": "Run exchange analyzer on response for static security findings (headers, cookies, tech detection)",
                        "default": True,
                    }
                },
                "required": ["method", "url"]
            }
        ),
        Tool(
            name="http_send_batch",
            description=(
                "Send multiple HTTP requests concurrently with automatic rate limiting, budget tracking, "
                "and concurrency control. More efficient than NÃ—http_send() calls for bulk operations like "
                "IDOR enumeration, parameter fuzzing, and resource discovery. All requests share same rate "
                "limiter (MAX_RPS) and respect MAX_CONCURRENT limit (default 5). Automatic scope validation "
                "and budget enforcement across entire batch. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) for bulk testing operations. Essential "
                "for IDOR enumeration (/api/users/{1..100}), multi-parameter testing, A/B comparison (same "
                "endpoint with different payloads), sitemap validation, and resource discovery. Use instead "
                "of loop+http_send() for 3+ similar requests to maximize efficiency and respect rate limits. "
                "Budget-aware tool for high-volume testing. "

                "**Dependencies:** Same as http_send() but multiplied by N requests. Requires scope_validate_target() "
                "for each URL (automatic). Check scope_check_budget() BEFORE calling to ensure sufficient "
                "budget for entire batch. Follow with sequence_data_ownership() for IDOR validation or "
                "auth_diff_test() for authorization analysis of batch results. "

                "**Budget impact:** MEDIUM to HIGH - N requests where N = array length. Typical: 10-100 requests "
                "for IDOR testing, 50-500 for fuzzing, 100-1000 for discovery. Budget-efficient vs individual "
                "calls due to batching optimizations. Max MAX_CONCURRENT (default 5) requests execute in parallel, "
                "rest queued with rate limiting. Check http_get_stats() to verify budget before large batches. "

                "**Failure modes:** 'Budget exhausted mid-batch' - some requests succeed, rest fail with budget "
                "error (partial results still returned). 'Mixed scope violations' - out-of-scope URLs skipped, "
                "in-scope requests proceed (check per-request status). 'Partial timeouts' - slow endpoints time "
                "out while fast ones complete (tune timeout parameter). 'Rate limit backpressure' - large batches "
                "(>100 requests) may queue for extended time (~10 seconds for 100 requests at MAX_RPS=10). "
                "Recommend batch sizes <=50 for responsiveness. "

                "**Risk level:** CAUTION to HIGH RISK depending on payloads. High volume of requests in short "
                "time highly detectable by rate limiting, anomaly detection, and WAFs. May trigger IP bans or "
                "account lockouts if too aggressive. Use responsibly with appropriate MAX_RPS settings. All "
                "requests logged with correlation headers for audit trail. "

                "**Returns:** Array of response objects, one per request, in same order as input array. Each "
                "response includes status, headers, body, timing, correlation_id, and success flag. Failed "
                "requests return error field with reason (timeout/scope/budget). Use for differential analysis "
                "(compare responses), enumeration (find accessible IDs), and bulk validation. Suitable for "
                "evidence_add_artifact() as batch test results."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "requests": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "method": {
                                    "type": "string",
                                    "enum": ["GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"],
                                    "description": "HTTP method to use"
                                },
                                "url": {
                                    "type": "string",
                                    "description": "Target URL (must include http:// or https://)"
                                },
                                "headers": {
                                    "type": "object",
                                    "description": "Optional HTTP headers as key-value pairs"
                                },
                                "body": {
                                    "type": "string",
                                    "description": "Optional request body"
                                },
                                "timeout": {
                                    "type": "number",
                                    "description": "Request timeout in milliseconds"
                                },
                                "identity_id": {
                                    "type": "string",
                                    "description": "Optional identity ID for correlation tracking"
                                }
                            },
                            "required": ["method", "url"]
                        },
                        "description": "Array of HTTP requests to send concurrently"
                    },
                    "analyze": {
                        "type": "boolean",
                        "description": "Run exchange analysis on each successful response (default: true)",
                        "default": True
                    }
                },
                "required": ["requests"]
            }
        ),
        Tool(
            name="http_get_stats",
            description=(
                "Get HTTP client statistics including total requests sent, current rate limit status, "
                "budget remaining, per-target request counts, and performance metrics. Essential for budget-aware "
                "testing and optimizing test strategy based on available capacity. Returns real-time view of "
                "HTTP client state without consuming budget. "

                "**When to use:** Phase 3-4 (Assessment/Exploitation) periodically to monitor budget consumption. "
                "Call every 20-30 tool invocations, especially BEFORE expensive operations like nuclei_scan_template(), "
                "fuzz_parameter(), or large http_send_batch() calls. Use to make strategic decisions about testing "
                "depth - when budget low, prioritize high-value tests and skip comprehensive fuzzing. "

                "**Dependencies:** No prerequisites - query only tool. Use result to decide between http_send() "
                "(low budget) vs http_send_batch() (sufficient budget) approaches. Check remaining_requests "
                "field before calling budget-intensive tools. Compare with scope_check_budget() for comprehensive "
                "constraint view (scope_check includes per-target limits, this shows global HTTP stats). "

                "**Budget impact:** LOW - Zero requests, instant local query. Returns cached statistics from "
                "HTTP client state. Completes in <10ms. Does NOT count against MAX_TOTAL_REQUESTS budget. "
                "Call as frequently as needed for monitoring. "

                "**Failure modes:** No expected failures - query-only operation. May return 0 stats if HTTP "
                "client not yet initialized (first http_send() call initializes). Statistics reset on server "
                "restart (not persistent across sessions). "

                "**Risk level:** SAFE - Read-only local query, no network requests or target interaction. "
                "Pure monitoring tool with zero security risk. No logging or external visibility. "

                "**Returns:** Statistics object with: total_requests (sent so far), remaining_requests "
                "(MAX_TOTAL_REQUESTS - total), rate_limit_status (current RPS and MAX_RPS), per_target_counts "
                "(requests per domain for analysis), average_response_time_ms, success_rate percentage, "
                "error_breakdown (timeouts, scope violations, etc). Use remaining_requests to decide testing "
                "strategy: >500 = comprehensive testing, 100-500 = targeted testing, <100 = critical tests only, "
                "<20 = evidence collection only."
            ),
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
    ]


async def handle_http_tool(name: str, arguments: dict, mcp_service) -> List[TextContent]:
    """Route HTTP tool calls to the appropriate handler."""
    if name == "http_send":
        return await _handle_http_send(arguments, mcp_service)
    elif name == "http_send_batch":
        return await _handle_http_send_batch(arguments, mcp_service)
    elif name == "http_get_stats":
        return await _handle_http_get_stats(arguments, mcp_service)
    return [TextContent(type="text", text=json.dumps({
        "error": "UNKNOWN_TOOL",
        "message": f"Unknown HTTP tool: {name}"
    }))]


async def _handle_http_send(arguments: dict, mcp_service) -> List[TextContent]:
    """Handle http_send - Send a single HTTP request."""
    method = arguments.get("method")
    url = arguments.get("url")

    if not method or not url:
        return [TextContent(type="text", text=json.dumps({
            "error": "INVALID_PARAMS",
            "message": "Both 'method' and 'url' are required"
        }))]

    if not _validate_url(url):
        return [TextContent(type="text", text=json.dumps({
            "error": "INVALID_URL",
            "message": f"Invalid URL format: {url}. Must include http:// or https:// scheme."
        }))]

    try:
        client = _get_http_client(mcp_service)
        result = await client.send(
            request={
                "method": method,
                "url": url,
                "headers": arguments.get("headers"),
                "body": arguments.get("body"),
                "timeout": arguments.get("timeout"),
            },
            identity_id=arguments.get("identity_id"),
        )

        # Run exchange analyzer when analyze=true (default) and request succeeded
        if arguments.get("analyze", True) and result.get("success"):
            try:
                from lib.exchange_analyzer import get_exchange_analyzer
                ea = get_exchange_analyzer()
                ea_result = ea.analyze(
                    request={"method": method, "url": url,
                             "headers": arguments.get("headers") or {}, "parameters": []},
                    response={"status": result["response"]["status"],
                              "headers": result["response"].get("headers", {}),
                              "body": (result["response"].get("body") or "")[:4096]},
                )
                result["exchange_analysis"] = {
                    "recommended_tests": list(dict.fromkeys(ea_result.recommended_tests)),
                    "risk_signals": ea_result.risk_signals,
                    "detected_technologies": ea_result.detected_technologies,
                    "priority_adjustments": ea_result.priority_adjustments,
                    "parameter_recommendations": ea_result.parameter_recommendations,
                }

                # Round 11 Fix 1B: Auto-persist significant risk signals as findings
                if mcp_service and ea_result.risk_signals:
                    try:
                        created = await mcp_service.auto_persist_risk_signals(ea_result.risk_signals, url)
                        if created > 0:
                            result["auto_findings_created"] = created
                    except Exception:
                        pass
            except Exception:
                pass  # Never let analysis break the response

        return [TextContent(type="text", text=json.dumps(result))]
    except Exception as e:
        return [TextContent(type="text", text=json.dumps({
            "error": "REQUEST_FAILED",
            "message": str(e)
        }))]


async def _handle_http_send_batch(arguments: dict, mcp_service) -> List[TextContent]:
    """Handle http_send_batch - Send multiple HTTP requests with concurrency control."""
    requests = arguments.get("requests")
    analyze = arguments.get("analyze", True)

    if not requests or not isinstance(requests, list):
        return [TextContent(type="text", text=json.dumps({
            "error": "INVALID_PARAMS",
            "message": "'requests' must be a non-empty array"
        }))]

    # Validate all request URLs before sending any
    for i, req in enumerate(requests):
        if not req.get("method") or not req.get("url"):
            return [TextContent(type="text", text=json.dumps({
                "error": "INVALID_PARAMS",
                "message": f"Request at index {i} is missing required 'method' or 'url'"
            }))]
        if not _validate_url(req["url"]):
            return [TextContent(type="text", text=json.dumps({
                "error": "INVALID_URL",
                "message": f"Invalid URL format at index {i}: {req['url']}. Must include http:// or https:// scheme."
            }))]

    try:
        client = _get_http_client(mcp_service)
        # Wrap requests in correct format for HttpClient.send_batch()
        batch_items = [{"request": req, "identity_id": None} for req in requests]
        result = await client.send_batch(batch_items)

        # Run exchange analysis on each successful response (Gap 5)
        if analyze and result.get("results"):
            from lib.exchange_analyzer import get_exchange_analyzer
            ea = get_exchange_analyzer()
            batch_findings = []
            for i, item_result in enumerate(result["results"]):
                if item_result.get("success") and item_result.get("response"):
                    resp = item_result["response"]
                    # Fix C3: Correct analyze() signature - takes request and response dicts
                    ea_result = ea.analyze(
                        request={
                            "method": requests[i].get("method", "GET"),
                            "url": requests[i].get("url", ""),
                            "headers": requests[i].get("headers", {}),
                            "body": requests[i].get("body", ""),
                        },
                        response={
                            "status": resp.get("status", 0),
                            "headers": resp.get("headers", {}),
                            "body": resp.get("body", "")[:4096],
                        }
                    )
                    if ea_result.risk_signals or ea_result.detected_technologies:
                        from dataclasses import asdict
                        item_result["exchange_analysis"] = asdict(ea_result)
                        batch_findings.extend(ea_result.risk_signals)

            # Build batch_analysis dict first
            if batch_findings:
                result["batch_analysis"] = {
                    "total_findings": len(batch_findings),
                    "unique_types": list({f["type"] for f in batch_findings}),
                }

                # Round 11 Fix 1B: Auto-persist batch risk signals (AFTER building dict)
                if mcp_service:
                    try:
                        created = await mcp_service.auto_persist_risk_signals(batch_findings, "batch_request")
                        if created > 0:
                            result["batch_analysis"]["auto_findings_created"] = created
                    except Exception:
                        pass

        return [TextContent(type="text", text=json.dumps(result))]
    except Exception as e:
        return [TextContent(type="text", text=json.dumps({
            "error": "BATCH_REQUEST_FAILED",
            "message": str(e)
        }))]


async def _handle_http_get_stats(arguments: dict, mcp_service) -> List[TextContent]:
    """Handle http_get_stats - Get HTTP client statistics."""
    try:
        client = _get_http_client(mcp_service)
        stats = client.get_stats()
        return [TextContent(type="text", text=json.dumps(stats))]
    except Exception as e:
        return [TextContent(type="text", text=json.dumps({
            "error": "STATS_FAILED",
            "message": str(e)
        }))]
