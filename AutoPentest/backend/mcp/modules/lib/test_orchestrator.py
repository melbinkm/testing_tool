"""
Test Orchestrator

State machine managing the crawl -> analyze -> build_matrix -> test -> re-crawl cycle.
Provides structured decision-making for when to continue testing, when to re-crawl,
and what actions the LLM should take next.
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Set
from enum import Enum
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class OrchestratorState(Enum):
    """Testing orchestrator states."""
    INIT = "init"
    CRAWL = "crawl"
    ANALYZE = "analyze"
    BUILD_MATRIX = "build_matrix"
    TEST = "test"
    RECRAWL = "recrawl"
    COMPLETE = "complete"


@dataclass
class CrawlRecord:
    """Record of a crawl operation."""
    crawl_id: str
    identity_id: Optional[str]
    endpoint_count: int
    timestamp: datetime
    trigger: str  # initial|auth_change|credential_discovery


@dataclass
class TestingProgress:
    """Overall testing progress tracking."""
    total_cells: int = 0
    tested_cells: int = 0
    confirmed_vulns: int = 0
    suspicious_cells: int = 0
    categories_tested: Set[str] = field(default_factory=set)
    categories_complete: Set[str] = field(default_factory=set)


@dataclass
class ContinueDecision:
    """Decision on whether to continue testing a specific target."""
    should_continue: bool
    recommendation: str  # continue_hardcoded|generate_llm_payloads|move_to_next|log_suspicious
    reasoning: str
    confidence: float  # 0.0-1.0
    next_payload_type: Optional[str] = None  # hardcoded|llm_generated|targeted


@dataclass
class CellTestingState:
    """Factual data about a coverage cell's testing state. LLM decides what to do."""
    cell_id: str
    vuln_spec_id: str
    endpoint_id: str
    parameter: Optional[str]
    attempt_count: int
    max_attempts: int
    payload_types_tried: List[str]
    suspicious_signal_count: int
    suspicious_signals: List[Dict[str, Any]]
    vulnerability_confirmed: bool
    max_attempts_reached: bool
    available_payload_count: int
    results_summary: Dict[str, int]  # {"clean": N, "suspicious": N, "vulnerable": N}


class TestOrchestrator:
    """
    Orchestrates the comprehensive testing workflow.

    Manages state transitions, tracks progress, and provides
    structured guidance for LLM decision-making.
    """

    def __init__(self, assessment_id: int, base_url: str):
        """
        Initialize test orchestrator.

        Args:
            assessment_id: Assessment ID
            base_url: Base target URL
        """
        self.assessment_id = assessment_id
        self.base_url = base_url
        self.state = OrchestratorState.INIT
        self.crawl_history: List[CrawlRecord] = []
        self.progress = TestingProgress()
        self.pending_recrawls: List[Dict[str, Any]] = []
        self.auth_changes: List[Dict[str, Any]] = []

        # Per-cell testing state
        self.cell_attempts: Dict[str, int] = {}  # cell_id -> attempt count
        self.cell_payloads_tried: Dict[str, Set[str]] = {}  # cell_id -> {payload_type}
        self.cell_signals: Dict[str, List[Dict]] = {}  # cell_id -> [risk_signals]

    def get_current_state(self) -> str:
        """Get current orchestrator state."""
        return self.state.value

    def transition_to(self, new_state: OrchestratorState) -> None:
        """Transition to a new state."""
        logger.info(f"State transition: {self.state.value} -> {new_state.value}")
        self.state = new_state

    def record_crawl(self, crawl_id: str, endpoint_count: int, identity_id: Optional[str] = None, trigger: str = "initial") -> None:
        """
        Record a crawl operation.

        Args:
            crawl_id: Unique crawl identifier
            endpoint_count: Number of endpoints discovered
            identity_id: Identity used for crawl (if any)
            trigger: What triggered this crawl
        """
        record = CrawlRecord(
            crawl_id=crawl_id,
            identity_id=identity_id,
            endpoint_count=endpoint_count,
            timestamp=datetime.now(),
            trigger=trigger
        )
        self.crawl_history.append(record)

        logger.info(f"Recorded crawl: {crawl_id} ({endpoint_count} endpoints, trigger={trigger})")

    def record_auth_change(self, identity_id: str, change_type: str, details: Dict[str, Any]) -> Dict[str, Any]:
        """
        Record an authentication state change and schedule re-crawl.

        Args:
            identity_id: Identity that changed
            change_type: new_credential|privilege_escalation|session_token
            details: Additional context

        Returns:
            Dict with status and what happens next
        """
        change_record = {
            'identity_id': identity_id,
            'change_type': change_type,
            'details': details,
            'timestamp': datetime.now().isoformat(),
            'recrawl_pending': True
        }
        self.auth_changes.append(change_record)

        # Schedule re-crawl
        self.pending_recrawls.append({
            'identity_id': identity_id,
            'reason': f"{change_type} for {identity_id}",
            'priority': 'high' if change_type == 'privilege_escalation' else 'medium'
        })

        logger.info(f"Auth change recorded: {change_type} for {identity_id} - re-crawl scheduled")

        return {
            'status': 'recorded',
            'recrawl_scheduled': True,
            'next_actions': [
                f"Run crawler_start with identity_id={identity_id}",
                "Run coverage_discover to extend matrix with new endpoints",
                "Resume testing with expanded coverage"
            ]
        }

    def get_next_actions(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get next N actions the LLM should take.

        Args:
            limit: Maximum number of actions to return

        Returns:
            List of action dicts with keys:
            - action: Action type
            - tool: MCP tool to call
            - args: Tool arguments
            - priority: Priority level
            - reasoning: Why this action
        """
        actions = []

        # Priority 1: Pending re-crawls
        for recrawl in self.pending_recrawls[:limit]:
            actions.append({
                'action': 'recrawl',
                'tool': 'crawler_start',
                'args': {
                    'url': self.base_url,
                    'identity_id': recrawl['identity_id']
                },
                'priority': recrawl['priority'],
                'reasoning': f"Re-crawl needed: {recrawl['reason']}"
            })

        if len(actions) >= limit:
            return actions[:limit]

        # Priority 2: State-based actions
        if self.state == OrchestratorState.INIT:
            actions.append({
                'action': 'initial_crawl',
                'tool': 'crawler_start',
                'args': {'url': self.base_url, 'extract_js': True, 'parse_sitemap': True},
                'priority': 'critical',
                'reasoning': 'Initial crawl to discover endpoints'
            })

        elif self.state == OrchestratorState.CRAWL:
            actions.append({
                'action': 'get_crawl_results',
                'tool': 'crawler_results',
                'args': {'crawl_id': self.crawl_history[-1].crawl_id if self.crawl_history else None, 'result_type': 'all'},
                'priority': 'high',
                'reasoning': 'Retrieve discovered endpoints'
            })

        elif self.state == OrchestratorState.ANALYZE:
            actions.append({
                'action': 'build_coverage_matrix',
                'tool': 'testing_build_matrix',
                'args': {'base_url': self.base_url},
                'priority': 'high',
                'reasoning': 'Build 42-category coverage matrix'
            })

        elif self.state == OrchestratorState.TEST:
            actions.append({
                'action': 'get_next_tests',
                'tool': 'testing_next',
                'args': {'limit': limit, 'strategy': 'hardcoded_first'},
                'priority': 'high',
                'reasoning': 'Get next test cells with pre-loaded payloads'
            })

        return actions[:limit]

    def should_continue_testing(
        self,
        vuln_spec_id: str,
        endpoint_id: str,
        parameter: Optional[str] = None,
        results_so_far: Optional[List[Dict]] = None
    ) -> ContinueDecision:
        """
        Decide if testing should continue for a specific target.

        Implements the decision tree:
        1. Hardcoded payloads not exhausted -> continue_hardcoded
        2. Vulnerability confirmed -> move_to_next
        3. Suspicious signals + no LLM payloads tried -> generate_llm_payloads
        4. LLM payloads tried + still suspicious -> log_suspicious
        5. All clean -> move_to_next

        Args:
            vuln_spec_id: Vulnerability specification ID
            endpoint_id: Endpoint being tested
            parameter: Parameter being tested (if parameter-bound)
            results_so_far: Test results so far

        Returns:
            ContinueDecision with recommendation
        """
        # Build cell ID
        cell_id = f"{endpoint_id}:{vuln_spec_id}"
        if parameter:
            cell_id += f":{parameter}"

        # Get testing history for this cell
        attempts = self.cell_attempts.get(cell_id, 0)
        payloads_tried = self.cell_payloads_tried.get(cell_id, set())
        signals = self.cell_signals.get(cell_id, [])

        # Parse results
        confirmed_vuln = False
        has_suspicious = False

        if results_so_far:
            for result in results_so_far:
                status = result.get('status', 'clean')
                if status == 'vulnerable':
                    confirmed_vuln = True
                elif status == 'suspicious':
                    has_suspicious = True
                    # Record signal
                    if cell_id not in self.cell_signals:
                        self.cell_signals[cell_id] = []
                    self.cell_signals[cell_id].append(result)

        # Decision tree

        MAX_CELL_ATTEMPTS = 5

        # 0. Hard stop: too many attempts on this cell
        if attempts >= MAX_CELL_ATTEMPTS:
            return ContinueDecision(
                should_continue=False,
                recommendation='move_to_next',
                reasoning=f'Maximum attempts ({MAX_CELL_ATTEMPTS}) reached for this cell',
                confidence=1.0,
            )

        # 1. Vulnerability confirmed -> stop testing this cell
        if confirmed_vuln:
            return ContinueDecision(
                should_continue=False,
                recommendation='move_to_next',
                reasoning='Vulnerability confirmed - move to next test',
                confidence=1.0
            )

        # 2. Hardcoded payloads not exhausted -> continue with hardcoded
        if 'hardcoded' not in payloads_tried:
            return ContinueDecision(
                should_continue=True,
                recommendation='continue_hardcoded',
                reasoning='Hardcoded payloads not yet exhausted',
                confidence=0.9,
                next_payload_type='hardcoded'
            )

        # 3. Suspicious signals + no LLM payloads tried -> generate LLM payloads
        if has_suspicious and 'llm_generated' not in payloads_tried:
            return ContinueDecision(
                should_continue=True,
                recommendation='generate_llm_payloads',
                reasoning=f'Suspicious signals detected ({len(signals)} signals), generate targeted LLM payloads',
                confidence=0.8,
                next_payload_type='llm_generated'
            )

        # 4. LLM payloads tried + still suspicious -> log and move on
        if has_suspicious and 'llm_generated' in payloads_tried:
            return ContinueDecision(
                should_continue=False,
                recommendation='log_suspicious',
                reasoning='LLM payloads tried but no confirmation - log as suspicious and move on',
                confidence=0.6
            )

        # 5. All clean -> move to next
        return ContinueDecision(
            should_continue=False,
            recommendation='move_to_next',
            reasoning='No suspicious activity detected - move to next test',
            confidence=0.9
        )

    def get_cell_testing_state(
        self,
        vuln_spec_id: str,
        endpoint_id: str,
        parameter: Optional[str] = None,
        results_so_far: Optional[List[Dict]] = None
    ) -> CellTestingState:
        """
        Get factual data about a cell's testing state.

        Returns raw state information without making decisions. The LLM uses this
        data to decide its own testing strategy.

        Args:
            vuln_spec_id: Vulnerability specification ID
            endpoint_id: Endpoint being tested
            parameter: Parameter being tested (if parameter-bound)
            results_so_far: Test results so far

        Returns:
            CellTestingState with factual data
        """
        # Build cell ID
        cell_id = f"{endpoint_id}:{vuln_spec_id}"
        if parameter:
            cell_id += f":{parameter}"

        # Get testing history for this cell
        attempts = self.cell_attempts.get(cell_id, 0)
        payloads_tried = list(self.cell_payloads_tried.get(cell_id, set()))
        signals = self.cell_signals.get(cell_id, [])

        # Parse results
        confirmed_vuln = False
        results_summary = {"clean": 0, "suspicious": 0, "vulnerable": 0}
        suspicious_signals_from_results = []

        if results_so_far:
            for result in results_so_far:
                status = result.get('status', 'clean')
                if status == 'vulnerable':
                    confirmed_vuln = True
                    results_summary["vulnerable"] += 1
                elif status == 'suspicious':
                    results_summary["suspicious"] += 1
                    suspicious_signals_from_results.append(result)
                    # Record signal in orchestrator state
                    if cell_id not in self.cell_signals:
                        self.cell_signals[cell_id] = []
                    self.cell_signals[cell_id].append(result)
                else:
                    results_summary["clean"] += 1

        # Combine signals from orchestrator state and current results
        all_signals = signals + suspicious_signals_from_results

        # Get available payload count
        MAX_CELL_ATTEMPTS = 5
        available_payload_count = 0
        try:
            from lib.payload_registry import get_payload_registry
            registry = get_payload_registry()
            payloads = registry.get_payloads(vuln_spec_id)
            available_payload_count = len(payloads)
        except Exception:
            # Unknown vuln class or registry error
            available_payload_count = 0

        return CellTestingState(
            cell_id=cell_id,
            vuln_spec_id=vuln_spec_id,
            endpoint_id=endpoint_id,
            parameter=parameter,
            attempt_count=attempts,
            max_attempts=MAX_CELL_ATTEMPTS,
            payload_types_tried=payloads_tried,
            suspicious_signal_count=len(all_signals),
            suspicious_signals=all_signals,
            vulnerability_confirmed=confirmed_vuln,
            max_attempts_reached=(attempts >= MAX_CELL_ATTEMPTS),
            available_payload_count=available_payload_count,
            results_summary=results_summary
        )

    def get_payload_generation_context(
        self,
        vuln_spec_id: str,
        endpoint_id: str,
        parameter: Optional[str],
        results_so_far: Optional[List[Dict]] = None,
    ) -> Dict[str, Any]:
        """Build structured context to help Claude generate targeted payloads.

        Returns a dict with vuln class info, example payloads from library,
        suspicious signals from prior results, and generation guidance.
        """
        from lib.vuln_checklist import get_vuln_checklist
        from lib.payload_registry import get_payload_registry

        checklist = get_vuln_checklist()
        spec = checklist.get_spec_by_id(vuln_spec_id)
        registry = get_payload_registry()

        # Get example payloads from library for pattern reference
        library_payloads = registry.get_payloads(vuln_spec_id)
        example_patterns = registry.to_string_payloads(library_payloads[:5])

        # Extract suspicious signals from results
        suspicious = []
        if results_so_far:
            suspicious = [r for r in results_so_far if r.get("status") == "suspicious"]

        return {
            "vuln_class": vuln_spec_id,
            "vuln_description": spec.description if spec else "",
            "category": spec.category if spec else "",
            "parameter": parameter or "",
            "endpoint_id": endpoint_id,
            "suspicious_signals": suspicious[:5],
            "library_payload_examples": example_patterns,
            "guidance": (
                f"Generate 5-10 targeted {vuln_spec_id} payloads for parameter '{parameter or 'unknown'}'. "
                f"The library payloads above were tried but only produced suspicious (not confirmed) signals. "
                f"Craft payloads that specifically target the suspicious behavior observed. "
                f"Consider WAF evasion, encoding variations, and technology-specific syntax."
            ),
        }

    def record_test_attempt(
        self,
        vuln_spec_id: str,
        endpoint_id: str,
        parameter: Optional[str],
        payload_type: str
    ) -> None:
        """
        Record a test attempt.

        Args:
            vuln_spec_id: Vulnerability spec ID
            endpoint_id: Endpoint ID
            parameter: Parameter (if parameter-bound)
            payload_type: hardcoded|llm_generated|targeted
        """
        cell_id = f"{endpoint_id}:{vuln_spec_id}"
        if parameter:
            cell_id += f":{parameter}"

        # Increment attempts
        self.cell_attempts[cell_id] = self.cell_attempts.get(cell_id, 0) + 1

        # Record payload type
        if cell_id not in self.cell_payloads_tried:
            self.cell_payloads_tried[cell_id] = set()
        self.cell_payloads_tried[cell_id].add(payload_type)

    def update_progress(self, progress_dict: Dict[str, Any]) -> None:
        """
        Update testing progress.

        Args:
            progress_dict: Dict with keys:
                          - total_cells: Total coverage matrix cells
                          - tested_cells: Cells tested so far
                          - confirmed_vulns: Confirmed vulnerabilities
                          - suspicious_cells: Cells with suspicious activity
                          - categories: List of category progress dicts
        """
        self.progress.total_cells = progress_dict.get('total_cells', 0)
        self.progress.tested_cells = progress_dict.get('tested_cells', 0)
        self.progress.confirmed_vulns = progress_dict.get('confirmed_vulns', 0)
        self.progress.suspicious_cells = progress_dict.get('suspicious_cells', 0)

        # Update category tracking
        for cat_dict in progress_dict.get('categories', []):
            cat_name = cat_dict['category']
            self.progress.categories_tested.add(cat_name)

            # Mark complete if 100% tested
            if cat_dict.get('coverage_percent', 0) >= 100:
                self.progress.categories_complete.add(cat_name)

    def get_status(self) -> Dict[str, Any]:
        """
        Get comprehensive orchestrator status.

        Returns:
            Status dict with:
            - state: Current state
            - progress: Testing progress summary
            - crawl_count: Number of crawls performed
            - pending_recrawls: Number of pending re-crawls
            - auth_changes: Recent auth state changes
            - recommendations: Next recommended actions
        """
        return {
            'state': self.state.value,
            'progress': {
                'total_cells': self.progress.total_cells,
                'tested_cells': self.progress.tested_cells,
                'confirmed_vulns': self.progress.confirmed_vulns,
                'suspicious_cells': self.progress.suspicious_cells,
                'coverage_percent': (self.progress.tested_cells / self.progress.total_cells * 100)
                                   if self.progress.total_cells > 0 else 0,
                'categories_tested': len(self.progress.categories_tested),
                'categories_complete': len(self.progress.categories_complete)
            },
            'crawl_count': len(self.crawl_history),
            'last_crawl': {
                'crawl_id': self.crawl_history[-1].crawl_id,
                'endpoint_count': self.crawl_history[-1].endpoint_count,
                'trigger': self.crawl_history[-1].trigger,
                'timestamp': self.crawl_history[-1].timestamp.isoformat()
            } if self.crawl_history else None,
            'pending_recrawls': len(self.pending_recrawls),
            'auth_changes': len(self.auth_changes),
            'recent_auth_changes': [
                {
                    'identity_id': ac['identity_id'],
                    'change_type': ac['change_type'],
                    'timestamp': ac['timestamp']
                }
                for ac in self.auth_changes[-5:]
            ],
            'recommendations': self.get_next_actions(limit=5)
        }

    def is_complete(self, min_coverage: float = 1.0) -> bool:
        """Check if testing is complete.

        Parameters
        ----------
        min_coverage : float
            Minimum coverage ratio required (default 1.0 = 100%).
        """
        if self.state == OrchestratorState.COMPLETE:
            return True

        # Check for completion criteria
        if self.progress.total_cells > 0:
            coverage = self.progress.tested_cells / self.progress.total_cells
            if coverage >= min_coverage and len(self.pending_recrawls) == 0:
                return True

        return False

    def mark_complete(self) -> None:
        """Mark testing as complete."""
        self.transition_to(OrchestratorState.COMPLETE)
        logger.info(f"Testing complete: {self.progress.confirmed_vulns} vulns, {self.progress.tested_cells}/{self.progress.total_cells} cells")


# Orchestrator instance management (per-assessment)
_orchestrators: Dict[int, TestOrchestrator] = {}


def get_orchestrator(assessment_id: int, base_url: Optional[str] = None) -> TestOrchestrator:
    """
    Get orchestrator instance for an assessment.

    Args:
        assessment_id: Assessment ID
        base_url: Base URL (required for new orchestrators)

    Returns:
        TestOrchestrator instance
    """
    if assessment_id not in _orchestrators:
        if base_url is None:
            raise ValueError(f"base_url required to create new orchestrator for assessment {assessment_id}")
        _orchestrators[assessment_id] = TestOrchestrator(assessment_id, base_url)

    return _orchestrators[assessment_id]


def clear_orchestrator(assessment_id: int) -> None:
    """Clear orchestrator instance for an assessment."""
    if assessment_id in _orchestrators:
        del _orchestrators[assessment_id]
