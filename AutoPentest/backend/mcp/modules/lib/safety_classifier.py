"""
Safety Classifier - 4-tier safety classification for commands and payloads.

Adapted from Zen-Ai-Pentest exploit safety levels.
Classifies commands and payloads into SAFE, CAUTION, DANGEROUS, or BLOCKED
based on pattern matching against known-dangerous operations.
"""

from __future__ import annotations

import re
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple


class SafetyLevel(Enum):
    """Four-tier safety classification."""
    SAFE = "safe"           # Read-only, no side effects
    CAUTION = "caution"     # May modify state, needs awareness
    DANGEROUS = "dangerous" # Can cause damage, needs confirmation
    BLOCKED = "blocked"     # Out-of-scope or destructive, refuse


# ---------------------------------------------------------------------------
# Pattern definitions: (regex_pattern, reason)
# Patterns are checked in order: BLOCKED first, then DANGEROUS, then CAUTION.
# Anything that doesn't match is SAFE.
# ---------------------------------------------------------------------------

_BLOCKED_COMMAND_PATTERNS: List[Tuple[str, str]] = [
    (r"\brm\s+(-[rfRF]+\s+)?/\s*$", "Recursive deletion of root filesystem"),
    (r"\brm\s+-[rfRF]*\s+/\b", "Recursive deletion of root or system path"),
    (r"\bshutdown\b", "System shutdown"),
    (r"\breboot\b", "System reboot"),
    (r"\binit\s+[06]\b", "System init level change"),
    (r"\bsystemctl\s+(poweroff|halt|reboot)\b", "System power control"),
    (r"\b(dd\s+.*of=/dev/[sh]d[a-z])\b", "Direct disk write"),
    (r"\bmkfs\b", "Filesystem format"),
    (r"\bfdisk\b", "Disk partition modification"),
    (r"\b:(){ :\|:& };:", "Fork bomb"),
    (r"\b>\s*/dev/[sh]d[a-z]\b", "Direct device overwrite"),
    (r"\biptables\s+(-F|--flush)\b", "Firewall flush"),
]

_BLOCKED_PAYLOAD_PATTERNS: List[Tuple[str, str]] = [
    (r"\bDROP\s+DATABASE\b", "Database destruction"),
    (r"\bDROP\s+ALL\b", "Mass drop operation"),
    (r"\bTRUNCATE\s+TABLE\b", "Table truncation"),
    (r"\bFORMAT\s+C:", "Drive format"),
    (r"\bxp_cmdshell\b.*\b(del|rm|format)\b", "OS command via xp_cmdshell with destructive action"),
    (r"\bDELETE\s+FROM\s+\w+\s*;\s*$", "Unqualified DELETE (no WHERE clause)"),
    (r"\bALTER\s+TABLE\s+\w+\s+DROP\b", "SQL ALTER TABLE DROP column/constraint"),
]

_DANGEROUS_COMMAND_PATTERNS: List[Tuple[str, str]] = [
    (r"\brm\s+-[rfRF]", "Recursive file deletion"),
    (r"\bDROP\s+TABLE\b", "SQL table drop"),
    (r"\bDELETE\s+FROM\b", "SQL row deletion"),
    (r"\btruncate\b", "Data truncation"),
    (r"\bchmod\s+777\b", "Overly permissive file permissions"),
    (r"\bchown\s+.*root\b", "Ownership change to root"),
    (r"\bsqlmap\b.*--os-shell\b", "sqlmap OS shell access"),
    (r"\bmetasploit\b|\bmsfconsole\b|\bmsfvenom\b", "Metasploit framework"),
    (r"\bhydra\b.*-l\b.*-P\b", "Brute-force credential attack"),
    (r"\bjohn\b.*--wordlist\b", "Password cracking"),
    (r"\bhashcat\b", "Password hash cracking"),
    (r"\bwget\b.*\|\s*(sh|bash)\b", "Remote code execution via pipe"),
    (r"\bcurl\b.*\|\s*(sh|bash)\b", "Remote code execution via pipe"),
]

_DANGEROUS_PAYLOAD_PATTERNS: List[Tuple[str, str]] = [
    (r"\bDROP\s+TABLE\b", "SQL table drop"),
    (r"\bDELETE\s+FROM\b", "SQL data deletion"),
    (r"\bALTER\s+TABLE\b", "SQL schema modification"),
    (r"\bxp_cmdshell\b", "SQL Server command execution"),
    (r"\bUTL_HTTP\b", "Oracle HTTP callout"),
    (r"\bDBMS_PIPE\b", "Oracle pipe command"),
    (r"\bLOAD_FILE\b", "MySQL file read"),
    (r"\bINTO\s+OUTFILE\b", "MySQL file write"),
    (r"\bINTO\s+DUMPFILE\b", "MySQL binary file write"),
]

_CAUTION_COMMAND_PATTERNS: List[Tuple[str, str]] = [
    (r"\bsqlmap\b", "SQL injection testing tool"),
    (r"\bnikto\b", "Web vulnerability scanner"),
    (r"\bwfuzz\b", "Web fuzzer"),
    (r"\bffuf\b", "Fast web fuzzer"),
    (r"\bdirb\b", "Directory brute-forcer"),
    (r"\bgobuster\b", "Directory/DNS brute-forcer"),
    (r"\bnuclei\b", "Vulnerability scanner"),
    (r"\bwpscan\b", "WordPress scanner"),
    (r"\bsearchsploit\b", "Exploit database search"),
    (r"\bcurl\b.*-X\s*(POST|PUT|DELETE|PATCH)\b", "HTTP state-changing request"),
    (r"\bINSERT\s+INTO\b", "SQL data insertion"),
    (r"\bUPDATE\s+.*\bSET\b", "SQL data update"),
    (r"\bCREATE\s+(TABLE|DATABASE)\b", "SQL schema creation"),
]

_CAUTION_PAYLOAD_PATTERNS: List[Tuple[str, str]] = [
    (r"\bINSERT\s+INTO\b", "SQL data insertion"),
    (r"\bUPDATE\s+.*\bSET\b", "SQL data update"),
    (r"\bCREATE\s+(TABLE|INDEX)\b", "SQL schema modification"),
    (r"\bUNION\s+SELECT\b", "SQL union injection"),
    (r"<script\b", "XSS script injection"),
    (r"javascript:", "JavaScript URI injection"),
    (r"\bonerror\s*=", "Event handler injection"),
]


def _check_patterns(
    text: str,
    patterns: List[Tuple[str, str]],
) -> Optional[Tuple[str, str]]:
    """Check text against a list of (pattern, reason) tuples.
    Returns (matched_pattern, reason) or None.
    """
    for pattern, reason in patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return (pattern, reason)
    return None


class SafetyClassifier:
    """Classify commands and payloads by safety level."""

    def classify_command(self, command: str) -> Dict[str, Any]:
        """Classify a shell command.

        Returns
        -------
        dict
            level (SafetyLevel value str), reason, matched_pattern
        """
        if not command or not command.strip():
            return {"level": SafetyLevel.SAFE.value, "reason": "Empty command", "matched_pattern": ""}

        # Check BLOCKED
        match = _check_patterns(command, _BLOCKED_COMMAND_PATTERNS)
        if match:
            return {"level": SafetyLevel.BLOCKED.value, "reason": match[1], "matched_pattern": match[0]}

        # Check DANGEROUS
        match = _check_patterns(command, _DANGEROUS_COMMAND_PATTERNS)
        if match:
            return {"level": SafetyLevel.DANGEROUS.value, "reason": match[1], "matched_pattern": match[0]}

        # Check CAUTION
        match = _check_patterns(command, _CAUTION_COMMAND_PATTERNS)
        if match:
            return {"level": SafetyLevel.CAUTION.value, "reason": match[1], "matched_pattern": match[0]}

        return {"level": SafetyLevel.SAFE.value, "reason": "No dangerous patterns detected", "matched_pattern": ""}

    def classify_payload(self, payload: str, payload_type: str = "generic", scope_domains: Optional[List[str]] = None) -> Dict[str, Any]:
        """Classify a fuzz payload.

        Parameters
        ----------
        payload : str
            The payload string.
        payload_type : str
            Hint about the payload type (sqli, xss, cmdi, etc.).
        scope_domains : list[str], optional
            List of approved in-scope domains. If target is in scope,
            slightly higher-risk actions may be permitted (DANGEROUS->CAUTION).
        """
        if not payload:
            return {"level": SafetyLevel.SAFE.value, "reason": "Empty payload", "matched_pattern": ""}

        # Check BLOCKED
        match = _check_patterns(payload, _BLOCKED_PAYLOAD_PATTERNS)
        if match:
            return {"level": SafetyLevel.BLOCKED.value, "reason": match[1], "matched_pattern": match[0]}

        # Check obfuscation patterns
        obfuscation = self._detect_obfuscation(payload)
        if obfuscation:
            return {"level": SafetyLevel.DANGEROUS.value, "reason": obfuscation, "matched_pattern": "obfuscation"}

        # Check DANGEROUS
        match = _check_patterns(payload, _DANGEROUS_PAYLOAD_PATTERNS)
        if match:
            # Scope-awareness: if target is in approved scope, downgrade DANGEROUS to CAUTION
            if scope_domains:
                return {"level": SafetyLevel.CAUTION.value, "reason": f"{match[1]} (in-scope target)", "matched_pattern": match[0]}
            return {"level": SafetyLevel.DANGEROUS.value, "reason": match[1], "matched_pattern": match[0]}

        # Check context-aware INSERT
        insert_result = self._classify_insert_context(payload)
        if insert_result:
            return insert_result

        # Check CAUTION
        match = _check_patterns(payload, _CAUTION_PAYLOAD_PATTERNS)
        if match:
            return {"level": SafetyLevel.CAUTION.value, "reason": match[1], "matched_pattern": match[0]}

        return {"level": SafetyLevel.SAFE.value, "reason": "No dangerous patterns detected", "matched_pattern": ""}

    def _detect_obfuscation(self, payload: str) -> Optional[str]:
        """Detect obfuscation techniques in payloads.

        Returns a reason string if obfuscation detected, None otherwise.
        """
        # Base64-encoded commands (strings > 20 chars that look like base64)
        import re as _re
        b64_matches = _re.findall(r'[A-Za-z0-9+/]{20,}={0,2}', payload)
        for b64 in b64_matches:
            try:
                import base64
                decoded = base64.b64decode(b64).decode('utf-8', errors='ignore')
                # Check if decoded content contains dangerous patterns
                dangerous_in_decoded = any(
                    kw in decoded.lower()
                    for kw in ['select', 'drop', 'delete', 'exec', '/bin/', 'cmd', 'powershell']
                )
                if dangerous_in_decoded:
                    return f"Base64-encoded command detected: decoded contains suspicious content"
            except Exception:
                pass

        # Hex-encoded payloads (0x prefix patterns common in SQL injection)
        hex_pattern = _re.findall(r'0x[0-9a-fA-F]{6,}', payload)
        if hex_pattern:
            return f"Hex-encoded payload detected ({len(hex_pattern)} hex strings)"

        # Unicode escaping (\u00 patterns used to bypass WAF)
        unicode_pattern = _re.findall(r'\\u00[0-9a-fA-F]{2}', payload)
        if len(unicode_pattern) >= 3:
            return f"Unicode escape sequences detected ({len(unicode_pattern)} sequences)"

        return None

    def _classify_insert_context(self, payload: str) -> Optional[Dict[str, Any]]:
        """Context-aware INSERT classification.

        INSERT INTO audit_log/log/event tables -> SAFE
        INSERT INTO users/accounts/sessions -> CAUTION
        """
        import re as _re
        insert_match = _re.search(r'\bINSERT\s+INTO\s+(\w+)', payload, re.IGNORECASE)
        if not insert_match:
            return None

        table_name = insert_match.group(1).lower()

        # Safe tables (audit/logging)
        safe_tables = {'audit_log', 'log', 'logs', 'event', 'events', 'activity_log', 'access_log', 'audit'}
        if table_name in safe_tables:
            return {"level": SafetyLevel.SAFE.value, "reason": f"INSERT into audit/log table ({table_name})", "matched_pattern": ""}

        # Sensitive tables (user data)
        sensitive_tables = {'users', 'accounts', 'sessions', 'credentials', 'tokens', 'passwords', 'admins', 'roles'}
        if table_name in sensitive_tables:
            return {"level": SafetyLevel.CAUTION.value, "reason": f"INSERT into sensitive table ({table_name})", "matched_pattern": r"\bINSERT\s+INTO\b"}

        return None

    def classify_url(self, url: str, scope_validator=None) -> Dict[str, Any]:
        """Classify a URL for safety.

        Parameters
        ----------
        url : str
            The URL to classify.
        scope_validator :
            Optional callable(url) -> bool to check if the URL is in scope.
        """
        if not url:
            return {"level": SafetyLevel.SAFE.value, "reason": "Empty URL", "matched_pattern": ""}

        # Check if out of scope
        if scope_validator is not None:
            try:
                if not scope_validator(url):
                    return {
                        "level": SafetyLevel.BLOCKED.value,
                        "reason": "URL is out of scope",
                        "matched_pattern": url,
                    }
            except Exception:
                pass

        # Internal/metadata endpoints
        metadata_patterns = [
            (r"169\.254\.169\.254", "AWS metadata endpoint"),
            (r"metadata\.google\.internal", "GCP metadata endpoint"),
            (r"100\.100\.100\.200", "Alibaba metadata endpoint"),
        ]
        match = _check_patterns(url, metadata_patterns)
        if match:
            return {"level": SafetyLevel.CAUTION.value, "reason": f"Cloud metadata: {match[1]}", "matched_pattern": match[0]}

        return {"level": SafetyLevel.SAFE.value, "reason": "URL appears safe", "matched_pattern": ""}


# ---------------------------------------------------------------------------
# Module-level singleton
# ---------------------------------------------------------------------------

_classifier_instance: Optional[SafetyClassifier] = None


def get_safety_classifier() -> SafetyClassifier:
    """Return (or create) the module-level SafetyClassifier singleton."""
    global _classifier_instance
    if _classifier_instance is None:
        _classifier_instance = SafetyClassifier()
    return _classifier_instance
