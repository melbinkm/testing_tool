"""
ConfidenceScorer - Calculates confidence scores for findings

Combines reproduction, negative control, and cross-identity results
to determine overall confidence and promotion recommendation.

Weighted scoring:
  - repro: 0.4
  - negative_control: 0.35
  - cross_identity: 0.25

Thresholds:
  - promote: >= 0.8
  - investigate: >= 0.5
  - dismiss: < 0.5

Ported from validator-mcp/src/confidence-scorer.ts
"""
from __future__ import annotations

from typing import Any, Dict, List, Optional


# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

CONFIDENCE_THRESHOLDS: Dict[str, float] = {
    "PROMOTE": 0.8,
    "INVESTIGATE": 0.5,
    "DISMISS": 0.3,
}

VALIDATION_WEIGHTS: Dict[str, float] = {
    "REPRO": 0.4,
    "NEGATIVE_CONTROL": 0.35,
    "CROSS_IDENTITY": 0.25,
}


class ConfidenceScorer:
    """Calculates confidence scores based on validation results."""

    def __init__(
        self,
        promote_threshold: float = CONFIDENCE_THRESHOLDS["PROMOTE"],
        investigate_threshold: float = CONFIDENCE_THRESHOLDS["INVESTIGATE"],
    ) -> None:
        self._promote_threshold = promote_threshold
        self._investigate_threshold = investigate_threshold

    # ------------------------------------------------------------------
    # Individual score calculators
    # ------------------------------------------------------------------

    def calculate_repro_score(self, result: Dict[str, Any]) -> float:
        """Calculate reproduction score.

        Factors:
          - Success rate (primary factor)
          - Consistency of responses
          - Number of attempts
        """
        if result.get("total_attempts", 0) == 0:
            return 0.0

        # Base score from success rate
        score = result.get("success_rate", 0.0)

        # Bonus for consistency
        if result.get("consistent") and result.get("successful_attempts", 0) > 1:
            score = min(1.0, score + 0.1)

        # Slight penalty for very few attempts
        if result.get("total_attempts", 0) < 3:
            score *= 0.9

        # Bonus for many successful attempts
        if result.get("successful_attempts", 0) >= 5:
            score = min(1.0, score + 0.05)

        return round(score * 100) / 100

    def calculate_negative_control_score(self, result: Dict[str, Any]) -> float:
        """Calculate negative control score.

        Factors:
          - Whether the control passed
          - Type of control (some are more critical)
        """
        if result.get("passed"):
            # Control passed - high confidence
            return 1.0

        # Control failed - score depends on control type
        control_type = result.get("control_type", "")

        if control_type == "unauthenticated":
            # Unauthenticated access is critical
            return 0.1
        elif control_type == "invalid_token":
            # Invalid token bypass is serious
            return 0.2
        elif control_type == "different_user":
            # Unauthorized user access is serious
            return 0.15
        elif control_type == "modified_request":
            # May be less critical depending on context
            return 0.3
        else:
            return 0.2

    def calculate_cross_identity_score(self, result: Dict[str, Any]) -> float:
        """Calculate cross-identity score.

        Factors:
          - Number of violations
          - Total identities tested
          - Types of violations
        """
        identities_tested = result.get("identities_tested", [])
        if len(identities_tested) == 0:
            return 0.0

        if result.get("authorization_enforced"):
            # No violations - full score
            return 1.0

        # Calculate based on violation ratio
        violations = result.get("violations", [])
        violation_ratio = len(violations) / len(identities_tested)

        # Check for unauthorized access violations (more severe)
        unauthorized_access_violations = sum(
            1 for v in violations if "unauthorized access" in v
        )

        if unauthorized_access_violations > 0:
            # Unauthorized access is critical
            return max(0.1, 0.5 - violation_ratio * 0.4)

        # Denied access violations are less severe (could be overly restrictive)
        return max(0.3, 1.0 - violation_ratio * 0.7)

    # ------------------------------------------------------------------
    # Recommendation
    # ------------------------------------------------------------------

    def get_recommendation(self, overall_score: float) -> str:
        """Determine recommendation based on overall score.

        Returns:
            One of ``'promote'``, ``'investigate'``, or ``'dismiss'``.
        """
        if overall_score >= self._promote_threshold:
            return "promote"
        if overall_score >= self._investigate_threshold:
            return "investigate"
        return "dismiss"

    # ------------------------------------------------------------------
    # Factor generation
    # ------------------------------------------------------------------

    def generate_factors(
        self,
        inputs: Dict[str, Any],
        repro_score: float,
        negative_control_score: float,
        cross_identity_score: float,
    ) -> List[str]:
        """Generate explanation factors for the score."""
        factors: List[str] = []

        # Reproduction factors
        repro_result: Optional[Dict[str, Any]] = inputs.get("repro_result")
        if repro_result is not None:
            success_rate = repro_result.get("success_rate", 0.0)
            successful = repro_result.get("successful_attempts", 0)
            total = repro_result.get("total_attempts", 0)

            if success_rate >= 1.0:
                factors.append(
                    f"Reproduction: 100% success rate ({successful}/{total})"
                )
            elif success_rate >= 0.8:
                factors.append(
                    f"Reproduction: High success rate ({round(success_rate * 100)}%)"
                )
            elif success_rate >= 0.5:
                factors.append(
                    f"Reproduction: Moderate success rate ({round(success_rate * 100)}%)"
                )
            else:
                factors.append(
                    f"Reproduction: Low success rate ({round(success_rate * 100)}%) - finding may be flaky"
                )

            if repro_result.get("consistent"):
                factors.append("Reproduction: Responses are consistent")
            elif successful > 1:
                factors.append("Reproduction: Responses vary between attempts")
        else:
            factors.append("Reproduction: Not tested")

        # Negative control factors
        nc_result: Optional[Dict[str, Any]] = inputs.get("negative_control_result")
        if nc_result is not None:
            control_type = nc_result.get("control_type", "")
            if nc_result.get("passed"):
                factors.append(
                    f"Negative control ({control_type}): Passed - authorization enforced"
                )
            else:
                actual_behavior = nc_result.get("actual_behavior", "")
                factors.append(
                    f"Negative control ({control_type}): FAILED - {actual_behavior}"
                )
        else:
            factors.append("Negative control: Not tested")

        # Cross-identity factors
        ci_result: Optional[Dict[str, Any]] = inputs.get("cross_identity_result")
        if ci_result is not None:
            identities = ci_result.get("identities_tested", [])
            violations = ci_result.get("violations", [])
            if ci_result.get("authorization_enforced"):
                factors.append(
                    f"Cross-identity: Authorization enforced across {len(identities)} identities"
                )
            else:
                factors.append(
                    f"Cross-identity: {len(violations)} violation(s) found"
                )
                for violation in violations[:3]:
                    factors.append(f"  - {violation}")
        else:
            factors.append("Cross-identity: Not tested")

        return factors

    # ------------------------------------------------------------------
    # Main entry point
    # ------------------------------------------------------------------

    def calculate_confidence(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate overall confidence score.

        Args:
            inputs: A ValidationInputs dict with:
                - finding_id (str)
                - repro_result (dict, optional)
                - negative_control_result (dict, optional)
                - cross_identity_result (dict, optional)

        Returns:
            A ConfidenceScore dict with recommendation.
        """
        # Calculate individual scores
        repro_score = (
            self.calculate_repro_score(inputs["repro_result"])
            if inputs.get("repro_result") is not None
            else 0.0
        )

        negative_control_score = (
            self.calculate_negative_control_score(inputs["negative_control_result"])
            if inputs.get("negative_control_result") is not None
            else 0.0
        )

        cross_identity_score = (
            self.calculate_cross_identity_score(inputs["cross_identity_result"])
            if inputs.get("cross_identity_result") is not None
            else 0.0
        )

        # Calculate weighted overall score
        # Only include weights for tests that were actually performed
        total_weight = 0.0
        weighted_sum = 0.0

        if inputs.get("repro_result") is not None:
            weighted_sum += repro_score * VALIDATION_WEIGHTS["REPRO"]
            total_weight += VALIDATION_WEIGHTS["REPRO"]

        if inputs.get("negative_control_result") is not None:
            weighted_sum += negative_control_score * VALIDATION_WEIGHTS["NEGATIVE_CONTROL"]
            total_weight += VALIDATION_WEIGHTS["NEGATIVE_CONTROL"]

        if inputs.get("cross_identity_result") is not None:
            weighted_sum += cross_identity_score * VALIDATION_WEIGHTS["CROSS_IDENTITY"]
            total_weight += VALIDATION_WEIGHTS["CROSS_IDENTITY"]

        overall_score = weighted_sum / total_weight if total_weight > 0 else 0.0
        rounded_overall = round(overall_score * 100) / 100

        # Generate recommendation and factors
        recommendation = self.get_recommendation(rounded_overall)
        factors = self.generate_factors(
            inputs, repro_score, negative_control_score, cross_identity_score
        )

        return {
            "finding_id": inputs["finding_id"],
            "repro_score": repro_score,
            "negative_control_score": negative_control_score,
            "cross_identity_score": cross_identity_score,
            "overall_score": rounded_overall,
            "recommendation": recommendation,
            "factors": factors,
        }

    # ------------------------------------------------------------------
    # Accessors
    # ------------------------------------------------------------------

    def get_thresholds(self) -> Dict[str, float]:
        """Get thresholds used for recommendations."""
        return {
            "promote": self._promote_threshold,
            "investigate": self._investigate_threshold,
        }
