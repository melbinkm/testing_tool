"""
Response Classifier - Deterministic vulnerability detection during test execution.

Classifies HTTP responses to determine if a payload successfully triggered
a vulnerability. Used by TestPlanExecutor to produce per-payload verdicts.
"""

from __future__ import annotations

import hashlib
import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

from lib.signal_detector import ERROR_INDICATORS


# ---------------------------------------------------------------------------
# Classification result
# ---------------------------------------------------------------------------

@dataclass
class ClassificationResult:
    """Result of classifying a single response against a payload."""
    is_vulnerable: bool
    confidence: float  # 0.0 â€“ 1.0
    severity: str  # info, low, medium, high, critical
    evidence: List[str] = field(default_factory=list)
    signal_type: str = ""  # error, timing, reflection, differential, content, header
    vuln_class: str = ""
    parameter: str = ""
    payload_used: str = ""


# ---------------------------------------------------------------------------
# SQL error patterns (extended from signal_detector)
# ---------------------------------------------------------------------------

_SQL_ERROR_PATTERNS: List[re.Pattern] = [
    re.compile(p, re.IGNORECASE) for p in [
        r"sql\s*syntax",
        r"mysql_fetch",
        r"ora-\d{5}",
        r"postgresql",
        r"sqlite3?\.\w+Error",
        r"jdbc\s*exception",
        r"odbc\s*(driver|error)",
        r"syntax error.*(?:near|at)",
        r"unclosed quotation",
        r"unterminated string",
        r"microsoft.*sql\s*server",
        r"sqlstate\[",
    ]
]

# ---------------------------------------------------------------------------
# XSS dangerous reflection patterns
# ---------------------------------------------------------------------------

_XSS_DANGEROUS_PATTERNS = [
    "<script", "onerror=", "onload=", "onclick=", "onmouseover=",
    "javascript:", "alert(", "prompt(", "confirm(",
    "<img src=", "<svg ", "<iframe ",
]

# ---------------------------------------------------------------------------
# SSTI computation markers
# ---------------------------------------------------------------------------

_SSTI_TEMPLATES = {
    "{{7*7}}": "49",
    "${7*7}": "49",
    "#{7*7}": "49",
    "{{7*'7'}}": "7777777",
    "<%= 7*7 %>": "49",
}

# ---------------------------------------------------------------------------
# Path traversal file content patterns
# ---------------------------------------------------------------------------

_PATH_TRAVERSAL_PATTERNS: List[re.Pattern] = [
    re.compile(p, re.IGNORECASE) for p in [
        r"root:.*:0:0:",          # /etc/passwd
        r"\[extensions\]",        # win.ini
        r"\[fonts\]",             # win.ini
        r";\s*for 16-bit app",    # boot.ini
        r"\[boot\s*loader\]",     # boot.ini
        r"localhost",             # /etc/hosts common pattern
    ]
]

# ---------------------------------------------------------------------------
# SSRF internal/metadata content patterns
# ---------------------------------------------------------------------------

_SSRF_PATTERNS: List[re.Pattern] = [
    re.compile(p, re.IGNORECASE) for p in [
        r"ami-id",
        r"instance-id",
        r"iam/security-credentials",
        r"meta-data",
        r"computeMetadata",
        r"169\.254\.169\.254",
        r"metadata\.google\.internal",
    ]
]

# ---------------------------------------------------------------------------
# Command injection patterns
# ---------------------------------------------------------------------------

_CMDI_PATTERNS: List[re.Pattern] = [
    re.compile(p) for p in [
        r"uid=\d+",               # id command output
        r"drwx[r-][w-][x-]",     # ls -la output
        r"total\s+\d+\s",        # ls -la header
        r"root:x:0:0:",          # /etc/passwd read via cmdi
    ]
]


# ---------------------------------------------------------------------------
# ResponseClassifier
# ---------------------------------------------------------------------------

class ResponseClassifier:
    """Deterministic classifier for vulnerability detection per vuln class."""

    def classify(
        self,
        vuln_class: str,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Classify a single response against the baseline for a given vuln class.

        Parameters
        ----------
        vuln_class : str
            The vulnerability class being tested (sqli, xss, ssti, etc.).
        response : dict
            ``{status, headers, body, timing}`` of the test request.
        baseline : dict
            Fingerprint of the baseline response:
            ``{status, body_hash, body_length, timing_ms}``.
        payload : str
            The payload that was sent.
        parameter : str
            The parameter that was injected.

        Returns
        -------
        ClassificationResult
        """
        dispatcher = {
            "sqli": self._classify_sqli,
            "xss": self._classify_xss,
            "ssti": self._classify_ssti,
            "path_traversal": self._classify_path_traversal,
            "ssrf": self._classify_ssrf,
            "injection": self._classify_injection,
            "overflow": self._classify_overflow,
            "type_confusion": self._classify_type_confusion,
            "info_disclosure": self._classify_info_disclosure,
            "misconfig": self._classify_misconfig,
        }

        classify_fn = dispatcher.get(vuln_class, self._classify_generic)
        result = classify_fn(response, baseline, payload, parameter)
        result.vuln_class = vuln_class
        result.parameter = parameter
        result.payload_used = payload
        return result

    # ------------------------------------------------------------------
    # Per-class classifiers
    # ------------------------------------------------------------------

    def _classify_sqli(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect SQL injection via error-based, time-based, and boolean-blind."""
        body = response.get("body") or ""
        body_lower = body.lower()
        evidence: List[str] = []
        confidence = 0.0

        # Error-based: check for SQL error patterns
        for pattern in _SQL_ERROR_PATTERNS:
            match = pattern.search(body_lower)
            if match:
                evidence.append(f"SQL error pattern matched: {match.group()}")
                confidence = max(confidence, 0.85)

        # Time-based: response significantly slower than baseline
        timing = response.get("timing") or {}
        resp_time = timing.get("duration_ms", 0)
        baseline_time = baseline.get("timing_ms", 0)

        if baseline_time > 0 and resp_time > 0:
            # Confirmed if > 3x baseline AND > 2500ms absolute
            if resp_time > (baseline_time * 3) and resp_time > 2500:
                evidence.append(
                    f"Timing anomaly: {resp_time:.0f}ms vs {baseline_time:.0f}ms baseline "
                    f"({resp_time / baseline_time:.1f}x)"
                )
                confidence = max(confidence, 0.8)
            # Suspicious if > 1.5x baseline but below threshold
            elif resp_time > (baseline_time * 1.5) and resp_time > 1000:
                evidence.append(
                    f"Slight timing increase: {resp_time:.0f}ms vs {baseline_time:.0f}ms baseline"
                )
                confidence = max(confidence, 0.4)

        # Boolean-blind: body hash differs for boolean payloads
        resp_hash = _hash_body(body)
        if baseline.get("body_hash") and resp_hash != baseline["body_hash"]:
            if any(kw in payload.lower() for kw in ("1=1", "1=2", "or 1", "and 1")):
                evidence.append("Response body changed for boolean SQL payload")
                confidence = max(confidence, 0.5)

        # Status code change to 500
        resp_status = response.get("status", 200)
        if resp_status == 500 and baseline.get("status", 200) != 500:
            evidence.append(f"Status changed to 500 (baseline: {baseline.get('status', 200)})")
            confidence = max(confidence, 0.45)

        is_vulnerable = confidence >= 0.6
        severity = "high" if is_vulnerable else "medium" if confidence >= 0.3 else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="error" if any("SQL error" in e for e in evidence) else "timing",
        )

    def _classify_xss(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect XSS via unencoded payload reflection."""
        body = response.get("body") or ""
        evidence: List[str] = []
        confidence = 0.0

        if payload and payload in body:
            # Check if dangerous patterns are reflected
            payload_lower = payload.lower()
            body_lower = body.lower()

            for pattern in _XSS_DANGEROUS_PATTERNS:
                if pattern.lower() in payload_lower and pattern.lower() in body_lower:
                    evidence.append(f"Payload reflected verbatim with dangerous pattern: {pattern}")
                    confidence = max(confidence, 0.9)
                    break

            if not evidence and payload in body:
                evidence.append("Payload reflected in response body")
                confidence = max(confidence, 0.5)

        is_vulnerable = confidence >= 0.6
        severity = "high" if is_vulnerable else "low"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="reflection",
        )

    def _classify_ssti(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect SSTI via computation marker presence."""
        body = response.get("body") or ""
        evidence: List[str] = []
        confidence = 0.0

        # Check if template computation result appears in response
        expected = _SSTI_TEMPLATES.get(payload)
        if expected and expected in body:
            # Verify it wasn't already in the baseline
            baseline_body_has = False
            if baseline.get("body_hash"):
                # We can't check baseline body directly; use heuristic:
                # if baseline body_length is similar and status same, assume it's new
                pass
            evidence.append(f"Template computation result '{expected}' found in response for payload '{payload}'")
            confidence = 0.85

        is_vulnerable = confidence >= 0.6
        severity = "critical" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="content",
        )

    def _classify_path_traversal(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect path traversal via file content patterns."""
        body = response.get("body") or ""
        evidence: List[str] = []
        confidence = 0.0

        for pattern in _PATH_TRAVERSAL_PATTERNS:
            match = pattern.search(body)
            if match:
                evidence.append(f"File content pattern detected: {match.group()}")
                confidence = max(confidence, 0.85)

        is_vulnerable = confidence >= 0.6
        severity = "high" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="content",
        )

    def _classify_ssrf(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect SSRF via internal/cloud metadata content."""
        body = response.get("body") or ""
        evidence: List[str] = []
        confidence = 0.0

        for pattern in _SSRF_PATTERNS:
            match = pattern.search(body)
            if match:
                evidence.append(f"Internal/metadata content detected: {match.group()}")
                confidence = max(confidence, 0.8)

        is_vulnerable = confidence >= 0.6
        severity = "high" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="content",
        )

    def _classify_injection(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Union of SQL + XSS + command injection patterns."""
        # Try SQL first
        sqli_result = self._classify_sqli(response, baseline, payload, parameter)
        if sqli_result.is_vulnerable:
            sqli_result.signal_type = "error"
            return sqli_result

        # Try XSS
        xss_result = self._classify_xss(response, baseline, payload, parameter)
        if xss_result.is_vulnerable:
            return xss_result

        # Command injection patterns
        body = response.get("body") or ""
        evidence: List[str] = []
        confidence = 0.0

        for pattern in _CMDI_PATTERNS:
            match = pattern.search(body)
            if match:
                evidence.append(f"Command injection output detected: {match.group()}")
                confidence = max(confidence, 0.8)

        if confidence >= 0.6:
            return ClassificationResult(
                is_vulnerable=True,
                confidence=confidence,
                severity="critical",
                evidence=evidence,
                signal_type="content",
            )

        # Return the highest-confidence non-vulnerable result
        best = max([sqli_result, xss_result], key=lambda r: r.confidence)
        return ClassificationResult(
            is_vulnerable=False,
            confidence=best.confidence,
            severity=best.severity,
            evidence=best.evidence,
            signal_type=best.signal_type,
        )

    def _classify_overflow(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect overflow via status 500 on large payload when baseline was 200."""
        resp_status = response.get("status", 200)
        base_status = baseline.get("status", 200)
        evidence: List[str] = []
        confidence = 0.0

        if resp_status == 500 and base_status == 200:
            evidence.append(f"Server error (500) triggered by oversized input (baseline: {base_status})")
            confidence = 0.7

        # Also check for significant body length change
        body_len = len(response.get("body") or "")
        baseline_len = baseline.get("body_length", 0) or 1
        if body_len < baseline_len * 0.3 and resp_status >= 400:
            evidence.append(f"Response truncated: {body_len} bytes vs {baseline_len} baseline")
            confidence = max(confidence, 0.5)

        is_vulnerable = confidence >= 0.6
        severity = "medium" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="differential",
        )

    def _classify_type_confusion(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect type confusion via differential response analysis."""
        body = response.get("body") or ""
        resp_status = response.get("status", 200)
        base_status = baseline.get("status", 200)
        evidence: List[str] = []
        confidence = 0.0

        # Status code changed
        if resp_status != base_status:
            evidence.append(f"Status changed: {base_status} -> {resp_status}")
            confidence = max(confidence, 0.5)

        # Body hash differs significantly
        resp_hash = _hash_body(body)
        if baseline.get("body_hash") and resp_hash != baseline["body_hash"]:
            body_len = len(body)
            baseline_len = baseline.get("body_length", 0) or 1
            ratio = body_len / baseline_len
            if ratio < 0.5 or ratio > 2.0:
                evidence.append(f"Significant body change: {body_len} vs {baseline_len} bytes")
                confidence = max(confidence, 0.6)

        is_vulnerable = confidence >= 0.6
        severity = "medium" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="differential",
        )

    def _classify_info_disclosure(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect information disclosure via server headers, debug info, stack traces."""
        headers = response.get("headers") or {}
        body_lower = (response.get("body") or "").lower()
        evidence: List[str] = []
        confidence = 0.0

        # Server version header
        server = ""
        for k, v in headers.items():
            if k.lower() == "server" and "/" in v:
                server = v
                evidence.append(f"Server version disclosed: {v}")
                confidence = max(confidence, 0.7)
            if k.lower() == "x-powered-by":
                evidence.append(f"X-Powered-By header: {v}")
                confidence = max(confidence, 0.7)

        # Debug info in body
        for indicator in ERROR_INDICATORS.get("debug", []):
            if indicator in body_lower:
                evidence.append(f"Debug information detected: {indicator}")
                confidence = max(confidence, 0.7)
                break

        # Stack traces
        for indicator in ERROR_INDICATORS.get("stackTrace", []):
            if indicator in body_lower:
                evidence.append(f"Stack trace detected: {indicator}")
                confidence = max(confidence, 0.75)
                break

        # Internal paths
        for indicator in ERROR_INDICATORS.get("path", []):
            if indicator in body_lower:
                evidence.append(f"Internal path disclosed: {indicator}")
                confidence = max(confidence, 0.65)
                break

        is_vulnerable = confidence >= 0.6
        severity = "medium" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="header" if server else "content",
        )

    def _classify_misconfig(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Detect misconfigurations via CORS, missing security headers, OPTIONS."""
        headers = response.get("headers") or {}
        lower_headers = {k.lower(): v for k, v in headers.items()}
        evidence: List[str] = []
        confidence = 0.0

        # Wildcard CORS
        acao = lower_headers.get("access-control-allow-origin", "")
        if acao == "*":
            evidence.append("Access-Control-Allow-Origin: * (wildcard CORS)")
            confidence = max(confidence, 0.75)

        # Missing security headers
        from lib.response_analyzer import _SECURITY_HEADERS
        missing_count = 0
        for header in _SECURITY_HEADERS:
            if header.lower() not in lower_headers:
                missing_count += 1
        if missing_count >= 4:
            evidence.append(f"{missing_count} security headers missing")
            confidence = max(confidence, 0.65)

        # OPTIONS reveals unexpected methods
        resp_status = response.get("status", 200)
        allow = lower_headers.get("allow", lower_headers.get("access-control-allow-methods", ""))
        if allow and resp_status < 400:
            methods = [m.strip().upper() for m in allow.split(",")]
            dangerous = {"DELETE", "PUT", "PATCH", "TRACE"}
            found_dangerous = dangerous & set(methods)
            if found_dangerous:
                evidence.append(f"Unexpected HTTP methods allowed: {', '.join(found_dangerous)}")
                confidence = max(confidence, 0.7)

        is_vulnerable = confidence >= 0.6
        severity = "medium" if is_vulnerable else "info"
        return ClassificationResult(
            is_vulnerable=is_vulnerable,
            confidence=confidence,
            severity=severity,
            evidence=evidence,
            signal_type="header",
        )

    def _classify_generic(
        self,
        response: Dict[str, Any],
        baseline: Dict[str, Any],
        payload: str,
        parameter: str,
    ) -> ClassificationResult:
        """Fallback classifier: differential analysis."""
        resp_status = response.get("status", 200)
        base_status = baseline.get("status", 200)
        evidence: List[str] = []
        confidence = 0.0

        if resp_status != base_status:
            evidence.append(f"Status changed: {base_status} -> {resp_status}")
            confidence = 0.3

        return ClassificationResult(
            is_vulnerable=False,
            confidence=confidence,
            severity="info",
            evidence=evidence,
            signal_type="differential",
        )


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _hash_body(body: str) -> str:
    """SHA-256 hash of body, truncated to 16 hex chars."""
    return hashlib.sha256(body.encode("utf-8", errors="replace")).hexdigest()[:16]
