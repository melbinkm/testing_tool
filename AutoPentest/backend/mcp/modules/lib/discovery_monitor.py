"""
Discovery Monitor - Feedback loop that detects newly discovered endpoints
and auto-extends the coverage matrix.

Watches the world model for new endpoints added during any assessment phase
(crawling, probing, form discovery, etc.), classifies their priority, and
feeds them into the coverage tracker so they are automatically queued for
vulnerability testing.
"""

from __future__ import annotations

import json
import logging
import re
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

from lib.coverage_tracker import CoverageTracker
from lib.phase_orchestrator import PhaseOrchestrator

logger = logging.getLogger("autopentest-mcp")


# ---------------------------------------------------------------------------
# Priority classification patterns
# ---------------------------------------------------------------------------

# HIGH priority: admin/debug/config/internal/management panels, auth flows,
# API endpoints with parameters
_HIGH_PATH_PATTERNS: List[re.Pattern] = [
    re.compile(r"/admin", re.IGNORECASE),
    re.compile(r"/debug", re.IGNORECASE),
    re.compile(r"/config", re.IGNORECASE),
    re.compile(r"/internal", re.IGNORECASE),
    re.compile(r"/management", re.IGNORECASE),
    re.compile(r"/login", re.IGNORECASE),
    re.compile(r"/auth", re.IGNORECASE),
    re.compile(r"/oauth", re.IGNORECASE),
    re.compile(r"/token", re.IGNORECASE),
    re.compile(r"/signup", re.IGNORECASE),
    re.compile(r"/register", re.IGNORECASE),
    re.compile(r"/password", re.IGNORECASE),
    re.compile(r"/reset", re.IGNORECASE),
]

# MEDIUM priority: standard API paths, REST versioned paths, state-changing
# methods, path parameters
_MEDIUM_PATH_PATTERNS: List[re.Pattern] = [
    re.compile(r"/api/", re.IGNORECASE),
    re.compile(r"/v\d+/", re.IGNORECASE),
    re.compile(r"/rest/", re.IGNORECASE),
    re.compile(r"/graphql", re.IGNORECASE),
    re.compile(r"\{[^}]+\}"),  # path parameters like {id}, {user_id}
]

# LOW priority: static resources and known non-functional paths
_LOW_PATH_PATTERNS: List[re.Pattern] = [
    re.compile(r"/static/", re.IGNORECASE),
    re.compile(r"/assets/", re.IGNORECASE),
    re.compile(r"/css/", re.IGNORECASE),
    re.compile(r"/js/", re.IGNORECASE),
    re.compile(r"/images/", re.IGNORECASE),
    re.compile(r"/fonts/", re.IGNORECASE),
    re.compile(r"/media/", re.IGNORECASE),
    re.compile(r"/public/", re.IGNORECASE),
]

_LOW_EXTENSION_RE = re.compile(
    r"\.(ico|png|jpg|jpeg|gif|svg|webp|css|js|map|woff2?|ttf|eot|otf)$",
    re.IGNORECASE,
)

# Methods that indicate state-changing operations (bump to MEDIUM at least)
_STATE_CHANGING_METHODS = {"POST", "PUT", "PATCH", "DELETE"}


# ---------------------------------------------------------------------------
# DiscoveryEvent dataclass
# ---------------------------------------------------------------------------

@dataclass
class DiscoveryEvent:
    """Represents a newly discovered endpoint during an assessment."""

    endpoint_id: str
    method: str
    path: str
    source: str  # what discovered it (e.g., "crawler", "endpoint_probe", "form_discovery")
    phase: str   # which assessment phase it was discovered in
    created_at: str  # ISO-8601 timestamp
    priority: str    # "high", "medium", or "low"


# ---------------------------------------------------------------------------
# DiscoveryMonitor
# ---------------------------------------------------------------------------

class DiscoveryMonitor:
    """Monitors the world model for new endpoints and auto-extends coverage.

    The monitor is designed to be called periodically (or after each tool
    execution) to detect newly added endpoints and ensure the coverage
    matrix stays up to date.

    Usage::

        monitor = DiscoveryMonitor(db)
        events = await monitor.check_new_endpoints(since="2025-01-15T10:30:00Z")
        if events:
            result = await monitor.extend_coverage(events, base_url="https://target.com")
    """

    def __init__(self, db: Any) -> None:
        """Initialize with a WorldModelDatabase instance.

        Parameters
        ----------
        db : WorldModelDatabase
            An initialized world model database bound to an assessment_id.
        """
        self._db = db

    # ------------------------------------------------------------------
    # Public methods
    # ------------------------------------------------------------------

    async def check_new_endpoints(self, since: str) -> List[DiscoveryEvent]:
        """Check for endpoints discovered after the given timestamp.

        Parameters
        ----------
        since : str
            ISO-8601 datetime string.  Supports both timezone-aware
            (``2025-01-15T10:30:00Z``, ``2025-01-15T10:30:00+00:00``)
            and naive (``2025-01-15T10:30:00``) formats.

        Returns
        -------
        List[DiscoveryEvent]
            Newly discovered endpoints classified by priority.
        """
        since_dt = self._parse_datetime(since)
        if since_dt is None:
            logger.warning("DiscoveryMonitor: could not parse 'since' timestamp: %s", since)
            return []

        try:
            rows = await self._db._fetchall(
                "SELECT * FROM wm_endpoints "
                "WHERE assessment_id = $1 AND discovered_at > $2 "
                "ORDER BY discovered_at DESC",
                (self._db._assessment_id, since_dt),
            )
        except Exception as exc:
            logger.warning("DiscoveryMonitor: failed to query new endpoints: %s", exc)
            return []

        events: List[DiscoveryEvent] = []
        for row in rows:
            row_dict = dict(row)
            method = row_dict.get("method", "GET")
            path = row_dict.get("path", "")
            metadata = row_dict.get("metadata")
            if isinstance(metadata, str):
                try:
                    metadata = json.loads(metadata)
                except (json.JSONDecodeError, TypeError):
                    metadata = {}

            priority = self._classify_endpoint_priority(method, path, metadata)

            # Extract source and phase from metadata if available
            source = "unknown"
            phase = "unknown"
            if isinstance(metadata, dict):
                source = metadata.get("discovered_by", metadata.get("source", "unknown"))
                phase = metadata.get("phase", metadata.get("discovered_in_phase", "unknown"))

            discovered_at_raw = row_dict.get("discovered_at", "")
            if isinstance(discovered_at_raw, datetime):
                discovered_at_str = discovered_at_raw.isoformat()
            else:
                discovered_at_str = str(discovered_at_raw)

            events.append(DiscoveryEvent(
                endpoint_id=row_dict.get("id", ""),
                method=method,
                path=path,
                source=source,
                phase=phase,
                created_at=discovered_at_str,
                priority=priority,
            ))

        logger.info(
            "DiscoveryMonitor: found %d new endpoints since %s (high=%d, medium=%d, low=%d)",
            len(events),
            since,
            sum(1 for e in events if e.priority == "high"),
            sum(1 for e in events if e.priority == "medium"),
            sum(1 for e in events if e.priority == "low"),
        )
        return events

    async def extend_coverage(
        self,
        events: List[DiscoveryEvent],
        base_url: str,
        vuln_classes: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """Extend the coverage matrix with newly discovered endpoints.

        Fetches full endpoint data from the world model, builds coverage
        matrix rows via ``CoverageTracker.build_matrix()``, and inserts
        them.  The underlying ``ON CONFLICT DO NOTHING`` makes this
        operation idempotent -- safe to call multiple times with the same
        events.

        Parameters
        ----------
        events : List[DiscoveryEvent]
            Discovery events from ``check_new_endpoints()``.
        base_url : str
            Base URL of the target (e.g., ``https://target.com``).
        vuln_classes : List[str], optional
            Limit coverage to specific vulnerability classes.

        Returns
        -------
        dict
            ``{new_cells_created, endpoints_covered, details}``
        """
        if not events:
            return {"new_cells_created": 0, "endpoints_covered": 0, "details": []}

        # Fetch full endpoint data for each event
        new_endpoints: List[Dict[str, Any]] = []
        for event in events:
            try:
                endpoint = await self._db.get_by_id("endpoints", event.endpoint_id)
                if endpoint:
                    new_endpoints.append(endpoint)
                else:
                    logger.warning(
                        "DiscoveryMonitor: endpoint %s not found in world model",
                        event.endpoint_id,
                    )
            except Exception as exc:
                logger.warning(
                    "DiscoveryMonitor: failed to fetch endpoint %s: %s",
                    event.endpoint_id, exc,
                )

        if not new_endpoints:
            return {"new_cells_created": 0, "endpoints_covered": 0, "details": []}

        # Build the coverage matrix rows
        try:
            matrix_rows = CoverageTracker.build_matrix(
                new_endpoints, base_url, vuln_classes
            )
        except Exception as exc:
            logger.warning("DiscoveryMonitor: failed to build coverage matrix: %s", exc)
            return {"new_cells_created": 0, "endpoints_covered": 0, "details": [],
                    "error": str(exc)}

        if not matrix_rows:
            return {"new_cells_created": 0, "endpoints_covered": len(new_endpoints),
                    "details": []}

        # Insert rows -- ON CONFLICT DO NOTHING makes this idempotent
        try:
            result = await self._db.coverage_init_rows(matrix_rows)
        except Exception as exc:
            logger.warning("DiscoveryMonitor: failed to insert coverage rows: %s", exc)
            return {"new_cells_created": 0, "endpoints_covered": 0, "details": [],
                    "error": str(exc)}

        # Build per-endpoint detail summary
        details: List[Dict[str, str]] = []
        for ep in new_endpoints:
            matching_event = next(
                (e for e in events if e.endpoint_id == ep.get("id")), None
            )
            details.append({
                "endpoint_id": ep.get("id", ""),
                "method": ep.get("method", ""),
                "path": ep.get("path", ""),
                "priority": matching_event.priority if matching_event else "unknown",
            })

        created = result.get("created", 0)
        logger.info(
            "DiscoveryMonitor: extended coverage with %d new cells for %d endpoints "
            "(skipped %d existing)",
            created, len(new_endpoints), result.get("skipped_existing", 0),
        )

        return {
            "new_cells_created": created,
            "endpoints_covered": len(new_endpoints),
            "details": details,
        }

    async def update_phase_metrics(self) -> Dict[str, Any]:
        """Refresh and return current phase orchestration status.

        Creates a ``PhaseOrchestrator`` and queries the latest metrics
        and gate conditions from the world model.

        Returns
        -------
        dict
            ``{current_phase, metrics, gate_conditions_met, message}``
        """
        try:
            orchestrator = PhaseOrchestrator(self._db)
            metrics = await orchestrator.get_metrics()
            status = await orchestrator.get_status()

            current_phase = status.get("current_phase", 1)
            next_gates = status.get("next_phase_gates")
            gate_conditions_met = next_gates.get("met", False) if next_gates else None

            if current_phase >= 5:
                message = "Assessment in final phase (Reporting)."
            elif gate_conditions_met:
                message = (
                    f"Phase {current_phase} ({status.get('phase_name', '')}) complete. "
                    f"Gate conditions for phase {current_phase + 1} are met -- "
                    f"ready to advance."
                )
            else:
                unmet = []
                if next_gates and "conditions" in next_gates:
                    unmet = [
                        c["name"] for c in next_gates["conditions"] if not c.get("met")
                    ]
                message = (
                    f"Phase {current_phase} ({status.get('phase_name', '')}) in progress. "
                    f"Unmet gate conditions for phase {current_phase + 1}: "
                    f"{', '.join(unmet) if unmet else 'none'}."
                )

            return {
                "current_phase": current_phase,
                "metrics": metrics,
                "gate_conditions_met": gate_conditions_met,
                "message": message,
            }
        except Exception as exc:
            logger.warning("DiscoveryMonitor: failed to get phase metrics: %s", exc)
            return {
                "current_phase": None,
                "metrics": {},
                "gate_conditions_met": None,
                "message": f"Error retrieving phase metrics: {exc}",
            }

    async def get_discovery_summary(self, since: str) -> Dict[str, Any]:
        """Generate a summary of new discoveries and current coverage state.

        Parameters
        ----------
        since : str
            ISO-8601 timestamp for the discovery window.

        Returns
        -------
        dict
            ``{new_endpoints, by_priority, coverage_status, recommendations}``
        """
        events = await self.check_new_endpoints(since)

        by_priority: Dict[str, int] = {"high": 0, "medium": 0, "low": 0}
        for event in events:
            by_priority[event.priority] = by_priority.get(event.priority, 0) + 1

        # Get current coverage report (no filters = full report)
        coverage_status: Optional[Dict[str, Any]] = None
        try:
            coverage_status = await self._db.coverage_report()
        except Exception as exc:
            logger.warning("DiscoveryMonitor: failed to get coverage report: %s", exc)

        recommendations = self._generate_recommendations(events, coverage_status)

        return {
            "new_endpoints": len(events),
            "by_priority": by_priority,
            "coverage_status": coverage_status,
            "recommendations": recommendations,
        }

    # ------------------------------------------------------------------
    # Priority classification
    # ------------------------------------------------------------------

    @staticmethod
    def _classify_endpoint_priority(
        method: str,
        path: str,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Classify an endpoint's testing priority.

        Classification rules (checked in order):
            - **LOW**: static resources, known asset paths, file extensions
              like ``.ico``, ``.png``, ``.jpg``, ``.css``, ``.js``.
            - **HIGH**: admin/debug/config/internal/management panels,
              authentication endpoints (login, auth, oauth, token),
              API endpoints with parameters.
            - **MEDIUM**: standard API paths (``/api/``, ``/v1/``, ``/rest/``),
              state-changing methods (POST/PUT/DELETE), paths with
              path parameters (``{id}``).
            - Otherwise defaults to **low**.

        Parameters
        ----------
        method : str
            HTTP method (GET, POST, etc.).
        path : str
            URL path of the endpoint.
        metadata : dict, optional
            Endpoint metadata (may contain parameter info).

        Returns
        -------
        str
            ``"high"``, ``"medium"``, or ``"low"``.
        """
        method_upper = (method or "GET").upper()
        path_lower = path or ""

        # Check LOW first -- static resources should never be high priority
        if _LOW_EXTENSION_RE.search(path_lower):
            return "low"
        for pattern in _LOW_PATH_PATTERNS:
            if pattern.search(path_lower):
                return "low"

        # Check HIGH -- sensitive/admin/auth paths
        for pattern in _HIGH_PATH_PATTERNS:
            if pattern.search(path_lower):
                return "high"

        # HIGH: API endpoints that accept parameters
        has_parameters = False
        if isinstance(metadata, dict):
            params = metadata.get("parameters") or metadata.get("params")
            if isinstance(params, dict) and params:
                has_parameters = True
            elif isinstance(params, list) and params:
                has_parameters = True
        if has_parameters and re.search(r"/api/", path_lower, re.IGNORECASE):
            return "high"

        # Check MEDIUM -- standard API paths, path params, state-changing
        for pattern in _MEDIUM_PATH_PATTERNS:
            if pattern.search(path_lower):
                return "medium"
        if method_upper in _STATE_CHANGING_METHODS:
            return "medium"

        return "low"

    # ------------------------------------------------------------------
    # Recommendation engine
    # ------------------------------------------------------------------

    @staticmethod
    def _generate_recommendations(
        events: List[DiscoveryEvent],
        coverage_report: Optional[Dict[str, Any]] = None,
    ) -> List[str]:
        """Generate actionable recommendations based on discoveries.

        Parameters
        ----------
        events : List[DiscoveryEvent]
            Recently discovered endpoints.
        coverage_report : dict, optional
            Current coverage report from the world model.

        Returns
        -------
        List[str]
            Human-readable recommendation strings.
        """
        recommendations: List[str] = []

        if not events:
            recommendations.append("No new endpoints discovered in this window.")
            return recommendations

        # Count by priority
        high_count = sum(1 for e in events if e.priority == "high")
        medium_count = sum(1 for e in events if e.priority == "medium")
        low_count = sum(1 for e in events if e.priority == "low")

        # High priority admin/debug endpoints
        admin_endpoints = [
            e for e in events
            if e.priority == "high"
            and any(
                kw in e.path.lower()
                for kw in ("admin", "debug", "config", "internal", "management")
            )
        ]
        if admin_endpoints:
            recommendations.append(
                f"{len(admin_endpoints)} new admin/debug endpoint(s) found -- "
                f"run nuclei scan with admin-panel and misconfig templates."
            )

        # Auth endpoints
        auth_endpoints = [
            e for e in events
            if e.priority == "high"
            and any(
                kw in e.path.lower()
                for kw in ("login", "auth", "oauth", "token", "signup", "register", "password")
            )
        ]
        if auth_endpoints:
            recommendations.append(
                f"{len(auth_endpoints)} new authentication endpoint(s) discovered -- "
                f"run auth_diff_test for authorization bypass testing."
            )

        # State-changing endpoints
        state_changing = [e for e in events if e.method.upper() in _STATE_CHANGING_METHODS]
        if state_changing:
            recommendations.append(
                f"{len(state_changing)} state-changing endpoint(s) ({', '.join(set(e.method.upper() for e in state_changing))}) "
                f"discovered -- prioritize injection and CSRF testing."
            )

        # Coverage gaps
        if coverage_report:
            total_cells = coverage_report.get("total_cells", 0)
            by_status = coverage_report.get("by_status", {})
            pending = by_status.get("pending", 0)
            coverage_pct = coverage_report.get("coverage_pct", 0.0)

            if pending > 0:
                recommendations.append(
                    f"Coverage gap: {pending} pending test cells "
                    f"({coverage_pct}% complete) -- run coverage_next to continue testing."
                )
            gaps = coverage_report.get("gaps", [])
            if gaps:
                high_prio_gaps = [g for g in gaps if g.get("priority", 0) >= 70]
                if high_prio_gaps:
                    recommendations.append(
                        f"{len(high_prio_gaps)} high-priority coverage gap(s) remain -- "
                        f"focus on these before advancing phase."
                    )

        # General summary
        if len(events) > 0 and not recommendations:
            recommendations.append(
                f"{len(events)} new endpoint(s) discovered "
                f"(high={high_count}, medium={medium_count}, low={low_count}) -- "
                f"run extend_coverage to add them to the coverage matrix."
            )

        # Suggest extending coverage if new endpoints exist
        if events and coverage_report is not None:
            recommendations.append(
                f"{len(events)} new endpoint(s) not yet in coverage matrix -- "
                f"run extend_coverage to auto-generate test cells."
            )

        return recommendations

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------

    @staticmethod
    def _parse_datetime(value: str) -> Optional[datetime]:
        """Parse an ISO-8601 datetime string flexibly.

        Handles:
        - ``2025-01-15T10:30:00Z``
        - ``2025-01-15T10:30:00+00:00``
        - ``2025-01-15T10:30:00``  (assumed UTC)
        - ``2025-01-15 10:30:00``
        - ``2025-01-15``
        """
        if not value or not isinstance(value, str):
            return None

        value = value.strip()

        # Replace trailing 'Z' with +00:00 for fromisoformat compatibility
        if value.endswith("Z"):
            value = value[:-1] + "+00:00"

        # Try standard ISO parsing first
        try:
            dt = datetime.fromisoformat(value)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except (ValueError, TypeError):
            pass

        # Try space-separated datetime
        for fmt in (
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M:%S%z",
            "%Y-%m-%dT%H:%M:%S.%f",
            "%Y-%m-%dT%H:%M:%S.%f%z",
            "%Y-%m-%d",
        ):
            try:
                dt = datetime.strptime(value, fmt)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt
            except (ValueError, TypeError):
                continue

        return None
