"""
LLM-in-the-Loop Pentest Tools

8 tools that expose raw HTTP traffic and attack surface data to the LLM,
enabling end-to-end security testing where the LLM sees every request/response,
decides what to test, and controls the flow.

Tools:
1. recon_endpoint - Send baseline HTTP request, return full request/response
2. get_test_payloads - Return actual payload strings from PayloadRegistry
3. inject_payload - Inject single payload, return full request/response
4. inject_batch - Send multiple payloads, return baseline diff analysis
5. analyze_headers - Extract security headers, cookies, CORS, server info
6. discover_attack_surface - Return all known endpoints, parameters, coverage
7. record_finding - Record confirmed vulnerability to world model + cards
8. get_test_progress - Show what's tested, findings count, coverage %
"""

import json
import html
import re
from typing import List, Dict, Any, Optional
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

from mcp.types import Tool, TextContent

from lib.payload_registry import PayloadRegistry
from lib.test_plan_executor import TestPlanExecutor


# ========== Shared Helpers ==========

from lib.tool_helpers import _get_http_client, _get_db, _json_content, _error_content


def _preprocess_body(body: str, content_type: str = "", payload: str = None) -> str:
    """Strip noise from response body to maximize useful content within truncation budget.

    For HTML: remove <style> blocks, <link> stylesheet tags, <noscript> blocks, collapse whitespace.
    For JSON: minify (strip indentation whitespace).
    Preserves <script> blocks (security-relevant for XSS).
    Preserves HTML comments (may contain sensitive data).

    Args:
        body: Response body string
        content_type: Content-Type header value
        payload: Optional payload string (preserve SVG blocks containing it)

    Returns:
        Preprocessed body with noise removed
    """
    if not body:
        return body

    ct = content_type.lower()

    if "html" in ct or body.lstrip().startswith("<!") or body.lstrip().startswith("<html"):
        # Strip <style>...</style> blocks (CSS is never security-relevant)
        body = re.sub(r'<style[^>]*>.*?</style>', '', body, flags=re.DOTALL | re.IGNORECASE)
        # Strip <link rel="stylesheet" ...> tags
        body = re.sub(r'<link[^>]*rel=["\']stylesheet["\'][^>]*>', '', body, flags=re.IGNORECASE)
        # Strip <noscript>...</noscript> blocks
        body = re.sub(r'<noscript[^>]*>.*?</noscript>', '', body, flags=re.DOTALL | re.IGNORECASE)
        # Strip <svg>...</svg> blocks UNLESS they contain the payload
        if payload and payload in body:
            # Preserve SVG blocks containing the payload (XSS vector)
            pass
        else:
            body = re.sub(r'<svg[^>]*>.*?</svg>', '', body, flags=re.DOTALL | re.IGNORECASE)
        # Collapse runs of whitespace (spaces, tabs) to single space
        body = re.sub(r'[ \t]+', ' ', body)
        # Collapse multiple blank lines to single newline
        body = re.sub(r'\n\s*\n', '\n', body)

    elif "json" in ct:
        # Minify JSON: strip indentation whitespace
        try:
            import json as _json
            parsed = _json.loads(body)
            body = _json.dumps(parsed, separators=(',', ':'))
        except (ValueError, TypeError):
            pass  # Not valid JSON, return as-is

    else:
        # Plain text: collapse whitespace
        body = re.sub(r'[ \t]+', ' ', body)
        body = re.sub(r'\n\s*\n', '\n', body)

    return body.strip()


def _truncate_body(body: str, max_len: int) -> Dict[str, Any]:
    """Truncate body and return metadata.

    Returns:
        {"body": str, "truncated": bool, "full_length": int}
    """
    full_length = len(body)
    if full_length > max_len:
        return {
            "body": body[:max_len],
            "truncated": True,
            "full_length": full_length,
        }
    return {
        "body": body,
        "truncated": False,
        "full_length": full_length,
    }


def _compute_baseline_diff(baseline: Dict, response: Dict) -> Dict[str, Any]:
    """Compute simple factual diff between baseline and response.

    Returns:
        {
            "status_changed": bool,
            "body_length_diff_pct": float,
            "timing_ratio": float,
        }
    """
    status_changed = baseline.get("status") != response.get("status")

    baseline_len = len(baseline.get("body", ""))
    response_len = len(response.get("body", ""))

    if baseline_len > 0:
        body_diff_pct = abs(response_len - baseline_len) / baseline_len * 100
    else:
        body_diff_pct = 0.0 if response_len == 0 else 100.0

    baseline_time = baseline.get("timing_ms", 1)
    response_time = response.get("timing_ms", 1)
    timing_ratio = response_time / max(baseline_time, 1)

    return {
        "status_changed": status_changed,
        "body_length_diff_pct": round(body_diff_pct, 2),
        "timing_ratio": round(timing_ratio, 2),
    }


def _parse_security_headers(headers: Dict[str, str]) -> Dict[str, Any]:
    """Parse security-relevant headers.

    Returns:
        {
            "security_headers_present": {...},
            "security_headers_missing": [...],
            "server_info": {...},
            "cors_headers": {...},
            "cookies": [...],
            "cache_headers": {...},
        }
    """
    # Normalize header keys to lowercase
    headers_lower = {k.lower(): v for k, v in headers.items()}

    # Security headers to check
    security_headers_check = [
        "strict-transport-security",
        "content-security-policy",
        "x-content-type-options",
        "x-frame-options",
        "x-xss-protection",
        "referrer-policy",
        "permissions-policy",
        "cross-origin-opener-policy",
        "cross-origin-resource-policy",
        "cross-origin-embedder-policy",
    ]

    present = {}
    missing = []

    for hdr in security_headers_check:
        if hdr in headers_lower:
            present[hdr] = headers_lower[hdr]
        else:
            missing.append(hdr)

    # Server disclosure headers
    server_info = {}
    for hdr in ["server", "x-powered-by", "x-aspnet-version", "x-generator"]:
        if hdr in headers_lower:
            server_info[hdr] = headers_lower[hdr]

    # CORS headers
    cors_headers = {}
    for hdr in headers_lower:
        if hdr.startswith("access-control-"):
            cors_headers[hdr] = headers_lower[hdr]

    # Parse cookies
    cookies = []
    if "set-cookie" in headers_lower:
        # Note: headers_lower may have single value or list
        cookie_values = headers_lower["set-cookie"]
        if not isinstance(cookie_values, list):
            cookie_values = [cookie_values]

        for cookie_str in cookie_values:
            parts = cookie_str.split(";")
            if not parts:
                continue

            name_value = parts[0].split("=", 1)
            if len(name_value) != 2:
                continue

            cookie = {
                "name": name_value[0].strip(),
                "httpOnly": "HttpOnly" in cookie_str,
                "secure": "Secure" in cookie_str,
                "sameSite": None,
            }

            # Extract SameSite
            for part in parts:
                part = part.strip()
                if part.lower().startswith("samesite="):
                    cookie["sameSite"] = part.split("=", 1)[1]

            cookies.append(cookie)

    # Cache headers
    cache_headers = {}
    for hdr in ["cache-control", "pragma", "expires", "etag"]:
        if hdr in headers_lower:
            cache_headers[hdr] = headers_lower[hdr]

    return {
        "security_headers_present": present,
        "security_headers_missing": missing,
        "server_info": server_info,
        "cors_headers": cors_headers,
        "cookies": cookies,
        "cache_headers": cache_headers,
    }


# ========== Tool Definitions ==========

def get_pentest_tools() -> List[Tool]:
    """Get LLM-in-the-loop pentest tool definitions."""
    return [
        Tool(
            name="recon_endpoint",
            description=(
                "Send a baseline HTTP request and return the FULL request/response pair to the LLM. "
                "Unlike endpoint_probe (which truncates to 500 chars), this returns the complete response "
                "body (up to max_response_body chars) for LLM analysis. Use this to examine application "
                "behavior, error messages, reflected input, and other signals needed for vulnerability testing."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "Target URL"},
                    "method": {"type": "string", "default": "GET", "enum": ["GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"]},
                    "headers": {"type": "object", "description": "Optional HTTP headers"},
                    "body": {"type": "string", "description": "Optional request body"},
                    "identity_id": {"type": "string", "description": "Optional identity ID for authenticated requests"},
                    "max_response_body": {"type": "integer", "default": 8192, "description": "Max response body chars to return"},
                    "include_analysis": {"type": "boolean", "default": False, "description": "Include exchange analysis (risk signals, recommended tests). Default: false — set true for quick triage."},
                },
                "required": ["url"],
            },
        ),
        Tool(
            name="get_test_payloads",
            description=(
                "Return actual payload strings from PayloadRegistry for a vulnerability class. "
                "This lets the LLM inspect and select from real payloads (300+ across 46 vuln classes). "
                "Use this to see what payloads are available before testing, or to craft custom variants."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "vuln_class": {"type": "string", "description": "Vulnerability class (e.g., sqli_error, xss_reflected, ssrf)"},
                    "limit": {"type": "integer", "default": 25, "description": "Max payloads to return"},
                    "context": {"type": "object", "description": "Optional context (endpoint, tech, parameter info)"},
                },
                "required": ["vuln_class"],
            },
        ),
        Tool(
            name="inject_payload",
            description=(
                "Inject a single payload into a specific parameter location and return the FULL "
                "request/response. Supports 5 injection locations: query, body (JSON/form), path, "
                "header, cookie. Returns complete response for LLM analysis of reflected input, "
                "error messages, status changes, and other vulnerability signals."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "Target URL"},
                    "method": {"type": "string", "default": "GET"},
                    "parameter": {"type": "string", "description": "Parameter name to inject into"},
                    "location": {"type": "string", "enum": ["query", "body", "path", "header", "cookie"], "description": "Where to inject payload"},
                    "payload": {"type": "string", "description": "Payload string to inject"},
                    "headers": {"type": "object", "description": "Optional base headers"},
                    "body": {"type": "string", "description": "Optional base body (for POST/PUT)"},
                    "identity_id": {"type": "string", "description": "Optional identity for auth"},
                    "max_response_body": {"type": "integer", "default": 8192},
                    "include_analysis": {"type": "boolean", "default": False, "description": "Include exchange analysis (risk signals, recommended tests). Default: false — set true for quick triage."},
                },
                "required": ["url", "parameter", "location", "payload"],
            },
        ),
        Tool(
            name="inject_batch",
            description=(
                "Send multiple payloads to the same injection point with baseline comparison. "
                "Returns full responses for each payload plus factual diff metrics (status changes, "
                "body length variance, timing anomalies). Use this to sweep hardcoded payloads and "
                "identify outliers that warrant deeper investigation."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string"},
                    "method": {"type": "string", "default": "GET"},
                    "parameter": {"type": "string"},
                    "location": {"type": "string", "enum": ["query", "body", "path", "header", "cookie"]},
                    "payloads": {"type": "array", "items": {"type": "string"}, "description": "Array of payload strings"},
                    "headers": {"type": "object"},
                    "body": {"type": "string"},
                    "include_baseline": {"type": "boolean", "default": True, "description": "Send clean request first for comparison"},
                    "compact": {"type": "boolean", "default": True, "description": "Return full response body only for outliers (status change, body diff >10%, timing >2x, payload reflected). Non-outliers get metrics only. Set false for full bodies on every result."},
                    "max_response_body": {"type": "integer", "default": 8192},
                    "max_batch_size": {"type": "integer", "default": 50, "description": "Max payloads to send"},
                    "include_analysis": {"type": "boolean", "default": False, "description": "Include exchange analysis (risk signals, recommended tests). Default: false — set true for quick triage."},
                },
                "required": ["url", "parameter", "location", "payloads"],
            },
        ),
        Tool(
            name="analyze_headers",
            description=(
                "Extract and present security-relevant headers from a response. Returns factual data "
                "about security headers (present/missing), cookies (HttpOnly/Secure/SameSite flags), "
                "CORS configuration, server disclosure, and cache headers. The LLM decides what's a finding."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string"},
                    "method": {"type": "string", "default": "GET"},
                    "headers": {"type": "object"},
                    "identity_id": {"type": "string"},
                },
                "required": ["url"],
            },
        ),
        Tool(
            name="discover_attack_surface",
            description=(
                "Return all known endpoints, parameters, and coverage status from the world model. "
                "Shows what has been discovered via recon/crawling/OpenAPI parsing, what's been tested, "
                "and what has findings. Use this at the start of testing to understand the attack surface."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "base_url": {"type": "string", "description": "Optional URL filter (e.g., https://api.example.com)"},
                    "include_parameters": {"type": "boolean", "default": True},
                    "include_coverage": {"type": "boolean", "default": True},
                },
                "required": [],
            },
        ),
        Tool(
            name="record_finding",
            description=(
                "Record a confirmed vulnerability to the world model and card system. Bridges findings "
                "and cards with automatic deduplication. Updates coverage matrix to mark endpoint/vuln_class "
                "as vulnerable. Call this when you've confirmed a vulnerability through testing."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "title": {"type": "string", "description": "Finding title (e.g., 'SQL Injection in /api/users')"},
                    "severity": {"type": "string", "enum": ["info", "low", "medium", "high", "critical"]},
                    "url": {"type": "string", "description": "Vulnerable endpoint URL"},
                    "vuln_class": {"type": "string", "description": "Vuln class (e.g., sqli_error, xss_reflected)"},
                    "parameter": {"type": "string", "description": "Vulnerable parameter name"},
                    "description": {"type": "string", "description": "Detailed vulnerability description"},
                    "evidence": {
                        "type": "object",
                        "description": "Evidence with request/response/payload/description",
                        "properties": {
                            "request": {"type": "object"},
                            "response": {"type": "object"},
                            "payload": {"type": "string"},
                            "description": {"type": "string"},
                        },
                    },
                    "remediation": {"type": "string", "description": "Remediation guidance (maps to recommendation field)"},
                    "cvss_vector": {"type": "string", "description": "CVSS:3.1 vector string (e.g., CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"},
                    "affected_endpoints": {"type": "string", "description": "Comma-separated or JSON array of affected URLs (defaults to url if not provided)"},
                    "attack_scenario": {"type": "string", "description": "How an attacker exploits this vulnerability"},
                    "confidence": {"type": "number", "default": 0.8, "minimum": 0.0, "maximum": 1.0},
                    "proof_level": {"type": "string", "enum": ["theoretical", "partial", "bypass", "takeover"], "description": "Evidence strength. Critical severity requires bypass or takeover."},
                    "verdict": {"type": "string", "enum": ["exploited", "blocked_by_security", "out_of_scope", "false_positive"], "description": "Final classification after validation."},
                    "poc_code": {"type": "string", "description": "Optional proof-of-concept exploit code for this finding"},
                },
                "required": ["title", "severity", "url", "cvss_vector", "description", "attack_scenario", "evidence", "remediation"],
            },
        ),
        Tool(
            name="generate_poc",
            description=(
                "Generate proof-of-concept exploit code for a recorded finding using the vulnerability "
                "type, URL, and parameters. Supports 20+ vulnerability types including SQLi, XSS, IDOR, "
                "SSRF, LFI, CMDi, JWT, CSRF, SSTI, and more. Returns Python script + curl command."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "ID of the finding in wm_findings",
                    },
                },
                "required": ["finding_id"],
            },
        ),
        Tool(
            name="get_test_progress",
            description=(
                "Show what has been tested, findings count, and coverage completeness. Returns "
                "endpoint counts, coverage %, findings by severity, budget usage, vuln classes "
                "tested/untested, and per-endpoint testing status. Use this to verify coverage."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "base_url": {"type": "string", "description": "Optional URL filter"},
                },
                "required": [],
            },
        ),
        Tool(
            name="race_condition_test",
            description=(
                "Test for race condition vulnerabilities by sending N concurrent identical requests "
                "and analyzing response variance. Detects TOCTOU, double-spend, and time-of-check "
                "issues by measuring timing differences and response inconsistencies. "

                "**When to use:** Phase 4 when testing state-changing endpoints (transfers, purchases, "
                "coupon redemption, voting, reservations). Use after identifying endpoints that modify "
                "server-side state. "

                "**Budget impact:** MEDIUM - sends concurrent_count requests (default 10). "

                "**Risk level:** CAUTION - sends multiple concurrent state-changing requests. May "
                "create duplicate records or inconsistent state on vulnerable targets."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "Target URL to test"},
                    "method": {"type": "string", "description": "HTTP method (default: POST)"},
                    "headers": {"type": "object", "description": "Request headers"},
                    "body": {"type": "string", "description": "Request body"},
                    "concurrent_count": {"type": "integer", "description": "Number of concurrent requests (default: 10, max: 50)"},
                    "timeout_ms": {"type": "integer", "description": "Per-request timeout in ms (default: 10000)"},
                },
                "required": ["url"],
            },
        ),
        Tool(
            name="test_csrf",
            description=(
                "Test an endpoint for CSRF vulnerabilities. Runs 5 bypass variants: remove token, "
                "empty token, content-type switch, remove Origin/Referer, cross-origin Origin/Referer. "
                "Compares each variant's status code against the baseline to detect bypasses."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string"},
                    "method": {"type": "string", "default": "POST"},
                    "body": {"type": "string", "description": "Request body (JSON or form-encoded)"},
                    "headers": {"type": "object"},
                    "csrf_token_name": {"type": "string", "description": "CSRF token parameter name (e.g., 'csrf_token', '_token')"},
                    "csrf_token_location": {
                        "type": "string",
                        "enum": ["body", "header", "cookie"],
                        "default": "body"
                    }
                },
                "required": ["url", "method", "body"]
            }
        ),
        Tool(
            name="think",
            description=(
                "Record reasoning and scratchpad notes during a pentest. No side effects - use for "
                "structured thinking before taking action."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "reasoning": {
                        "type": "string",
                        "description": "Your reasoning, analysis, or planning notes"
                    }
                },
                "required": ["reasoning"]
            }
        ),
        # ---- get_exploitation_decision ---------------------------------
        Tool(
            name="get_exploitation_decision",
            description=(
                "Get the exploitation decision for a specific finding or all findings. "
                "Returns whether to attempt exploitation, retry, or skip, based on previous "
                "attempt history. Decision logic: skip after 3 failed attempts, skip if "
                "blocked by WAF/security, retry if partial success. "

                "**When to use:** Phase 5 before attempting exploitation of a finding. "
                "Check the decision queue to see if exploitation should be attempted. "

                "**Budget impact:** ZERO - local database read. "

                "**Risk level:** SAFE - read-only query."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID to check (omit for all findings)",
                    },
                },
            },
        ),
        # ---- get_relevant_skills ------------------------------------------
        Tool(
            name="get_relevant_skills",
            description=(
                "Get recommended vulnerability methodology skills based on vuln class or tech stack. "
                "Returns skill names and URIs to load via read_resource. Skills provide detailed "
                "attack methodologies, reconnaissance steps, payload strategies, and validation "
                "techniques for specific vulnerability types and frameworks."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "vuln_class": {
                        "type": "string",
                        "description": "Vulnerability class keyword (e.g., 'sql', 'xss', 'idor', 'jwt', 'race')"
                    },
                    "tech_stack": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Technology stack items (e.g., ['fastapi', 'graphql', 'supabase'])"
                    }
                }
            },
        ),
        # ---- update_exploitation_decision ------------------------------
        Tool(
            name="update_exploitation_decision",
            description=(
                "Record the result of an exploitation attempt for a finding. Updates the "
                "decision queue with the result and recalculates whether to retry. "
                "Results: 'success', 'partial', 'blocked_by_security', 'failed', 'not_attempted'. "

                "**When to use:** Phase 5 after each exploitation attempt. Record the outcome "
                "so the decision queue tracks attempts and makes retry/skip decisions. "

                "**Budget impact:** ZERO - local database write. "

                "**Risk level:** SAFE - updates local state only."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID to update",
                    },
                    "result": {
                        "type": "string",
                        "enum": ["success", "partial", "blocked_by_security", "failed", "not_attempted"],
                        "description": "Exploitation result",
                    },
                    "vuln_type": {
                        "type": "string",
                        "description": "Vulnerability type (e.g. 'sqli', 'xss')",
                    },
                    "notes": {
                        "type": "string",
                        "description": "Notes about the attempt",
                    },
                },
                "required": ["finding_id", "result"],
            },
        ),
    ]


# ========== Tool Handlers ==========

async def handle_pentest_tool(name: str, arguments: dict, mcp_service) -> List[TextContent]:
    """Handle all pentest tool calls."""

    try:
        if name == "recon_endpoint":
            return await _handle_recon_endpoint(arguments, mcp_service)
        elif name == "get_test_payloads":
            return await _handle_get_test_payloads(arguments, mcp_service)
        elif name == "inject_payload":
            return await _handle_inject_payload(arguments, mcp_service)
        elif name == "inject_batch":
            return await _handle_inject_batch(arguments, mcp_service)
        elif name == "analyze_headers":
            return await _handle_analyze_headers(arguments, mcp_service)
        elif name == "discover_attack_surface":
            return await _handle_discover_attack_surface(arguments, mcp_service)
        elif name == "record_finding":
            return await _handle_record_finding(arguments, mcp_service)
        elif name == "generate_poc":
            return await _handle_generate_poc(arguments, mcp_service)
        elif name == "get_test_progress":
            return await _handle_get_test_progress(arguments, mcp_service)
        elif name == "test_csrf":
            return await _handle_test_csrf(arguments, mcp_service)
        elif name == "think":
            return await _handle_think(arguments, mcp_service)
        elif name == "get_relevant_skills":
            return await _handle_get_relevant_skills(arguments)
        elif name == "race_condition_test":
            return await _handle_race_condition_test(arguments, mcp_service)
        elif name == "get_exploitation_decision":
            return await _handle_get_exploitation_decision(arguments, mcp_service)
        elif name == "update_exploitation_decision":
            return await _handle_update_exploitation_decision(arguments, mcp_service)
        else:
            return _error_content(f"Unknown pentest tool: {name}")
    except Exception as e:
        import traceback
        return _error_content(f"Error in {name}: {str(e)}\n{traceback.format_exc()}")


async def _handle_recon_endpoint(args: dict, mcp_service) -> List[TextContent]:
    """Send baseline HTTP request and return full request/response."""
    url = args["url"]
    method = args.get("method", "GET")
    headers = args.get("headers", {})
    body = args.get("body")
    max_response_body = args.get("max_response_body", 8192)

    identity_id = args.get("identity_id")
    if identity_id:
        try:
            db = await _get_db(mcp_service)
            rows = await db.query("identities", {"id": identity_id})
            if rows:
                meta = rows[0].get("metadata") or {}
                if isinstance(meta, str):
                    meta = json.loads(meta)
                token = meta.get("token") or meta.get("access_token")
                if token:
                    headers["Authorization"] = f"Bearer {token}"
        except Exception:
            pass

    client = _get_http_client(mcp_service)

    # Send request via HttpClient (handles rate limiting, scope validation, budget)
    result = await client.send(
        request={
            "method": method,
            "url": url,
            "headers": headers,
            "body": body,
        }
    )

    # Detect content type
    content_type = result.get("headers", {}).get("content-type", "")

    # Preprocess body to strip noise before truncation
    raw_body = result.get("body", "")
    clean_body = _preprocess_body(raw_body, content_type)
    body_data = _truncate_body(clean_body, max_response_body)
    is_json = "json" in content_type.lower()
    is_html = "html" in content_type.lower()

    response_data = {
        "request": {
            "method": method,
            "url": url,
            "headers": headers,
            "body": body,
        },
        "response": {
            "status": result.get("status"),
            "status_text": result.get("statusText"),
            "headers": result.get("headers", {}),
            "body": body_data["body"],
            "timing_ms": result.get("timing", {}).get("duration_ms", 0),
        },
        "metadata": {
            "content_type": content_type,
            "body_length": body_data["full_length"],
            "body_truncated": body_data["truncated"],
            "is_json": is_json,
            "is_html": is_html,
        },
    }

    # Run exchange analysis only if requested (opt-in for LLM reasoning)
    if args.get("include_analysis", False):
        from lib.exchange_analyzer import get_exchange_analyzer
        analyzer = get_exchange_analyzer()
        request_dict = {"method": method, "url": url, "headers": headers, "body": body or ""}
        response_dict = {
            "status": result.get("status", 0),
            "headers": result.get("headers", {}),
            "body": body_data["body"]
        }
        analysis = analyzer.analyze(request_dict, response_dict)

        response_data["exchange_analysis"] = {
            "risk_signals": analysis.risk_signals,
            "recommended_tests": analysis.recommended_tests,
            "detected_technologies": analysis.detected_technologies,
            "advisory": f"{len(analysis.risk_signals)} risk signal(s) detected. Review and use record_finding to persist confirmed vulnerabilities." if analysis.risk_signals else None,
        }

    return _json_content(response_data)


async def _handle_get_test_payloads(args: dict, mcp_service) -> List[TextContent]:
    """Return payload strings from PayloadRegistry."""
    vuln_class = args["vuln_class"]
    limit = args.get("limit", 25)
    context = args.get("context")

    registry = PayloadRegistry()

    # Get payloads
    payloads = registry.get_payloads(vuln_class, context)

    # Convert to strings
    string_payloads = registry.to_string_payloads(payloads)

    # Limit results
    string_payloads = string_payloads[:limit]

    # Build payload list with metadata
    payload_list = []
    for idx, payload_str in enumerate(string_payloads):
        payload_obj = payloads[idx] if idx < len(payloads) else None

        entry = {
            "index": idx,
            "value": payload_str,
        }

        # Extract technique/platform metadata if available
        if payload_obj and hasattr(payload_obj, "technique"):
            entry["technique"] = payload_obj.technique
        if payload_obj and hasattr(payload_obj, "platform"):
            entry["platform"] = payload_obj.platform

        payload_list.append(entry)

    result = {
        "vuln_class": vuln_class,
        "total_available": len(payloads),
        "payloads": payload_list,
        "available_classes": sorted(list(registry.PAYLOAD_GETTERS.keys())),
    }

    return _json_content(result)


async def _handle_inject_payload(args: dict, mcp_service) -> List[TextContent]:
    """Inject single payload and return full request/response."""
    url = args["url"]
    method = args.get("method", "GET")
    parameter = args["parameter"]
    location = args["location"]
    payload = args["payload"]
    headers = args.get("headers", {})
    body = args.get("body", "")
    max_response_body = args.get("max_response_body", 8192)

    identity_id = args.get("identity_id")
    if identity_id:
        try:
            db = await _get_db(mcp_service)
            rows = await db.query("identities", {"id": identity_id})
            if rows:
                meta = rows[0].get("metadata") or {}
                if isinstance(meta, str):
                    meta = json.loads(meta)
                token = meta.get("token") or meta.get("access_token")
                if token:
                    headers["Authorization"] = f"Bearer {token}"
        except Exception:
            pass

    # Inject payload using TestPlanExecutor's static method
    injected_url, injected_body, injected_headers = TestPlanExecutor._inject_payload(
        url=url,
        method=method,
        headers=headers,
        body=body,
        parameter=parameter,
        location=location,
        payload=payload,
    )

    # Send injected request
    client = _get_http_client(mcp_service)
    result = await client.send(
        request={
            "method": method,
            "url": injected_url,
            "headers": injected_headers,
            "body": injected_body,
        }
    )

    # Check if payload reflected in FULL original response body (before preprocessing)
    full_body = result.get("body", "")
    payload_reflected = payload in full_body

    # Detect content type
    content_type = result.get("headers", {}).get("content-type", "")

    # Preprocess body to strip noise before truncation
    clean_body = _preprocess_body(full_body, content_type, payload)
    body_data = _truncate_body(clean_body, max_response_body)

    # Check if payload is visible in truncated body (may differ from full_body reflection)
    reflected_in_truncated = payload in body_data["body"] if (payload_reflected and body_data["truncated"]) else None

    response_data = {
        "request": {
            "method": method,
            "url": injected_url,
            "headers": injected_headers,
            "body": injected_body,
        },
        "response": {
            "status": result.get("status"),
            "status_text": result.get("statusText"),
            "headers": result.get("headers", {}),
            "body": body_data["body"],
            "timing_ms": result.get("timing", {}).get("duration_ms", 0),
        },
        "injection": {
            "parameter": parameter,
            "location": location,
            "payload": payload,
            "payload_reflected_in_body": payload_reflected,
        },
        "metadata": {
            "body_length": body_data["full_length"],
            "body_truncated": body_data["truncated"],
            "reflected_in_truncated_body": reflected_in_truncated,
        },
    }

    # Run exchange analysis only if requested (opt-in for LLM reasoning)
    if args.get("include_analysis", False):
        from lib.exchange_analyzer import get_exchange_analyzer
        analyzer = get_exchange_analyzer()
        request_dict = {"method": method, "url": injected_url, "headers": injected_headers, "body": injected_body or ""}
        response_dict = {
            "status": result.get("status", 0),
            "headers": result.get("headers", {}),
            "body": body_data["body"]
        }
        analysis = analyzer.analyze(request_dict, response_dict)

        response_data["exchange_analysis"] = {
            "risk_signals": analysis.risk_signals,
            "recommended_tests": analysis.recommended_tests,
            "detected_technologies": analysis.detected_technologies,
            "advisory": f"{len(analysis.risk_signals)} risk signal(s) detected. Review and use record_finding to persist confirmed vulnerabilities." if analysis.risk_signals else None,
        }

    return _json_content(response_data)


async def _handle_inject_batch(args: dict, mcp_service) -> List[TextContent]:
    """Send multiple payloads with baseline comparison."""
    url = args["url"]
    method = args.get("method", "GET")
    parameter = args["parameter"]
    location = args["location"]
    payloads = args["payloads"]
    headers = args.get("headers", {})
    body = args.get("body", "")
    include_baseline = args.get("include_baseline", True)
    compact = args.get("compact", True)
    max_response_body = args.get("max_response_body", 8192)
    max_batch_size = args.get("max_batch_size", 50)

    # Cap payloads
    payloads = payloads[:max_batch_size]

    client = _get_http_client(mcp_service)

    baseline_data = None

    # Send baseline if requested
    baseline_exchange_analysis = None
    if include_baseline:
        baseline_result = await client.send(
            request={
                "method": method,
                "url": url,
                "headers": headers,
                "body": body,
            }
        )
        baseline_content_type = baseline_result.get("headers", {}).get("content-type", "")
        baseline_raw_body = baseline_result.get("body", "")
        baseline_clean_body = _preprocess_body(baseline_raw_body, baseline_content_type)
        baseline_body = _truncate_body(baseline_clean_body, max_response_body)
        baseline_data = {
            "status": baseline_result.get("status"),
            "body_length": baseline_body["full_length"],
            "timing_ms": baseline_result.get("timing", {}).get("duration_ms", 0),
            "body": baseline_body["body"],
            "body_truncated": baseline_body["truncated"],
        }

        # Run exchange analysis on baseline request only if requested (opt-in for LLM reasoning)
        if args.get("include_analysis", False):
            from lib.exchange_analyzer import get_exchange_analyzer
            analyzer = get_exchange_analyzer()
            request_dict = {"method": method, "url": url, "headers": headers, "body": body or ""}
            response_dict = {
                "status": baseline_result.get("status", 0),
                "headers": baseline_result.get("headers", {}),
                "body": baseline_body["body"]
            }
            analysis = analyzer.analyze(request_dict, response_dict)

            baseline_exchange_analysis = {
                "risk_signals": analysis.risk_signals,
                "recommended_tests": analysis.recommended_tests,
                "detected_technologies": analysis.detected_technologies,
                "advisory": f"{len(analysis.risk_signals)} risk signal(s) detected. Review and use record_finding to persist confirmed vulnerabilities." if analysis.risk_signals else None,
            }

    # Send payloads
    results = []
    unique_statuses = set()
    payloads_reflected = 0
    status_changes = 0
    timing_anomalies = 0

    for idx, payload in enumerate(payloads):
        # Inject payload
        injected_url, injected_body, injected_headers = TestPlanExecutor._inject_payload(
            url=url,
            method=method,
            headers=headers,
            body=body,
            parameter=parameter,
            location=location,
            payload=payload,
        )

        # Send request
        result = await client.send(
            request={
                "method": method,
                "url": injected_url,
                "headers": injected_headers,
                "body": injected_body,
            }
        )

        # Detect content type
        content_type = result.get("headers", {}).get("content-type", "")

        # Check payload reflection in full original body (before preprocessing)
        full_body = result.get("body", "")
        payload_reflected = payload in full_body
        if payload_reflected:
            payloads_reflected += 1

        # Preprocess body to strip noise before truncation
        clean_body = _preprocess_body(full_body, content_type, payload)
        body_data = _truncate_body(clean_body, max_response_body)

        # Build result entry
        status = result.get("status")
        unique_statuses.add(status)

        # Compute diff vs baseline
        diff = {}
        is_outlier = False
        if baseline_data:
            response_dict = {
                "status": status,
                "body": clean_body,  # Use clean body for length comparison
                "timing_ms": result.get("timing", {}).get("duration_ms", 0),
            }
            diff = _compute_baseline_diff(baseline_data, response_dict)

            if diff["status_changed"]:
                status_changes += 1
            if diff["timing_ratio"] > 2.0:
                timing_anomalies += 1

            # Determine if this result is an outlier (worthy of full body)
            is_outlier = (
                diff.get("status_changed", False)
                or diff.get("body_length_diff_pct", 0) > 10.0
                or diff.get("timing_ratio", 1.0) > 2.0
                or payload_reflected
            )

        # In compact mode, omit body/headers for non-outlier results
        if compact and baseline_data and not is_outlier:
            # Compact entry with metrics only
            entry = {
                "index": idx,
                "payload": payload,
                "status": status,
                "payload_reflected": payload_reflected,
                **diff,  # status_changed, body_length_diff_pct, timing_ratio
            }
        else:
            # Full entry with body and headers
            entry = {
                "index": idx,
                "payload": payload,
                "response": {
                    "status": status,
                    "headers": result.get("headers", {}),
                    "body": body_data["body"],
                    "timing_ms": result.get("timing", {}).get("duration_ms", 0),
                },
                "payload_reflected": payload_reflected,
                "body_truncated": body_data["truncated"],
                "body_length": body_data["full_length"],
            }
            if diff:
                entry.update(diff)

        results.append(entry)

    response_data = {
        "baseline": baseline_data,
        "results": results,
        "summary": {
            "total_sent": len(results),
            "unique_status_codes": sorted(list(unique_statuses)),
            "payloads_reflected": payloads_reflected,
            "status_changes": status_changes,
            "timing_anomalies": timing_anomalies,
        },
    }

    # Include baseline exchange analysis if it was generated (controlled by include_analysis param)
    if baseline_exchange_analysis:
        response_data["baseline_exchange_analysis"] = baseline_exchange_analysis

    return _json_content(response_data)


async def _handle_analyze_headers(args: dict, mcp_service) -> List[TextContent]:
    """Extract security-relevant headers."""
    url = args["url"]
    method = args.get("method", "GET")
    headers = args.get("headers", {})

    identity_id = args.get("identity_id")
    if identity_id:
        try:
            db = await _get_db(mcp_service)
            rows = await db.query("identities", {"id": identity_id})
            if rows:
                meta = rows[0].get("metadata") or {}
                if isinstance(meta, str):
                    meta = json.loads(meta)
                token = meta.get("token") or meta.get("access_token")
                if token:
                    headers["Authorization"] = f"Bearer {token}"
        except Exception:
            pass

    client = _get_http_client(mcp_service)

    # Send request
    result = await client.send(
        request={
            "method": method,
            "url": url,
            "headers": headers,
        }
    )

    # Parse headers with custom parser
    response_headers = result.get("headers", {})
    analysis = _parse_security_headers(response_headers)

    # Also run exchange analysis for comprehensive detection
    from lib.exchange_analyzer import get_exchange_analyzer
    analyzer = get_exchange_analyzer()
    request_dict = {"method": method, "url": url, "headers": headers, "body": ""}

    # Use _truncate_body helper instead of raw [:4096] slice
    content_type = response_headers.get("content-type", "")
    raw_body = result.get("body", "")
    clean_body = _preprocess_body(raw_body, content_type)
    body_data = _truncate_body(clean_body, 4096)

    response_dict = {
        "status": result.get("status", 0),
        "headers": response_headers,
        "body": body_data["body"]
    }
    ea_result = analyzer.analyze(request_dict, response_dict)

    analysis["exchange_analysis"] = {
        "risk_signals": ea_result.risk_signals,
        "recommended_tests": ea_result.recommended_tests,
        "detected_technologies": ea_result.detected_technologies,
        "advisory": f"{len(ea_result.risk_signals)} risk signal(s) detected. Review and use record_finding to persist confirmed vulnerabilities." if ea_result.risk_signals else None,
    }

    return _json_content(analysis)


async def _handle_discover_attack_surface(args: dict, mcp_service) -> List[TextContent]:
    """Return all known endpoints, parameters, coverage from world model."""
    base_url = args.get("base_url")
    include_parameters = args.get("include_parameters", True)
    include_coverage = args.get("include_coverage", True)

    db = await _get_db(mcp_service)

    # Query endpoints
    endpoints_raw = await db.query("endpoints")

    # Filter by base_url if provided
    if base_url:
        parsed = urlparse(base_url)
        base_netloc = parsed.netloc
        endpoints_raw = [
            ep for ep in endpoints_raw
            if urlparse(ep.get("url", "")).netloc == base_netloc
        ]

    # Build endpoint list
    endpoints = []
    for ep in endpoints_raw:
        endpoint_data = {
            "url": ep.get("url"),
            "method": ep.get("method"),
            "id": ep.get("id"),
        }

        if include_parameters:
            # Get parameters from observations
            observations = await db.query("observations")
            params = [
                obs.get("context", {}).get("parameter_name")
                for obs in observations
                if obs.get("target_id") == ep.get("id")
                and obs.get("context", {}).get("parameter_name")
            ]
            endpoint_data["parameters"] = params

        if include_coverage:
            # Get coverage status
            coverage_rows = await db.query("coverage_matrix")
            endpoint_coverage = [
                c for c in coverage_rows
                if c.get("endpoint_id") == ep.get("id")
            ]

            if endpoint_coverage:
                tested = any(c.get("status") not in ["pending"] for c in endpoint_coverage)
                vulnerable = any(c.get("status") == "vulnerable" for c in endpoint_coverage)
                if vulnerable:
                    endpoint_data["coverage_status"] = "vulnerable"
                elif tested:
                    endpoint_data["coverage_status"] = "tested"
                else:
                    endpoint_data["coverage_status"] = "pending"
            else:
                endpoint_data["coverage_status"] = "untested"

        endpoints.append(endpoint_data)

    # Get findings count
    findings = await db.query("findings")
    findings_count = len(findings)

    # Get assets
    assets_raw = await db.query("assets")
    assets = [a.get("name") for a in assets_raw]

    # Get OpenAPI specs
    # Note: OpenAPI data stored in observations with type="openapi_spec"
    observations = await db.query("observations")
    openapi_specs = [
        obs.get("content", {}).get("spec_name", "unknown")
        for obs in observations
        if obs.get("type") == "openapi_spec"
    ]

    # Count parameters
    total_params = sum(len(ep.get("parameters", [])) for ep in endpoints)

    result = {
        "endpoints": endpoints,
        "total_endpoints": len(endpoints),
        "total_parameters": total_params,
        "findings_count": findings_count,
        "assets": assets,
        "openapi_specs": openapi_specs,
    }

    return _json_content(result)


async def _handle_record_finding(args: dict, mcp_service) -> List[TextContent]:
    """Record confirmed vulnerability to world model + cards."""
    title = args["title"]
    severity = args["severity"]
    url = args["url"]
    vuln_class = args.get("vuln_class")
    parameter = args.get("parameter")
    evidence = args.get("evidence", {})

    # Handle evidence as string (MCP client sometimes stringifies nested objects)
    if isinstance(evidence, str):
        try:
            import json
            evidence = json.loads(evidence)
        except json.JSONDecodeError:
            # If parsing fails, wrap the string in a description field
            evidence = {"description": evidence}

    remediation = args.get("remediation")
    confidence = args.get("confidence", 0.8)
    explicit_description = args.get("description")

    # Handle confidence as string (convert to float)
    if isinstance(confidence, str):
        try:
            confidence = float(confidence)
        except (ValueError, TypeError):
            confidence = 0.8

    cvss_vector = args.get("cvss_vector")
    affected_endpoints = args.get("affected_endpoints")
    attack_scenario = args.get("attack_scenario")

    # Auto-compute cvss_score from cvss_vector if provided
    cvss_score = None
    if cvss_vector:
        try:
            from lib.risk_engine import CVSSv31
            cvss_score = CVSSv31(cvss_vector).base_score()
        except Exception:
            pass  # Invalid vector, skip score

    # Default affected_endpoints to url if not provided
    if not affected_endpoints:
        affected_endpoints = url

    # Build card description
    description_parts = []

    if vuln_class:
        description_parts.append(f"**Vulnerability Class:** {vuln_class}")

    if parameter:
        description_parts.append(f"**Vulnerable Parameter:** {parameter}")

    if evidence.get("payload"):
        description_parts.append(f"**Payload:** `{evidence['payload']}`")

    if evidence.get("description"):
        description_parts.append(f"\n{evidence['description']}")

    if evidence.get("request"):
        req = evidence["request"]
        description_parts.append(f"\n**Request:**\n```\n{req.get('method', 'GET')} {req.get('url', url)}\n```")

    if evidence.get("response"):
        resp = evidence["response"]
        status = resp.get("status", "")
        body_preview = (resp.get("body", "") or "")[:500]
        description_parts.append(f"\n**Response:** {status}\n```\n{body_preview}\n```")

    if remediation:
        description_parts.append(f"\n**Remediation:**\n{remediation}")

    auto_description = "\n\n".join(description_parts)

    # Use explicit description if provided, otherwise fall back to auto-generated
    description = explicit_description if explicit_description else auto_description

    # Store poc_code in evidence if provided
    if args.get("poc_code"):
        evidence["poc_code"] = args["poc_code"]

    # Serialize evidence to JSON
    import json
    evidence_json = json.dumps(evidence) if evidence else None

    # Check for existing SAST card with same vuln_class to avoid duplicates
    if vuln_class:
        from lib.world_model_db import get_world_model_db
        db = await get_world_model_db(mcp_service.current_assessment_id)
        existing_cards = await db.query("findings", filters={}, limit=500)
        sast_match = None
        for card in existing_cards:
            card_meta = card.get("metadata") or {}
            if (card_meta.get("vuln_class") == vuln_class and
                card_meta.get("source", "").startswith("sast")):
                sast_match = card
                break

        if sast_match:
            # Merge: update existing SAST card with DAST evidence
            merge_metadata = {
                **(sast_match.get("metadata") or {}),
                "dast_confirmed": True,
                "dast_url": url,
                "dast_evidence": evidence_json,
                "confidence": max(float(sast_match.get("metadata", {}).get("confidence", 0.5)),
                                  float(confidence)),
            }
            # Update card metadata via backend API
            await mcp_service.update_card_metadata(sast_match["id"], merge_metadata)
            return _json_content({
                "merged": True,
                "card_id": sast_match["id"],
                "message": f"Merged with existing SAST finding (card {sast_match['id']}). SAST+DAST confirmed.",
            })

    # Semantic duplicate detection: check existing findings for near-duplicates
    try:
        db_dedup = await _get_db(mcp_service)
        existing_findings = await db_dedup.query("findings")
        parameter = args.get("parameter", "")
        new_text = f"{title} {vuln_class or ''} {url} {parameter}".strip()

        # Try semantic similarity via Embedder
        from lib.embedder import get_embedder, Embedder
        embedder = get_embedder()
        new_embedding = embedder.embed(new_text) if embedder.available else None

        for existing in existing_findings:
            ex_title = existing.get("title", "")
            ex_url = existing.get("url", "")
            ex_meta = existing.get("metadata") or {}
            if isinstance(ex_meta, str):
                try:
                    ex_meta = json.loads(ex_meta)
                except Exception:
                    ex_meta = {}
            ex_vuln = ex_meta.get("vuln_class", "")
            ex_param = ex_meta.get("parameter", "")
            ex_text = f"{ex_title} {ex_vuln} {ex_url} {ex_param}".strip()

            similarity = 0.0
            if new_embedding:
                ex_embedding = embedder.embed(ex_text)
                if ex_embedding:
                    similarity = Embedder.cosine_similarity(new_embedding, ex_embedding)
            else:
                # Fallback: exact title + URL match
                if ex_title.lower() == title.lower() and ex_url == url:
                    similarity = 1.0

            if similarity > 0.85:
                new_evidence = args.get("evidence", "")
                if new_evidence:
                    merge_text = new_evidence if isinstance(new_evidence, str) else json.dumps(new_evidence)
                    await db_dedup._execute(
                        "UPDATE wm_findings SET evidence_ids = COALESCE(evidence_ids, '[]'::jsonb) || $1::jsonb WHERE id = $2 AND assessment_id = $3",
                        (json.dumps([merge_text]), str(existing.get("id")), db_dedup._assessment_id)
                    )
                return _json_content({
                    "merged": True,
                    "duplicate_of": existing.get("id"),
                    "similarity": round(similarity, 3),
                    "message": f"Evidence merged into existing finding '{ex_title}' (similarity {similarity:.1%}).",
                })
    except Exception as dedup_err:
        import logging
        logging.warning(f"Dedup check failed (proceeding with creation): {dedup_err}")

    # Create card via safe_add_card (pass ALL new fields)
    result = await mcp_service.safe_add_card(
        card_type="finding",
        title=title,
        description=description,  # NOW saved (was silently dropped before)
        severity=severity.upper() if isinstance(severity, str) else severity,
        status="confirmed",  # Explicit confirmed status for pentest findings
        target_service=url,
        cvss_vector=cvss_vector,
        cvss_score=cvss_score,
        affected_endpoints=affected_endpoints,
        attack_scenario=attack_scenario,
        recommendation=remediation,  # Map remediation → recommendation column
        evidence=evidence_json,  # Structured JSON evidence
        confidence=confidence,
    )

    if not result.ok:
        return _error_content(f"Failed to create card: {result.reason}")

    # Update coverage matrix if vuln_class provided
    if vuln_class:
        try:
            db = await _get_db(mcp_service)

            # Find endpoint ID by URL
            endpoints = await db.query("endpoints")
            endpoint = next((ep for ep in endpoints if ep.get("url") == url), None)

            if endpoint:
                endpoint_id = endpoint.get("id")

                # Update coverage matrix
                coverage_rows = await db.query("coverage_matrix")
                cell = next(
                    (c for c in coverage_rows
                     if c.get("endpoint_id") == endpoint_id
                     and c.get("vuln_class") == vuln_class),
                    None
                )

                if cell:
                    # Update existing cell
                    card_id = result.data.get("id") if result.data else None
                    await db.coverage_mark(
                        cell_id=cell.get("id"),
                        status="vulnerable",
                        finding_id=str(card_id) if card_id else None,
                        result_summary=title,
                    )
        except Exception as e:
            # Don't fail the whole operation if coverage update fails
            import logging
            logging.warning(f"Failed to update coverage matrix: {e}")

    card_id = result.data.get("id") if result.data else None

    # Check for missing report-required fields
    missing_fields = []
    if not cvss_vector:
        missing_fields.append("cvss_vector")
    if not explicit_description:
        missing_fields.append("description")
    if not attack_scenario:
        missing_fields.append("attack_scenario")
    if not evidence:
        missing_fields.append("evidence")
    if not remediation:
        missing_fields.append("remediation")

    response = {
        "finding_id": str(card_id) if card_id else None,
        "card_id": str(card_id) if card_id else None,
        "success": True,
    }

    if missing_fields:
        response["missing_report_fields"] = missing_fields
        response["warning"] = f"Finding created but missing report fields: {', '.join(missing_fields)}. Update before report generation."

    return _json_content(response)


async def _handle_get_test_progress(args: dict, mcp_service) -> List[TextContent]:
    """Show testing progress, findings, coverage."""
    base_url = args.get("base_url")

    db = await _get_db(mcp_service)

    # Get endpoints
    endpoints_raw = await db.query("endpoints")

    if base_url:
        parsed = urlparse(base_url)
        base_netloc = parsed.netloc
        endpoints_raw = [
            ep for ep in endpoints_raw
            if urlparse(ep.get("url", "")).netloc == base_netloc
        ]

    total_endpoints = len(endpoints_raw)

    # Get coverage matrix
    coverage_rows = await db.query("coverage_matrix")

    # Get findings
    findings = await db.query("findings")

    # Count findings by severity
    findings_by_severity = {
        "critical": 0,
        "high": 0,
        "medium": 0,
        "low": 0,
        "info": 0,
    }

    for finding in findings:
        sev = finding.get("severity", "info")
        if sev in findings_by_severity:
            findings_by_severity[sev] += 1

    # Calculate tested endpoints
    tested_endpoint_ids = set()
    for row in coverage_rows:
        if row.get("status") not in ["pending"]:
            tested_endpoint_ids.add(row.get("endpoint_id"))

    tested_endpoints = len(tested_endpoint_ids)
    coverage_pct = (tested_endpoints / total_endpoints * 100) if total_endpoints > 0 else 0

    # Get budget from HTTP client
    client = _get_http_client(mcp_service)
    stats = client.get_stats()

    # Get vuln classes tested/untested
    vuln_classes_tested = set()
    for row in coverage_rows:
        if row.get("status") not in ["pending"]:
            vuln_classes_tested.add(row.get("vuln_class"))

    from lib.world_model_db import VULN_CLASSES
    vuln_classes_untested = [vc for vc in VULN_CLASSES if vc not in vuln_classes_tested]

    # Per-endpoint status
    per_endpoint = []
    for ep in endpoints_raw:
        ep_id = ep.get("id")
        ep_coverage = [c for c in coverage_rows if c.get("endpoint_id") == ep_id]
        ep_findings = [f for f in findings if f.get("url") == ep.get("url")]

        tests_run = len([c for c in ep_coverage if c.get("status") not in ["pending"]])

        if any(c.get("status") == "vulnerable" for c in ep_coverage):
            status = "vulnerable"
        elif tests_run > 0:
            status = "tested"
        else:
            status = "untested"

        per_endpoint.append({
            "url": ep.get("url"),
            "method": ep.get("method"),
            "tests_run": tests_run,
            "findings": len(ep_findings),
            "status": status,
        })

    result = {
        "total_endpoints": total_endpoints,
        "tested_endpoints": tested_endpoints,
        "coverage_pct": round(coverage_pct, 1),
        "findings": {
            "total": len(findings),
            **findings_by_severity,
        },
        "budget": {
            "used": stats.get("total_requests", 0),
            "remaining": stats.get("max_total_requests", 10000) - stats.get("total_requests", 0),
        },
        "vuln_classes_tested": sorted(list(vuln_classes_tested)),
        "vuln_classes_untested": sorted(vuln_classes_untested[:10]),  # Limit to 10 for brevity
        "per_endpoint": per_endpoint,
    }

    return _json_content(result)


async def _handle_race_condition_test(args: dict, mcp_service) -> List[TextContent]:
    """Send N concurrent identical requests and analyze response variance."""
    import asyncio
    import time

    url = args.get("url")
    if not url:
        return _error_content("url is required")

    method = args.get("method", "POST")
    headers = args.get("headers", {})
    body = args.get("body")
    concurrent_count = min(args.get("concurrent_count", 10), 50)
    timeout_ms = args.get("timeout_ms", 10000)

    client = _get_http_client(mcp_service)

    # Build identical requests
    from lib.race_condition_payloads import build_concurrent_requests
    requests = build_concurrent_requests(
        url=url, method=method, headers=headers, body=body, count=concurrent_count,
    )

    # Send all concurrently
    start = time.monotonic()

    async def _send_one(req):
        req_start = time.monotonic()
        try:
            result = await client.send(request=req)
            elapsed = (time.monotonic() - req_start) * 1000
            return {
                "status": result.get("status", 0),
                "body_length": len(result.get("body", "")),
                "timing_ms": round(elapsed, 1),
                "body_preview": (result.get("body") or "")[:200],
                "error": None,
            }
        except Exception as e:
            elapsed = (time.monotonic() - req_start) * 1000
            return {
                "status": 0,
                "body_length": 0,
                "timing_ms": round(elapsed, 1),
                "body_preview": "",
                "error": str(e),
            }

    results = await asyncio.gather(*[_send_one(r) for r in requests])
    total_time = (time.monotonic() - start) * 1000

    # Analyze results
    timings = [r["timing_ms"] for r in results if r["error"] is None]
    statuses = [r["status"] for r in results if r["error"] is None]
    body_lengths = [r["body_length"] for r in results if r["error"] is None]
    errors = [r for r in results if r["error"] is not None]

    timing_variance = (max(timings) - min(timings)) if timings else 0
    status_set = set(statuses)
    body_length_set = set(body_lengths)

    # Detect anomalies
    any_different_responses = len(status_set) > 1 or len(body_length_set) > 1
    possible_race = any_different_responses or (timing_variance > 500)

    return _json_content({
        "url": url,
        "method": method,
        "request_count": concurrent_count,
        "successful_requests": len(timings),
        "failed_requests": len(errors),
        "total_time_ms": round(total_time, 1),
        "timing": {
            "min_ms": round(min(timings), 1) if timings else 0,
            "max_ms": round(max(timings), 1) if timings else 0,
            "avg_ms": round(sum(timings) / len(timings), 1) if timings else 0,
            "variance_ms": round(timing_variance, 1),
        },
        "status_codes": dict(sorted(
            {str(s): statuses.count(s) for s in status_set}.items()
        )),
        "body_length_variance": len(body_length_set) > 1,
        "body_lengths_unique": sorted(list(body_length_set)),
        "any_different_responses": any_different_responses,
        "possible_race_condition": possible_race,
        "analysis": (
            "POSSIBLE RACE CONDITION: Responses differ across concurrent requests. "
            "Different status codes or body lengths indicate the server handles "
            "concurrent requests inconsistently."
            if possible_race else
            "No obvious race condition detected. All responses were consistent."
        ),
        "responses": results[:5],  # First 5 for inspection
    })


# ========== Exploitation Decision Handlers ==========

async def _handle_get_exploitation_decision(args: dict, mcp_service) -> List[TextContent]:
    """Get exploitation decision for a finding or all findings."""
    from lib.exploitation_decision import load_decision_queue

    db = await _get_db(mcp_service)
    queue = await load_decision_queue(db, mcp_service.current_assessment_id)

    finding_id = args.get("finding_id")
    if finding_id:
        decision = queue.get_decision(finding_id)
        return _json_content({
            "success": True,
            "decision": decision.to_dict(),
        })

    # Return all decisions + summary
    all_decisions = queue.to_dict()
    pending = queue.get_pending()
    completed = queue.get_completed()

    return _json_content({
        "success": True,
        "decisions": all_decisions,
        "summary": {
            "total": len(queue.decisions),
            "pending_exploitation": len(pending),
            "completed": len(completed),
            "pending_ids": [d.finding_id for d in pending],
        },
    })


async def _handle_update_exploitation_decision(args: dict, mcp_service) -> List[TextContent]:
    """Update exploitation decision after an attempt."""
    from lib.exploitation_decision import (
        ExploitResult, load_decision_queue, save_decision_queue,
    )

    finding_id = args["finding_id"]
    result_str = args["result"]
    vuln_type = args.get("vuln_type", "")
    notes = args.get("notes", "")

    try:
        result = ExploitResult(result_str)
    except ValueError:
        return _error_content(f"Invalid result: {result_str}. Must be one of: success, partial, blocked_by_security, failed, not_attempted")

    db = await _get_db(mcp_service)
    queue = await load_decision_queue(db, mcp_service.current_assessment_id)

    decision = queue.update_decision(finding_id, result, vuln_type=vuln_type, notes=notes)
    await save_decision_queue(db, mcp_service.current_assessment_id, queue)

    return _json_content({
        "success": True,
        "decision": decision.to_dict(),
        "message": (
            f"Finding {finding_id}: {result_str} (attempt {decision.attempt_count}). "
            f"{'Retry recommended.' if decision.should_retry else 'No retry needed.'}"
        ),
    })


async def _handle_get_relevant_skills(args: dict) -> List[TextContent]:
    """Get recommended vulnerability methodology skills based on vuln class or tech stack."""
    vuln_class = args.get("vuln_class", "").lower()
    tech_stack = [t.lower() for t in args.get("tech_stack", [])]

    # Keyword -> skill mapping
    VULN_SKILL_MAP = {
        "sql": "sql_injection", "sqli": "sql_injection", "injection": "sql_injection",
        "xss": "xss", "cross-site scripting": "xss", "script": "xss",
        "idor": "idor", "broken object": "idor", "object reference": "idor",
        "jwt": "authentication_jwt", "oauth": "authentication_jwt", "auth": "authentication_jwt", "token": "authentication_jwt",
        "race": "race_conditions", "toctou": "race_conditions", "concurrent": "race_conditions",
        "ssrf": "ssrf", "server-side request": "ssrf",
        "rce": "rce", "command injection": "rce", "template injection": "rce", "deserialization": "rce",
        "xxe": "xxe", "xml": "xxe",
        "csrf": "csrf", "cross-site request": "csrf",
        "path traversal": "path_traversal_lfi_rfi", "lfi": "path_traversal_lfi_rfi", "rfi": "path_traversal_lfi_rfi", "directory traversal": "path_traversal_lfi_rfi",
        "file upload": "insecure_file_uploads", "upload": "insecure_file_uploads",
        "mass assignment": "mass_assignment", "parameter binding": "mass_assignment",
        "redirect": "open_redirect", "open redirect": "open_redirect",
        "authorization": "broken_function_level_authorization", "privilege": "broken_function_level_authorization", "bfla": "broken_function_level_authorization",
        "information disclosure": "information_disclosure", "disclosure": "information_disclosure", "leakage": "information_disclosure",
        "subdomain": "subdomain_takeover", "takeover": "subdomain_takeover", "dns": "subdomain_takeover",
        "business logic": "business_logic", "logic": "business_logic", "workflow": "business_logic",
        "graphql": "graphql",
    }

    # Tech -> framework/protocol skill map
    TECH_SKILL_MAP = {
        "fastapi": ("framework", "fastapi"),
        "fast api": ("framework", "fastapi"),
        "nextjs": ("framework", "nextjs"),
        "next.js": ("framework", "nextjs"),
        "supabase": ("framework", "supabase"),
        "firebase": ("framework", "firebase_firestore"),
        "firestore": ("framework", "firebase_firestore"),
        "graphql": ("protocol", "graphql"),
    }

    recommended = []

    # Match vuln_class
    if vuln_class:
        for keyword, skill in VULN_SKILL_MAP.items():
            if keyword in vuln_class:
                uri_prefix = "protocol" if skill == "graphql" else "skill"
                recommended.append({
                    "skill": skill,
                    "type": "vulnerability" if skill != "graphql" else "protocol",
                    "uri": f"autopentest://{uri_prefix}/{skill}"
                })
                break

    # Match tech_stack
    for tech in tech_stack:
        for keyword, (skill_type, skill_name) in TECH_SKILL_MAP.items():
            if keyword in tech:
                uri_type = "framework" if skill_type == "framework" else "protocol"
                recommended.append({
                    "skill": skill_name,
                    "type": skill_type,
                    "uri": f"autopentest://{uri_type}/{skill_name}"
                })
                break

    # Deduplicate
    seen = set()
    unique = []
    for r in recommended:
        if r["skill"] not in seen:
            seen.add(r["skill"])
            unique.append(r)

    if not unique:
        return _json_content({
            "skills": [],
            "message": "No matching skills found. Try vuln_class like 'sql', 'xss', 'idor', or tech_stack like ['fastapi', 'graphql']"
        })

    return _json_content({
        "skills": unique,
        "message": f"Found {len(unique)} relevant skill(s). Use read_resource with the URI to load each skill.",
        "all_skills_uri": "autopentest://skill/{name} - replace {name} with skill name"
    })


# ========== CSRF Testing Handler ==========

async def _handle_test_csrf(args: dict, mcp_service) -> List[TextContent]:
    """Test an endpoint for CSRF vulnerabilities with 5 bypass variants."""
    url = args["url"]
    method = args.get("method", "POST")
    body = args.get("body", "")
    headers = args.get("headers", {})
    csrf_token_name = args.get("csrf_token_name", "csrf_token")
    csrf_token_location = args.get("csrf_token_location", "body")

    client = _get_http_client(mcp_service)

    # Get baseline response
    try:
        baseline = await client.send(
            request={"method": method, "url": url, "headers": headers, "body": body}
        )
        baseline_status = baseline.get("status", 0)
    except Exception as e:
        return _error_content(f"Baseline request failed: {e}")

    bypasses = []

    # Helper functions
    def _remove_param(body_str: str, name: str) -> str:
        # Try JSON first
        try:
            data = json.loads(body_str)
            data.pop(name, None)
            return json.dumps(data)
        except Exception:
            pass
        # Form-encoded
        parts = [p for p in body_str.split("&") if not p.startswith(f"{name}=")]
        return "&".join(parts)

    def _set_param(body_str: str, name: str, value: str) -> str:
        try:
            data = json.loads(body_str)
            data[name] = value
            return json.dumps(data)
        except Exception:
            pass
        # Form-encoded
        parts = [p for p in body_str.split("&") if not p.startswith(f"{name}=")]
        parts.append(f"{name}={value}")
        return "&".join(parts)

    tests = [
        ("remove_token", lambda: (
            _remove_param(body, csrf_token_name) if csrf_token_location == "body" else body,
            {k: v for k, v in headers.items() if csrf_token_name.lower() not in k.lower()},
            "Removed CSRF token entirely"
        )),
        ("empty_token", lambda: (
            _set_param(body, csrf_token_name, "") if csrf_token_location == "body" else body,
            headers,
            "Set CSRF token to empty string"
        )),
        ("content_type_switch", lambda: (
            body,
            {**headers, "Content-Type": "text/plain"},
            "Switched Content-Type to text/plain"
        )),
        ("remove_origin_referer", lambda: (
            body,
            {k: v for k, v in headers.items() if k.lower() not in ("origin", "referer")},
            "Removed Origin and Referer headers"
        )),
        ("cross_origin", lambda: (
            body,
            {**headers, "Origin": "https://evil.com", "Referer": "https://evil.com/attack"},
            "Set cross-origin Origin and Referer"
        )),
    ]

    for test_name, build_test in tests:
        description = test_name
        try:
            test_body, test_headers, description = build_test()
            resp = await client.send(
                request={"method": method, "url": url, "headers": test_headers, "body": test_body}
            )
            resp_status = resp.get("status", 0)

            # A bypass is detected if: non-4xx response (success or server error but not auth error)
            bypass_detected = resp_status not in (403, 401, 422, 400)
            if bypass_detected and resp_status == baseline_status:
                bypass_detected = True  # Same result as baseline = bypass

            bypasses.append({
                "test": test_name,
                "description": description,
                "status_code": resp_status,
                "baseline_status": baseline_status,
                "bypass_detected": bypass_detected
            })
        except Exception as e:
            bypasses.append({
                "test": test_name,
                "description": description,
                "error": str(e),
                "bypass_detected": False
            })

    bypasses_found = sum(1 for b in bypasses if b.get("bypass_detected"))

    return _json_content({
        "url": url,
        "baseline_status": baseline_status,
        "csrf_vulnerable": bypasses_found > 0,
        "bypasses_found": bypasses_found,
        "tests": bypasses,
        "verdict": "CSRF VULNERABLE" if bypasses_found > 0 else "CSRF protection appears intact"
    })


# ========== Think/Scratchpad Handler ==========

async def _handle_think(args: dict, mcp_service) -> List[TextContent]:
    """Record reasoning and scratchpad notes - no side effects."""
    reasoning = args.get("reasoning", "").strip()
    if not reasoning:
        return _error_content("Reasoning cannot be empty")

    # Log to activity logger if available (audit trail only)
    if hasattr(mcp_service, 'activity_logger') and mcp_service.activity_logger:
        try:
            await mcp_service.activity_logger.log(
                event_type="think",
                details={"char_count": len(reasoning)}
            )
        except Exception:
            pass

    return _json_content({
        "success": True,
        "message": f"Thought recorded ({len(reasoning)} chars)",
        "char_count": len(reasoning)
    })


# ========== PoC Generation Handler ==========

async def _handle_generate_poc(args: dict, mcp_service) -> List[TextContent]:
    """Generate proof-of-concept exploit code for a recorded finding."""
    from lib.poc_generator import PoCGenerator
    import json as json_mod

    finding_id = args.get("finding_id", "").strip()
    if not finding_id:
        return _error_content("finding_id is required")

    db = await _get_db(mcp_service)

    # Fetch finding from DB
    try:
        rows = await db.query("findings", {"id": finding_id})
        if not rows:
            return _error_content(f"Finding {finding_id} not found")
        finding = rows[0]
    except Exception as e:
        return _error_content(f"Failed to fetch finding: {e}")

    # Parse metadata
    metadata = finding.get("metadata") or {}
    if isinstance(metadata, str):
        try:
            metadata = json_mod.loads(metadata)
        except Exception:
            metadata = {}

    # Build finding dict for PoCGenerator
    finding_data = {
        "id": finding_id,
        "title": finding.get("title", ""),
        "vuln_type": finding.get("vuln_class") or finding.get("category", ""),
        "url": finding.get("url", ""),
        "severity": finding.get("severity", "medium"),
        "parameter": metadata.get("parameter", ""),
        "payload": metadata.get("payload", ""),
        "method": metadata.get("method", "GET"),
        "evidence": finding.get("evidence", ""),
    }

    # Generate PoC
    try:
        generator = PoCGenerator()
        poc_result = generator.generate(finding_data)

        if isinstance(poc_result, str):
            poc_result = {"script": poc_result}

        return _json_content({
            "finding_id": finding_id,
            "vuln_type": finding_data["vuln_type"],
            "url": finding_data["url"],
            "poc": poc_result,
            "script": poc_result.get("script", ""),
            "curl": poc_result.get("curl_command", f"curl -X {finding_data['method']} '{finding_data['url']}'"),
        })
    except Exception as e:
        return _error_content(f"PoC generation failed: {e}")
