"""
LLM-in-the-Loop Pentest Tools

8 tools that expose raw HTTP traffic and attack surface data to the LLM,
enabling end-to-end security testing where the LLM sees every request/response,
decides what to test, and controls the flow.

Tools:
1. recon_endpoint - Send baseline HTTP request, return full request/response
2. get_test_payloads - Return actual payload strings from PayloadRegistry
3. inject_payload - Inject single payload, return full request/response
4. inject_batch - Send multiple payloads, return baseline diff analysis
5. analyze_headers - Extract security headers, cookies, CORS, server info
6. discover_attack_surface - Return all known endpoints, parameters, coverage
7. record_finding - Record confirmed vulnerability to world model + cards
8. get_test_progress - Show what's tested, findings count, coverage %
"""

import json
import html
from typing import List, Dict, Any, Optional
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

from mcp.types import Tool, TextContent

from lib.http_client import HttpClient
from lib.payload_registry import PayloadRegistry
from lib.test_plan_executor import TestPlanExecutor
from lib.world_model_db import get_world_model_db


# ========== Shared Helpers ==========

def _get_http_client(mcp_service) -> HttpClient:
    """Get or create HTTP client with per-assessment scope.

    Reuses the same pattern as tools_http.py:21-75.
    """
    import os

    # Cache HTTP client per assessment
    cache_key = mcp_service.current_assessment_id
    if hasattr(mcp_service, '_http_client_cache') and \
       hasattr(mcp_service, '_http_client_cache_key') and \
       mcp_service._http_client_cache_key == cache_key and \
       mcp_service._http_client_cache is not None:
        return mcp_service._http_client_cache

    # Build exchange logger callback for audit trail
    async def _log_exchange(request, response, correlation_ids, timing):
        if hasattr(mcp_service, 'activity_logger') and mcp_service.activity_logger:
            await mcp_service.activity_logger.log_http_exchange(
                url=request.get("url", ""),
                method=request.get("method", ""),
                status_code=response.get("status", 0),
                request_headers=request.get("headers", {}),
                response_headers=response.get("headers", {}),
                response_body_preview=(response.get("body") or "")[:2048],
                correlation_id=correlation_ids.get("request_id", ""),
                timing_ms=timing.get("duration_ms", 0),
            )

    # Create new HTTP client with assessment context
    client = HttpClient(
        config={
            "engagement_id": os.environ.get("ENGAGEMENT_ID", "default"),
            "proxy_url": os.environ.get("PROXY_URL"),
            "max_rps": float(os.environ.get("MAX_RPS", "10")),
            "max_concurrent": int(os.environ.get("MAX_CONCURRENT", "5")),
            "default_timeout": float(os.environ.get("DEFAULT_TIMEOUT", "30000")),
            "max_total_requests": int(os.environ.get("MAX_TOTAL_REQUESTS", "10000")),
        },
        assessment_id=mcp_service.current_assessment_id,
        scope_provider=mcp_service.scope_provider,
        exchange_logger=_log_exchange,
    )

    # Cache for reuse
    mcp_service._http_client_cache = client
    mcp_service._http_client_cache_key = cache_key
    return client


async def _get_db(mcp_service):
    """Get WorldModelDatabase for current assessment."""
    if mcp_service.current_assessment_id is None:
        raise ValueError("No assessment loaded. Call load_assessment first.")
    return await get_world_model_db(mcp_service.current_assessment_id)


def _json_content(data: Any) -> List[TextContent]:
    """JSON-wrapped TextContent."""
    return [TextContent(type="text", text=json.dumps(data, indent=2))]


def _error_content(msg: str) -> List[TextContent]:
    """Error JSON TextContent."""
    return [TextContent(type="text", text=json.dumps({"error": msg}, indent=2))]


def _truncate_body(body: str, max_len: int) -> Dict[str, Any]:
    """Truncate body and return metadata.

    Returns:
        {"body": str, "truncated": bool, "full_length": int}
    """
    full_length = len(body)
    if full_length > max_len:
        return {
            "body": body[:max_len],
            "truncated": True,
            "full_length": full_length,
        }
    return {
        "body": body,
        "truncated": False,
        "full_length": full_length,
    }


def _compute_baseline_diff(baseline: Dict, response: Dict) -> Dict[str, Any]:
    """Compute simple factual diff between baseline and response.

    Returns:
        {
            "status_changed": bool,
            "body_length_diff_pct": float,
            "timing_ratio": float,
        }
    """
    status_changed = baseline.get("status") != response.get("status")

    baseline_len = len(baseline.get("body", ""))
    response_len = len(response.get("body", ""))

    if baseline_len > 0:
        body_diff_pct = abs(response_len - baseline_len) / baseline_len * 100
    else:
        body_diff_pct = 0.0 if response_len == 0 else 100.0

    baseline_time = baseline.get("timing_ms", 1)
    response_time = response.get("timing_ms", 1)
    timing_ratio = response_time / max(baseline_time, 1)

    return {
        "status_changed": status_changed,
        "body_length_diff_pct": round(body_diff_pct, 2),
        "timing_ratio": round(timing_ratio, 2),
    }


def _parse_security_headers(headers: Dict[str, str]) -> Dict[str, Any]:
    """Parse security-relevant headers.

    Returns:
        {
            "security_headers_present": {...},
            "security_headers_missing": [...],
            "server_info": {...},
            "cors_headers": {...},
            "cookies": [...],
            "cache_headers": {...},
        }
    """
    # Normalize header keys to lowercase
    headers_lower = {k.lower(): v for k, v in headers.items()}

    # Security headers to check
    security_headers_check = [
        "strict-transport-security",
        "content-security-policy",
        "x-content-type-options",
        "x-frame-options",
        "x-xss-protection",
        "referrer-policy",
        "permissions-policy",
        "cross-origin-opener-policy",
        "cross-origin-resource-policy",
        "cross-origin-embedder-policy",
    ]

    present = {}
    missing = []

    for hdr in security_headers_check:
        if hdr in headers_lower:
            present[hdr] = headers_lower[hdr]
        else:
            missing.append(hdr)

    # Server disclosure headers
    server_info = {}
    for hdr in ["server", "x-powered-by", "x-aspnet-version", "x-generator"]:
        if hdr in headers_lower:
            server_info[hdr] = headers_lower[hdr]

    # CORS headers
    cors_headers = {}
    for hdr in headers_lower:
        if hdr.startswith("access-control-"):
            cors_headers[hdr] = headers_lower[hdr]

    # Parse cookies
    cookies = []
    if "set-cookie" in headers_lower:
        # Note: headers_lower may have single value or list
        cookie_values = headers_lower["set-cookie"]
        if not isinstance(cookie_values, list):
            cookie_values = [cookie_values]

        for cookie_str in cookie_values:
            parts = cookie_str.split(";")
            if not parts:
                continue

            name_value = parts[0].split("=", 1)
            if len(name_value) != 2:
                continue

            cookie = {
                "name": name_value[0].strip(),
                "httpOnly": "HttpOnly" in cookie_str,
                "secure": "Secure" in cookie_str,
                "sameSite": None,
            }

            # Extract SameSite
            for part in parts:
                part = part.strip()
                if part.lower().startswith("samesite="):
                    cookie["sameSite"] = part.split("=", 1)[1]

            cookies.append(cookie)

    # Cache headers
    cache_headers = {}
    for hdr in ["cache-control", "pragma", "expires", "etag"]:
        if hdr in headers_lower:
            cache_headers[hdr] = headers_lower[hdr]

    return {
        "security_headers_present": present,
        "security_headers_missing": missing,
        "server_info": server_info,
        "cors_headers": cors_headers,
        "cookies": cookies,
        "cache_headers": cache_headers,
    }


# ========== Tool Definitions ==========

def get_pentest_tools() -> List[Tool]:
    """Get LLM-in-the-loop pentest tool definitions."""
    return [
        Tool(
            name="recon_endpoint",
            description=(
                "Send a baseline HTTP request and return the FULL request/response pair to the LLM. "
                "Unlike endpoint_probe (which truncates to 500 chars), this returns the complete response "
                "body (up to max_response_body chars) for LLM analysis. Use this to examine application "
                "behavior, error messages, reflected input, and other signals needed for vulnerability testing."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "Target URL"},
                    "method": {"type": "string", "default": "GET", "enum": ["GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"]},
                    "headers": {"type": "object", "description": "Optional HTTP headers"},
                    "body": {"type": "string", "description": "Optional request body"},
                    "identity_id": {"type": "string", "description": "Optional identity ID for authenticated requests"},
                    "max_response_body": {"type": "integer", "default": 8192, "description": "Max response body chars to return"},
                },
                "required": ["url"],
            },
        ),
        Tool(
            name="get_test_payloads",
            description=(
                "Return actual payload strings from PayloadRegistry for a vulnerability class. "
                "This lets the LLM inspect and select from real payloads (300+ across 46 vuln classes). "
                "Use this to see what payloads are available before testing, or to craft custom variants."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "vuln_class": {"type": "string", "description": "Vulnerability class (e.g., sqli_error, xss_reflected, ssrf)"},
                    "limit": {"type": "integer", "default": 25, "description": "Max payloads to return"},
                    "context": {"type": "object", "description": "Optional context (endpoint, tech, parameter info)"},
                },
                "required": ["vuln_class"],
            },
        ),
        Tool(
            name="inject_payload",
            description=(
                "Inject a single payload into a specific parameter location and return the FULL "
                "request/response. Supports 5 injection locations: query, body (JSON/form), path, "
                "header, cookie. Returns complete response for LLM analysis of reflected input, "
                "error messages, status changes, and other vulnerability signals."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string", "description": "Target URL"},
                    "method": {"type": "string", "default": "GET"},
                    "parameter": {"type": "string", "description": "Parameter name to inject into"},
                    "location": {"type": "string", "enum": ["query", "body", "path", "header", "cookie"], "description": "Where to inject payload"},
                    "payload": {"type": "string", "description": "Payload string to inject"},
                    "headers": {"type": "object", "description": "Optional base headers"},
                    "body": {"type": "string", "description": "Optional base body (for POST/PUT)"},
                    "identity_id": {"type": "string", "description": "Optional identity for auth"},
                    "max_response_body": {"type": "integer", "default": 8192},
                },
                "required": ["url", "parameter", "location", "payload"],
            },
        ),
        Tool(
            name="inject_batch",
            description=(
                "Send multiple payloads to the same injection point with baseline comparison. "
                "Returns full responses for each payload plus factual diff metrics (status changes, "
                "body length variance, timing anomalies). Use this to sweep hardcoded payloads and "
                "identify outliers that warrant deeper investigation."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string"},
                    "method": {"type": "string", "default": "GET"},
                    "parameter": {"type": "string"},
                    "location": {"type": "string", "enum": ["query", "body", "path", "header", "cookie"]},
                    "payloads": {"type": "array", "items": {"type": "string"}, "description": "Array of payload strings"},
                    "headers": {"type": "object"},
                    "body": {"type": "string"},
                    "include_baseline": {"type": "boolean", "default": True, "description": "Send clean request first for comparison"},
                    "max_response_body": {"type": "integer", "default": 4096},
                    "max_batch_size": {"type": "integer", "default": 50, "description": "Max payloads to send"},
                },
                "required": ["url", "parameter", "location", "payloads"],
            },
        ),
        Tool(
            name="analyze_headers",
            description=(
                "Extract and present security-relevant headers from a response. Returns factual data "
                "about security headers (present/missing), cookies (HttpOnly/Secure/SameSite flags), "
                "CORS configuration, server disclosure, and cache headers. The LLM decides what's a finding."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "url": {"type": "string"},
                    "method": {"type": "string", "default": "GET"},
                    "headers": {"type": "object"},
                    "identity_id": {"type": "string"},
                },
                "required": ["url"],
            },
        ),
        Tool(
            name="discover_attack_surface",
            description=(
                "Return all known endpoints, parameters, and coverage status from the world model. "
                "Shows what has been discovered via recon/crawling/OpenAPI parsing, what's been tested, "
                "and what has findings. Use this at the start of testing to understand the attack surface."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "base_url": {"type": "string", "description": "Optional URL filter (e.g., https://api.example.com)"},
                    "include_parameters": {"type": "boolean", "default": True},
                    "include_coverage": {"type": "boolean", "default": True},
                },
                "required": [],
            },
        ),
        Tool(
            name="record_finding",
            description=(
                "Record a confirmed vulnerability to the world model and card system. Bridges findings "
                "and cards with automatic deduplication. Updates coverage matrix to mark endpoint/vuln_class "
                "as vulnerable. Call this when you've confirmed a vulnerability through testing."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "title": {"type": "string", "description": "Finding title (e.g., 'SQL Injection in /api/users')"},
                    "severity": {"type": "string", "enum": ["info", "low", "medium", "high", "critical"]},
                    "url": {"type": "string", "description": "Vulnerable endpoint URL"},
                    "vuln_class": {"type": "string", "description": "Vuln class (e.g., sqli_error, xss_reflected)"},
                    "parameter": {"type": "string", "description": "Vulnerable parameter name"},
                    "evidence": {
                        "type": "object",
                        "description": "Evidence with request/response/payload/description",
                        "properties": {
                            "request": {"type": "object"},
                            "response": {"type": "object"},
                            "payload": {"type": "string"},
                            "description": {"type": "string"},
                        },
                    },
                    "remediation": {"type": "string"},
                    "confidence": {"type": "number", "default": 0.8, "minimum": 0.0, "maximum": 1.0},
                },
                "required": ["title", "severity", "url"],
            },
        ),
        Tool(
            name="get_test_progress",
            description=(
                "Show what has been tested, findings count, and coverage completeness. Returns "
                "endpoint counts, coverage %, findings by severity, budget usage, vuln classes "
                "tested/untested, and per-endpoint testing status. Use this to verify coverage."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "base_url": {"type": "string", "description": "Optional URL filter"},
                },
                "required": [],
            },
        ),
    ]


# ========== Tool Handlers ==========

async def handle_pentest_tool(name: str, arguments: dict, mcp_service) -> List[TextContent]:
    """Handle all pentest tool calls."""

    try:
        if name == "recon_endpoint":
            return await _handle_recon_endpoint(arguments, mcp_service)
        elif name == "get_test_payloads":
            return await _handle_get_test_payloads(arguments, mcp_service)
        elif name == "inject_payload":
            return await _handle_inject_payload(arguments, mcp_service)
        elif name == "inject_batch":
            return await _handle_inject_batch(arguments, mcp_service)
        elif name == "analyze_headers":
            return await _handle_analyze_headers(arguments, mcp_service)
        elif name == "discover_attack_surface":
            return await _handle_discover_attack_surface(arguments, mcp_service)
        elif name == "record_finding":
            return await _handle_record_finding(arguments, mcp_service)
        elif name == "get_test_progress":
            return await _handle_get_test_progress(arguments, mcp_service)
        else:
            return _error_content(f"Unknown pentest tool: {name}")
    except Exception as e:
        import traceback
        return _error_content(f"Error in {name}: {str(e)}\n{traceback.format_exc()}")


async def _handle_recon_endpoint(args: dict, mcp_service) -> List[TextContent]:
    """Send baseline HTTP request and return full request/response."""
    url = args["url"]
    method = args.get("method", "GET")
    headers = args.get("headers", {})
    body = args.get("body")
    max_response_body = args.get("max_response_body", 8192)

    client = _get_http_client(mcp_service)

    # Send request via HttpClient (handles rate limiting, scope validation, budget)
    result = await client.send(
        method=method,
        url=url,
        headers=headers,
        body=body,
    )

    # Truncate response body
    body_data = _truncate_body(result.get("body", ""), max_response_body)

    # Detect content type
    content_type = result.get("headers", {}).get("content-type", "")
    is_json = "json" in content_type.lower()
    is_html = "html" in content_type.lower()

    response_data = {
        "request": {
            "method": method,
            "url": url,
            "headers": headers,
            "body": body,
        },
        "response": {
            "status": result.get("status"),
            "status_text": result.get("statusText"),
            "headers": result.get("headers", {}),
            "body": body_data["body"],
            "timing_ms": result.get("timing", {}).get("duration_ms", 0),
        },
        "metadata": {
            "content_type": content_type,
            "body_length": body_data["full_length"],
            "body_truncated": body_data["truncated"],
            "is_json": is_json,
            "is_html": is_html,
        },
    }

    # Run exchange analysis for automatic finding detection
    from lib.exchange_analyzer import get_exchange_analyzer
    analyzer = get_exchange_analyzer()
    request_dict = {"method": method, "url": url, "headers": headers, "body": body or ""}
    response_dict = {
        "status": result.get("status", 0),
        "headers": result.get("headers", {}),
        "body": body_data["body"]
    }
    analysis = analyzer.analyze(request_dict, response_dict)

    # Auto-persist any risk signals as findings
    auto_findings = 0
    if analysis.risk_signals and mcp_service:
        try:
            auto_findings = await mcp_service.auto_persist_risk_signals(analysis.risk_signals, url)
        except Exception:
            pass  # Don't fail the request if persistence fails

    response_data["exchange_analysis"] = {
        "risk_signals": analysis.risk_signals,
        "recommended_tests": analysis.recommended_tests,
        "detected_technologies": analysis.detected_technologies,
        "auto_findings_created": auto_findings,
    }

    return _json_content(response_data)


async def _handle_get_test_payloads(args: dict, mcp_service) -> List[TextContent]:
    """Return payload strings from PayloadRegistry."""
    vuln_class = args["vuln_class"]
    limit = args.get("limit", 25)
    context = args.get("context")

    registry = PayloadRegistry()

    # Get payloads
    payloads = registry.get_payloads(vuln_class, context)

    # Convert to strings
    string_payloads = registry.to_string_payloads(payloads)

    # Limit results
    string_payloads = string_payloads[:limit]

    # Build payload list with metadata
    payload_list = []
    for idx, payload_str in enumerate(string_payloads):
        payload_obj = payloads[idx] if idx < len(payloads) else None

        entry = {
            "index": idx,
            "value": payload_str,
        }

        # Extract technique/platform metadata if available
        if payload_obj and hasattr(payload_obj, "technique"):
            entry["technique"] = payload_obj.technique
        if payload_obj and hasattr(payload_obj, "platform"):
            entry["platform"] = payload_obj.platform

        payload_list.append(entry)

    result = {
        "vuln_class": vuln_class,
        "total_available": len(payloads),
        "payloads": payload_list,
        "available_classes": sorted(list(registry.PAYLOAD_GETTERS.keys())),
    }

    return _json_content(result)


async def _handle_inject_payload(args: dict, mcp_service) -> List[TextContent]:
    """Inject single payload and return full request/response."""
    url = args["url"]
    method = args.get("method", "GET")
    parameter = args["parameter"]
    location = args["location"]
    payload = args["payload"]
    headers = args.get("headers", {})
    body = args.get("body", "")
    max_response_body = args.get("max_response_body", 8192)

    # Inject payload using TestPlanExecutor's static method
    injected_url, injected_body, injected_headers = TestPlanExecutor._inject_payload(
        url=url,
        method=method,
        headers=headers,
        body=body,
        parameter=parameter,
        location=location,
        payload=payload,
    )

    # Send injected request
    client = _get_http_client(mcp_service)
    result = await client.send(
        method=method,
        url=injected_url,
        headers=injected_headers,
        body=injected_body,
    )

    # Truncate response body
    body_data = _truncate_body(result.get("body", ""), max_response_body)

    # Check if payload reflected in response body
    payload_reflected = payload in body_data["body"]

    response_data = {
        "request": {
            "method": method,
            "url": injected_url,
            "headers": injected_headers,
            "body": injected_body,
        },
        "response": {
            "status": result.get("status"),
            "status_text": result.get("statusText"),
            "headers": result.get("headers", {}),
            "body": body_data["body"],
            "timing_ms": result.get("timing", {}).get("duration_ms", 0),
        },
        "injection": {
            "parameter": parameter,
            "location": location,
            "payload": payload,
            "payload_reflected_in_body": payload_reflected,
        },
    }

    # Run exchange analysis for automatic finding detection
    from lib.exchange_analyzer import get_exchange_analyzer
    analyzer = get_exchange_analyzer()
    request_dict = {"method": method, "url": injected_url, "headers": injected_headers, "body": injected_body or ""}
    response_dict = {
        "status": result.get("status", 0),
        "headers": result.get("headers", {}),
        "body": body_data["body"]
    }
    analysis = analyzer.analyze(request_dict, response_dict)

    # Auto-persist any risk signals as findings
    auto_findings = 0
    if analysis.risk_signals and mcp_service:
        try:
            auto_findings = await mcp_service.auto_persist_risk_signals(analysis.risk_signals, injected_url)
        except Exception:
            pass  # Don't fail the request if persistence fails

    response_data["exchange_analysis"] = {
        "risk_signals": analysis.risk_signals,
        "recommended_tests": analysis.recommended_tests,
        "detected_technologies": analysis.detected_technologies,
        "auto_findings_created": auto_findings,
    }

    return _json_content(response_data)


async def _handle_inject_batch(args: dict, mcp_service) -> List[TextContent]:
    """Send multiple payloads with baseline comparison."""
    url = args["url"]
    method = args.get("method", "GET")
    parameter = args["parameter"]
    location = args["location"]
    payloads = args["payloads"]
    headers = args.get("headers", {})
    body = args.get("body", "")
    include_baseline = args.get("include_baseline", True)
    max_response_body = args.get("max_response_body", 4096)
    max_batch_size = args.get("max_batch_size", 50)

    # Cap payloads
    payloads = payloads[:max_batch_size]

    client = _get_http_client(mcp_service)

    baseline_data = None

    # Send baseline if requested
    baseline_exchange_analysis = None
    if include_baseline:
        baseline_result = await client.send(
            method=method,
            url=url,
            headers=headers,
            body=body,
        )
        baseline_body = _truncate_body(baseline_result.get("body", ""), max_response_body)
        baseline_data = {
            "status": baseline_result.get("status"),
            "body_length": baseline_body["full_length"],
            "timing_ms": baseline_result.get("timing", {}).get("duration_ms", 0),
            "body": baseline_body["body"],
        }

        # Run exchange analysis on baseline request
        from lib.exchange_analyzer import get_exchange_analyzer
        analyzer = get_exchange_analyzer()
        request_dict = {"method": method, "url": url, "headers": headers, "body": body or ""}
        response_dict = {
            "status": baseline_result.get("status", 0),
            "headers": baseline_result.get("headers", {}),
            "body": baseline_body["body"]
        }
        analysis = analyzer.analyze(request_dict, response_dict)

        # Auto-persist any risk signals as findings
        auto_findings = 0
        if analysis.risk_signals and mcp_service:
            try:
                auto_findings = await mcp_service.auto_persist_risk_signals(analysis.risk_signals, url)
            except Exception:
                pass  # Don't fail the request if persistence fails

        baseline_exchange_analysis = {
            "risk_signals": analysis.risk_signals,
            "recommended_tests": analysis.recommended_tests,
            "detected_technologies": analysis.detected_technologies,
            "auto_findings_created": auto_findings,
        }

    # Send payloads
    results = []
    unique_statuses = set()
    payloads_reflected = 0
    status_changes = 0
    timing_anomalies = 0

    for idx, payload in enumerate(payloads):
        # Inject payload
        injected_url, injected_body, injected_headers = TestPlanExecutor._inject_payload(
            url=url,
            method=method,
            headers=headers,
            body=body,
            parameter=parameter,
            location=location,
            payload=payload,
        )

        # Send request
        result = await client.send(
            method=method,
            url=injected_url,
            headers=injected_headers,
            body=injected_body,
        )

        # Truncate body
        body_data = _truncate_body(result.get("body", ""), max_response_body)

        # Build result entry
        status = result.get("status")
        unique_statuses.add(status)

        payload_reflected = payload in body_data["body"]
        if payload_reflected:
            payloads_reflected += 1

        entry = {
            "index": idx,
            "payload": payload,
            "response": {
                "status": status,
                "headers": result.get("headers", {}),
                "body": body_data["body"],
                "timing_ms": result.get("timing", {}).get("duration_ms", 0),
            },
            "payload_reflected": payload_reflected,
        }

        # Compute diff vs baseline
        if baseline_data:
            response_dict = {
                "status": status,
                "body": body_data["body"],
                "timing_ms": result.get("timing", {}).get("duration_ms", 0),
            }
            diff = _compute_baseline_diff(baseline_data, response_dict)
            entry.update(diff)

            if diff["status_changed"]:
                status_changes += 1
            if diff["timing_ratio"] > 2.0:
                timing_anomalies += 1

        results.append(entry)

    response_data = {
        "baseline": baseline_data,
        "results": results,
        "summary": {
            "total_sent": len(results),
            "unique_status_codes": sorted(list(unique_statuses)),
            "payloads_reflected": payloads_reflected,
            "status_changes": status_changes,
            "timing_anomalies": timing_anomalies,
        },
    }

    # Include baseline exchange analysis if available
    if baseline_exchange_analysis:
        response_data["baseline_exchange_analysis"] = baseline_exchange_analysis

    return _json_content(response_data)


async def _handle_analyze_headers(args: dict, mcp_service) -> List[TextContent]:
    """Extract security-relevant headers."""
    url = args["url"]
    method = args.get("method", "GET")
    headers = args.get("headers", {})

    client = _get_http_client(mcp_service)

    # Send request
    result = await client.send(
        method=method,
        url=url,
        headers=headers,
    )

    # Parse headers with custom parser
    response_headers = result.get("headers", {})
    analysis = _parse_security_headers(response_headers)

    # Also run exchange analysis for comprehensive detection
    from lib.exchange_analyzer import get_exchange_analyzer
    analyzer = get_exchange_analyzer()
    request_dict = {"method": method, "url": url, "headers": headers, "body": ""}
    response_dict = {
        "status": result.get("status", 0),
        "headers": response_headers,
        "body": result.get("body", "")[:4096]
    }
    ea_result = analyzer.analyze(request_dict, response_dict)

    # Auto-persist any risk signals as findings
    auto_findings = 0
    if ea_result.risk_signals and mcp_service:
        try:
            auto_findings = await mcp_service.auto_persist_risk_signals(ea_result.risk_signals, url)
        except Exception:
            pass

    analysis["exchange_analysis"] = {
        "risk_signals": ea_result.risk_signals,
        "recommended_tests": ea_result.recommended_tests,
        "detected_technologies": ea_result.detected_technologies,
        "auto_findings_created": auto_findings,
    }

    return _json_content(analysis)


async def _handle_discover_attack_surface(args: dict, mcp_service) -> List[TextContent]:
    """Return all known endpoints, parameters, coverage from world model."""
    base_url = args.get("base_url")
    include_parameters = args.get("include_parameters", True)
    include_coverage = args.get("include_coverage", True)

    db = await _get_db(mcp_service)

    # Query endpoints
    endpoints_raw = await db.query("endpoints")

    # Filter by base_url if provided
    if base_url:
        parsed = urlparse(base_url)
        base_netloc = parsed.netloc
        endpoints_raw = [
            ep for ep in endpoints_raw
            if urlparse(ep.get("url", "")).netloc == base_netloc
        ]

    # Build endpoint list
    endpoints = []
    for ep in endpoints_raw:
        endpoint_data = {
            "url": ep.get("url"),
            "method": ep.get("method"),
            "id": ep.get("id"),
        }

        if include_parameters:
            # Get parameters from observations
            observations = await db.query("observations")
            params = [
                obs.get("context", {}).get("parameter_name")
                for obs in observations
                if obs.get("target_id") == ep.get("id")
                and obs.get("context", {}).get("parameter_name")
            ]
            endpoint_data["parameters"] = params

        if include_coverage:
            # Get coverage status
            coverage_rows = await db.query("coverage_matrix")
            endpoint_coverage = [
                c for c in coverage_rows
                if c.get("endpoint_id") == ep.get("id")
            ]

            if endpoint_coverage:
                tested = any(c.get("status") not in ["pending"] for c in endpoint_coverage)
                vulnerable = any(c.get("status") == "vulnerable" for c in endpoint_coverage)
                if vulnerable:
                    endpoint_data["coverage_status"] = "vulnerable"
                elif tested:
                    endpoint_data["coverage_status"] = "tested"
                else:
                    endpoint_data["coverage_status"] = "pending"
            else:
                endpoint_data["coverage_status"] = "untested"

        endpoints.append(endpoint_data)

    # Get findings count
    findings = await db.query("findings")
    findings_count = len(findings)

    # Get assets
    assets_raw = await db.query("assets")
    assets = [a.get("name") for a in assets_raw]

    # Get OpenAPI specs
    # Note: OpenAPI data stored in observations with type="openapi_spec"
    observations = await db.query("observations")
    openapi_specs = [
        obs.get("content", {}).get("spec_name", "unknown")
        for obs in observations
        if obs.get("type") == "openapi_spec"
    ]

    # Count parameters
    total_params = sum(len(ep.get("parameters", [])) for ep in endpoints)

    result = {
        "endpoints": endpoints,
        "total_endpoints": len(endpoints),
        "total_parameters": total_params,
        "findings_count": findings_count,
        "assets": assets,
        "openapi_specs": openapi_specs,
    }

    return _json_content(result)


async def _handle_record_finding(args: dict, mcp_service) -> List[TextContent]:
    """Record confirmed vulnerability to world model + cards."""
    title = args["title"]
    severity = args["severity"]
    url = args["url"]
    vuln_class = args.get("vuln_class")
    parameter = args.get("parameter")
    evidence = args.get("evidence", {})
    remediation = args.get("remediation")
    confidence = args.get("confidence", 0.8)

    # Build card description
    description_parts = []

    if vuln_class:
        description_parts.append(f"**Vulnerability Class:** {vuln_class}")

    if parameter:
        description_parts.append(f"**Vulnerable Parameter:** {parameter}")

    if evidence.get("payload"):
        description_parts.append(f"**Payload:** `{evidence['payload']}`")

    if evidence.get("description"):
        description_parts.append(f"\n{evidence['description']}")

    if evidence.get("request"):
        req = evidence["request"]
        description_parts.append(f"\n**Request:**\n```\n{req.get('method', 'GET')} {req.get('url', url)}\n```")

    if evidence.get("response"):
        resp = evidence["response"]
        status = resp.get("status", "")
        body_preview = (resp.get("body", "") or "")[:500]
        description_parts.append(f"\n**Response:** {status}\n```\n{body_preview}\n```")

    if remediation:
        description_parts.append(f"\n**Remediation:**\n{remediation}")

    description = "\n\n".join(description_parts)

    # Create card via safe_add_card
    result = await mcp_service.safe_add_card(
        card_type="finding",
        title=title,
        description=description,
        severity=severity.upper() if isinstance(severity, str) else severity,  # Normalize to uppercase
        url=url,
        confidence=confidence,
    )

    if not result.ok:
        return _error_content(f"Failed to create card: {result.reason}")

    # Update coverage matrix if vuln_class provided
    if vuln_class:
        try:
            db = await _get_db(mcp_service)

            # Find endpoint ID by URL
            endpoints = await db.query("endpoints")
            endpoint = next((ep for ep in endpoints if ep.get("url") == url), None)

            if endpoint:
                endpoint_id = endpoint.get("id")

                # Update coverage matrix
                coverage_rows = await db.query("coverage_matrix")
                cell = next(
                    (c for c in coverage_rows
                     if c.get("endpoint_id") == endpoint_id
                     and c.get("vuln_class") == vuln_class),
                    None
                )

                if cell:
                    # Update existing cell
                    card_id = result.data.get("id") if result.data else None
                    await db.coverage_mark(
                        cell_id=cell.get("id"),
                        status="vulnerable",
                        finding_id=str(card_id) if card_id else None,
                        result_summary=title,
                    )
        except Exception as e:
            # Don't fail the whole operation if coverage update fails
            import logging
            logging.warning(f"Failed to update coverage matrix: {e}")

    card_id = result.data.get("id") if result.data else None
    response = {
        "finding_id": str(card_id) if card_id else None,
        "card_id": str(card_id) if card_id else None,
        "success": True,
    }

    return _json_content(response)


async def _handle_get_test_progress(args: dict, mcp_service) -> List[TextContent]:
    """Show testing progress, findings, coverage."""
    base_url = args.get("base_url")

    db = await _get_db(mcp_service)

    # Get endpoints
    endpoints_raw = await db.query("endpoints")

    if base_url:
        parsed = urlparse(base_url)
        base_netloc = parsed.netloc
        endpoints_raw = [
            ep for ep in endpoints_raw
            if urlparse(ep.get("url", "")).netloc == base_netloc
        ]

    total_endpoints = len(endpoints_raw)

    # Get coverage matrix
    coverage_rows = await db.query("coverage_matrix")

    # Get findings
    findings = await db.query("findings")

    # Count findings by severity
    findings_by_severity = {
        "critical": 0,
        "high": 0,
        "medium": 0,
        "low": 0,
        "info": 0,
    }

    for finding in findings:
        sev = finding.get("severity", "info")
        if sev in findings_by_severity:
            findings_by_severity[sev] += 1

    # Calculate tested endpoints
    tested_endpoint_ids = set()
    for row in coverage_rows:
        if row.get("status") not in ["pending"]:
            tested_endpoint_ids.add(row.get("endpoint_id"))

    tested_endpoints = len(tested_endpoint_ids)
    coverage_pct = (tested_endpoints / total_endpoints * 100) if total_endpoints > 0 else 0

    # Get budget from HTTP client
    client = _get_http_client(mcp_service)
    stats = client.get_stats()

    # Get vuln classes tested/untested
    vuln_classes_tested = set()
    for row in coverage_rows:
        if row.get("status") not in ["pending"]:
            vuln_classes_tested.add(row.get("vuln_class"))

    from lib.world_model_db import VULN_CLASSES
    vuln_classes_untested = [vc for vc in VULN_CLASSES if vc not in vuln_classes_tested]

    # Per-endpoint status
    per_endpoint = []
    for ep in endpoints_raw:
        ep_id = ep.get("id")
        ep_coverage = [c for c in coverage_rows if c.get("endpoint_id") == ep_id]
        ep_findings = [f for f in findings if f.get("url") == ep.get("url")]

        tests_run = len([c for c in ep_coverage if c.get("status") not in ["pending"]])

        if any(c.get("status") == "vulnerable" for c in ep_coverage):
            status = "vulnerable"
        elif tests_run > 0:
            status = "tested"
        else:
            status = "untested"

        per_endpoint.append({
            "url": ep.get("url"),
            "method": ep.get("method"),
            "tests_run": tests_run,
            "findings": len(ep_findings),
            "status": status,
        })

    result = {
        "total_endpoints": total_endpoints,
        "tested_endpoints": tested_endpoints,
        "coverage_pct": round(coverage_pct, 1),
        "findings": {
            "total": len(findings),
            **findings_by_severity,
        },
        "budget": {
            "used": stats.get("total_requests", 0),
            "remaining": stats.get("max_total_requests", 10000) - stats.get("total_requests", 0),
        },
        "vuln_classes_tested": sorted(list(vuln_classes_tested)),
        "vuln_classes_untested": sorted(vuln_classes_untested[:10]),  # Limit to 10 for brevity
        "per_endpoint": per_endpoint,
    }

    return _json_content(result)
