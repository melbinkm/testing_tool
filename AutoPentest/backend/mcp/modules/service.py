"""
AutoPentest MCP Service - Unified MCP service with structured logging
"""
import asyncio
import time
import json
import re
import sys
from dataclasses import dataclass
from typing import Any, Dict, List, Optional
from pathlib import Path
import httpx

# Add parent directories to path for utils import
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from utils.logger import get_logger
from utils.log_context import set_assessment_id, set_container_name

# Global structured logger
logger = get_logger(__name__)
file_log = logger  # Alias for backward compatibility
log = logger  # Alias for backward compatibility


@dataclass
class SafeResult:
    """Structured result for safe_add_* methods.

    Replaces the previous Optional[Dict] return type so callers can
    distinguish success, skip (duplicate / no assessment), and error.
    """
    ok: bool
    data: Optional[Dict[str, Any]] = None
    skipped: bool = False
    reason: str = ""

    def __bool__(self) -> bool:
        return self.ok


class AssessmentScopeProvider:
    """Provides per-assessment scope validators and budget trackers.

    Manages caching and lazy-loading of scope configuration and budget state
    from the database. Each assessment gets its own isolated scope and budget.
    """

    def __init__(self, pool):
        """Initialize the scope provider.

        Parameters
        ----------
        pool : asyncpg.Pool
            Database connection pool for loading scope and budget state.
        """
        self.pool = pool
        self._validator_cache: Dict[int, Any] = {}  # assessment_id -> TargetValidator
        self._budget_tracker_cache: Dict[int, Any] = {}  # assessment_id -> BudgetTracker
        self._scope_cache: Dict[int, Any] = {}  # assessment_id -> EngagementScope
        self._cache_timestamps: Dict[int, float] = {}  # assessment_id -> timestamp
        self._cache_ttl: float = 300.0  # 5 minutes
        logger.info("AssessmentScopeProvider initialized")

    async def get_scope(self, assessment_id: int) -> Optional[Any]:
        """Get the scope configuration for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get scope for.

        Returns
        -------
        EngagementScope or None
            Scope configuration, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._scope_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached scope for assessment {assessment_id}")
                return self._scope_cache[assessment_id]

        # Load from database with file fallback
        try:
            from lib.scope_loader import load_scope_hybrid
            scope = await load_scope_hybrid(
                assessment_id,
                self.pool,
                fallback_file="./scope/engagement.yaml",
            )
            self._scope_cache[assessment_id] = scope
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Loaded scope for assessment {assessment_id}")
            return scope
        except Exception as exc:
            logger.warning(f"Failed to load scope for assessment {assessment_id}: {exc}")
            return None

    async def get_validator(self, assessment_id: int) -> Optional[Any]:
        """Get the scope validator for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get validator for.

        Returns
        -------
        TargetValidator or None
            Validator for this assessment's scope, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._validator_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached validator for assessment {assessment_id}")
                return self._validator_cache[assessment_id]

        # Get scope and create validator
        scope = await self.get_scope(assessment_id)
        if not scope:
            return None

        try:
            from lib.scope_validator import TargetValidator
            validator = TargetValidator(scope)
            self._validator_cache[assessment_id] = validator
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Created validator for assessment {assessment_id}")
            return validator
        except Exception as exc:
            logger.warning(f"Failed to create validator for assessment {assessment_id}: {exc}")
            return None

    async def get_budget_tracker(self, assessment_id: int) -> Optional[Any]:
        """Get the budget tracker for an assessment.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to get budget tracker for.

        Returns
        -------
        BudgetTracker or None
            Budget tracker for this assessment, or None if no scope configured.
        """
        # Check cache
        now = time.time()
        if assessment_id in self._budget_tracker_cache:
            cache_age = now - self._cache_timestamps.get(assessment_id, 0)
            if cache_age < self._cache_ttl:
                logger.debug(f"Using cached budget tracker for assessment {assessment_id}")
                return self._budget_tracker_cache[assessment_id]

        # Get scope and create budget tracker
        scope = await self.get_scope(assessment_id)
        if not scope:
            return None

        try:
            from lib.budget_tracker import BudgetTracker
            tracker = BudgetTracker(
                constraints=scope.constraints,
                assessment_id=assessment_id,
                pool=self.pool,
            )
            # Initialize tracker (loads state from DB)
            await tracker.initialize()

            self._budget_tracker_cache[assessment_id] = tracker
            self._cache_timestamps[assessment_id] = now
            logger.info(f"Created budget tracker for assessment {assessment_id}")
            return tracker
        except Exception as exc:
            logger.warning(f"Failed to create budget tracker for assessment {assessment_id}: {exc}")
            return None

    def invalidate_cache(self, assessment_id: int) -> None:
        """Invalidate cached scope/validator/tracker for an assessment.

        Call this when scope configuration changes to force reload.

        Parameters
        ----------
        assessment_id : int
            Assessment ID to invalidate cache for.
        """
        self._scope_cache.pop(assessment_id, None)
        self._validator_cache.pop(assessment_id, None)
        self._budget_tracker_cache.pop(assessment_id, None)
        self._cache_timestamps.pop(assessment_id, None)
        logger.info(f"Invalidated scope cache for assessment {assessment_id}")


class AutoPentestService:
    """AutoPentest MCP service with backend integration and container management"""

    def __init__(self, backend_url: str = None):
        # Load backend URL from environment or use default
        import os
        self.backend_url = backend_url or os.getenv("BACKEND_API_URL", "http://localhost:8000/api")
        self.current_assessment_id: Optional[int] = None
        self.current_assessment_name: Optional[str] = None
        self.current_base_url: Optional[str] = None  # Fix B3: Add current_base_url attribute
        self.http_client: Optional[httpx.AsyncClient] = None

        # Docker/Container management
        self.current_container: Optional[str] = None
        self.claude_container_name: str = "kali-autopentest"  # Default Kali container for AutoPentest
        self.containers_cache: List[Dict[str, Any]] = []
        self.cache_timestamp: float = 0
        self.cache_ttl: int = 30
        self.command_history: List[Dict[str, Any]] = []
        self.max_history: int = 50
        self.is_initialized: bool = False
        self.tool_cache: Dict[str, bool] = {}
        self.current_target: Optional[str] = None

        # Card deduplication cache
        self._card_title_cache: set = set()
        self._card_cache_assessment_id: Optional[int] = None

        # Activity logger for detailed audit trails (Fix 3)
        self.activity_logger: Optional[Any] = None

        # Output formatting settings
        self.output_max_length: int = 5000  # Default value
        self.output_max_length_cache_time: float = 0
        self.output_max_length_cache_ttl: int = 60  # Cache for 60 seconds

        # Command history settings
        self.command_history_limit: int = 10  # Default value
        self.command_history_limit_cache_time: float = 0
        self.command_history_limit_cache_ttl: int = 60  # Cache for 60 seconds

        # Scope provider (initialized in initialize() method)
        self.scope_provider: Optional[AssessmentScopeProvider] = None

    async def initialize(self):
        """Initialize HTTP client, asyncpg pool, and auto-detect containers"""
        self.http_client = httpx.AsyncClient(timeout=120.0)

        # Create asyncpg connection pool for the world model database
        try:
            import asyncpg
            import os
            db_url = os.getenv(
                "DATABASE_URL",
                "postgresql://autopentest:autopentest@localhost:5433/autopentest_db",
            )
            self.pg_pool = await asyncpg.create_pool(db_url, min_size=2, max_size=10)

            # Register the pool with the world model module
            from lib.world_model_db import set_shared_pool
            set_shared_pool(self.pg_pool)

            # Initialize scope provider for per-assessment scope management
            self.scope_provider = AssessmentScopeProvider(self.pg_pool)

            # Ensure activity_log table exists (Fix 9)
            try:
                async with self.pg_pool.acquire() as conn:
                    exists = await conn.fetchval(
                        "SELECT EXISTS(SELECT 1 FROM information_schema.tables WHERE table_name = 'activity_log')"
                    )
                    if not exists:
                        # Read and execute the SQL scripts
                        import os
                        scripts_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'scripts')
                        for script_name in ['create_activity_log_table.sql', 'create_activity_notify_trigger.sql']:
                            script_path = os.path.join(scripts_dir, script_name)
                            if os.path.exists(script_path):
                                with open(script_path) as f:
                                    await conn.execute(f.read())
                                file_log.info(f"Executed {script_name}")
            except Exception as e:
                file_log.warning(f"Failed to ensure activity_log table: {e}")

            # Auto-initialize ActivityLogger if assessment already set (Fix 1)
            if self.current_assessment_id:
                self.initialize_activity_logger()

            file_log.info("asyncpg connection pool created for world model")
        except Exception as exc:
            file_log.warning("Failed to create asyncpg pool: %s (world model tools will not work)", exc)
            self.pg_pool = None
            self.scope_provider = None

        if not self.is_initialized:
            file_log.info("Auto-detecting Kali containers...")
            containers = await self.discover_containers()

            # Look for existing pentest container
            pentest_container = next(
                (c for c in containers if c["name"] == self.claude_container_name),
                None
            )

            if pentest_container:
                self.current_container = self.claude_container_name
                file_log.info(f"Auto-selected pentest container: {self.claude_container_name}")
            else:
                # Look for running containers first
                running_containers = [c for c in containers if "running" in c["status"].lower()]
                if running_containers:
                    self.current_container = running_containers[0]["name"]
                    file_log.info(f"Auto-selected running container: {self.current_container}")
                elif containers:
                    self.current_container = containers[0]["name"]
                    file_log.info(f"Auto-selected first available container: {self.current_container}")

            self.is_initialized = True
            log.info("MCP initialized with backend connection and Docker capabilities")

    async def cleanup(self):
        """Cleanup resources"""
        if self.http_client:
            await self.http_client.aclose()
        if hasattr(self, 'pg_pool') and self.pg_pool:
            await self.pg_pool.close()
            file_log.info("asyncpg pool closed")

    # ========== Backend Integration Methods ==========

    def initialize_activity_logger(self):
        """Initialize ActivityLogger when an assessment is loaded (Fix 3).

        Called automatically by load_assessment tool handler after setting
        current_assessment_id. Requires pg_pool to be initialized.
        """
        if self.current_assessment_id and hasattr(self, 'pg_pool') and self.pg_pool:
            try:
                from lib.activity_logger import ActivityLogger
                self.activity_logger = ActivityLogger(
                    assessment_id=self.current_assessment_id,
                    db_pool=self.pg_pool
                )
                file_log.info(f"ActivityLogger initialized for assessment {self.current_assessment_id}")
            except Exception as e:
                file_log.warning(f"Failed to initialize ActivityLogger: {e}")
                self.activity_logger = None
        else:
            self.activity_logger = None

    async def get_assessment_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """Get assessment data by name"""
        try:
            # First get the list to find the ID
            response = await self.http_client.get(f"{self.backend_url}/assessments")
            response.raise_for_status()
            assessments = response.json()

            # Find assessment by name (case-insensitive and trim whitespace)
            assessment_id = None
            for assessment in assessments:
                if assessment["name"].strip().lower() == name.strip().lower():
                    assessment_id = assessment["id"]
                    break

            if not assessment_id:
                return None

            # Get full assessment data
            detail_response = await self.http_client.get(f"{self.backend_url}/assessments/{assessment_id}")
            detail_response.raise_for_status()
            return detail_response.json()

        except Exception as e:
            log.error(f"Error fetching assessment: {e}")
            return None

    async def get_assessment_full_data(self, assessment_id: int) -> Dict[str, Any]:
        """Get complete assessment data with all related info"""
        try:
            response = await self.http_client.get(
                f"{self.backend_url}/assessments/{assessment_id}/full"
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error fetching full assessment data: {e}")
            raise

    async def add_recon_data(
        self,
        assessment_id: int,
        data_type: str,
        name: str,
        details: Optional[Dict[str, Any]],
        discovered_in_phase: Optional[str]
    ) -> Dict[str, Any]:
        """Add recon data (endpoint, technology, service, subdomain)"""
        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/recon",
                json={
                    "data_type": data_type,
                    "name": name,
                    "details": details,
                    "discovered_in_phase": discovered_in_phase
                }
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error adding recon data: {e}")
            raise

    async def add_card(
        self,
        assessment_id: int,
        card_type: str,
        title: str,
        **kwargs
    ) -> Dict[str, Any]:
        """Add a card (finding, observation, info)"""
        try:
            card_data = {
                "card_type": card_type,
                "title": title,
                **kwargs
            }

            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/cards",
                json=card_data
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error adding card: {e}")
            raise

    async def update_section(
        self,
        assessment_id: int,
        section_type: str,
        section_number: float,
        title: Optional[str],
        content: str
    ) -> Dict[str, Any]:
        """Update or create a section (phase)"""
        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{assessment_id}/sections",
                json={
                    "section_type": section_type,
                    "section_number": section_number,
                    "title": title,
                    "content": content
                }
            )
            response.raise_for_status()
            return response.json()

        except Exception as e:
            log.error(f"Error updating section: {e}")
            raise

    # ========== Safe Auto-Save Methods ==========

    async def card_exists(self, assessment_id: int, title: str) -> bool:
        """Check if a card with the given title already exists for this assessment.

        Uses an in-memory title cache to avoid repeated API calls.
        """
        # Invalidate cache if assessment changed
        if self._card_cache_assessment_id != assessment_id:
            self._card_title_cache.clear()
            self._card_cache_assessment_id = assessment_id

        # Check cache first
        if title in self._card_title_cache:
            return True

        # Fetch cards from backend and populate cache
        try:
            response = await self.http_client.get(
                f"{self.backend_url}/assessments/{assessment_id}/cards"
            )
            if response.status_code == 200:
                cards = response.json()
                for card in cards:
                    card_title = card.get("title", "")
                    if card_title:
                        self._card_title_cache.add(card_title)
                return title in self._card_title_cache
        except Exception as e:
            log.warning(f"card_exists: failed to fetch cards: {e}")

        return False

    async def safe_add_card(
        self,
        card_type: str,
        title: str,
        **kwargs,
    ) -> SafeResult:
        """Add a card to the current assessment, safely.

        Never raises.  Returns a :class:`SafeResult` indicating success,
        skip (duplicate / no assessment), or error.
        """
        if self.current_assessment_id is None:
            log.error(f"safe_add_card: Cannot add card '{title}' - no assessment loaded")
            return SafeResult(ok=False, skipped=True, reason="no_assessment")

        # EAGER CACHE INVALIDATION: Clear cache if assessment changed
        # This prevents false duplicate detection when switching assessments
        if self._card_cache_assessment_id != self.current_assessment_id:
            log.debug(
                f"safe_add_card: Assessment changed ({self._card_cache_assessment_id} -> "
                f"{self.current_assessment_id}), clearing card cache"
            )
            self._card_title_cache.clear()
            self._card_cache_assessment_id = self.current_assessment_id

        # Normalize severity to uppercase for consistent display (Fix: CAPS vs lowercase issue)
        if "severity" in kwargs and isinstance(kwargs["severity"], str):
            kwargs["severity"] = kwargs["severity"].upper()

        # Auto-set section_number from current phase if not provided (Fix 2)
        if "section_number" not in kwargs and self.current_assessment_id:
            try:
                from lib.phase_orchestrator import PhaseOrchestrator
                from lib.world_model_db import get_world_model_db
                db = await get_world_model_db(self.current_assessment_id)
                orch = PhaseOrchestrator(db, activity_logger=self.activity_logger)
                current_phase = await orch._get_current_phase()
                kwargs["section_number"] = str(current_phase)
                log.debug(f"safe_add_card: Auto-set section_number={current_phase} from phase orchestrator")
            except Exception as e:
                kwargs["section_number"] = "3"  # Default to phase 3 (assessment)
                log.debug(f"safe_add_card: Failed to get current phase, defaulting to 3: {e}")

        try:
            if await self.card_exists(self.current_assessment_id, title):
                log.debug(f"safe_add_card: skipping duplicate '{title}'")
                return SafeResult(ok=True, skipped=True, reason="duplicate")

            result = await self.add_card(
                assessment_id=self.current_assessment_id,
                card_type=card_type,
                title=title,
                **kwargs,
            )
            self._card_title_cache.add(title)

            # Sync finding cards to wm_findings table (Fix 3)
            if card_type == "finding" and self.current_assessment_id:
                try:
                    from lib.world_model_db import get_world_model_db
                    db = await get_world_model_db(self.current_assessment_id)
                    # Create or find hypothesis for this finding
                    hypothesis_id = f"auto-{result.get('id', 'unknown')}"
                    await db.add_finding(
                        hypothesis_id=hypothesis_id,
                        title=title,
                        severity=kwargs.get("severity", "MEDIUM").lower(),
                        confidence=0.8,
                        evidence_ids=[],
                        remediation=kwargs.get("remediation"),
                        metadata={
                            "source": "safe_add_card",
                            "card_id": result.get("id"),
                            "status": kwargs.get("status", "confirmed"),
                            "technical_analysis": kwargs.get("technical_analysis", "")[:2000],
                        }
                    )
                    log.debug(f"safe_add_card: Synced finding to wm_findings table")
                except Exception as e:
                    log.debug(f"Failed to sync finding to wm_findings: {e}")

            # Auto-mark coverage matrix when a finding is created
            if card_type == "finding":
                await self._try_mark_coverage(
                    kwargs.get("target_service"), title, kwargs.get("context")
                )

            return SafeResult(ok=True, data=result)
        except Exception as e:
            log.warning(f"safe_add_card failed for '{title}': {e}")
            return SafeResult(ok=False, reason=f"error: {e}")

    # Signal type -> card metadata mapping (Universal Exchange Analysis - Fix 1)
    # Keys MUST match exactly what ExchangeAnalyzer emits in 'type' field
    _RISK_SIGNAL_CARDS = {
        # HIGH severity (3 signals)
        "cors_wildcard": ("Wildcard CORS Configuration", "high", "cors_misconfig"),
        "cors_null": ("CORS Null Origin Allowed", "high", "cors_misconfig"),
        "cors_credentials": ("CORS with Credentials Enabled", "high", "cors_misconfig"),
        "template_syntax": ("Potential Server-Side Template Injection", "high", "ssti"),

        # MEDIUM severity (11 signals)
        "missing_csp": ("Missing Content Security Policy Header", "medium", "security_headers"),
        "missing_hsts": ("Missing HTTP Strict Transport Security Header", "medium", "security_headers"),
        "cookie_missing_httponly": ("Insecure Cookie - Missing HttpOnly Flag", "medium", "cookie_security"),
        "cookie_missing_secure": ("Insecure Cookie - Missing Secure Flag", "medium", "cookie_security"),
        "missing_csrf_token": ("Missing CSRF Protection on Forms", "medium", "csrf"),
        "stack_trace_disclosure": ("Stack Trace Information Disclosure", "medium", "info_leak_errors"),
        "enumerable_id": ("Enumerable Resource IDs (IDOR Risk)", "medium", "idor"),
        "parameter_reflection": ("Parameter Reflected in Response (XSS Risk)", "medium", "xss_risk"),

        # LOW severity (7 signals)
        "missing_x_content_type_options": ("Missing X-Content-Type-Options Header", "low", "security_headers"),
        "invalid_x_content_type_options": ("Invalid X-Content-Type-Options Value", "low", "security_headers"),
        "missing_referrer_policy": ("Missing Referrer-Policy Header", "low", "security_headers"),
        "cookie_missing_samesite": ("Insecure Cookie - Missing SameSite Attribute", "low", "cookie_security"),
        "missing_cache_control_no_store": ("Missing Cache-Control No-Store on Sensitive Endpoint", "low", "security_headers"),
        "sensitive_comment": ("Sensitive Information in HTML Comments", "low", "info_leak_comments"),

        # INFO severity (4 signals) - these won't be auto-persisted but are tracked
        "version_disclosure": ("Server Version Disclosure", "info", "info_leak_headers"),
        "missing_x_xss_protection": ("Missing X-XSS-Protection Header", "info", "security_headers"),
        "missing_permissions_policy": ("Missing Permissions-Policy Header", "info", "security_headers"),
        "redirect_detected": ("HTTP Redirect Detected", "info", "redirect"),
        "error_page_title": ("Error Page Title Disclosure", "info", "info_leak_errors"),
        "jwt_detected": ("JWT Token Detected", "info", "auth_token"),
        "slow_response": ("Slow Response Time (Timing Attack Risk)", "info", "timing"),
    }

    async def auto_persist_risk_signals(self, risk_signals: list, url: str) -> int:
        """Auto-create finding cards from exchange analyzer risk signals.

        Only persists HIGH and MEDIUM severity signals. Returns count of cards created.

        Args:
            risk_signals: List of risk signal dicts from exchange analyzer
            url: Target URL for context

        Returns:
            Number of cards successfully created
        """
        if not risk_signals or not self.current_assessment_id:
            return 0

        created = 0
        seen_types = set()

        for signal in risk_signals:
            sig_type = signal.get("type", "")
            severity = signal.get("severity", "info")

            # Only persist high/medium/low severity (not info), deduplicate by type per call
            if severity in ("info",) or sig_type in seen_types:
                continue
            seen_types.add(sig_type)

            # Look up card info from mapping
            card_info = self._RISK_SIGNAL_CARDS.get(sig_type)
            if not card_info:
                continue

            title, card_severity, vuln_class = card_info
            detail = signal.get("detail", "")

            result = await self.safe_add_card(
                card_type="finding",
                title=title,
                severity=card_severity.upper(),  # Normalize to uppercase for consistent display
                target_service=url,
                context=f"Detected via automated exchange analysis. {detail}",
                technical_analysis=detail,
            )

            if result.ok and not result.skipped:
                created += 1
                log.info(f"auto_persist_risk_signals: Created finding '{title}' for {url}")

        return created

    async def safe_add_recon(
        self,
        data_type: str,
        name: str,
        details: Optional[Dict[str, Any]] = None,
        phase: Optional[str] = None,
    ) -> SafeResult:
        """Add recon data to the current assessment, safely.

        Never raises.  Returns a :class:`SafeResult`.
        """
        if self.current_assessment_id is None:
            return SafeResult(ok=False, skipped=True, reason="no_assessment")

        try:
            result = await self.add_recon_data(
                assessment_id=self.current_assessment_id,
                data_type=data_type,
                name=name,
                details=details,
                discovered_in_phase=phase,
            )
            return SafeResult(ok=True, data=result)
        except Exception as e:
            log.warning(f"safe_add_recon failed for '{name}': {e}")
            return SafeResult(ok=False, reason=f"error: {e}")

    async def safe_add_recon_batch(
        self,
        entries: List[Dict[str, Any]],
    ) -> SafeResult:
        """Add multiple recon entries in one call, safely.

        Each entry should have keys: data_type, name, and optionally
        details, discovered_in_phase.

        Never raises.  Returns a :class:`SafeResult`.
        """
        if self.current_assessment_id is None:
            return SafeResult(ok=False, skipped=True, reason="no_assessment")
        if not entries:
            return SafeResult(ok=True, skipped=True, reason="empty_entries")

        try:
            response = await self.http_client.post(
                f"{self.backend_url}/assessments/{self.current_assessment_id}/recon/batch",
                json=entries,
            )
            response.raise_for_status()
            return SafeResult(ok=True, data=response.json())
        except Exception as e:
            # Fallback: add entries one-by-one
            log.warning(f"safe_add_recon_batch: batch endpoint failed ({e}), falling back to individual adds")
            for entry in entries:
                await self.safe_add_recon(
                    data_type=entry.get("data_type", ""),
                    name=entry.get("name", ""),
                    details=entry.get("details"),
                    phase=entry.get("discovered_in_phase"),
                )
            return SafeResult(ok=False, reason=f"batch_failed_used_fallback: {e}")

    # ========== Coverage Tracking Integration ==========

    async def _try_mark_coverage(
        self,
        target_service: Optional[str],
        title: str,
        context: Optional[str],
    ) -> None:
        """Best-effort: auto-mark matching coverage cells as vulnerable.

        Infers vuln_class from title/context keywords and looks for a
        matching pending cell in the coverage matrix.  Failures are
        logged at debug level and never raised.
        """
        if self.current_assessment_id is None:
            return

        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(self.current_assessment_id)

            # Infer vuln_class from keywords in title + context
            combined = f"{title or ''} {context or ''}".lower()
            vuln_class = None
            keyword_map = {
                "sqli": ["sql injection", "sqli", "sql error", "union select"],
                "xss": ["xss", "cross-site scripting", "script injection"],
                "ssrf": ["ssrf", "server-side request"],
                "idor": ["idor", "insecure direct object", "bola"],
                "auth_bypass": ["auth bypass", "authentication bypass", "unauthorized"],
                "path_traversal": ["path traversal", "directory traversal", "lfi", "rfi"],
                "injection": ["command injection", "cmdi", "rce", "code injection"],
                "misconfig": ["misconfiguration", "misconfig", "default cred"],
                "info_disclosure": ["information disclosure", "info leak", "sensitive data"],
            }
            for vc, keywords in keyword_map.items():
                if any(kw in combined for kw in keywords):
                    vuln_class = vc
                    break

            if not vuln_class:
                return

            # Look for matching pending coverage cell
            rows = await db._fetchall(
                "SELECT id, endpoint_id FROM wm_coverage_matrix "
                "WHERE assessment_id = $1 AND vuln_class = $2 AND status = 'pending' "
                "LIMIT 5",
                (db._assessment_id, vuln_class),
            )

            if not rows:
                return

            # If target_service is set, try to match against endpoints
            for row in rows:
                cell_id = row["id"]
                try:
                    await db._execute(
                        "UPDATE wm_coverage_matrix SET status = 'vulnerable', "
                        "result_summary = $1, updated_at = NOW() "
                        "WHERE id = $2 AND assessment_id = $3",
                        (f"Auto-marked from finding: {title[:100]}", cell_id, db._assessment_id),
                    )
                    log.debug("Auto-marked coverage cell %s as vulnerable", cell_id)
                    break  # Mark only the first matching cell
                except Exception:
                    pass
        except Exception as exc:
            log.debug("_try_mark_coverage failed: %s", exc)

    # ========== Discovery Feedback Loop ==========

    async def _on_endpoint_discovered(self, event_data: Dict[str, Any]) -> None:
        """Best-effort hook called when new endpoints are discovered.

        Called by crawler, endpoint_probe, and form discovery when new
        endpoints are found. Attempts to auto-extend the coverage matrix
        if one exists for the current assessment.

        Parameters
        ----------
        event_data : dict
            Keys: source (str), count (int), optional crawl_id, endpoint_id, etc.
        """
        if self.current_assessment_id is None:
            return

        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(self.current_assessment_id)

            # Check if a coverage matrix exists (has any rows)
            rows = await db._fetchall(
                "SELECT COUNT(*) as cnt FROM wm_coverage_matrix WHERE assessment_id = $1",
                (db._assessment_id,),
            )
            if not rows or rows[0]["cnt"] == 0:
                return  # No coverage matrix yet, nothing to extend

            source = event_data.get("source", "unknown")
            count = event_data.get("count", 0)
            log.info(
                "Endpoint discovery: %d new endpoint(s) from %s â€” extending matrix",
                count, source,
            )

            # Auto-extend coverage matrix with new endpoints
            from lib.discovery_monitor import DiscoveryMonitor
            monitor = DiscoveryMonitor(db)

            since = event_data.get("since")
            if since:
                events = await monitor.check_new_endpoints(since)
                if events:
                    base_url = self.current_base_url or event_data.get("base_url", "")
                    if base_url:
                        extend_result = await monitor.extend_coverage(events, base_url)
                        new_cells = extend_result.get("new_cells_created", 0)
                        if new_cells > 0:
                            log.info("Coverage matrix extended by %d new cells", new_cells)

                            if self.activity_logger:
                                await self.activity_logger.log_recon_data(
                                    data_type="coverage_matrix_extension",
                                    count=new_cells,
                                    details={"source": source, "trigger": "auto_discovery"},
                                )

        except Exception as exc:
            log.debug("_on_endpoint_discovered failed: %s", exc)

    # ========== Docker/Container Methods ==========

    async def _run_command(self, command: List[str], timeout: float = 120.0) -> Dict[str, Any]:
        """Run a system command with timeout to prevent hangs on docker socket issues."""
        try:
            file_log.debug(f"Executing command: {' '.join(command)}")

            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=timeout
            )

            return {
                "success": process.returncode == 0,
                "returncode": process.returncode,
                "stdout": stdout.decode('utf-8', errors='replace').strip(),
                "stderr": stderr.decode('utf-8', errors='replace').strip(),
                "command": ' '.join(command),
                "error_type": self._classify_error(process.returncode, stderr.decode('utf-8', errors='replace'))
            }

        except asyncio.TimeoutError:
            try:
                process.kill()
                await process.communicate()
            except Exception:
                pass
            file_log.warning(f"Command timed out after {timeout}s: {' '.join(command)}")
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Command timed out after {timeout}s",
                "command": ' '.join(command),
                "error_type": "timeout",
                "raw_error": f"Timed out after {timeout}s"
            }

        except FileNotFoundError as e:
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Command not found: {command[0]}",
                "command": ' '.join(command),
                "error_type": "command_not_found",
                "raw_error": str(e)
            }
        except Exception as e:
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Execution failed: {str(e)}",
                "command": ' '.join(command),
                "error_type": "execution_failed",
                "raw_error": str(e)
            }

    def _classify_error(self, returncode: int, stderr: str) -> str:
        """Classify the type of error based on return code and stderr"""
        if returncode == 127:
            return "command_not_found"
        elif returncode == 126:
            return "permission_denied"
        elif returncode == 2:
            return "invalid_arguments"
        elif "not found" in stderr.lower():
            return "command_not_found"
        elif "permission denied" in stderr.lower():
            return "permission_denied"
        elif "invalid" in stderr.lower() or "usage:" in stderr.lower():
            return "invalid_command"
        elif returncode != 0:
            return "command_failed"
        else:
            return "success"

    async def check_tool_availability(self, tool_name: str) -> bool:
        """Check if a tool is available in the container"""
        if not self.current_container:
            return False

        # Use cache if available
        cache_key = f"{self.current_container}:{tool_name}"
        if cache_key in self.tool_cache:
            return self.tool_cache[cache_key]

        try:
            result = await self._run_command([
                "docker", "exec", self.current_container, "bash", "-c",
                f"which {tool_name}"
            ])

            available = result["success"]
            self.tool_cache[cache_key] = available
            return available

        except Exception:
            self.tool_cache[cache_key] = False
            return False

    async def validate_container_status(self) -> Dict[str, Any]:
        """Validate and potentially start the current container"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        try:
            # Check container status
            result = await self._run_command([
                "docker", "inspect", self.current_container, "--format", "{{.State.Status}}"
            ])

            if not result["success"]:
                return {"success": False, "error": "Container not found", "details": result["stderr"]}

            status = result["stdout"].strip()

            if status == "running":
                return {"success": True, "status": "running"}
            elif status in ["created", "exited"]:
                # Try to start the container
                file_log.info(f"Starting container {self.current_container}...")
                start_result = await self._run_command([
                    "docker", "start", self.current_container
                ])

                if start_result["success"]:
                    return {"success": True, "status": "started"}
                else:
                    return {
                        "success": False,
                        "error": f"Failed to start container",
                        "details": start_result["stderr"]
                    }
            else:
                return {"success": False, "error": f"Container in invalid state: {status}"}

        except Exception as e:
            return {"success": False, "error": f"Container validation failed: {str(e)}"}

    async def get_output_max_length(self) -> int:
        """Get output_max_length setting from backend (with cache)"""
        current_time = time.time()

        # Return cached value if still valid
        if (current_time - self.output_max_length_cache_time) < self.output_max_length_cache_ttl:
            return self.output_max_length

        # Fetch from backend
        try:
            response = await self.http_client.get(f"{self.backend_url}/system/settings/output_max_length")
            if response.status_code == 200:
                data = response.json()
                self.output_max_length = int(data["value"])
                self.output_max_length_cache_time = current_time
                file_log.debug(f"Loaded output_max_length setting: {self.output_max_length}")
            else:
                file_log.warning(f"Failed to load output_max_length setting, using default: {self.output_max_length}")
        except Exception as e:
            file_log.warning(f"Error fetching output_max_length setting: {e}, using default: {self.output_max_length}")

        return self.output_max_length

    async def get_command_history_limit(self) -> int:
        """Get command_history_limit setting from backend (with cache)"""
        current_time = time.time()

        # Return cached value if still valid
        if (current_time - self.command_history_limit_cache_time) < self.command_history_limit_cache_ttl:
            return self.command_history_limit

        # Fetch from backend
        try:
            response = await self.http_client.get(f"{self.backend_url}/system/settings/command_history_limit")
            if response.status_code == 200:
                data = response.json()
                self.command_history_limit = int(data["value"])
                self.command_history_limit_cache_time = current_time
                file_log.debug(f"Loaded command_history_limit setting: {self.command_history_limit}")
            else:
                file_log.warning(f"Failed to load command_history_limit setting, using default: {self.command_history_limit}")
        except Exception as e:
            file_log.warning(f"Error fetching command_history_limit setting: {e}, using default: {self.command_history_limit}")

        return self.command_history_limit

    def format_output(self, output: str, max_length: Optional[int] = None) -> str:
        """Format and truncate output for display"""
        if not output:
            return output

        # Use provided max_length or fall back to instance variable
        if max_length is None:
            max_length = self.output_max_length

        # Remove ANSI escape sequences
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        clean_output = ansi_escape.sub('', output)

        # Truncate if too long (skip if max_length is -1 for unlimited)
        if max_length != -1 and len(clean_output) > max_length:
            return clean_output[:max_length] + f"\n\n...(output truncated - showing {max_length}/{len(clean_output)} chars)"

        return clean_output

    async def discover_containers(self, force_refresh: bool = False) -> List[Dict[str, Any]]:
        """Discover Kali pentesting containers with intelligent caching"""
        current_time = time.time()

        if (not force_refresh and
                self.containers_cache and
                (current_time - self.cache_timestamp) < self.cache_ttl):
            file_log.debug("Using cached container list")
            return self.containers_cache

        file_log.info("Discovering Kali containers...")
        containers = []

        try:
            # Try Docker approach first
            result = await self._run_command([
                "docker", "ps", "-a",
                "--format", "json"
            ])

            if result["success"] and result["stdout"]:
                for line in result["stdout"].split('\n'):
                    if line.strip():
                        try:
                            container_data = json.loads(line)
                            image = container_data.get("Image", "")
                            name = container_data.get("Names", "unknown").lstrip('/')

                            if ("kali" in image.lower() or
                                    "kalilinux" in image.lower() or
                                    name.startswith(("kali-", "pentest-"))):
                                containers.append({
                                    "name": name,
                                    "image": image,
                                    "status": container_data.get("State", "unknown"),
                                    "id": container_data.get("ID", "unknown")[:12],
                                    "created": container_data.get("CreatedAt", "unknown"),
                                    "ports": [],
                                    "source": "docker"
                                })
                        except (json.JSONDecodeError, KeyError, AttributeError) as e:
                            file_log.debug(f"Error parsing container data: {e}")
                            continue

        except Exception as e:
            log.error(f"Docker discovery failed: {e}")
            containers = []

        self.containers_cache = containers
        self.cache_timestamp = current_time
        file_log.info(f"Discovered {len(containers)} containers")
        return containers

    async def execute_container_command(self, container_name: str, command: str) -> Dict[str, Any]:
        """Execute a command in a pentesting container with improved error handling"""
        file_log.info(f"Executing in {container_name}: {command[:50]}...")

        # Validate container first
        validation = await self.validate_container_status()
        if not validation["success"]:
            return {
                "success": False,
                "container": container_name,
                "command": command,
                "error": f"Container validation failed: {validation['error']}",
                "details": validation.get("details", ""),
                "execution_time": 0
            }

        start_time = time.time()

        try:
            # Execute command directly (Kali doesn't need bashrc sourcing like Exegol)
            wrapped_command = f"{command}"

            result = await self._run_command([
                "docker", "exec", container_name, "bash", "-c", wrapped_command
            ])

            execution_time = time.time() - start_time

            # Add to history
            if len(self.command_history) >= self.max_history:
                self.command_history = self.command_history[-25:]

            self.command_history.append({
                "timestamp": start_time,
                "container": container_name,
                "command": command[:100] + "..." if len(command) > 100 else command,
                "success": result["success"],
                "execution_time": execution_time
            })

            # Persist to command_history table for audit trail
            await self._log_command_to_db(
                container_name=container_name,
                command=command,
                stdout=result.get("stdout", ""),
                stderr=result.get("stderr", ""),
                returncode=result.get("returncode"),
                execution_time=execution_time,
                success=result["success"],
            )

            # Refresh output_max_length setting from backend
            await self.get_output_max_length()

            # Format outputs - preserve raw error messages
            formatted_stdout = self.format_output(result["stdout"]) if result["stdout"] else ""
            formatted_stderr = result["stderr"] if result["stderr"] else ""

            return {
                "success": result["success"],
                "container": container_name,
                "command": command,
                "stdout": formatted_stdout,
                "stderr": formatted_stderr,
                "returncode": result["returncode"],
                "execution_time": execution_time,
                "error_type": result.get("error_type", "success"),
                "raw_error": result.get("raw_error", ""),
                "method": "docker"
            }

        except Exception as e:
            execution_time = time.time() - start_time

            self.command_history.append({
                "timestamp": start_time,
                "container": container_name,
                "command": command[:100] + "..." if len(command) > 100 else command,
                "success": False,
                "execution_time": execution_time,
                "error": str(e)
            })

            # Persist failed command to database
            await self._log_command_to_db(
                container_name=container_name,
                command=command,
                stderr=str(e),
                execution_time=execution_time,
                success=False,
            )

            return {
                "success": False,
                "container": container_name,
                "command": command,
                "error": str(e),
                "execution_time": execution_time,
                "error_type": "execution_failed"
            }

    async def _log_command_to_db(
        self,
        container_name: str,
        command: str,
        stdout: str = "",
        stderr: str = "",
        returncode: Optional[int] = None,
        execution_time: float = 0.0,
        success: bool = False,
    ) -> None:
        """Persist a command execution to the command_history table.

        Best-effort: failures are logged but never raised.
        """
        if not (hasattr(self, "pg_pool") and self.pg_pool and self.current_assessment_id):
            return
        try:
            async with self.pg_pool.acquire() as conn:
                await conn.execute(
                    """INSERT INTO command_history
                       (assessment_id, container_name, command, stdout, stderr,
                        returncode, execution_time, success, phase, status, created_at)
                       VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, NOW())""",
                    self.current_assessment_id,
                    container_name,
                    command[:2000],
                    (stdout or "")[:10000],
                    (stderr or "")[:5000],
                    returncode,
                    execution_time,
                    success,
                    None,  # phase â€” could be wired later
                    "completed" if success else "failed",
                )
                file_log.debug(
                    "Logged command to database for assessment %s",
                    self.current_assessment_id,
                )
        except Exception as e:
            file_log.warning("Failed to log command to database: %s", e)

    async def subdomain_enumeration(self, domain: str) -> Dict[str, Any]:
        """Perform subdomain enumeration using available tools"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        commands = []
        results = []

        # Check for subfinder
        if await self.check_tool_availability("subfinder"):
            commands.append(f"subfinder -d {domain} -silent")

        # Check for amass
        if await self.check_tool_availability("amass"):
            commands.append(f"amass enum -passive -d {domain}")

        # Fallback to basic DNS techniques
        if not commands:
            commands.append(f"dig +short {domain} ANY")
            commands.append(f"dig +short www.{domain}")
            commands.append(f"dig +short mail.{domain}")
            commands.append(f"dig +short ftp.{domain}")

        for cmd in commands:
            result = await self.execute_container_command(self.current_container, cmd)
            results.append({
                "command": cmd,
                "success": result["success"],
                "output": result.get("stdout", ""),
                "error": result.get("stderr", ""),
                "error_type": result.get("error_type", "")
            })

        return {"success": True, "results": results}

    async def ssl_analysis(self, target: str) -> Dict[str, Any]:
        """Perform SSL certificate analysis"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        # Parse target to get host and port
        if ":" in target:
            host, port = target.split(":", 1)
        else:
            host, port = target, "443"

        commands = [
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -text",
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -dates",
            f"openssl s_client -connect {host}:{port} -servername {host} </dev/null 2>/dev/null | openssl x509 -noout -subject -issuer"
        ]

        results = []
        for cmd in commands:
            result = await self.execute_container_command(self.current_container, cmd)
            results.append({
                "command": cmd.split(" | ")[-1],
                "success": result["success"],
                "output": result.get("stdout", ""),
                "error": result.get("stderr", ""),
                "error_type": result.get("error_type", "")
            })

        return {"success": True, "results": results}

    async def tech_stack_detection(self, url: str) -> Dict[str, Any]:
        """Detect technology stack of a website"""
        if not self.current_container:
            return {"success": False, "error": "No container selected"}

        # Ensure URL has protocol
        if not url.startswith(("http://", "https://")):
            url = f"https://{url}"

        commands = [
            f"curl -I {url} 2>/dev/null | head -20",
            f"curl -s {url} 2>/dev/null | grep -i 'generator\\|powered\\|built\\|framework' | head -10",
            f"whatweb {url}" if await self.check_tool_availability("whatweb") else f"curl -s {url} 2>/dev/null | head -50"
        ]

        results = []
        for cmd in commands:
            if cmd:
                result = await self.execute_container_command(self.current_container, cmd)
                results.append({
                    "command": cmd.split(" | ")[0],
                    "success": result["success"],
                    "output": result.get("stdout", ""),
                    "error": result.get("stderr", ""),
                    "error_type": result.get("error_type", "")
                })

        return {"success": True, "results": results}
