"""
MCP Resources - Resource definitions and handlers
"""
import json
from typing import List
from mcp.types import Resource


def get_resources() -> List[Resource]:
    """List available resources"""
    return [
        Resource(
            uri="kali://status",
            name="Current Status",
            description="Current assessment status and container info",
            mimeType="application/json"
        ),
        Resource(
            uri="kali://containers",
            name="Kali Containers",
            description="List of all Kali pentesting containers",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://error-recovery",
            name="Error Recovery Patterns",
            description="Common errors and step-by-step recovery strategies for autonomous error handling",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://attack-patterns",
            name="Attack Chaining Patterns",
            description="Proven multi-tool attack sequences for complex exploitation chains",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://budget-optimization",
            name="Budget Management Strategies",
            description="Smart strategies for managing request budget and scope constraints",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://workflow-guide",
            name="Phase Workflow Guide",
            description="Dynamic workflow recommendations based on current assessment phase and state",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://tool-dependencies",
            name="Tool Dependencies & Chains",
            description="Tool sequencing rules, prerequisites, and common multi-tool workflows",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://tool-metadata",
            name="Tool Metadata Registry",
            description="Machine-readable tool categories, dependencies, risk levels, and phase mappings for all 98 tools",
            mimeType="application/json"
        )
    ]


async def handle_resource_read(uri: str, mcp_service) -> str:
    """Read resource content"""
    await mcp_service.initialize()

    if uri == "kali://status":
        status_info = {
            "current_assessment": mcp_service.current_assessment_name,
            "assessment_id": mcp_service.current_assessment_id,
            "current_container": mcp_service.current_container,
            "current_target": mcp_service.current_target,
            "containers_available": len(mcp_service.containers_cache),
            "recent_commands": len(mcp_service.command_history),
            "tool_cache_size": len(mcp_service.tool_cache)
        }
        return json.dumps(status_info, indent=2)

    elif uri == "kali://containers":
        containers = await mcp_service.discover_containers()
        return json.dumps(containers, indent=2)

    elif uri == "autopentest://error-recovery":
        return json.dumps(_get_error_recovery_patterns(), indent=2)

    elif uri == "autopentest://attack-patterns":
        return json.dumps(_get_attack_patterns(), indent=2)

    elif uri == "autopentest://budget-optimization":
        return json.dumps(_get_budget_optimization(), indent=2)

    elif uri == "autopentest://workflow-guide":
        return json.dumps(await _generate_workflow_guide(mcp_service), indent=2)

    elif uri == "autopentest://tool-dependencies":
        return json.dumps(_get_tool_dependencies(), indent=2)

    elif uri == "autopentest://tool-metadata":
        from lib.tool_metadata import TOOL_METADATA, TOOL_CATEGORIES, PHASE_TOOLS
        return json.dumps({
            "tool_metadata": TOOL_METADATA,
            "categories": TOOL_CATEGORIES,
            "phase_tools": PHASE_TOOLS,
            "summary": {
                "total_tools": len(TOOL_METADATA),
                "by_category": {cat: len(tools) for cat, tools in TOOL_CATEGORIES.items()},
                "by_phase": {phase: len(tools) for phase, tools in PHASE_TOOLS.items()},
                "high_risk_tools": len([t for t, m in TOOL_METADATA.items() if m.get("risk_level") == "high_risk"]),
                "high_budget_tools": len([t for t, m in TOOL_METADATA.items() if m.get("budget_impact") == "high"])
            }
        }, indent=2)

    else:
        raise ValueError(f"Unknown resource: {uri}")


def _get_error_recovery_patterns() -> dict:
    """Common errors and recovery strategies for autonomous error handling."""
    return {
        "common_errors": {
            "scope_violation": {
                "symptoms": ["out of scope", "target not in allowlist", "scope validation failed"],
                "recovery": [
                    "1. Call scope_get_allowlist() to see all allowed targets, domains, and IP ranges",
                    "2. Verify target matches allowlist patterns (exact domain, wildcard subdomain, or IP range)",
                    "3. If legitimately out of scope: document as observation and skip testing",
                    "4. If should be in scope: inform user and ask them to update allowlist configuration",
                    "5. Never bypass scope validation - fail closed for safety"
                ],
                "prevention": "Always call scope_validate_target() before ANY request to a target"
            },
            "budget_exhausted": {
                "symptoms": ["budget exceeded", "rate limit reached", "too many requests"],
                "recovery": [
                    "1. Call scope_check_budget() to see remaining requests and per-target limits",
                    "2. If >50 requests remain: prioritize high-value tests (coverage cells with priority>70)",
                    "3. If 20-50 requests: only test confirmed vulnerabilities and skip broad scanning",
                    "4. If <20 requests: complete evidence collection and generate report",
                    "5. Use http_send_batch() for parallel requests to optimize budget",
                    "6. Skip expensive tools: nuclei_scan_template, fuzz_endpoint, crawler_start"
                ],
                "prevention": "Call scope_check_budget() every 20-30 tool calls, especially before high-cost operations"
            },
            "empty_crawl_results": {
                "symptoms": ["0 pages crawled", "no endpoints found", "crawler returned empty"],
                "recovery": [
                    "1. Check if JavaScript rendering needed: use browser_navigate() + browser_discover_forms()",
                    "2. Try authenticated crawl: credentials_add() then crawler_start(identity_id=...)",
                    "3. Use directory discovery: execute('gobuster dir ...') or scan(type='gobuster')",
                    "4. Parse API specs if available: openapi_parse() + openapi_list_endpoints()",
                    "5. Manual endpoint addition: wm_add_endpoint() for known paths"
                ],
                "prevention": "Check if target uses JavaScript-heavy SPA or requires authentication before crawling"
            },
            "nuclei_no_findings": {
                "symptoms": ["0 vulnerabilities found", "all nuclei templates returned clean"],
                "recovery": [
                    "1. This is EXPECTED for secure targets - not an error",
                    "2. Proceed to manual testing: fuzz_parameter(), endpoint_execute_plan()",
                    "3. Focus on business logic: sequence_workflow_bypass(), auth_diff_test()",
                    "4. Test authorization: auth_diff_test() with multiple identities",
                    "5. Custom injection tests: http_send() with crafted payloads"
                ],
                "note": "Nuclei finds known CVEs and misconfigurations, not custom application logic flaws"
            },
            "validation_failure": {
                "symptoms": ["validate_repro failed", "cannot reproduce", "inconsistent results"],
                "recovery": [
                    "1. Check if timing-dependent: retry validate_repro() 2-3 times",
                    "2. Verify credentials still valid: test authentication separately",
                    "3. Check if WAF detected and blocked: look for 403/429 status codes",
                    "4. Verify exact request parameters: ensure payload not URL-encoded incorrectly",
                    "5. If consistently fails (3+ attempts): downgrade to 'observation' not 'finding'",
                    "6. Document unreliability in notes even if eventually succeeds"
                ],
                "prevention": "Run validate_repro() immediately after discovering potential finding, before state changes"
            },
            "tool_not_available": {
                "symptoms": ["tool not available", "command not found", "tool_help returned empty"],
                "recovery": [
                    "1. Check tool name spelling and case sensitivity",
                    "2. Use tool_help() to verify tool exists in Kali container",
                    "3. Try alternative tools: gobuster instead of ffuf, subfinder instead of amass",
                    "4. Use execute() with explicit path: /usr/bin/tool instead of tool",
                    "5. Install tool if missing: execute('apt-get update && apt-get install -y tool')"
                ],
                "prevention": "Call tool_help() before first use of unfamiliar tools"
            },
            "timeout": {
                "symptoms": ["timeout exceeded", "operation timed out", "no response"],
                "recovery": [
                    "1. For scan timeouts: reduce scope (fewer ports, specific targets only)",
                    "2. For directory scan timeouts: use smaller wordlist (wordlist='common')",
                    "3. For http_send timeouts: increase timeout parameter or check if target is down",
                    "4. For execute timeouts: break command into smaller steps or run manually",
                    "5. Verify target is responsive: simple GET request before complex scan"
                ],
                "prevention": "Start with quick scans (nmap_quick, common wordlist) before comprehensive scans"
            },
            "authentication_required": {
                "symptoms": ["401 Unauthorized", "403 Forbidden", "login required", "authentication needed"],
                "recovery": [
                    "1. Check scope_get_identities() for available credentials",
                    "2. If credentials exist: use identity_id parameter in crawler_start() or http_send()",
                    "3. If no credentials: test authentication bypass first (auth_diff_test, http_send with header manipulation)",
                    "4. Document accessible vs. authenticated attack surface separately",
                    "5. Re-run discovery after obtaining credentials: crawler_start(identity_id=...) then coverage_discover()"
                ],
                "note": "Always test both unauthenticated and authenticated attack surfaces separately"
            }
        },
        "general_principles": [
            "Read error messages carefully - they often suggest the fix",
            "Check budget and scope before retrying expensive operations",
            "Try alternative approaches when primary tool fails",
            "Document failures as observations even if they don't lead to findings",
            "Don't retry the exact same operation more than 3 times",
            "Consult tool descriptions for known failure modes and workarounds"
        ]
    }


def _get_attack_patterns() -> dict:
    """Proven multi-tool attack sequences for complex exploitation chains."""
    return {
        "patterns": {
            "auth_bypass_exploitation": {
                "description": "Full exploitation chain after discovering authentication bypass vulnerability",
                "use_when": "You discovered a way to bypass authentication (missing auth check, JWT manipulation, session fixation, etc.)",
                "sequence": [
                    {
                        "phase": "Confirm",
                        "tools": ["validate_repro", "validate_negative_control", "validate_promote"],
                        "note": "Ensure bypass is reproducible and not a false positive"
                    },
                    {
                        "phase": "Document",
                        "tools": ["evidence_bundle", "evidence_add_artifact", "poc_generate"],
                        "note": "Capture evidence before state changes"
                    },
                    {
                        "phase": "Store Credentials",
                        "tools": ["credentials_add"],
                        "note": "Store the bypass method as a usable identity for follow-up testing"
                    },
                    {
                        "phase": "Re-Crawl",
                        "tools": ["crawler_start"],
                        "params": {"identity_id": "<bypass_cred_id>"},
                        "note": "Re-crawl application with bypassed/elevated access to discover authenticated endpoints"
                    },
                    {
                        "phase": "Extend Coverage",
                        "tools": ["coverage_discover", "coverage_refresh"],
                        "note": "Detect newly accessible endpoints and add them to coverage matrix"
                    },
                    {
                        "phase": "Test New Surface",
                        "tools": ["coverage_next", "endpoint_execute_plan"],
                        "note": "Test the newly discovered authenticated endpoints for additional vulnerabilities"
                    },
                    {
                        "phase": "Document Chain",
                        "tools": ["wm_add_relationship"],
                        "params": {"rel_type": "leads_to"},
                        "note": "Link auth bypass finding to secondary findings discovered via elevated access"
                    }
                ],
                "expected_outcome": "Complete mapping of authenticated attack surface and potential secondary vulnerabilities"
            },
            "idor_to_data_exfil": {
                "description": "Chain IDOR discovery to comprehensive data enumeration and exfiltration",
                "use_when": "You found an endpoint where changing user ID/resource ID grants unauthorized access to other users' data",
                "sequence": [
                    {
                        "phase": "Discover",
                        "tools": ["auth_diff_test"],
                        "params": {"url": "/api/users/{id}", "identity_ids": ["user_a", "user_b"]},
                        "note": "Confirm different users can access each other's resources by changing ID parameter"
                    },
                    {
                        "phase": "Validate Ownership",
                        "tools": ["sequence_data_ownership"],
                        "params": {"url_template": "/api/users/{id}", "resource_ids": [1, 2, 3, 5, 10, 100]},
                        "note": "Test sample IDs to confirm pattern and identify accessible ID range"
                    },
                    {
                        "phase": "Enumerate IDs",
                        "tools": ["http_send_batch"],
                        "note": "Batch enumerate all accessible IDs (respect budget limits - prioritize sample over exhaustive)",
                        "caution": "Check budget first: scope_check_budget(). For large ID spaces, enumerate sample (every 10th, 100th)"
                    },
                    {
                        "phase": "Evidence Collection",
                        "tools": ["evidence_bundle", "evidence_add_artifact"],
                        "note": "Capture request/response examples showing unauthorized access to multiple users' data"
                    },
                    {
                        "phase": "Risk Assessment",
                        "tools": ["risk_score"],
                        "params": {"data_classification": "confidential", "confidence": 0.9},
                        "note": "Calculate business impact based on data sensitivity"
                    }
                ],
                "expected_outcome": "Proof of IDOR vulnerability with evidence of data exfiltration and business impact assessment"
            },
            "sqli_to_rce": {
                "description": "Escalate SQL injection to remote code execution through database features",
                "use_when": "You confirmed SQL injection in a parameter and want to maximize impact",
                "sequence": [
                    {
                        "phase": "Detect",
                        "tools": ["fuzz_parameter"],
                        "params": {"payload_types": ["sqli_db"], "db_type": "mysql"},
                        "note": "Identify SQL injection with database-specific payloads"
                    },
                    {
                        "phase": "Validate",
                        "tools": ["validate_repro", "validate_negative_control"],
                        "note": "Confirm injection is real and not a false positive from error message variations"
                    },
                    {
                        "phase": "Promote",
                        "tools": ["validate_promote", "evidence_bundle"],
                        "note": "Mark as confirmed finding and start evidence collection"
                    },
                    {
                        "phase": "Advanced Exploitation",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap -u 'URL' -p 'param' --batch --risk=3 --level=5 --threads=5"},
                        "note": "Use sqlmap for advanced enumeration: db version, users, tables, data extraction"
                    },
                    {
                        "phase": "Privilege Escalation",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --is-dba --privileges"},
                        "note": "Check if database user has DBA privileges for file operations"
                    },
                    {
                        "phase": "File Operations",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --file-write=shell.php --file-dest=/var/www/html/shell.php"},
                        "note": "Attempt file write (PHP webshell) if DBA. ONLY if explicitly authorized in scope."
                    },
                    {
                        "phase": "OS Command Execution",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --os-shell"},
                        "note": "Attempt command execution via xp_cmdshell (MSSQL) or sys_exec (MySQL). HIGH RISK - requires explicit authorization."
                    },
                    {
                        "phase": "Documentation",
                        "tools": ["wm_store", "poc_generate", "evidence_add_artifact"],
                        "note": "Store full sqlmap output, generate PoC, and package evidence"
                    }
                ],
                "expected_outcome": "Comprehensive SQLi documentation from detection through potential RCE",
                "warnings": [
                    "OS command execution and file write operations are HIGH RISK",
                    "Verify scope explicitly permits exploitation beyond detection",
                    "Stop at database enumeration if RCE attempts are out of scope"
                ]
            },
            "xss_to_session_hijack": {
                "description": "Escalate XSS discovery to session hijacking and account takeover demonstration",
                "use_when": "You discovered XSS and want to demonstrate maximum business impact",
                "sequence": [
                    {
                        "phase": "Detect",
                        "tools": ["browser_test_xss", "fuzz_parameter"],
                        "params": {"payload_types": ["injection", "format"]},
                        "note": "Identify XSS vulnerability in parameter with JavaScript execution"
                    },
                    {
                        "phase": "Confirm Execution",
                        "tools": ["browser_navigate", "browser_eval"],
                        "params": {"expression": "document.cookie"},
                        "note": "Load page in real browser and verify JavaScript executes in user context"
                    },
                    {
                        "phase": "Test Cookie Exfiltration",
                        "tools": ["browser_eval"],
                        "params": {"expression": "document.cookie"},
                        "note": "Check if session cookies are accessible (httpOnly flag not set)"
                    },
                    {
                        "phase": "Visual Evidence",
                        "tools": ["browser_screenshot"],
                        "note": "Capture screenshot of alert() or modified DOM as visual proof"
                    },
                    {
                        "phase": "Validate",
                        "tools": ["validate_repro", "validate_negative_control"],
                        "note": "Confirm XSS is reproducible and not filtered by WAF"
                    },
                    {
                        "phase": "PoC Development",
                        "tools": ["poc_generate"],
                        "note": "Generate PoC showing session cookie exfiltration payload (DO NOT actually exfiltrate)"
                    },
                    {
                        "phase": "Evidence Collection",
                        "tools": ["evidence_bundle", "evidence_add_artifact"],
                        "note": "Package screenshot, PoC, request/response, and cookie accessibility proof"
                    }
                ],
                "expected_outcome": "Demonstrated XSS with proof of session cookie accessibility for account takeover scenario",
                "warnings": [
                    "DO NOT actually exfiltrate session cookies to external server",
                    "Stop at proof-of-concept - demonstrate capability without causing harm"
                ]
            },
            "subdomain_takeover": {
                "description": "Discover and validate subdomain takeover vulnerability through full reconnaissance chain",
                "use_when": "Performing domain reconnaissance and discovering dangling DNS records",
                "sequence": [
                    {
                        "phase": "Discovery",
                        "tools": ["subdomain_enum"],
                        "note": "Discover all subdomains via passive reconnaissance"
                    },
                    {
                        "phase": "Validation",
                        "tools": ["scope_validate_target"],
                        "note": "Verify each subdomain is in scope before testing"
                    },
                    {
                        "phase": "DNS Analysis",
                        "tools": ["execute"],
                        "params": {"command": "dig +short subdomain.example.com"},
                        "note": "Check DNS records for each subdomain to identify CNAME records"
                    },
                    {
                        "phase": "HTTP Testing",
                        "tools": ["http_send"],
                        "note": "Attempt to access each subdomain and look for service-specific takeover signatures"
                    },
                    {
                        "phase": "Service Identification",
                        "tools": ["tech_detection"],
                        "note": "Identify hosting platform (GitHub Pages, AWS S3, Heroku, etc.) for dangling CNAMEs"
                    },
                    {
                        "phase": "Takeover Validation",
                        "note": "Document dangling CNAME but DO NOT claim subdomain - only demonstrate vulnerability exists"
                    },
                    {
                        "phase": "Documentation",
                        "tools": ["add_card", "evidence_bundle"],
                        "note": "Document finding with DNS records, HTTP responses, and service identification"
                    }
                ],
                "expected_outcome": "Subdomain takeover vulnerability documented without actual takeover",
                "warnings": [
                    "DO NOT claim or takeover subdomains - only document vulnerability",
                    "Subdomain takeover can have legal implications - document, don't exploit"
                ]
            }
        },
        "general_workflow": {
            "description": "Standard multi-tool workflow for comprehensive endpoint testing",
            "sequence": [
                "1. Discover (recon_pipeline_run, crawler_start, openapi_parse)",
                "2. Map (coverage_init, wm_add_endpoint, wm_add_hypothesis)",
                "3. Prioritize (coverage_next with priority>70 first)",
                "4. Test (endpoint_execute_plan, fuzz_parameter, auth_diff_test)",
                "5. Validate (validate_repro, validate_negative_control, validate_promote)",
                "6. Document (evidence_bundle, poc_generate, evidence_export)",
                "7. Report (evidence_generate_report only when user requests)"
            ]
        }
    }


def _get_budget_optimization() -> dict:
    """Smart strategies for managing request budget and scope constraints."""
    return {
        "budget_check_frequency": "Call scope_check_budget() every 20-30 tool calls, especially before high-cost operations",
        "optimization_strategies": {
            "high_budget": {
                "threshold": ">500 requests remaining",
                "strategy": "Comprehensive discovery - use all reconnaissance and scanning tools",
                "recommended_tools": [
                    "recon_pipeline_run (full 6-stage pipeline)",
                    "crawler_start (with max_pages=200)",
                    "nuclei_scan_template (with multiple tags: cve, misconfig, default-logins)",
                    "scan (type='nmap_full' for comprehensive port scan)",
                    "fuzz_endpoint (test all parameters with full payload sets)"
                ],
                "rationale": "Early reconnaissance phases need broad discovery to identify complete attack surface. Invest budget in comprehensive coverage now to find all testing targets."
            },
            "medium_budget": {
                "threshold": "100-500 requests remaining",
                "strategy": "Targeted testing - prioritize high-value endpoints and known vulnerability classes",
                "recommended_tools": [
                    "coverage_next (with limit=20, prioritize cells with priority>70)",
                    "endpoint_probe (gather context before full testing)",
                    "endpoint_execute_plan (with use_library=true for curated payloads)",
                    "auth_diff_test (focus on authorization issues)",
                    "http_send_batch (batch parallel requests for efficiency)"
                ],
                "tools_to_avoid": [
                    "recon_pipeline_run (too expensive for remaining budget)",
                    "nuclei_scan_template with broad tags (hundreds of templates)",
                    "fuzz_endpoint (high request volume per endpoint)",
                    "scan with type='nmap_full' (use nmap_quick instead)"
                ],
                "rationale": "Focus on likely vulnerabilities and high-priority targets. Use budget efficiently with batching and targeted testing."
            },
            "low_budget": {
                "threshold": "20-100 requests remaining",
                "strategy": "Validation and evidence collection only - stop new discovery",
                "recommended_tools": [
                    "validate_repro (confirm existing findings)",
                    "validate_negative_control (rule out false positives)",
                    "validate_promote (graduate validated findings)",
                    "evidence_bundle (create evidence packages)",
                    "evidence_add_artifact (collect proof)",
                    "http_send (surgical single requests for critical tests)"
                ],
                "tools_to_avoid": [
                    "ANY scanning tools (scan, nuclei_scan_template)",
                    "crawler_start (even small crawls use 50+ requests)",
                    "fuzz_parameter or fuzz_endpoint",
                    "coverage_next (stop new testing, focus on validation)"
                ],
                "rationale": "Preserve budget for confirming discovered findings. Stop exploration, focus on quality over quantity."
            },
            "critical_budget": {
                "threshold": "<20 requests remaining",
                "strategy": "Documentation and reporting only - stop all testing",
                "recommended_tools": [
                    "evidence_export (export findings as SARIF/JSON/ZIP)",
                    "poc_generate (create PoC scripts for findings)",
                    "evidence_generate_report (if user requests report)",
                    "wm_query (retrieve findings and observations)",
                    "list_cards (review all findings)",
                    "risk_assess (calculate risk scores)"
                ],
                "stop_testing": "No more requests to targets - only local documentation and reporting operations",
                "rationale": "Budget exhausted. Complete assessment documentation and prepare deliverables."
            }
        },
        "budget_optimization_techniques": {
            "batching": {
                "description": "Use http_send_batch() instead of multiple http_send() calls",
                "example": "Instead of 10x http_send(), use 1x http_send_batch([...10 requests...])",
                "savings": "Shares rate limiting overhead across requests, more efficient budget usage"
            },
            "probing": {
                "description": "Use endpoint_probe() before endpoint_execute_plan() to gather context",
                "example": "endpoint_probe() returns reflected params, tech indicators, error patterns - use this to craft targeted payloads instead of brute-force testing",
                "savings": "Reduces unnecessary payload attempts by targeting only relevant vulnerability classes"
            },
            "library_payloads": {
                "description": "Set use_library=true in endpoint_execute_plan() to use curated payload sets",
                "example": "Library payloads are pre-selected high-quality payloads (20-50 per vuln class) instead of LLM-generated exhaustive sets (hundreds)",
                "savings": "Reduces payload count by 80-90% while maintaining detection effectiveness"
            },
            "coverage_prioritization": {
                "description": "Use coverage_next() priority scores to test high-value cells first",
                "example": "coverage_next(limit=10) returns cells sorted by priority (endpoint risk × vuln class severity × parameter exposure)",
                "savings": "Test 20% of coverage matrix to find 80% of vulnerabilities (Pareto principle)"
            },
            "incremental_scanning": {
                "description": "Start with quick scans, only escalate to comprehensive if findings warrant it",
                "example": "scan(type='nmap_quick') first (~100 requests), only run scan(type='nmap_full') if interesting services found",
                "savings": "Avoid wasting budget on comprehensive scans of uninteresting targets"
            },
            "smart_wordlists": {
                "description": "Use smaller wordlists for directory discovery",
                "example": "wordlist='common' (~4500 paths) instead of wordlist='large' (~220000 paths)",
                "savings": "Common wordlist finds 90% of directories using 2% of requests"
            },
            "knowledge_reuse": {
                "description": "Check wm_recall() before re-scanning to see if data already exists",
                "example": "Before running scan(), call wm_recall(category='scan_output', target='example.com') to see if already scanned",
                "savings": "Avoid redundant scans when resuming assessment or testing similar targets"
            }
        },
        "budget_monitoring": {
            "check_before": [
                "recon_pipeline_run (500-2000 requests)",
                "nuclei_scan_template (100-1000 requests per target)",
                "fuzz_endpoint (200-500 requests per endpoint)",
                "crawler_start (50-200 requests per site)",
                "scan with type='nmap_full' or directory discovery (100-1000 requests)"
            ],
            "safe_anytime": [
                "wm_* tools (world model operations - local only)",
                "list_* tools (listing operations - local only)",
                "scope_* tools (scope operations - local only)",
                "evidence_* tools (evidence operations - local only)",
                "coverage_* tools except coverage_next execution (most are local planning)",
                "openapi_parse (local parsing - no requests)"
            ],
            "budget_recovery": "Budget does NOT recover during assessment - it's a fixed allocation. Plan budget usage across entire assessment lifecycle, not per-phase."
        },
        "phase_budget_allocation": {
            "recommended_distribution": {
                "Phase 1 Recon": "40% of budget - broad discovery to identify all targets",
                "Phase 2 Mapping": "25% of budget - enumerate endpoints and build coverage matrix",
                "Phase 3 Assessment": "25% of budget - test vulnerabilities with targeted payloads",
                "Phase 4 Validation": "10% of budget - confirm findings and collect evidence"
            },
            "note": "Adjust based on assessment type - API testing needs more mapping, network testing needs more recon"
        }
    }


async def _generate_workflow_guide(mcp_service) -> dict:
    """Generate dynamic workflow guidance based on current assessment phase and state."""
    # Try to detect current phase from mcp_service
    current_phase = 1
    phase_name = "Reconnaissance"

    # Get current state if assessment loaded
    if mcp_service and hasattr(mcp_service, "current_assessment_id") and mcp_service.current_assessment_id:
        # Query world model for current state indicators
        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(mcp_service.current_assessment_id)

            # Check what's been done to infer phase
            assets = await db.query("assets", limit=1)
            endpoints = await db.query("endpoints", limit=1)
            findings = await db.query("findings", limit=1)

            if findings:
                current_phase = 4
                phase_name = "Exploitation & Validation"
            elif endpoints and len(endpoints) > 5:
                current_phase = 3
                phase_name = "Vulnerability Assessment"
            elif endpoints:
                current_phase = 2
                phase_name = "Mapping & Enumeration"
            elif assets:
                current_phase = 1
                phase_name = "Reconnaissance"
        except Exception:
            pass  # Fall back to defaults

    # Phase-specific guidance
    phase_guides = {
        1: {
            "current_phase": 1,
            "phase_name": "Reconnaissance",
            "recommended_tools": [
                {"tool": "recon_pipeline_run", "priority": "high", "reason": "Automated 6-stage recon (subdomain → nmap → tech → SSL → directory → nuclei)"},
                {"tool": "scope_validate_target", "priority": "critical", "reason": "MUST validate every target before testing"},
                {"tool": "scope_check_budget", "priority": "high", "reason": "Check budget before expensive scans"},
                {"tool": "subdomain_enum", "priority": "high", "reason": "Discover all subdomains for complete attack surface"},
                {"tool": "scan", "priority": "high", "reason": "Port/service discovery on all in-scope targets"},
                {"tool": "tech_detection", "priority": "medium", "reason": "Identify tech stack for targeted nuclei templates"},
                {"tool": "ssl_analysis", "priority": "low", "reason": "Extract SANs for additional domains"}
            ],
            "next_actions": [
                "1. Validate scope: scope_get_allowlist() to see all allowed targets",
                "2. Check budget: scope_check_budget() to plan reconnaissance depth",
                "3. Run recon pipeline OR manual recon:",
                "   - AUTO: recon_pipeline_run(target_domain='example.com')",
                "   - MANUAL: subdomain_enum → scan(type='nmap_quick') → tech_detection → ssl_analysis",
                "4. Record discoveries: add_recon_data() for all findings",
                "5. Add assets to world model: wm_add_asset() for each target",
                "6. Store scan output: wm_store() for later recall"
            ],
            "common_mistakes": [
                "❌ Forgetting to call scope_validate_target() before first scan",
                "❌ Running nmap_full on all hosts (budget killer) - use nmap_quick first",
                "❌ Not checking for existing data with wm_recall() before re-scanning",
                "❌ Skipping tech_detection - needed for nuclei template filtering later",
                "❌ Running nuclei_scan_template in recon phase - save for Phase 3"
            ],
            "success_criteria": [
                "✓ All in-scope domains/IPs discovered and added as assets",
                "✓ All open ports and services identified",
                "✓ Technology stack documented for each service",
                "✓ Recon data stored in world model for query"
            ]
        },
        2: {
            "current_phase": 2,
            "phase_name": "Mapping & Enumeration",
            "recommended_tools": [
                {"tool": "openapi_parse", "priority": "high", "reason": "Parse API specs if available (fastest way to map APIs)"},
                {"tool": "crawler_start", "priority": "high", "reason": "Discover all pages/endpoints with authenticated or unauthenticated crawl"},
                {"tool": "browser_discover_forms", "priority": "high", "reason": "Find all HTML forms and input vectors"},
                {"tool": "coverage_init", "priority": "medium", "reason": "Build coverage matrix after endpoints discovered"},
                {"tool": "wm_add_endpoint", "priority": "medium", "reason": "Manually add endpoints not found by automated discovery"},
                {"tool": "wm_add_hypothesis", "priority": "medium", "reason": "Document testable security hypotheses for each attack vector"}
            ],
            "next_actions": [
                "1. Parse API specs if available: openapi_parse() then openapi_list_endpoints()",
                "2. Crawl web applications:",
                "   - Unauthenticated: crawler_start(start_url='https://target.com')",
                "   - Authenticated: credentials_add() → crawler_start(identity_id=...)",
                "3. Discover forms: browser_navigate() → browser_discover_forms()",
                "4. Build coverage matrix: coverage_init(base_url='https://target.com')",
                "5. Create hypotheses: wm_add_hypothesis() for each identified attack vector",
                "6. Map assets in world model: wm_add_endpoint() for each discovered endpoint"
            ],
            "common_mistakes": [
                "❌ Not running authenticated crawl - misses privileged endpoints",
                "❌ Calling coverage_init() before endpoints discovered (empty matrix)",
                "❌ Skipping openapi_parse even when /swagger.json exists",
                "❌ Not using coverage_discover() after authenticated crawl to extend matrix",
                "❌ Creating findings instead of hypotheses - hypotheses come BEFORE testing"
            ],
            "success_criteria": [
                "✓ All endpoints documented in world model (wm_query table='endpoints')",
                "✓ Coverage matrix initialized with endpoint × vuln_class cells",
                "✓ Hypotheses created for major attack vectors (auth bypass, IDOR, SQLi, XSS)",
                "✓ Forms and input vectors catalogued"
            ]
        },
        3: {
            "current_phase": 3,
            "phase_name": "Vulnerability Assessment",
            "recommended_tools": [
                {"tool": "coverage_next", "priority": "critical", "reason": "Get prioritized test cases from coverage matrix"},
                {"tool": "endpoint_execute_plan", "priority": "high", "reason": "LLM-driven adaptive testing of endpoints"},
                {"tool": "nuclei_scan_template", "priority": "high", "reason": "Known CVE and misconfiguration scanning"},
                {"tool": "fuzz_parameter", "priority": "high", "reason": "Parameter-level injection testing (SQLi, XSS, etc.)"},
                {"tool": "auth_diff_test", "priority": "high", "reason": "IDOR and authorization bypass testing"},
                {"tool": "http_send_batch", "priority": "medium", "reason": "Efficient parallel testing"},
                {"tool": "browser_test_xss", "priority": "medium", "reason": "Automated XSS detection in forms"}
            ],
            "next_actions": [
                "1. Check remaining budget: scope_check_budget()",
                "2. Get next tests: coverage_next(limit=10) - returns prioritized cells",
                "3. For each cell, execute the exact tool_call returned by coverage_next",
                "4. For custom testing:",
                "   - SQLi: fuzz_parameter(payload_types=['sqli_db'], db_type='mysql')",
                "   - IDOR: auth_diff_test(url, identity_a, identity_b)",
                "   - XSS: browser_test_xss() or fuzz_parameter(payload_types=['injection'])",
                "5. Mark coverage: coverage_mark(cell_id, status='vulnerable'|'passed')",
                "6. Document findings: add_card(card_type='finding') for confirmed issues",
                "7. Update hypotheses: wm_update_hypothesis(status='confirmed'|'rejected')"
            ],
            "common_mistakes": [
                "❌ Testing randomly instead of using coverage_next() prioritization",
                "❌ Forgetting to call coverage_mark() after testing (coverage tracking breaks)",
                "❌ Running nuclei_scan_template without checking budget first (expensive)",
                "❌ Creating findings before validation - use validate_repro() first",
                "❌ Not using http_send_batch() for parallel tests (inefficient)",
                "❌ Ignoring endpoint_probe() context before endpoint_execute_plan()"
            ],
            "success_criteria": [
                "✓ Coverage matrix >60% complete (coverage_report shows progress)",
                "✓ All high-priority cells tested (priority>70)",
                "✓ Findings documented with add_card() for validated issues",
                "✓ Hypotheses updated to confirmed/rejected status"
            ]
        },
        4: {
            "current_phase": 4,
            "phase_name": "Exploitation & Validation",
            "recommended_tools": [
                {"tool": "validate_repro", "priority": "critical", "reason": "Confirm findings are reproducible (3x minimum)"},
                {"tool": "validate_negative_control", "priority": "high", "reason": "Rule out false positives with benign input"},
                {"tool": "validate_cross_identity", "priority": "high", "reason": "Test authorization vulns across users"},
                {"tool": "validate_promote", "priority": "high", "reason": "Promote validated findings to confirmed"},
                {"tool": "evidence_bundle", "priority": "high", "reason": "Package evidence for each confirmed finding"},
                {"tool": "poc_generate", "priority": "medium", "reason": "Generate reproduction scripts"},
                {"tool": "browser_screenshot", "priority": "low", "reason": "Visual evidence for XSS/visual bugs"}
            ],
            "next_actions": [
                "1. List all findings: list_cards(card_type='finding', status='potential')",
                "2. For each finding:",
                "   a. validate_repro(finding_id) - run 3+ times",
                "   b. validate_negative_control(finding_id) - test benign input",
                "   c. For authz bugs: validate_cross_identity(finding_id, identities=[...])",
                "   d. If all pass: validate_promote(finding_id)",
                "3. Create evidence bundles: evidence_bundle(finding_id)",
                "4. Add artifacts: evidence_add_artifact(bundle_id, type='request'|'response'|'screenshot', ...)",
                "5. Generate PoCs: poc_generate(finding_id)",
                "6. Calculate risk: risk_score(finding_id, cvss_vector='...')",
                "7. Export evidence: evidence_export(bundle_id, format='zip'|'json'|'sarif')"
            ],
            "common_mistakes": [
                "❌ Skipping validate_negative_control - leads to false positive findings",
                "❌ Not testing reproducibility enough (1-2x insufficient, need 3+ successes)",
                "❌ Promoting findings before validation complete",
                "❌ Forgetting to create evidence bundles before state changes",
                "❌ Not testing findings across multiple user identities (misses scope)"
            ],
            "success_criteria": [
                "✓ All potential findings validated or rejected",
                "✓ Confirmed findings have evidence bundles with artifacts",
                "✓ PoC scripts generated for reproducibility",
                "✓ Risk scores calculated for prioritization"
            ]
        }
    }

    return phase_guides.get(current_phase, phase_guides[1])


def _get_tool_dependencies() -> dict:
    """Tool sequencing rules and common multi-tool workflows."""
    return {
        "tool_chains": {
            "authenticated_recon": {
                "description": "Discover authenticated attack surface after obtaining credentials",
                "steps": [
                    {"step": 1, "tool": "credentials_add", "description": "Store discovered credentials with auto-generated placeholder"},
                    {"step": 2, "tool": "crawler_start", "params": {"identity_id": "<cred_id>"}, "description": "Crawl with authentication to discover privileged endpoints"},
                    {"step": 3, "tool": "coverage_discover", "params": {"since": "<crawl_timestamp>"}, "description": "Detect new endpoints and auto-extend coverage matrix"},
                    {"step": 4, "tool": "coverage_next", "params": {"limit": 20}, "description": "Get prioritized tests for newly discovered endpoints"}
                ]
            },
            "api_testing": {
                "description": "Systematic API testing from spec to complete coverage",
                "steps": [
                    {"step": 1, "tool": "http_send", "params": {"method": "GET", "url": "https://api.example.com/swagger.json"}, "description": "Fetch API specification"},
                    {"step": 2, "tool": "openapi_parse", "params": {"content": "<spec_content>"}, "description": "Parse OpenAPI specification"},
                    {"step": 3, "tool": "openapi_list_endpoints", "params": {"spec_id": "<id>"}, "description": "List all API endpoints"},
                    {"step": 4, "tool": "coverage_init", "params": {"base_url": "https://api.example.com"}, "description": "Build endpoint × vuln_class matrix"},
                    {"step": 5, "tool": "coverage_next", "params": {"limit": 10}, "description": "Get next priority tests"},
                    {"step": 6, "tool": "endpoint_execute_plan", "description": "Execute tests with exact tool_call from coverage_next"}
                ]
            },
            "finding_validation": {
                "description": "Complete validation and evidence collection for a potential finding",
                "steps": [
                    {"step": 1, "tool": "validate_repro", "params": {"finding_id": "<id>", "count": 3}, "description": "Reproduce 3x to confirm consistency"},
                    {"step": 2, "tool": "validate_negative_control", "params": {"finding_id": "<id>"}, "description": "Test with benign input to rule out false positive"},
                    {"step": 3, "tool": "validate_cross_identity", "params": {"finding_id": "<id>", "identities": [...]}, "description": "Test across user contexts if authorization-related"},
                    {"step": 4, "tool": "validate_promote", "params": {"finding_id": "<id>"}, "description": "Promote to confirmed status if validation passes"},
                    {"step": 5, "tool": "evidence_bundle", "params": {"finding_id": "<id>"}, "description": "Create evidence package"},
                    {"step": 6, "tool": "evidence_add_artifact", "description": "Add request/response/screenshot artifacts"},
                    {"step": 7, "tool": "poc_generate", "params": {"finding_id": "<id>"}, "description": "Generate curl + Python PoC scripts"}
                ]
            },
            "web_app_discovery": {
                "description": "Complete web application mapping from URL to full endpoint list",
                "steps": [
                    {"step": 1, "tool": "scope_validate_target", "params": {"target": "https://example.com"}, "description": "Verify target is in scope"},
                    {"step": 2, "tool": "browser_navigate", "params": {"url": "https://example.com"}, "description": "Load application in browser"},
                    {"step": 3, "tool": "browser_discover_forms", "description": "Find all HTML forms and input vectors"},
                    {"step": 4, "tool": "crawler_start", "params": {"start_url": "https://example.com", "max_pages": 200}, "description": "Crawl all pages"},
                    {"step": 5, "tool": "wm_query", "params": {"table": "endpoints"}, "description": "Query discovered endpoints from world model"},
                    {"step": 6, "tool": "coverage_init", "params": {"base_url": "https://example.com"}, "description": "Build coverage matrix"}
                ]
            }
        },
        "prerequisites": {
            "ANY_TOOL_TO_TARGET": ["scope_validate_target"],
            "crawler_start": ["scope_validate_target"],
            "coverage_init": ["wm_query(table='endpoints') shows endpoints"],
            "endpoint_execute_plan": ["endpoint_probe", "coverage_init"],
            "validate_repro": ["add_card(card_type='finding')"],
            "nuclei_scan_template": ["scope_validate_target", "scope_check_budget"],
            "fuzz_parameter": ["scope_validate_target", "scope_check_budget"],
            "evidence_bundle": ["validate_promote"],
            "poc_generate": ["validate_promote"],
            "coverage_mark": ["coverage_next returned this cell_id"],
            "browser_discover_forms": ["browser_navigate"],
            "browser_test_xss": ["browser_navigate"],
            "openapi_list_endpoints": ["openapi_parse"],
            "openapi_get_endpoint": ["openapi_parse"],
            "openapi_get_schemas": ["openapi_parse"]
        },
        "common_sequences": {
            "before_any_request": [
                "scope_validate_target(url) - MANDATORY",
                "scope_record_request() - for rate limiting",
                "scope_check_budget() - periodically"
            ],
            "discovering_new_endpoints": [
                "crawler_start() OR openapi_parse() OR execute('gobuster')",
                "coverage_discover(since=<timestamp>)",
                "coverage_next() - get new tests"
            ],
            "testing_an_endpoint": [
                "endpoint_probe() - gather context",
                "endpoint_execute_plan() - run tests",
                "coverage_mark() - record result"
            ],
            "confirming_a_finding": [
                "validate_repro() - reproduce 3x",
                "validate_negative_control() - rule out FP",
                "validate_promote() - confirm",
                "evidence_bundle() - package"
            ]
        },
        "anti_patterns": [
            "❌ Calling coverage_next() but not calling coverage_mark() after testing",
            "❌ Running nuclei/fuzz without scope_validate_target() first",
            "❌ Creating findings before validation (should be observations first)",
            "❌ Using scan() when dedicated tools exist (use fuzz_parameter not execute('sqlmap'))",
            "❌ Not checking wm_recall() before re-running expensive scans",
            "❌ Calling endpoint_execute_plan() without endpoint_probe() first",
            "❌ Using execute() for HTTP requests (use http_send for budget tracking)"
        ]
    }
