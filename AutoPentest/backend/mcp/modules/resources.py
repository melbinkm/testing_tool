"""
MCP Resources - Resource definitions and handlers
"""
import json
from typing import List
from mcp.types import Resource


def get_resources() -> List[Resource]:
    """List available resources"""
    return [
        Resource(
            uri="kali://status",
            name="Current Status",
            description="Current assessment status and container info",
            mimeType="application/json"
        ),
        Resource(
            uri="kali://containers",
            name="Kali Containers",
            description="List of all Kali pentesting containers",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://error-recovery",
            name="Error Recovery Patterns",
            description="Common errors and step-by-step recovery strategies for autonomous error handling",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://attack-patterns",
            name="Attack Chaining Patterns",
            description="Proven multi-tool attack sequences for complex exploitation chains",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://budget-optimization",
            name="Budget Management Strategies",
            description="Smart strategies for managing request budget and scope constraints",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://workflow-guide",
            name="Phase Workflow Guide",
            description="Dynamic workflow recommendations based on current assessment phase and state",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://tool-dependencies",
            name="Tool Dependencies & Chains",
            description="Tool sequencing rules, prerequisites, and common multi-tool workflows",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://tool-metadata",
            name="Tool Metadata Registry",
            description="Machine-readable tool categories, dependencies, risk levels, and phase mappings for all 98 tools",
            mimeType="application/json"
        ),
        Resource(
            uri="autopentest://pentest-workflow",
            name="LLM-in-the-Loop Pentest Workflow",
            description="Step-by-step workflow for manual security testing using the 8 pentest tools",
            mimeType="application/json"
        )
    ]


async def handle_resource_read(uri: str, mcp_service) -> str:
    """Read resource content"""
    await mcp_service.initialize()

    if uri == "kali://status":
        status_info = {
            "current_assessment": mcp_service.current_assessment_name,
            "assessment_id": mcp_service.current_assessment_id,
            "current_container": mcp_service.current_container,
            "current_target": mcp_service.current_target,
            "containers_available": len(mcp_service.containers_cache),
            "recent_commands": len(mcp_service.command_history),
            "tool_cache_size": len(mcp_service.tool_cache)
        }
        return json.dumps(status_info, indent=2)

    elif uri == "kali://containers":
        containers = await mcp_service.discover_containers()
        return json.dumps(containers, indent=2)

    elif uri == "autopentest://error-recovery":
        return json.dumps(_get_error_recovery_patterns(), indent=2)

    elif uri == "autopentest://attack-patterns":
        return json.dumps(_get_attack_patterns(), indent=2)

    elif uri == "autopentest://budget-optimization":
        return json.dumps(_get_budget_optimization(), indent=2)

    elif uri == "autopentest://workflow-guide":
        return json.dumps(await _generate_workflow_guide(mcp_service), indent=2)

    elif uri == "autopentest://tool-dependencies":
        return json.dumps(_get_tool_dependencies(), indent=2)

    elif uri == "autopentest://tool-metadata":
        from lib.tool_metadata import TOOL_METADATA, TOOL_CATEGORIES, PHASE_TOOLS
        return json.dumps({
            "tool_metadata": TOOL_METADATA,
            "categories": TOOL_CATEGORIES,
            "phase_tools": PHASE_TOOLS,
            "summary": {
                "total_tools": len(TOOL_METADATA),
                "by_category": {cat: len(tools) for cat, tools in TOOL_CATEGORIES.items()},
                "by_phase": {phase: len(tools) for phase, tools in PHASE_TOOLS.items()},
                "high_risk_tools": len([t for t, m in TOOL_METADATA.items() if m.get("risk_level") == "high_risk"]),
                "high_budget_tools": len([t for t, m in TOOL_METADATA.items() if m.get("budget_impact") == "high"])
            }
        }, indent=2)

    elif uri == "autopentest://pentest-workflow":
        return json.dumps(_get_pentest_workflow(), indent=2)

    else:
        raise ValueError(f"Unknown resource: {uri}")


def _get_error_recovery_patterns() -> dict:
    """Common errors and recovery strategies for autonomous error handling."""
    return {
        "common_errors": {
            "scope_violation": {
                "symptoms": ["out of scope", "target not in allowlist", "scope validation failed"],
                "recovery": [
                    "1. Call scope_get_allowlist() to see all allowed targets, domains, and IP ranges",
                    "2. Verify target matches allowlist patterns (exact domain, wildcard subdomain, or IP range)",
                    "3. If legitimately out of scope: document as observation and skip testing",
                    "4. If should be in scope: inform user and ask them to update allowlist configuration",
                    "5. Never bypass scope validation - fail closed for safety"
                ],
                "prevention": "Always call scope_validate_target() before ANY request to a target"
            },
            "budget_exhausted": {
                "symptoms": ["budget exceeded", "rate limit reached", "too many requests"],
                "recovery": [
                    "1. Call scope_check_budget() to see remaining requests and per-target limits",
                    "2. If >50 requests remain: prioritize high-value tests (coverage cells with priority>70)",
                    "3. If 20-50 requests: only test confirmed vulnerabilities and skip broad scanning",
                    "4. If <20 requests: complete evidence collection and generate report",
                    "5. Use http_send_batch() for parallel requests to optimize budget",
                    "6. Skip expensive tools: nuclei_scan_template, fuzz_endpoint, crawler_start"
                ],
                "prevention": "Call scope_check_budget() every 20-30 tool calls, especially before high-cost operations"
            },
            "empty_crawl_results": {
                "symptoms": ["0 pages crawled", "no endpoints found", "crawler returned empty"],
                "recovery": [
                    "1. Check if JavaScript rendering needed: use browser_navigate() + browser_discover_forms()",
                    "2. Try authenticated crawl: credentials_add() then crawler_start(identity_id=...)",
                    "3. Use directory discovery: execute('gobuster dir ...') or scan(type='gobuster')",
                    "4. Parse API specs if available: openapi_parse() + openapi_list_endpoints()",
                    "5. Manual endpoint addition: wm_add_endpoint() for known paths"
                ],
                "prevention": "Check if target uses JavaScript-heavy SPA or requires authentication before crawling"
            },
            "nuclei_no_findings": {
                "symptoms": ["0 vulnerabilities found", "all nuclei templates returned clean"],
                "recovery": [
                    "1. This is EXPECTED for secure targets - not an error",
                    "2. Proceed to manual testing: fuzz_parameter(), endpoint_execute_plan()",
                    "3. Focus on business logic: sequence_workflow_bypass(), auth_diff_test()",
                    "4. Test authorization: auth_diff_test() with multiple identities",
                    "5. Custom injection tests: http_send() with crafted payloads"
                ],
                "note": "Nuclei finds known CVEs and misconfigurations, not custom application logic flaws"
            },
            "validation_failure": {
                "symptoms": ["validate_repro failed", "cannot reproduce", "inconsistent results"],
                "recovery": [
                    "1. Check if timing-dependent: retry validate_repro() 2-3 times",
                    "2. Verify credentials still valid: test authentication separately",
                    "3. Check if WAF detected and blocked: look for 403/429 status codes",
                    "4. Verify exact request parameters: ensure payload not URL-encoded incorrectly",
                    "5. If consistently fails (3+ attempts): downgrade to 'observation' not 'finding'",
                    "6. Document unreliability in notes even if eventually succeeds"
                ],
                "prevention": "Run validate_repro() immediately after discovering potential finding, before state changes"
            },
            "tool_not_available": {
                "symptoms": ["tool not available", "command not found", "tool_help returned empty"],
                "recovery": [
                    "1. Check tool name spelling and case sensitivity",
                    "2. Use tool_help() to verify tool exists in Kali container",
                    "3. Try alternative tools: gobuster instead of ffuf, subfinder instead of amass",
                    "4. Use execute() with explicit path: /usr/bin/tool instead of tool",
                    "5. Install tool if missing: execute('apt-get update && apt-get install -y tool')"
                ],
                "prevention": "Call tool_help() before first use of unfamiliar tools"
            },
            "timeout": {
                "symptoms": ["timeout exceeded", "operation timed out", "no response"],
                "recovery": [
                    "1. For scan timeouts: reduce scope (fewer ports, specific targets only)",
                    "2. For directory scan timeouts: use smaller wordlist (wordlist='common')",
                    "3. For http_send timeouts: increase timeout parameter or check if target is down",
                    "4. For execute timeouts: break command into smaller steps or run manually",
                    "5. Verify target is responsive: simple GET request before complex scan"
                ],
                "prevention": "Start with quick scans (nmap_quick, common wordlist) before comprehensive scans"
            },
            "authentication_required": {
                "symptoms": ["401 Unauthorized", "403 Forbidden", "login required", "authentication needed"],
                "recovery": [
                    "1. Check scope_get_identities() for available credentials",
                    "2. If credentials exist: use identity_id parameter in crawler_start() or http_send()",
                    "3. If no credentials: test authentication bypass first (auth_diff_test, http_send with header manipulation)",
                    "4. Document accessible vs. authenticated attack surface separately",
                    "5. Re-run discovery after obtaining credentials: crawler_start(identity_id=...) then coverage_discover()"
                ],
                "note": "Always test both unauthenticated and authenticated attack surfaces separately"
            }
        },
        "general_principles": [
            "Read error messages carefully - they often suggest the fix",
            "Check budget and scope before retrying expensive operations",
            "Try alternative approaches when primary tool fails",
            "Document failures as observations even if they don't lead to findings",
            "Don't retry the exact same operation more than 3 times",
            "Consult tool descriptions for known failure modes and workarounds"
        ]
    }


def _get_attack_patterns() -> dict:
    """Proven multi-tool attack sequences for complex exploitation chains."""
    return {
        "patterns": {
            "auth_bypass_exploitation": {
                "description": "Full exploitation chain after discovering authentication bypass vulnerability",
                "use_when": "You discovered a way to bypass authentication (missing auth check, JWT manipulation, session fixation, etc.)",
                "sequence": [
                    {
                        "phase": "Confirm",
                        "tools": ["validate_repro", "validate_negative_control", "validate_promote"],
                        "note": "Ensure bypass is reproducible and not a false positive"
                    },
                    {
                        "phase": "Document",
                        "tools": ["evidence_bundle", "evidence_add_artifact", "poc_generate"],
                        "note": "Capture evidence before state changes"
                    },
                    {
                        "phase": "Store Credentials",
                        "tools": ["credentials_add"],
                        "note": "Store the bypass method as a usable identity for follow-up testing"
                    },
                    {
                        "phase": "Re-Crawl",
                        "tools": ["crawler_start"],
                        "params": {"identity_id": "<bypass_cred_id>"},
                        "note": "Re-crawl application with bypassed/elevated access to discover authenticated endpoints"
                    },
                    {
                        "phase": "Extend Coverage",
                        "tools": ["coverage_discover", "coverage_refresh"],
                        "note": "Detect newly accessible endpoints and add them to coverage matrix"
                    },
                    {
                        "phase": "Test New Surface",
                        "tools": ["coverage_next", "endpoint_execute_plan"],
                        "note": "Test the newly discovered authenticated endpoints for additional vulnerabilities"
                    },
                    {
                        "phase": "Document Chain",
                        "tools": ["wm_add_relationship"],
                        "params": {"rel_type": "leads_to"},
                        "note": "Link auth bypass finding to secondary findings discovered via elevated access"
                    }
                ],
                "expected_outcome": "Complete mapping of authenticated attack surface and potential secondary vulnerabilities"
            },
            "idor_to_data_exfil": {
                "description": "Chain IDOR discovery to comprehensive data enumeration and exfiltration",
                "use_when": "You found an endpoint where changing user ID/resource ID grants unauthorized access to other users' data",
                "sequence": [
                    {
                        "phase": "Discover",
                        "tools": ["auth_diff_test"],
                        "params": {"url": "/api/users/{id}", "identity_ids": ["user_a", "user_b"]},
                        "note": "Confirm different users can access each other's resources by changing ID parameter"
                    },
                    {
                        "phase": "Validate Ownership",
                        "tools": ["sequence_data_ownership"],
                        "params": {"url_template": "/api/users/{id}", "resource_ids": [1, 2, 3, 5, 10, 100]},
                        "note": "Test sample IDs to confirm pattern and identify accessible ID range"
                    },
                    {
                        "phase": "Enumerate IDs",
                        "tools": ["http_send_batch"],
                        "note": "Batch enumerate all accessible IDs (respect budget limits - prioritize sample over exhaustive)",
                        "caution": "Check budget first: scope_check_budget(). For large ID spaces, enumerate sample (every 10th, 100th)"
                    },
                    {
                        "phase": "Evidence Collection",
                        "tools": ["evidence_bundle", "evidence_add_artifact"],
                        "note": "Capture request/response examples showing unauthorized access to multiple users' data"
                    },
                    {
                        "phase": "Risk Assessment",
                        "tools": ["risk_score"],
                        "params": {"data_classification": "confidential", "confidence": 0.9},
                        "note": "Calculate business impact based on data sensitivity"
                    }
                ],
                "expected_outcome": "Proof of IDOR vulnerability with evidence of data exfiltration and business impact assessment"
            },
            "sqli_to_rce": {
                "description": "Escalate SQL injection to remote code execution through database features",
                "use_when": "You confirmed SQL injection in a parameter and want to maximize impact",
                "sequence": [
                    {
                        "phase": "Detect",
                        "tools": ["fuzz_parameter"],
                        "params": {"payload_types": ["sqli_db"], "db_type": "mysql"},
                        "note": "Identify SQL injection with database-specific payloads"
                    },
                    {
                        "phase": "Validate",
                        "tools": ["validate_repro", "validate_negative_control"],
                        "note": "Confirm injection is real and not a false positive from error message variations"
                    },
                    {
                        "phase": "Promote",
                        "tools": ["validate_promote", "evidence_bundle"],
                        "note": "Mark as confirmed finding and start evidence collection"
                    },
                    {
                        "phase": "Advanced Exploitation",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap -u 'URL' -p 'param' --batch --risk=3 --level=5 --threads=5"},
                        "note": "Use sqlmap for advanced enumeration: db version, users, tables, data extraction"
                    },
                    {
                        "phase": "Privilege Escalation",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --is-dba --privileges"},
                        "note": "Check if database user has DBA privileges for file operations"
                    },
                    {
                        "phase": "File Operations",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --file-write=shell.php --file-dest=/var/www/html/shell.php"},
                        "note": "Attempt file write (PHP webshell) if DBA. ONLY if explicitly authorized in scope."
                    },
                    {
                        "phase": "OS Command Execution",
                        "tools": ["execute"],
                        "params": {"command": "sqlmap ... --os-shell"},
                        "note": "Attempt command execution via xp_cmdshell (MSSQL) or sys_exec (MySQL). HIGH RISK - requires explicit authorization."
                    },
                    {
                        "phase": "Documentation",
                        "tools": ["wm_store", "poc_generate", "evidence_add_artifact"],
                        "note": "Store full sqlmap output, generate PoC, and package evidence"
                    }
                ],
                "expected_outcome": "Comprehensive SQLi documentation from detection through potential RCE",
                "warnings": [
                    "OS command execution and file write operations are HIGH RISK",
                    "Verify scope explicitly permits exploitation beyond detection",
                    "Stop at database enumeration if RCE attempts are out of scope"
                ]
            },
            "xss_to_session_hijack": {
                "description": "Escalate XSS discovery to session hijacking and account takeover demonstration",
                "use_when": "You discovered XSS and want to demonstrate maximum business impact",
                "sequence": [
                    {
                        "phase": "Detect",
                        "tools": ["browser_test_xss", "fuzz_parameter"],
                        "params": {"payload_types": ["injection", "format"]},
                        "note": "Identify XSS vulnerability in parameter with JavaScript execution"
                    },
                    {
                        "phase": "Confirm Execution",
                        "tools": ["browser_navigate", "browser_eval"],
                        "params": {"expression": "document.cookie"},
                        "note": "Load page in real browser and verify JavaScript executes in user context"
                    },
                    {
                        "phase": "Test Cookie Exfiltration",
                        "tools": ["browser_eval"],
                        "params": {"expression": "document.cookie"},
                        "note": "Check if session cookies are accessible (httpOnly flag not set)"
                    },
                    {
                        "phase": "Visual Evidence",
                        "tools": ["browser_screenshot"],
                        "note": "Capture screenshot of alert() or modified DOM as visual proof"
                    },
                    {
                        "phase": "Validate",
                        "tools": ["validate_repro", "validate_negative_control"],
                        "note": "Confirm XSS is reproducible and not filtered by WAF"
                    },
                    {
                        "phase": "PoC Development",
                        "tools": ["poc_generate"],
                        "note": "Generate PoC showing session cookie exfiltration payload (DO NOT actually exfiltrate)"
                    },
                    {
                        "phase": "Evidence Collection",
                        "tools": ["evidence_bundle", "evidence_add_artifact"],
                        "note": "Package screenshot, PoC, request/response, and cookie accessibility proof"
                    }
                ],
                "expected_outcome": "Demonstrated XSS with proof of session cookie accessibility for account takeover scenario",
                "warnings": [
                    "DO NOT actually exfiltrate session cookies to external server",
                    "Stop at proof-of-concept - demonstrate capability without causing harm"
                ]
            },
            "subdomain_takeover": {
                "description": "Discover and validate subdomain takeover vulnerability through full reconnaissance chain",
                "use_when": "Performing domain reconnaissance and discovering dangling DNS records",
                "sequence": [
                    {
                        "phase": "Discovery",
                        "tools": ["subdomain_enum"],
                        "note": "Discover all subdomains via passive reconnaissance"
                    },
                    {
                        "phase": "Validation",
                        "tools": ["scope_validate_target"],
                        "note": "Verify each subdomain is in scope before testing"
                    },
                    {
                        "phase": "DNS Analysis",
                        "tools": ["execute"],
                        "params": {"command": "dig +short subdomain.example.com"},
                        "note": "Check DNS records for each subdomain to identify CNAME records"
                    },
                    {
                        "phase": "HTTP Testing",
                        "tools": ["http_send"],
                        "note": "Attempt to access each subdomain and look for service-specific takeover signatures"
                    },
                    {
                        "phase": "Service Identification",
                        "tools": ["tech_detection"],
                        "note": "Identify hosting platform (GitHub Pages, AWS S3, Heroku, etc.) for dangling CNAMEs"
                    },
                    {
                        "phase": "Takeover Validation",
                        "note": "Document dangling CNAME but DO NOT claim subdomain - only demonstrate vulnerability exists"
                    },
                    {
                        "phase": "Documentation",
                        "tools": ["add_card", "evidence_bundle"],
                        "note": "Document finding with DNS records, HTTP responses, and service identification"
                    }
                ],
                "expected_outcome": "Subdomain takeover vulnerability documented without actual takeover",
                "warnings": [
                    "DO NOT claim or takeover subdomains - only document vulnerability",
                    "Subdomain takeover can have legal implications - document, don't exploit"
                ]
            }
        },
        "general_workflow": {
            "description": "Standard multi-tool workflow for comprehensive endpoint testing",
            "sequence": [
                "1. Discover (recon_pipeline_run, crawler_start, openapi_parse)",
                "2. Map (coverage_init, wm_add_endpoint, wm_add_hypothesis)",
                "3. Prioritize (coverage_next with priority>70 first)",
                "4. Test (endpoint_execute_plan, fuzz_parameter, auth_diff_test)",
                "5. Validate (validate_repro, validate_negative_control, validate_promote)",
                "6. Document (evidence_bundle, poc_generate, evidence_export)",
                "7. Report (evidence_generate_report only when user requests)"
            ]
        }
    }


def _get_budget_optimization() -> dict:
    """Smart strategies for managing request budget and scope constraints."""
    return {
        "budget_check_frequency": "Call scope_check_budget() every 20-30 tool calls, especially before high-cost operations",
        "optimization_strategies": {
            "high_budget": {
                "threshold": ">500 requests remaining",
                "strategy": "Comprehensive discovery - use all reconnaissance and scanning tools",
                "recommended_tools": [
                    "recon_pipeline_run (full 6-stage pipeline)",
                    "crawler_start (with max_pages=200)",
                    "nuclei_scan_template (with multiple tags: cve, misconfig, default-logins)",
                    "scan (type='nmap_full' for comprehensive port scan)",
                    "fuzz_endpoint (test all parameters with full payload sets)"
                ],
                "rationale": "Early reconnaissance phases need broad discovery to identify complete attack surface. Invest budget in comprehensive coverage now to find all testing targets."
            },
            "medium_budget": {
                "threshold": "100-500 requests remaining",
                "strategy": "Targeted testing - prioritize high-value endpoints and known vulnerability classes",
                "recommended_tools": [
                    "coverage_next (with limit=20, prioritize cells with priority>70)",
                    "endpoint_probe (gather context before full testing)",
                    "endpoint_execute_plan (with use_library=true for curated payloads)",
                    "auth_diff_test (focus on authorization issues)",
                    "http_send_batch (batch parallel requests for efficiency)"
                ],
                "tools_to_avoid": [
                    "recon_pipeline_run (too expensive for remaining budget)",
                    "nuclei_scan_template with broad tags (hundreds of templates)",
                    "fuzz_endpoint (high request volume per endpoint)",
                    "scan with type='nmap_full' (use nmap_quick instead)"
                ],
                "rationale": "Focus on likely vulnerabilities and high-priority targets. Use budget efficiently with batching and targeted testing."
            },
            "low_budget": {
                "threshold": "20-100 requests remaining",
                "strategy": "Validation and evidence collection only - stop new discovery",
                "recommended_tools": [
                    "validate_repro (confirm existing findings)",
                    "validate_negative_control (rule out false positives)",
                    "validate_promote (graduate validated findings)",
                    "evidence_bundle (create evidence packages)",
                    "evidence_add_artifact (collect proof)",
                    "http_send (surgical single requests for critical tests)"
                ],
                "tools_to_avoid": [
                    "ANY scanning tools (scan, nuclei_scan_template)",
                    "crawler_start (even small crawls use 50+ requests)",
                    "fuzz_parameter or fuzz_endpoint",
                    "coverage_next (stop new testing, focus on validation)"
                ],
                "rationale": "Preserve budget for confirming discovered findings. Stop exploration, focus on quality over quantity."
            },
            "critical_budget": {
                "threshold": "<20 requests remaining",
                "strategy": "Documentation and reporting only - stop all testing",
                "recommended_tools": [
                    "evidence_export (export findings as SARIF/JSON/ZIP)",
                    "poc_generate (create PoC scripts for findings)",
                    "evidence_generate_report (if user requests report)",
                    "wm_query (retrieve findings and observations)",
                    "list_cards (review all findings)",
                    "risk_assess (calculate risk scores)"
                ],
                "stop_testing": "No more requests to targets - only local documentation and reporting operations",
                "rationale": "Budget exhausted. Complete assessment documentation and prepare deliverables."
            }
        },
        "budget_optimization_techniques": {
            "batching": {
                "description": "Use http_send_batch() instead of multiple http_send() calls",
                "example": "Instead of 10x http_send(), use 1x http_send_batch([...10 requests...])",
                "savings": "Shares rate limiting overhead across requests, more efficient budget usage"
            },
            "probing": {
                "description": "Use endpoint_probe() before endpoint_execute_plan() to gather context",
                "example": "endpoint_probe() returns reflected params, tech indicators, error patterns - use this to craft targeted payloads instead of brute-force testing",
                "savings": "Reduces unnecessary payload attempts by targeting only relevant vulnerability classes"
            },
            "library_payloads": {
                "description": "Set use_library=true in endpoint_execute_plan() to use curated payload sets",
                "example": "Library payloads are pre-selected high-quality payloads (20-50 per vuln class) instead of LLM-generated exhaustive sets (hundreds)",
                "savings": "Reduces payload count by 80-90% while maintaining detection effectiveness"
            },
            "coverage_prioritization": {
                "description": "Use coverage_next() priority scores to test high-value cells first",
                "example": "coverage_next(limit=10) returns cells sorted by priority (endpoint risk × vuln class severity × parameter exposure)",
                "savings": "Test 20% of coverage matrix to find 80% of vulnerabilities (Pareto principle)"
            },
            "incremental_scanning": {
                "description": "Start with quick scans, only escalate to comprehensive if findings warrant it",
                "example": "scan(type='nmap_quick') first (~100 requests), only run scan(type='nmap_full') if interesting services found",
                "savings": "Avoid wasting budget on comprehensive scans of uninteresting targets"
            },
            "smart_wordlists": {
                "description": "Use smaller wordlists for directory discovery",
                "example": "wordlist='common' (~4500 paths) instead of wordlist='large' (~220000 paths)",
                "savings": "Common wordlist finds 90% of directories using 2% of requests"
            },
            "knowledge_reuse": {
                "description": "Check wm_recall() before re-scanning to see if data already exists",
                "example": "Before running scan(), call wm_recall(category='scan_output', target='example.com') to see if already scanned",
                "savings": "Avoid redundant scans when resuming assessment or testing similar targets"
            }
        },
        "budget_monitoring": {
            "check_before": [
                "recon_pipeline_run (500-2000 requests)",
                "nuclei_scan_template (100-1000 requests per target)",
                "fuzz_endpoint (200-500 requests per endpoint)",
                "crawler_start (50-200 requests per site)",
                "scan with type='nmap_full' or directory discovery (100-1000 requests)"
            ],
            "safe_anytime": [
                "wm_* tools (world model operations - local only)",
                "list_* tools (listing operations - local only)",
                "scope_* tools (scope operations - local only)",
                "evidence_* tools (evidence operations - local only)",
                "coverage_* tools except coverage_next execution (most are local planning)",
                "openapi_parse (local parsing - no requests)"
            ],
            "budget_recovery": "Budget does NOT recover during assessment - it's a fixed allocation. Plan budget usage across entire assessment lifecycle, not per-phase."
        },
        "phase_budget_allocation": {
            "recommended_distribution": {
                "Phase 1 Recon": "40% of budget - broad discovery to identify all targets",
                "Phase 2 Mapping": "25% of budget - enumerate endpoints and build coverage matrix",
                "Phase 3 Assessment": "25% of budget - test vulnerabilities with targeted payloads",
                "Phase 4 Validation": "10% of budget - confirm findings and collect evidence"
            },
            "note": "Adjust based on assessment type - API testing needs more mapping, network testing needs more recon"
        }
    }


async def _generate_workflow_guide(mcp_service) -> dict:
    """Generate dynamic workflow guidance based on current assessment phase and state."""
    # Try to detect current phase from mcp_service
    current_phase = 1
    phase_name = "Reconnaissance"

    # Get current state if assessment loaded
    if mcp_service and hasattr(mcp_service, "current_assessment_id") and mcp_service.current_assessment_id:
        # Query world model for current state indicators
        try:
            from lib.world_model_db import get_world_model_db
            db = await get_world_model_db(mcp_service.current_assessment_id)

            # Check what's been done to infer phase
            assets = await db.query("assets", limit=1)
            endpoints = await db.query("endpoints", limit=1)
            findings = await db.query("findings", limit=1)

            if findings:
                current_phase = 4
                phase_name = "Exploitation & Validation"
            elif endpoints and len(endpoints) > 5:
                current_phase = 3
                phase_name = "Vulnerability Assessment"
            elif endpoints:
                current_phase = 2
                phase_name = "Mapping & Enumeration"
            elif assets:
                current_phase = 1
                phase_name = "Reconnaissance"
        except Exception:
            pass  # Fall back to defaults

    # Phase-specific guidance
    phase_guides = {
        1: {
            "current_phase": 1,
            "phase_name": "Reconnaissance",
            "recommended_tools": [
                {"tool": "recon_pipeline_run", "priority": "high", "reason": "Automated 6-stage recon (subdomain → nmap → tech → SSL → directory → nuclei)"},
                {"tool": "scope_validate_target", "priority": "critical", "reason": "MUST validate every target before testing"},
                {"tool": "scope_check_budget", "priority": "high", "reason": "Check budget before expensive scans"},
                {"tool": "subdomain_enum", "priority": "high", "reason": "Discover all subdomains for complete attack surface"},
                {"tool": "scan", "priority": "high", "reason": "Port/service discovery on all in-scope targets"},
                {"tool": "tech_detection", "priority": "medium", "reason": "Identify tech stack for targeted nuclei templates"},
                {"tool": "ssl_analysis", "priority": "low", "reason": "Extract SANs for additional domains"}
            ],
            "next_actions": [
                "1. Validate scope: scope_get_allowlist() to see all allowed targets",
                "2. Check budget: scope_check_budget() to plan reconnaissance depth",
                "3. Run recon pipeline OR manual recon:",
                "   - AUTO: recon_pipeline_run(target_domain='example.com')",
                "   - MANUAL: subdomain_enum → scan(type='nmap_quick') → tech_detection → ssl_analysis",
                "4. Record discoveries: add_recon_data() for all findings",
                "5. Add assets to world model: wm_add_asset() for each target",
                "6. Store scan output: wm_store() for later recall"
            ],
            "common_mistakes": [
                "❌ Forgetting to call scope_validate_target() before first scan",
                "❌ Running nmap_full on all hosts (budget killer) - use nmap_quick first",
                "❌ Not checking for existing data with wm_recall() before re-scanning",
                "❌ Skipping tech_detection - needed for nuclei template filtering later",
                "❌ Running nuclei_scan_template in recon phase - save for Phase 3"
            ],
            "success_criteria": [
                "✓ All in-scope domains/IPs discovered and added as assets",
                "✓ All open ports and services identified",
                "✓ Technology stack documented for each service",
                "✓ Recon data stored in world model for query"
            ]
        },
        2: {
            "current_phase": 2,
            "phase_name": "Mapping & Enumeration",
            "recommended_tools": [
                {"tool": "openapi_parse", "priority": "high", "reason": "Parse API specs if available (fastest way to map APIs)"},
                {"tool": "crawler_start", "priority": "high", "reason": "Discover all pages/endpoints with authenticated or unauthenticated crawl"},
                {"tool": "browser_discover_forms", "priority": "high", "reason": "Find all HTML forms and input vectors"},
                {"tool": "coverage_init", "priority": "medium", "reason": "Build coverage matrix after endpoints discovered"},
                {"tool": "wm_add_endpoint", "priority": "medium", "reason": "Manually add endpoints not found by automated discovery"},
                {"tool": "wm_add_hypothesis", "priority": "medium", "reason": "Document testable security hypotheses for each attack vector"}
            ],
            "next_actions": [
                "1. Parse API specs if available: openapi_parse() then openapi_list_endpoints()",
                "2. Crawl web applications:",
                "   - Unauthenticated: crawler_start(start_url='https://target.com')",
                "   - Authenticated: credentials_add() → crawler_start(identity_id=...)",
                "3. Discover forms: browser_navigate() → browser_discover_forms()",
                "4. Build coverage matrix: coverage_init(base_url='https://target.com')",
                "5. Create hypotheses: wm_add_hypothesis() for each identified attack vector",
                "6. Map assets in world model: wm_add_endpoint() for each discovered endpoint"
            ],
            "common_mistakes": [
                "❌ Not running authenticated crawl - misses privileged endpoints",
                "❌ Calling coverage_init() before endpoints discovered (empty matrix)",
                "❌ Skipping openapi_parse even when /swagger.json exists",
                "❌ Not using coverage_discover() after authenticated crawl to extend matrix",
                "❌ Creating findings instead of hypotheses - hypotheses come BEFORE testing"
            ],
            "success_criteria": [
                "✓ All endpoints documented in world model (wm_query table='endpoints')",
                "✓ Coverage matrix initialized with endpoint × vuln_class cells",
                "✓ Hypotheses created for major attack vectors (auth bypass, IDOR, SQLi, XSS)",
                "✓ Forms and input vectors catalogued"
            ]
        },
        3: {
            "current_phase": 3,
            "phase_name": "Vulnerability Assessment",
            "recommended_tools": [
                {"tool": "testing_build_matrix", "priority": "critical", "reason": "Build 42-class coverage matrix for comprehensive testing"},
                {"tool": "testing_next", "priority": "critical", "reason": "Get prioritized test cells with pre-loaded payloads"},
                {"tool": "testing_should_continue", "priority": "high", "reason": "Decide when to stop testing each vuln class"},
                {"tool": "testing_status", "priority": "high", "reason": "Check progress, completeness, and checklist compliance"},
                {"tool": "endpoint_execute_plan", "priority": "high", "reason": "LLM-driven adaptive testing of endpoints"},
                {"tool": "nuclei_scan_template", "priority": "high", "reason": "Known CVE and misconfiguration scanning"},
                {"tool": "fuzz_parameter", "priority": "high", "reason": "Parameter-level injection testing (SQLi, XSS, etc.)"},
                {"tool": "auth_diff_test", "priority": "high", "reason": "IDOR and authorization bypass testing"},
                {"tool": "http_send_batch", "priority": "medium", "reason": "Efficient parallel testing with analysis"},
                {"tool": "browser_test_xss", "priority": "medium", "reason": "Automated XSS detection in forms"}
            ],
            "next_actions": [
                "MANDATORY: Before testing any endpoint:",
                "1. Call testing_build_matrix(base_url=...) to build the 42-class coverage matrix",
                "2. Use testing_next() to get prioritized test cells with pre-loaded payloads",
                "3. After each test, call testing_should_continue() to decide next steps",
                "4. Periodically call testing_status() to check progress and completeness",
                "",
                "Standard workflow:",
                "1. Check remaining budget: scope_check_budget()",
                "2. Build coverage: testing_build_matrix(base_url='https://target.com')",
                "3. Get next tests: testing_next(limit=5) - returns cells with payloads",
                "4. For each cell, use the provided tool_call or execute manually:",
                "   - SQLi: fuzz_parameter(payload_types=['sqli_db'], db_type='mysql')",
                "   - IDOR: auth_diff_test(url, identity_a, identity_b)",
                "   - XSS: browser_test_xss() or fuzz_parameter(payload_types=['injection'])",
                "5. Check if done: testing_should_continue(vuln_spec_id, endpoint_id, results_so_far)",
                "6. Document findings: add_card(card_type='finding') for confirmed issues",
                "7. Monitor: testing_status() shows endpoint coverage % and checklist compliance %"
            ],
            "common_mistakes": [
                "❌ NOT calling testing_build_matrix() first - matrix must be built before testing",
                "❌ Testing randomly instead of using testing_next() prioritization",
                "❌ Skipping testing_should_continue() - may over-test or under-test",
                "❌ Not checking testing_status() - may miss untested vuln classes or endpoints",
                "❌ Running nuclei_scan_template without checking budget first (expensive)",
                "❌ Creating findings before validation - use validate_repro() first",
                "❌ Not using http_send_batch() for parallel tests (inefficient)",
                "❌ Ignoring endpoint_probe() context before endpoint_execute_plan()"
            ],
            "success_criteria": [
                "✓ Coverage matrix built (testing_status shows matrix_built: true)",
                "✓ Endpoint completeness >90% (testing_status shows coverage_percentage)",
                "✓ Checklist compliance >70% (testing_status shows classes_with_test_activity)",
                "✓ All high-priority cells tested (priority>70)",
                "✓ Findings documented with add_card() for validated issues",
                "✓ Hypotheses updated to confirmed/rejected status"
            ]
        },
        4: {
            "current_phase": 4,
            "phase_name": "Exploitation & Validation",
            "recommended_tools": [
                {"tool": "validate_repro", "priority": "critical", "reason": "Confirm findings are reproducible (3x minimum)"},
                {"tool": "validate_negative_control", "priority": "high", "reason": "Rule out false positives with benign input"},
                {"tool": "validate_cross_identity", "priority": "high", "reason": "Test authorization vulns across users"},
                {"tool": "validate_promote", "priority": "high", "reason": "Promote validated findings to confirmed"},
                {"tool": "evidence_bundle", "priority": "high", "reason": "Package evidence for each confirmed finding"},
                {"tool": "poc_generate", "priority": "medium", "reason": "Generate reproduction scripts"},
                {"tool": "browser_screenshot", "priority": "low", "reason": "Visual evidence for XSS/visual bugs"}
            ],
            "next_actions": [
                "1. List all findings: list_cards(card_type='finding', status='potential')",
                "2. For each finding:",
                "   a. validate_repro(finding_id) - run 3+ times",
                "   b. validate_negative_control(finding_id) - test benign input",
                "   c. For authz bugs: validate_cross_identity(finding_id, identities=[...])",
                "   d. If all pass: validate_promote(finding_id)",
                "3. Create evidence bundles: evidence_bundle(finding_id)",
                "4. Add artifacts: evidence_add_artifact(bundle_id, type='request'|'response'|'screenshot', ...)",
                "5. Generate PoCs: poc_generate(finding_id)",
                "6. Calculate risk: risk_score(finding_id, cvss_vector='...')",
                "7. Export evidence: evidence_export(bundle_id, format='zip'|'json'|'sarif')"
            ],
            "common_mistakes": [
                "❌ Skipping validate_negative_control - leads to false positive findings",
                "❌ Not testing reproducibility enough (1-2x insufficient, need 3+ successes)",
                "❌ Promoting findings before validation complete",
                "❌ Forgetting to create evidence bundles before state changes",
                "❌ Not testing findings across multiple user identities (misses scope)"
            ],
            "success_criteria": [
                "✓ All potential findings validated or rejected",
                "✓ Confirmed findings have evidence bundles with artifacts",
                "✓ PoC scripts generated for reproducibility",
                "✓ Risk scores calculated for prioritization"
            ]
        }
    }

    return phase_guides.get(current_phase, phase_guides[1])


def _get_tool_dependencies() -> dict:
    """Tool sequencing rules and common multi-tool workflows."""
    return {
        "tool_chains": {
            "authenticated_recon": {
                "description": "Discover authenticated attack surface after obtaining credentials",
                "steps": [
                    {"step": 1, "tool": "credentials_add", "description": "Store discovered credentials with auto-generated placeholder"},
                    {"step": 2, "tool": "crawler_start", "params": {"identity_id": "<cred_id>"}, "description": "Crawl with authentication to discover privileged endpoints"},
                    {"step": 3, "tool": "coverage_discover", "params": {"since": "<crawl_timestamp>"}, "description": "Detect new endpoints and auto-extend coverage matrix"},
                    {"step": 4, "tool": "coverage_next", "params": {"limit": 20}, "description": "Get prioritized tests for newly discovered endpoints"}
                ]
            },
            "api_testing": {
                "description": "Systematic API testing from spec to complete coverage",
                "steps": [
                    {"step": 1, "tool": "http_send", "params": {"method": "GET", "url": "https://api.example.com/swagger.json"}, "description": "Fetch API specification"},
                    {"step": 2, "tool": "openapi_parse", "params": {"content": "<spec_content>"}, "description": "Parse OpenAPI specification"},
                    {"step": 3, "tool": "openapi_list_endpoints", "params": {"spec_id": "<id>"}, "description": "List all API endpoints"},
                    {"step": 4, "tool": "coverage_init", "params": {"base_url": "https://api.example.com"}, "description": "Build endpoint × vuln_class matrix"},
                    {"step": 5, "tool": "coverage_next", "params": {"limit": 10}, "description": "Get next priority tests"},
                    {"step": 6, "tool": "endpoint_execute_plan", "description": "Execute tests with exact tool_call from coverage_next"}
                ]
            },
            "finding_validation": {
                "description": "Complete validation and evidence collection for a potential finding",
                "steps": [
                    {"step": 1, "tool": "validate_repro", "params": {"finding_id": "<id>", "count": 3}, "description": "Reproduce 3x to confirm consistency"},
                    {"step": 2, "tool": "validate_negative_control", "params": {"finding_id": "<id>"}, "description": "Test with benign input to rule out false positive"},
                    {"step": 3, "tool": "validate_cross_identity", "params": {"finding_id": "<id>", "identities": [...]}, "description": "Test across user contexts if authorization-related"},
                    {"step": 4, "tool": "validate_promote", "params": {"finding_id": "<id>"}, "description": "Promote to confirmed status if validation passes"},
                    {"step": 5, "tool": "evidence_bundle", "params": {"finding_id": "<id>"}, "description": "Create evidence package"},
                    {"step": 6, "tool": "evidence_add_artifact", "description": "Add request/response/screenshot artifacts"},
                    {"step": 7, "tool": "poc_generate", "params": {"finding_id": "<id>"}, "description": "Generate curl + Python PoC scripts"}
                ]
            },
            "web_app_discovery": {
                "description": "Complete web application mapping from URL to full endpoint list",
                "steps": [
                    {"step": 1, "tool": "scope_validate_target", "params": {"target": "https://example.com"}, "description": "Verify target is in scope"},
                    {"step": 2, "tool": "browser_navigate", "params": {"url": "https://example.com"}, "description": "Load application in browser"},
                    {"step": 3, "tool": "browser_discover_forms", "description": "Find all HTML forms and input vectors"},
                    {"step": 4, "tool": "crawler_start", "params": {"start_url": "https://example.com", "max_pages": 200}, "description": "Crawl all pages"},
                    {"step": 5, "tool": "wm_query", "params": {"table": "endpoints"}, "description": "Query discovered endpoints from world model"},
                    {"step": 6, "tool": "coverage_init", "params": {"base_url": "https://example.com"}, "description": "Build coverage matrix"}
                ]
            }
        },
        "prerequisites": {
            "ANY_TOOL_TO_TARGET": ["scope_validate_target"],
            "crawler_start": ["scope_validate_target"],
            "coverage_init": ["wm_query(table='endpoints') shows endpoints"],
            "endpoint_execute_plan": ["endpoint_probe", "coverage_init"],
            "validate_repro": ["add_card(card_type='finding')"],
            "nuclei_scan_template": ["scope_validate_target", "scope_check_budget"],
            "fuzz_parameter": ["scope_validate_target", "scope_check_budget"],
            "evidence_bundle": ["validate_promote"],
            "poc_generate": ["validate_promote"],
            "coverage_mark": ["coverage_next returned this cell_id"],
            "browser_discover_forms": ["browser_navigate"],
            "browser_test_xss": ["browser_navigate"],
            "openapi_list_endpoints": ["openapi_parse"],
            "openapi_get_endpoint": ["openapi_parse"],
            "openapi_get_schemas": ["openapi_parse"]
        },
        "common_sequences": {
            "before_any_request": [
                "scope_validate_target(url) - MANDATORY",
                "scope_record_request() - for rate limiting",
                "scope_check_budget() - periodically"
            ],
            "discovering_new_endpoints": [
                "crawler_start() OR openapi_parse() OR execute('gobuster')",
                "coverage_discover(since=<timestamp>)",
                "coverage_next() - get new tests"
            ],
            "testing_an_endpoint": [
                "endpoint_probe() - gather context",
                "endpoint_execute_plan() - run tests",
                "coverage_mark() - record result"
            ],
            "confirming_a_finding": [
                "validate_repro() - reproduce 3x",
                "validate_negative_control() - rule out FP",
                "validate_promote() - confirm",
                "evidence_bundle() - package"
            ]
        },
        "anti_patterns": [
            "❌ Calling coverage_next() but not calling coverage_mark() after testing",
            "❌ Running nuclei/fuzz without scope_validate_target() first",
            "❌ Creating findings before validation (should be observations first)",
            "❌ Using scan() when dedicated tools exist (use fuzz_parameter not execute('sqlmap'))",
            "❌ Not checking wm_recall() before re-running expensive scans",
            "❌ Calling endpoint_execute_plan() without endpoint_probe() first",
            "❌ Using execute() for HTTP requests (use http_send for budget tracking)"
        ]
    }


def _get_pentest_workflow() -> dict:
    """LLM-in-the-loop pentest workflow using the 8 new pentest tools."""
    return {
        "overview": "Manual security testing workflow where the LLM sees raw HTTP traffic, selects payloads, and controls the testing flow. Unlike automated tools that return pre-digested summaries, these tools expose complete request/response data for LLM reasoning.",
        "workflow": [
            {
                "step": 1,
                "tool": "discover_attack_surface",
                "description": "See what endpoints, parameters, and findings are known",
                "example": "discover_attack_surface()",
                "what_to_look_for": [
                    "Total endpoints discovered",
                    "Untested endpoints",
                    "Known parameters on each endpoint",
                    "Existing findings count",
                    "Assets in scope"
                ]
            },
            {
                "step": 2,
                "tool": "recon_endpoint",
                "description": "Send baseline request to each endpoint, examine full response",
                "example": "recon_endpoint(url='https://api.example.com/users', method='GET')",
                "what_to_look_for": [
                    "Response status and error messages",
                    "Reflected parameters in body",
                    "JSON structure or HTML templates",
                    "Technology signatures (framework errors, server headers)",
                    "Authentication requirements (401/403)",
                    "Rate limiting headers"
                ]
            },
            {
                "step": 3,
                "tool": "analyze_headers",
                "description": "Check security headers and cookie configuration",
                "example": "analyze_headers(url='https://example.com')",
                "what_to_look_for": [
                    "Missing security headers (CSP, HSTS, X-Frame-Options)",
                    "Cookies without HttpOnly or Secure flags",
                    "Permissive CORS (Access-Control-Allow-Origin: *)",
                    "Server version disclosure",
                    "Weak cache headers (Cache-Control: public on sensitive endpoints)"
                ]
            },
            {
                "step": 4,
                "tool": "get_test_payloads",
                "description": "Get payloads for suspected vulnerability classes",
                "example": "get_test_payloads(vuln_class='sqli_error', limit=10)",
                "decision_tree": {
                    "sql_error_in_response": ["sqli_error", "sqli_union", "sqli_blind_time"],
                    "template_rendering_detected": ["ssti"],
                    "parameter_reflected_in_html": ["xss_reflected", "xss_dom"],
                    "json_api_with_ids": ["idor", "nosql_injection", "mass_assignment"],
                    "file_upload_found": ["path_traversal", "command_injection"],
                    "external_url_parameter": ["ssrf", "open_redirect"],
                    "xml_content_type": ["xml_injection"],
                    "jwt_authentication": ["jwt_manipulation"]
                },
                "available_classes": [
                    "sqli_error", "sqli_blind_boolean", "sqli_blind_time", "sqli_union",
                    "xss_reflected", "xss_stored", "xss_dom",
                    "ssti", "ssrf", "path_traversal", "command_injection",
                    "ldap_injection", "xml_injection", "header_injection", "nosql_injection",
                    "idor", "auth_bypass", "jwt_manipulation", "cors_misconfig", "open_redirect",
                    "mass_assignment", "param_pollution", "rate_limit_bypass"
                ]
            },
            {
                "step": 5,
                "tool": "inject_batch",
                "description": "Sweep hardcoded payloads against parameter, compare to baseline",
                "example": "inject_batch(url='https://api.example.com/search', parameter='q', location='query', payloads=[...], include_baseline=true)",
                "what_to_look_for": [
                    "Status code changes (500 errors = likely SQLi/SSTI)",
                    "Response body length variance (significant diff = injection success)",
                    "Timing anomalies (>2x baseline = blind time-based injection)",
                    "Payloads reflected in response",
                    "Error messages revealing injection success"
                ],
                "best_practices": [
                    "Always include baseline for comparison",
                    "Start with small payload set (10-25) for quick triage",
                    "Cap max_batch_size to respect budget",
                    "Look for outliers in summary stats first, then examine individual responses"
                ]
            },
            {
                "step": 6,
                "tool": "inject_payload",
                "description": "Craft and send targeted payloads based on observed behavior",
                "example": "inject_payload(url='https://api.example.com/users', parameter='id', location='query', payload=\"1' OR '1'='1\")",
                "use_cases": [
                    "Test custom payloads crafted for specific framework/DB",
                    "Follow up on promising batch results with refined payloads",
                    "Test context-specific injection (JSON vs URL-encoded vs path)",
                    "Verify payload reflection and encoding behavior",
                    "Check for WAF bypass with obfuscated payloads"
                ],
                "injection_locations": {
                    "query": "URL query parameters (?id=PAYLOAD)",
                    "body": "JSON body {\"param\": \"PAYLOAD\"} or form data",
                    "path": "URL path segments /users/{id} where {id}=PAYLOAD",
                    "header": "Custom headers (X-Forwarded-For: PAYLOAD)",
                    "cookie": "Cookie values (session=PAYLOAD)"
                }
            },
            {
                "step": 7,
                "tool": "record_finding",
                "description": "Record confirmed vulnerabilities with evidence",
                "example": "record_finding(title='SQL Injection in /api/users', severity='high', url='https://api.example.com/users', vuln_class='sqli_error', parameter='id', evidence={...})",
                "when_to_use": [
                    "After confirming vulnerability through multiple payloads",
                    "When you have clear evidence (error message, reflected payload, status change)",
                    "When vulnerability is reproducible (not intermittent)",
                    "When you understand the root cause and impact"
                ],
                "evidence_structure": {
                    "request": "Full request that triggered vulnerability",
                    "response": "Full response showing vulnerability behavior",
                    "payload": "Exact payload that worked",
                    "description": "Explanation of how to reproduce and why it's vulnerable"
                },
                "severity_guidelines": {
                    "critical": "RCE, SQL injection with data exfil, auth bypass to admin",
                    "high": "XSS in admin panel, IDOR on sensitive data, SSRF to internal network",
                    "medium": "XSS in user context, CSRF, info disclosure",
                    "low": "Verbose errors, missing security headers",
                    "info": "Observations, potential misconfigurations"
                }
            },
            {
                "step": 8,
                "tool": "get_test_progress",
                "description": "Verify coverage completeness and testing status",
                "example": "get_test_progress()",
                "use_to_answer": [
                    "How many endpoints have I tested?",
                    "What's my coverage percentage?",
                    "How many findings by severity?",
                    "How much budget remains?",
                    "Which vuln classes are untested?",
                    "Which endpoints need more testing?"
                ],
                "success_criteria": [
                    "Coverage >80% for comprehensive assessment",
                    "All high-risk endpoints tested",
                    "Budget usage proportional to phase (40% recon, 25% mapping, 25% testing, 10% validation)",
                    "Findings validated and documented"
                ]
            }
        ],
        "complete_example": {
            "scenario": "Testing a REST API endpoint for SQL injection",
            "sequence": [
                {
                    "step": "1. Discover",
                    "call": "discover_attack_surface()",
                    "observe": "Found /api/users?id=1 endpoint with 'id' parameter"
                },
                {
                    "step": "2. Baseline",
                    "call": "recon_endpoint(url='https://api.example.com/users?id=1', method='GET')",
                    "observe": "Returns 200 OK with user JSON. Response time 145ms."
                },
                {
                    "step": "3. Get Payloads",
                    "call": "get_test_payloads(vuln_class='sqli_error', limit=20)",
                    "observe": "Retrieved 20 error-based SQL injection payloads"
                },
                {
                    "step": "4. Batch Test",
                    "call": "inject_batch(url='https://api.example.com/users', parameter='id', location='query', payloads=[...20 payloads...], include_baseline=true)",
                    "observe": "15 payloads → 200 OK, 3 payloads → 500 error, 2 payloads → timing anomaly (2.3x baseline). Status changes detected!"
                },
                {
                    "step": "5. Targeted Test",
                    "call": "inject_payload(url='https://api.example.com/users', parameter='id', location='query', payload=\"1' OR '1'='1\")",
                    "observe": "500 Internal Server Error. Response body contains: 'You have an error in your SQL syntax'. Confirmed SQLi!"
                },
                {
                    "step": "6. Record",
                    "call": "record_finding(title='SQL Injection in /api/users?id parameter', severity='high', url='https://api.example.com/users', vuln_class='sqli_error', parameter='id', evidence={request: {...}, response: {...}, payload: \"1' OR '1'='1\", description: 'Error-based SQLi confirmed via MySQL error message'})",
                    "observe": "Finding recorded with card_id and finding_id"
                },
                {
                    "step": "7. Progress",
                    "call": "get_test_progress()",
                    "observe": "1 endpoint tested, 1 high finding, 248 requests remaining"
                }
            ]
        },
        "tips": [
            "Use recon_endpoint first to understand normal behavior before injecting",
            "Start with inject_batch for broad sweep, then inject_payload for targeted tests",
            "Always compare injected responses to baseline (status, length, timing)",
            "Look for error messages, SQL syntax errors, stack traces in responses",
            "Check if payloads are reflected HTML-encoded (XSS mitigation)",
            "Test all 5 injection locations (query, body, path, header, cookie)",
            "Record findings with complete evidence while memory is fresh",
            "Monitor budget with get_test_progress to avoid exhaustion"
        ],
        "vs_automated_tools": {
            "fuzz_endpoint": {
                "automated": "Sends payloads, returns vuln class verdicts (sqli: true/false)",
                "llm_pentest": "LLM sees every response, reasons about error patterns, crafts adaptive payloads"
            },
            "endpoint_probe": {
                "automated": "Returns 500-char response snippet",
                "llm_pentest": "recon_endpoint returns 8KB+ full response for complete analysis"
            },
            "testing_next": {
                "automated": "Returns pre-determined test plan with tool calls to execute",
                "llm_pentest": "LLM controls flow: sees response → decides next payload → injects → observes → repeats"
            }
        },
        "when_to_use_this_workflow": [
            "When automated testing (fuzz_endpoint, endpoint_execute_plan) returns false negatives",
            "When you need to understand WHY a test failed or succeeded",
            "When testing complex business logic that requires adaptive payloads",
            "When you want to craft context-specific exploits (not hardcoded payloads)",
            "When debugging an unclear vulnerability signal",
            "When the LLM needs to make decisions based on application behavior"
        ],
        "when_to_use_automated_tools": [
            "Phase 1-2 (Recon/Mapping): Use recon_pipeline_run, crawler_start for broad discovery",
            "Phase 3 (Testing): Use testing_build_matrix → testing_next for comprehensive coverage",
            "When you need to test 100+ endpoints quickly (batch automation)",
            "When vulnerability patterns are well-known (Nuclei templates, standard SQLi/XSS)",
            "When budget is limited (automated tools are more efficient)"
        ],
        "simple_vulnerability_checklist": {
            "description": "MANDATORY simple tests that must be performed in Phase 3 before advancing to Phase 4. These catch easy wins that automated scanning often misses. Assessment 4 found 24 findings; Assessments 10/11 found only 8 each because these basic tests were skipped.",
            "requirement": "Complete at least 6 of 8 tests before Phase 4. These are low-hanging fruit that yield high-impact findings.",
            "tests": [
                {
                    "name": "Security Headers",
                    "tool": "analyze_headers",
                    "priority": "CRITICAL",
                    "effort": "1-2 minutes",
                    "how": "Call analyze_headers on main URL and 2-3 key endpoints. Check response for missing headers.",
                    "what_to_check": [
                        "Content-Security-Policy (CSP) header present?",
                        "HTTP Strict-Transport-Security (HSTS) header present?",
                        "X-Content-Type-Options: nosniff present?",
                        "X-Frame-Options present?",
                        "Cookies have HttpOnly, Secure, and SameSite flags?"
                    ],
                    "record_if": "Missing CSP, HSTS, or insecure cookie flags. Severity: medium (missing CSP/HSTS), low (other headers).",
                    "typical_findings": "Missing CSP, missing HSTS, cookies without HttpOnly/Secure flags"
                },
                {
                    "name": "Weak Password Policy",
                    "tool": "inject_payload",
                    "priority": "HIGH",
                    "effort": "2-3 minutes",
                    "how": "If registration or password-change endpoint exists, try setting passwords: '123456', 'password', 'a', 'test'. Check if accepted.",
                    "what_to_check": [
                        "Are passwords shorter than 8 chars accepted?",
                        "Are common passwords ('password', '123456') accepted?",
                        "Is there a minimum complexity requirement (uppercase, numbers, symbols)?",
                        "Does the API return specific errors for weak passwords?"
                    ],
                    "record_if": "Passwords shorter than 8 chars OR common passwords accepted. Severity: medium.",
                    "typical_findings": "Weak password policy allowing '123456' or single-character passwords"
                },
                {
                    "name": "Username Enumeration",
                    "tool": "inject_batch",
                    "priority": "HIGH",
                    "effort": "3-5 minutes",
                    "how": "Send login requests with known-valid username (if available) and known-invalid username (e.g., 'nonexistent_user_xyz'). Use inject_batch with 2 requests. Compare response status, body length, and timing.",
                    "what_to_check": [
                        "Do valid and invalid usernames return different status codes (200 vs 404)?",
                        "Do valid and invalid usernames return different response bodies ('User not found' vs 'Invalid password')?",
                        "Do valid and invalid usernames have different response times (>100ms difference)?",
                        "Does the API reveal whether a username exists before checking the password?"
                    ],
                    "record_if": "Different responses for valid vs invalid usernames (status, body content, or timing). Severity: medium.",
                    "typical_findings": "Login endpoint returns 'User not found' for invalid users and 'Invalid password' for valid users"
                },
                {
                    "name": "CSRF Protection",
                    "tool": "recon_endpoint",
                    "priority": "MEDIUM",
                    "effort": "2-3 minutes",
                    "how": "For state-changing endpoints (POST/PUT/DELETE), send request WITHOUT any CSRF token or anti-CSRF header. Check if request succeeds.",
                    "what_to_check": [
                        "Do POST/PUT/DELETE endpoints require a CSRF token?",
                        "Do forms include hidden CSRF token fields?",
                        "Does the API use SameSite cookies as CSRF protection?",
                        "Can you perform state-changing actions without CSRF protection?"
                    ],
                    "record_if": "State-changing requests succeed without CSRF token. Severity: medium. NOTE: Exchange analyzer will auto-detect missing CSRF tokens in forms.",
                    "typical_findings": "POST /api/users endpoint accepts requests without CSRF token"
                },
                {
                    "name": "Default Credentials",
                    "tool": "inject_batch",
                    "priority": "HIGH",
                    "effort": "2-3 minutes",
                    "how": "Try default credential pairs on login endpoint: admin:admin, admin:password, admin:123456, test:test, root:root. Use inject_batch with 5 requests.",
                    "what_to_check": [
                        "Do any default credential pairs return 200 OK or a session token?",
                        "Are there error messages revealing valid usernames ('Invalid password for admin')?",
                        "Is there an admin or test account with default password?"
                    ],
                    "record_if": "Any default credential pair grants access (200 OK with session/token). Severity: critical.",
                    "typical_findings": "Admin account with password 'admin' grants full access"
                },
                {
                    "name": "Input Validation",
                    "tool": "inject_batch",
                    "priority": "MEDIUM",
                    "effort": "3-5 minutes",
                    "how": "Send boundary values to API parameters: empty string '', very long string (5000 chars), special chars '<>\"&', negative numbers -1, zero, null, undefined. Use inject_batch with 6-8 payloads.",
                    "what_to_check": [
                        "Does the API accept invalid input (negative IDs, empty required fields)?",
                        "Does the API return 500 errors or stack traces for invalid input?",
                        "Are there verbose error messages revealing internal logic?",
                        "Does the API validate data types (string vs int, email format)?"
                    ],
                    "record_if": "API accepts invalid input OR returns 500 errors with stack traces. Severity: low (weak validation), medium (error disclosure).",
                    "typical_findings": "API accepts negative user IDs, returns 500 error with stack trace for malformed input"
                },
                {
                    "name": "Rate Limiting",
                    "tool": "inject_batch",
                    "priority": "MEDIUM",
                    "effort": "2-3 minutes",
                    "how": "Send 20-30 rapid identical requests to login endpoint or sensitive endpoint. Use inject_batch with 25 requests. Check if any rate limiting applied (429 status, lockout, delay).",
                    "what_to_check": [
                        "Does the API return 429 Too Many Requests after N attempts?",
                        "Does response time increase after repeated requests (throttling)?",
                        "Is there account lockout after N failed login attempts?",
                        "Are there rate-limiting headers (X-RateLimit-Remaining)?"
                    ],
                    "record_if": "No rate limiting after 20+ rapid requests on sensitive endpoint. Severity: medium.",
                    "typical_findings": "Login endpoint accepts 1000+ login attempts with no rate limiting or lockout"
                },
                {
                    "name": "Error Handling",
                    "tool": "recon_endpoint",
                    "priority": "MEDIUM",
                    "effort": "2-3 minutes",
                    "how": "Request non-existent URLs (404), use invalid HTTP methods (OPTIONS on restricted endpoint), send malformed JSON. Check for stack traces, debug info, or detailed error messages.",
                    "what_to_check": [
                        "Do 404 pages reveal framework/version info (Django debug page, Spring error)?",
                        "Do 500 errors include stack traces with file paths?",
                        "Do error messages reveal internal logic ('Database connection failed at line 42 in auth.py')?",
                        "Is debug mode enabled in production (verbose errors)?"
                    ],
                    "record_if": "Stack traces, debug info, or detailed error messages exposed. Severity: medium (stack traces), low (verbose errors). NOTE: Exchange analyzer will auto-detect stack traces.",
                    "typical_findings": "404 page shows Django debug page with installed apps, 500 error shows Python traceback"
                }
            ],
            "completion_criteria": {
                "minimum_tests": 6,
                "recommended_tests": 8,
                "expected_findings": "3-8 findings from simple tests alone",
                "phase_gate": "Before advancing to Phase 4, verify at least 6 of 8 tests completed and findings recorded"
            },
            "why_these_matter": "Assessment 4 (manual testing) found weak passwords, username enumeration, missing headers, no rate limiting, and verbose errors. Assessments 10/11 (automated only) missed these because they require simple manual checks that automated tools skip. These tests take 15-20 minutes total and often yield 30-50% of total findings.",
            "integration_with_automated_testing": "Run these simple tests FIRST in Phase 3, then use testing_build_matrix for comprehensive coverage. Simple tests are high-yield and help you understand the application before deep testing."
        }
    }
