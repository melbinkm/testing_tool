"""
Autonomous Execution Mode - Step-based runbook navigator for automated pentesting.

Provides a state machine that guides the LLM through predefined runbook steps across all 6 phases.
Acts as a "copilot navigator" - tracks progress, tells the LLM what tool to call next, handles
approval gates, and manages error recovery. Does NOT execute other tools directly (avoiding circular
imports); instead returns instructions that the LLM executes.
"""

import json
from typing import List, Dict, Any, Optional, Tuple
from urllib.parse import urlparse
from mcp.types import Tool, TextContent


# ========== Runbook Definition ==========

RUNBOOK_PLAN_TITLE = "Autonomous Runbook Execution"

RUNBOOK_STEPS = {
    1: [  # Phase 1: Reconnaissance (7 steps)
        {
            "id": "1.1",
            "name": "Verify scope allowlist",
            "tool": "scope_get_allowlist",
            "args_template": {},
            "description": "Get all allowed targets, domains, and IP ranges",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.2",
            "name": "Subdomain enumeration",
            "tool": "subdomain_enum",
            "args_template": {"domain": "{target_domain}"},
            "description": "Discover subdomains for in-scope domains",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.3",
            "name": "Port and service scan",
            "tool": "scan",
            "args_template": {"target": "{base_url}", "type": "nmap_quick"},
            "description": "Scan for open ports and services",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.4",
            "name": "Technology detection",
            "tool": "tech_detection",
            "args_template": {"url": "{base_url}"},
            "description": "Identify frameworks and technologies",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.5",
            "name": "SSL/TLS analysis",
            "tool": "ssl_analysis",
            "args_template": {"url": "{base_url}"},
            "description": "Check SSL/TLS configuration and vulnerabilities",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.6",
            "name": "Phase 1 gate check",
            "tool": "orchestration_status",
            "args_template": {},
            "description": "Check if Phase 1 gate requirements are met (≥3 assets, ≥5 endpoints)",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": True,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "1.7",
            "name": "Advance to Phase 2",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 2},
            "description": "Transition to mapping and enumeration phase",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": "gates_met",
            "repeatable": False,
        },
    ],
    2: [  # Phase 2: Mapping & Enumeration (6 steps)
        {
            "id": "2.1",
            "name": "Start web crawler",
            "tool": "crawler_start",
            "args_template": {"base_url": "{base_url}"},
            "description": "Crawl application to discover endpoints",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "2.2",
            "name": "Parse OpenAPI specification",
            "tool": "openapi_parse",
            "args_template": {"spec_url": "{base_url}/openapi.json"},
            "description": "Parse OpenAPI/Swagger spec if available",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "2.3",
            "name": "Discover forms with browser",
            "tool": "browser_discover_forms",
            "args_template": {"url": "{base_url}"},
            "description": "Find all HTML forms and input fields",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "2.4",
            "name": "Initialize coverage matrix",
            "tool": "coverage_init",
            "args_template": {"base_url": "{base_url}"},
            "description": "Create endpoint x vulnerability coverage matrix",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "2.5",
            "name": "Phase 2 gate check",
            "tool": "orchestration_status",
            "args_template": {},
            "description": "Check if Phase 2 gate requirements are met (≥5 endpoints, ≥1 finding)",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": True,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "2.6",
            "name": "Advance to Phase 3",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 3},
            "description": "Transition to SAST code review phase",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": "gates_met",
            "repeatable": False,
        },
    ],
    3: [  # Phase 3: SAST Code Review (8 steps)
        {
            "id": "3.1",
            "name": "Clone source repository",
            "tool": "sast_clone_repo",
            "args_template": {},
            "description": "Clone git repository for SAST analysis (skip if no repo)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.2",
            "name": "Index source code",
            "tool": "sast_index_repo",
            "args_template": {},
            "description": "Index source files for RAG-based code search (skip if clone failed)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.3",
            "name": "Run Semgrep scanner",
            "tool": "sast_scan_semgrep",
            "args_template": {},
            "description": "Run Semgrep static analysis (skip if clone failed)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.4",
            "name": "Run Bandit scanner",
            "tool": "sast_scan_bandit",
            "args_template": {},
            "description": "Run Bandit Python security scanner (skip if clone failed)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.5",
            "name": "Run Gitleaks scanner",
            "tool": "sast_scan_gitleaks",
            "args_template": {},
            "description": "Run Gitleaks secret scanner (skip if clone failed)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.6",
            "name": "Verify SAST findings dynamically",
            "tool": "sast_get_next_unverified",
            "args_template": {},
            "description": "Get next unverified SAST finding and test dynamically (repeatable until all verified)",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"sast_all_verified": True},
        },
        {
            "id": "3.7",
            "name": "Phase 3 gate check",
            "tool": "orchestration_status",
            "args_template": {},
            "description": "Check if Phase 3 gate requirements are met (100% SAST verified)",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": True,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "3.8",
            "name": "Advance to Phase 4",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 4},
            "description": "Transition to vulnerability assessment phase",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": "gates_met",
            "repeatable": False,
        },
    ],
    4: [  # Phase 4: Vulnerability Assessment (8 steps)
        {
            "id": "4.1",
            "name": "Discover attack surface",
            "tool": "discover_attack_surface",
            "args_template": {},
            "description": "Get all endpoints, parameters, and known findings",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.2",
            "name": "Analyze security headers",
            "tool": "analyze_headers",
            "args_template": {"url": "{base_url}"},
            "description": "Check for missing security headers and cookie flags",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.3",
            "name": "Get vulnerability checklist",
            "tool": "checklist_get",
            "args_template": {},
            "description": "Get 42-class vulnerability testing checklist",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.4",
            "name": "Build testing matrix",
            "tool": "testing_build_matrix",
            "args_template": {},
            "description": "Generate endpoint x vulnerability test matrix",
            "approval_required": True,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.5",
            "name": "Execute next test",
            "tool": "testing_next",
            "args_template": {},
            "description": "Get and execute next pending test from matrix",
            "approval_required": False,
            "on_failure": "retry",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"coverage_pct": 25, "findings_count": 3},
        },
        {
            "id": "4.6",
            "name": "Check testing progress",
            "tool": "get_test_progress",
            "args_template": {"base_url": "{base_url}"},
            "description": "Verify coverage and findings count",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.7",
            "name": "Phase 4 gate check",
            "tool": "orchestration_status",
            "args_template": {},
            "description": "Check if Phase 4 gate requirements are met (≥1 confirmed hypothesis, ≥3 findings, ≥25% coverage)",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": True,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "4.8",
            "name": "Advance to Phase 5",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 5},
            "description": "Transition to exploitation phase",
            "approval_required": True,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": "gates_met",
            "repeatable": False,
        },
    ],
    5: [  # Phase 5: Exploitation (8 steps)
        {
            "id": "5.1",
            "name": "Correlate SAST and DAST findings",
            "tool": "sast_correlate",
            "args_template": {},
            "description": "Cross-reference SAST findings with DAST findings for confirmation",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "5.2",
            "name": "Validate finding reproduction",
            "tool": "validate_repro",
            "args_template": {"card_id": "{next_unvalidated_finding}"},
            "description": "Reproduce finding 3 times to confirm consistency",
            "approval_required": True,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"validated_findings_count": 1},
        },
        {
            "id": "5.3",
            "name": "Promote validated finding",
            "tool": "validate_promote",
            "args_template": {"card_id": "{next_validated_finding}"},
            "description": "Promote validated finding to confirmed status",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"confirmed_findings_count": 1},
        },
        {
            "id": "5.4",
            "name": "Create evidence bundle",
            "tool": "evidence_bundle",
            "args_template": {"finding_id": "{next_confirmed_finding}"},
            "description": "Package all evidence for confirmed finding",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"all_confirmed_bundled": True},
        },
        {
            "id": "5.5",
            "name": "Generate PoC script",
            "tool": "poc_generate",
            "args_template": {"finding_id": "{next_confirmed_finding}"},
            "description": "Create proof-of-concept exploitation script",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"all_confirmed_have_poc": True},
        },
        {
            "id": "5.6",
            "name": "Calculate risk scores",
            "tool": "risk_score",
            "args_template": {"finding_id": "{next_confirmed_finding}"},
            "description": "Compute CVSS and business impact scores",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": True,
            "repeat_until": {"all_confirmed_scored": True},
        },
        {
            "id": "5.7",
            "name": "Phase 5 gate check",
            "tool": "orchestration_status",
            "args_template": {},
            "description": "Check if Phase 5 gate requirements are met (≥1 confirmed finding)",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": True,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "5.8",
            "name": "Advance to Phase 6",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 6},
            "description": "Transition to reporting phase",
            "approval_required": False,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": "gates_met",
            "repeatable": False,
        },
    ],
    6: [  # Phase 6: Post-Exploitation & Reporting (3 steps)
        {
            "id": "6.1",
            "name": "Generate assessment report",
            "tool": "evidence_generate_report",
            "args_template": {},
            "description": "Create comprehensive security assessment report",
            "approval_required": True,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "6.2",
            "name": "Export evidence artifacts",
            "tool": "evidence_export",
            "args_template": {},
            "description": "Export all evidence bundles and artifacts",
            "approval_required": False,
            "on_failure": "skip",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
        {
            "id": "6.3",
            "name": "Complete assessment",
            "tool": "orchestration_advance",
            "args_template": {"target_phase": 7},
            "description": "Mark assessment as complete",
            "approval_required": True,
            "on_failure": "halt",
            "is_gate_check": False,
            "condition": None,
            "repeatable": False,
        },
    ],
}


# ========== Tool Definition ==========

def get_auto_run_tools() -> List[Tool]:
    """Return autonomous execution tool."""
    return [
        Tool(
            name="orchestration_auto_run",
            description=(
                "Step-based autonomous runbook navigator for automated penetration testing. "
                "Call repeatedly to execute the complete 6-phase assessment workflow."
                "\n\n"
                "**How it works:**\n"
                "1. Call with action='next' (default) to get next step to execute\n"
                "2. Execute the returned tool call\n"
                "3. Call with action='step_done' and result_summary to report completion\n"
                "4. Repeat until status='complete'\n"
                "\n"
                "**Actions:**\n"
                "- next: Get next pending step (returns tool call instructions)\n"
                "- step_done: Mark current step completed, get next step\n"
                "- step_failed: Handle step failure per on_failure policy\n"
                "- status: Get runbook progress (phase, step, % complete)\n"
                "- reset: Reset all steps to pending\n"
                "\n"
                "**Approval gates:**\n"
                "Some steps require human approval. When encountered, status='awaiting_approval' "
                "with message. LLM relays message to user, waits for confirmation, then calls "
                "step_done to proceed.\n"
                "\n"
                "**Repeatable steps:**\n"
                "Some steps (testing_next, validate_repro) repeat until conditions met. "
                "step_done automatically repeats or advances based on current metrics.\n"
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["next", "step_done", "step_failed", "status", "reset"],
                        "default": "next",
                        "description": "Action to perform",
                    },
                    "result_summary": {
                        "type": "string",
                        "description": "Summary of completed step result (for step_done)",
                    },
                    "error": {
                        "type": "string",
                        "description": "Error message (for step_failed)",
                    },
                },
                "additionalProperties": False,
            },
        )
    ]


# ========== Handler ==========

async def handle_auto_run_tool(name: str, arguments: dict, mcp_service: Any) -> List[TextContent]:
    """Handle autonomous execution tool calls."""
    if name == "orchestration_auto_run":
        return await _handle_auto_run(arguments, mcp_service)
    return [_error_content(f"Unknown tool: {name}")]


async def _handle_auto_run(arguments: dict, mcp_service: Any) -> List[TextContent]:
    """Main handler for orchestration_auto_run."""
    # Validate assessment loaded
    if not mcp_service.current_assessment_id:
        return [_error_content("No assessment loaded. Call load_assessment() first.")]

    # Get database
    from lib.world_model_db import get_world_model_db
    db = await get_world_model_db(mcp_service.current_assessment_id)

    # Get or create runbook plan
    plan = await _get_or_create_runbook(db)

    action = arguments.get("action", "next")

    if action == "status":
        return await _handle_status(plan, db)
    elif action == "reset":
        return await _handle_reset(plan, db)
    elif action == "next":
        return await _handle_next(plan, db, mcp_service)
    elif action == "step_done":
        return await _handle_step_done(plan, db, mcp_service, arguments)
    elif action == "step_failed":
        return await _handle_step_failed(plan, db, mcp_service, arguments)
    else:
        return [_error_content(f"Unknown action: {action}")]


# ========== Action Handlers ==========

async def _handle_status(plan: dict, db: Any) -> List[TextContent]:
    """Return runbook progress status."""
    steps = plan.get("steps", [])
    progress = _compute_progress(steps)

    return [_json_content({
        "status": "ok",
        "runbook": {
            "phase": progress["phase"],
            "step": progress["step"],
            "progress_pct": progress["progress_pct"],
            "steps_done": progress["steps_done"],
            "steps_total": progress["steps_total"],
            "is_complete": progress["is_complete"],
        }
    })]


async def _handle_reset(plan: dict, db: Any) -> List[TextContent]:
    """Reset all steps to pending."""
    steps = plan.get("steps", [])
    for step in steps:
        step["status"] = "pending"
        step.pop("result", None)
        step.pop("error", None)

    # Reset all steps in DB
    for i in range(len(steps)):
        await db.update_plan(
            plan_id=plan["id"],
            step_index=i,
            step_status="pending",
        )

    return [_json_content({
        "status": "ok",
        "message": "All steps reset to pending",
        "steps_total": len(steps),
    })]


async def _handle_next(plan: dict, db: Any, mcp_service: Any) -> List[TextContent]:
    """Get next pending step and return tool call instructions."""
    steps = plan.get("steps", [])

    # Find current step (first non-done)
    current_index, step_def = _find_current_step(steps)

    if current_index is None:
        # All steps done
        return [_json_content({
            "status": "complete",
            "message": "Runbook complete. All 6 phases finished.",
        })]

    # Check if step requires approval
    if step_def.get("approval_required", False):
        # Check if already approved (step status is in_progress)
        if steps[current_index].get("status") != "in_progress":
            return [_json_content({
                "status": "awaiting_approval",
                "message": f"Step {step_def['id']} ({step_def['name']}) requires approval before proceeding.",
                "step": {
                    "id": step_def["id"],
                    "name": step_def["name"],
                    "tool": step_def["tool"],
                    "description": step_def["description"],
                },
                "instructions": "Relay this approval request to the user. When approved, call orchestration_auto_run(action='step_done') to proceed.",
            })]

    # Check condition (e.g., gates_met)
    if step_def.get("condition") == "gates_met":
        # Check previous gate step result
        if current_index > 0:
            prev_step = steps[current_index - 1]
            prev_step_id = prev_step.get("description", "")
            prev_step_def = _get_step_def_by_id(prev_step_id)

            if prev_step_def and prev_step_def.get("is_gate_check"):
                gate_result = prev_step.get("result", {})
                if isinstance(gate_result, str):
                    try:
                        gate_result = json.loads(gate_result)
                    except:
                        gate_result = {}

                gates_met = gate_result.get("gates_met", False)
                if not gates_met:
                    unmet = gate_result.get("unmet_conditions", [])
                    return [_json_content({
                        "status": "blocked",
                        "message": f"Cannot advance to next phase. Gate requirements not met.",
                        "unmet_conditions": unmet,
                        "instructions": "Complete the required work to meet gate conditions, then retry.",
                    })]

    # Resolve arguments
    try:
        args = await _resolve_args(step_def, mcp_service, db)
    except ValueError as e:
        return [_error_content(str(e))]

    # Mark step as in_progress
    await db.update_plan(
        plan_id=plan["id"],
        step_index=current_index,
        step_status="in_progress",
    )

    return [_json_content({
        "status": "ok",
        "next_step": {
            "id": step_def["id"],
            "name": step_def["name"],
            "tool": step_def["tool"],
            "args": args,
            "description": step_def["description"],
        },
        "instructions": f"Call {step_def['tool']}({json.dumps(args)}) and then report back with orchestration_auto_run(action='step_done', result_summary='...').",
    })]


async def _handle_step_done(plan: dict, db: Any, mcp_service: Any, arguments: dict) -> List[TextContent]:
    """Mark current step done and return next step."""
    result_summary = arguments.get("result_summary", "")
    steps = plan.get("steps", [])

    # Find current step (first in_progress)
    current_index = None
    for i, step in enumerate(steps):
        if step.get("status") == "in_progress":
            current_index = i
            break

    if current_index is None:
        return [_error_content("No step in progress. Call action='next' first.")]

    current_step = steps[current_index]
    step_def = _get_step_def_by_id(current_step.get("description", ""))

    # Store result
    current_step["result"] = result_summary

    # If this is a repeatable step, check if we should repeat
    if step_def and step_def.get("repeatable", False):
        repeat_until = step_def.get("repeat_until", {})
        should_repeat = await _check_repeat_condition(repeat_until, mcp_service, db)

        if should_repeat:
            # Keep step in_progress, return same step again
            return [_json_content({
                "status": "ok",
                "message": f"Step {step_def['id']} repeating (conditions not yet met)",
                "next_step": {
                    "id": step_def["id"],
                    "name": step_def["name"],
                    "tool": step_def["tool"],
                    "args": await _resolve_args(step_def, mcp_service, db),
                    "description": step_def["description"],
                },
                "instructions": f"Call {step_def['tool']}() again and report back with step_done.",
            })]

    # Mark done and advance
    steps[current_index]["status"] = "done"
    await db.update_plan(
        plan_id=plan["id"],
        step_index=current_index,
        step_status="done",
        step_result=result_summary,
    )

    # Return next step
    return await _handle_next(plan, db, mcp_service)


async def _handle_step_failed(plan: dict, db: Any, mcp_service: Any, arguments: dict) -> List[TextContent]:
    """Handle step failure per on_failure policy."""
    error = arguments.get("error", "Unknown error")
    steps = plan.get("steps", [])

    # Find current step
    current_index = None
    for i, step in enumerate(steps):
        if step.get("status") == "in_progress":
            current_index = i
            break

    if current_index is None:
        return [_error_content("No step in progress.")]

    current_step = steps[current_index]
    step_def = _get_step_def_by_id(current_step.get("description", ""))

    if not step_def:
        return [_error_content(f"Step definition not found for step {current_index}")]

    on_failure = step_def.get("on_failure", "halt")

    # Store error
    current_step["error"] = error

    if on_failure == "retry":
        # Keep in_progress, return same step
        return [_json_content({
            "status": "ok",
            "message": f"Step {step_def['id']} failed. Retrying...",
            "error": error,
            "next_step": {
                "id": step_def["id"],
                "name": step_def["name"],
                "tool": step_def["tool"],
                "args": await _resolve_args(step_def, mcp_service, db),
                "description": step_def["description"],
            },
            "instructions": f"Retry {step_def['tool']}().",
        })]

    elif on_failure == "skip":
        # Mark done, advance to next
        steps[current_index]["status"] = "done"
        await db.update_plan(
            plan_id=plan["id"],
            step_index=current_index,
            step_status="done",
        )
        return await _handle_next(plan, db, mcp_service)

    else:  # halt
        # Mark skipped (no "failed" status exists), stop runbook
        steps[current_index]["status"] = "skipped"
        await db.update_plan(
            plan_id=plan["id"],
            step_index=current_index,
            step_status="skipped",
        )
        return [_json_content({
            "status": "halted",
            "message": f"Runbook halted due to critical step failure: {step_def['name']}",
            "error": error,
            "step": {
                "id": step_def["id"],
                "name": step_def["name"],
            },
            "instructions": "Fix the error and call action='reset' to restart the runbook, or manually call the failed tool.",
        })]


# ========== Helper Functions ==========

async def _get_or_create_runbook(db: Any) -> dict:
    """Find or create the runbook plan in wm_plans."""
    plans = await db.query(table="plans", filters={"status": "active"}, limit=100)

    for plan in plans:
        if plan.get("title") == RUNBOOK_PLAN_TITLE:
            return plan

    # Create new runbook plan
    all_steps = []
    for phase_num in range(1, 7):
        phase_steps = RUNBOOK_STEPS.get(phase_num, [])
        for step_def in phase_steps:
            all_steps.append({
                "description": step_def["id"],  # Store step ID in description for lookup
                "status": "pending",
            })

    plan = await db.add_plan(
        title=RUNBOOK_PLAN_TITLE,
        goal="Automated 6-phase penetration testing workflow",
        steps=all_steps,
    )

    return plan


def _find_current_step(steps: List[dict]) -> Tuple[Optional[int], Optional[dict]]:
    """Find first non-done step and return (index, step_def)."""
    for i, step in enumerate(steps):
        if step.get("status") != "done":
            step_id = step.get("description", "")
            step_def = _get_step_def_by_id(step_id)
            return i, step_def

    return None, None


def _get_step_def_by_id(step_id: str) -> Optional[dict]:
    """Look up step definition by ID (e.g., '1.2')."""
    for phase_steps in RUNBOOK_STEPS.values():
        for step_def in phase_steps:
            if step_def["id"] == step_id:
                return step_def
    return None


async def _resolve_args(step_def: dict, mcp_service: Any, db: Any) -> dict:
    """Resolve argument template variables."""
    args_template = step_def.get("args_template", {})
    resolved = {}

    for key, value in args_template.items():
        if isinstance(value, str) and value.startswith("{") and value.endswith("}"):
            var_name = value[1:-1]  # Strip {}

            if var_name == "target_domain":
                # Extract domain from base_url
                base_url = getattr(mcp_service, "current_base_url", None)
                if not base_url:
                    raise ValueError("target_domain requires base_url to be set. Call load_assessment() first.")
                parsed = urlparse(base_url)
                resolved[key] = parsed.netloc

            elif var_name == "base_url":
                base_url = getattr(mcp_service, "current_base_url", None)
                if not base_url:
                    raise ValueError("base_url not set. Call load_assessment() first.")
                resolved[key] = base_url

            elif var_name == "next_unvalidated_finding":
                findings = await db.query("findings", filters={"status": "potential"}, limit=1)
                if not findings:
                    raise ValueError("No unvalidated findings found. All findings already validated or none exist.")
                resolved[key] = findings[0]["id"]

            elif var_name == "next_validated_finding":
                findings = await db.query("findings", filters={"status": "validated"}, limit=1)
                if not findings:
                    raise ValueError("No validated findings found.")
                resolved[key] = findings[0]["id"]

            elif var_name == "next_confirmed_finding":
                findings = await db.query("findings", filters={"status": "confirmed"}, limit=1)
                if not findings:
                    raise ValueError("No confirmed findings found.")
                resolved[key] = findings[0]["id"]

            else:
                raise ValueError(f"Unknown template variable: {var_name}")
        else:
            resolved[key] = value

    return resolved


async def _check_repeat_condition(repeat_until: dict, mcp_service: Any, db: Any) -> bool:
    """Check if repeatable step should repeat (True) or advance (False)."""
    if not repeat_until:
        return False

    # Check non-metrics-based conditions first
    non_metrics_conditions = {"sast_all_verified"}
    for key, threshold in repeat_until.items():
        if key == "sast_all_verified":
            # Check if all SAST scan results have been verified
            sast_results = await db.query("knowledge", filters={"category": "sast_scan_result"}, limit=500)
            unverified = [r for r in sast_results if not r.get("metadata", {}).get("verified", False)]
            if len(unverified) > 0:
                return True  # Keep repeating

    # Check if we have any metrics-based conditions
    metrics_based_conditions = set(repeat_until.keys()) - non_metrics_conditions
    if not metrics_based_conditions:
        # No metrics-based conditions, all done
        return False

    # Get current metrics from PhaseOrchestrator (for metrics-based conditions)
    from lib.phase_orchestrator import PhaseOrchestrator
    orch = PhaseOrchestrator(db, activity_logger=getattr(mcp_service, 'activity_logger', None))
    metrics = await orch.get_metrics()

    # Check metrics-based conditions
    for key, threshold in repeat_until.items():
        # Skip non-metrics conditions (already checked above)
        if key in non_metrics_conditions:
            continue
        if key == "coverage_pct":
            current = metrics.get("coverage_pct", 0)
            if current < threshold:
                return True  # Keep repeating

        elif key == "findings_count":
            current = metrics.get("findings", 0)
            if current < threshold:
                return True

        elif key == "validated_findings_count":
            findings = await db.query("findings", filters={"status": "validated"}, limit=100)
            if len(findings) < threshold:
                return True

        elif key == "confirmed_findings_count":
            findings = await db.query("findings", filters={"status": "confirmed"}, limit=100)
            if len(findings) < threshold:
                return True

        elif key == "all_confirmed_bundled":
            # Check if all confirmed findings have evidence bundles
            confirmed = await db.query("findings", filters={"status": "confirmed"}, limit=100)
            for finding in confirmed:
                evidence = finding.get("evidence", {})
                if not evidence or not evidence.get("bundle_id"):
                    return True  # Still need to bundle

        elif key == "all_confirmed_have_poc":
            # Check if all confirmed findings have PoC
            confirmed = await db.query("findings", filters={"status": "confirmed"}, limit=100)
            for finding in confirmed:
                if not finding.get("poc_script"):
                    return True

        elif key == "all_confirmed_scored":
            # Check if all confirmed findings have risk scores
            confirmed = await db.query("findings", filters={"status": "confirmed"}, limit=100)
            for finding in confirmed:
                if not finding.get("cvss_score"):
                    return True

    # All conditions met, advance
    return False


def _compute_progress(steps: List[dict]) -> dict:
    """Compute runbook progress metrics."""
    total = len(steps)
    done = sum(1 for s in steps if s.get("status") == "done")
    progress_pct = int((done / total) * 100) if total > 0 else 0

    # Determine current phase and step
    phase = 1
    step = 1
    for i, s in enumerate(steps):
        step_id = s.get("description", "")
        if "." in step_id:
            p, st = step_id.split(".")
            phase = int(p)
            step = int(st)
        if s.get("status") != "done":
            break

    is_complete = done == total

    return {
        "phase": phase,
        "step": step,
        "progress_pct": progress_pct,
        "steps_done": done,
        "steps_total": total,
        "is_complete": is_complete,
    }


def _json_content(data: dict) -> TextContent:
    """Return JSON TextContent."""
    return TextContent(type="text", text=json.dumps(data, indent=2))


def _error_content(message: str) -> TextContent:
    """Return error TextContent."""
    return TextContent(type="text", text=json.dumps({"error": message}, indent=2))
