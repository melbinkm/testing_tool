"""
Risk Tools - risk_score, risk_assess, poc_generate.

New tool module providing risk scoring, batch assessment, and PoC generation.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Dict, List

from mcp.types import Tool, TextContent

logger = logging.getLogger("autopentest-mcp")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _json_content(data: Any) -> List[TextContent]:
    """Return a single-element TextContent list with *data* as JSON."""
    return [TextContent(type="text", text=json.dumps(data, indent=2, default=str))]


def _error_content(message: str) -> List[TextContent]:
    """Return a JSON error object wrapped in TextContent."""
    return [TextContent(type="text", text=json.dumps({"success": False, "error": message}, indent=2))]


# ---------------------------------------------------------------------------
# Tool definitions
# ---------------------------------------------------------------------------

def get_risk_tools() -> List[Tool]:
    """Return the three risk tools."""
    return [
        # 1 ---- risk_score -------------------------------------------------
        Tool(
            name="risk_score",
            description=(
                "Calculate a unified risk score for a finding using CVSS v3.1 base score, validation "
                "confidence, business impact assessment, and EPSS (Exploit Prediction Scoring System). "
                "Produces risk_score (0-100), risk_level (Critical/High/Medium/Low), and priority ranking "
                "(1-5) for remediation planning. Combines technical severity with exploitability and business "
                "context for realistic risk assessment. "

                "**When to use:** Phase 4-5 (Exploitation/Reporting) after validate_promote() confirms a finding "
                "with high confidence. Calculate risk for all confirmed findings to prioritize remediation efforts. "
                "Use before evidence_bundle() to include risk metrics in report metadata. Essential for executive "
                "reporting and compliance documentation (PCI-DSS, GDPR, SOC2 require risk-based prioritization). "

                "**Dependencies:** Requires validate_promote() to provide confidence score (0.0-1.0). Requires "
                "CVSS v3.1 vector string - use online CVSS calculator or construct manually. Follow with "
                "risk_assess() to batch-score all findings, or evidence_bundle(metadata={'cvss_vector': ..., "
                "'risk_score': ...}) to attach risk data to evidence packages. Use with wm_update_finding() to "
                "store risk score in world model. "

                "**Budget impact:** LOW - Local calculation only, no HTTP requests. EPSS lookup uses cached "
                "NVD data (no external API calls in default implementation). Completes in <200ms including CVSS "
                "parsing and impact calculations. Does NOT count against request budget. "

                "**Failure modes:** 'Invalid CVSS vector' if vector string malformed (must be CVSS:3.1/... format "
                "with all required metrics). 'Confidence out of range' if not 0.0-1.0. Missing optional parameters "
                "(asset_type, data_classification) use defaults (web_app, internal) - still produces valid score "
                "but may underestimate business impact. Unknown CVE ID skips EPSS (still works, uses CVSS-based "
                "estimate). "

                "**Risk level:** SAFE - Pure calculation, no network activity or target interaction. Uses local "
                "risk engine with CVSS 3.1 specification. No external API dependencies in default configuration. "

                "**Returns:** Risk assessment object with: cvss (parsed vector, base_score, severity), "
                "business_impact (asset multiplier, data sensitivity, compliance requirements, overall score 0-1), "
                "epss (exploit probability 0-1 from CVE database), risk (risk_score 0-100, risk_level string, "
                "priority 1-5, recommended_action). Use risk_score for sorting/prioritization, risk_level for "
                "severity labels, priority for remediation sequencing (1=fix immediately, 5=low priority). Include "
                "in evidence metadata for reports and compliance documentation."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID for reference",
                    },
                    "cvss_vector": {
                        "type": "string",
                        "description": (
                            "CVSS v3.1 vector string "
                            "(e.g. 'CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H')"
                        ),
                    },
                    "confidence": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1,
                        "description": "Finding confidence (0.0-1.0)",
                    },
                    "asset_type": {
                        "type": "string",
                        "enum": ["web_app", "api", "database", "infrastructure", "iot"],
                        "description": "Type of target asset (for business impact)",
                    },
                    "data_classification": {
                        "type": "string",
                        "enum": ["public", "internal", "confidential", "restricted"],
                        "description": "Data sensitivity level (for business impact)",
                    },
                    "compliance_frameworks": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Applicable compliance frameworks (e.g. ['pci-dss', 'gdpr'])",
                    },
                    "cve_id": {
                        "type": "string",
                        "description": "CVE ID for EPSS lookup (optional)",
                    },
                },
                "required": ["finding_id", "cvss_vector", "confidence"],
            },
        ),

        # 2 ---- risk_assess ------------------------------------------------
        Tool(
            name="risk_assess",
            description=(
                "Run batch risk assessment on all confirmed and draft findings in the world model. Calculates "
                "unified risk scores for entire finding inventory and returns prioritized list sorted by "
                "remediation priority. More efficient than calling risk_score() individually for each finding. "
                "Provides executive dashboard view of overall security posture and remediation roadmap. "

                "**When to use:** Phase 5 (Reporting) after completing validation workflow for all findings. "
                "Call once at end of assessment to generate prioritized remediation list. Use before creating "
                "final report to include risk-prioritized findings list. Essential for stakeholder presentations "
                "and remediation planning meetings. Typically called after all validate_promote() operations complete. "

                "**Dependencies:** Requires wm_add_finding() or add_card(type='finding') to have created findings "
                "in world model. Findings should have severity (critical/high/medium/low/info) and confidence scores. "
                "Optional: CVSS vectors in finding metadata for accurate scoring (falls back to severity-based "
                "estimates). Follow with evidence_generate_report() to create prioritized findings report. "

                "**Budget impact:** LOW - Local query and batch calculation, no HTTP requests. Processes up to "
                "500 findings in <2 seconds. Does NOT count against request budget. Result caching recommended "
                "if called multiple times (findings don't change frequently). "

                "**Failure modes:** 'No assessment loaded' if load_assessment() not called first. Returns empty "
                "results if no confirmed/draft findings exist (valid response, indicates clean assessment or "
                "incomplete testing). Missing CVSS vectors use severity-to-CVSS mapping (critical=9.5, high=7.5, "
                "medium=5.5, low=3.0, info=1.0) - less accurate than explicit CVSS but functional. Large finding "
                "counts (>500) may truncate results. "

                "**Risk level:** SAFE - Read-only world model query with local calculations, no network activity "
                "or target interaction. Pure analysis of existing finding data. "

                "**Returns:** Assessment summary with: count (total findings assessed), results array (sorted by "
                "priority), message (top priority finding). Each result includes: finding_id, title, severity, "
                "confidence, cvss_score, risk_score (0-100), risk_level (Critical/High/Medium/Low), priority (1-5). "
                "Array sorted by priority ascending (1=critical first), then risk_score descending within same "
                "priority. Use for: executive dashboards, remediation roadmaps, risk registers, compliance reports, "
                "stakeholder presentations. Export to CSV/Excel for tracking remediation progress."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "asset_type": {
                        "type": "string",
                        "enum": ["web_app", "api", "database", "infrastructure", "iot"],
                        "description": "Default asset type for business impact",
                    },
                    "data_classification": {
                        "type": "string",
                        "enum": ["public", "internal", "confidential", "restricted"],
                        "description": "Default data classification",
                    },
                },
            },
        ),

        # 3 ---- poc_generate -----------------------------------------------
        Tool(
            name="poc_generate",
            description=(
                "Generate proof-of-concept (PoC) scripts for a confirmed finding in curl command and/or Python "
                "format. Demonstrates vulnerability existence with minimal exploitation - validates security issue "
                "can be reproduced by client teams. PoC-level only: shows the vulnerability but does NOT perform "
                "deep exploitation, data exfiltration, or credential extraction. Safe for client delivery. "

                "**When to use:** Phase 4-5 (Exploitation/Reporting) after validate_promote() confirms finding "
                "is reproducible and should be documented. Generate PoC for all confirmed high/critical findings "
                "to help client understand and reproduce issues. Use before evidence_add_artifact() to include "
                "PoC scripts in evidence bundle. Essential for client-facing reports and remediation handoff. "

                "**Dependencies:** Requires validated finding with request details (url, method, headers, body, "
                "parameters, payload). Best used after validate_repro() confirms reproducibility. Follow with "
                "evidence_add_artifact(type='other', content=poc_script) to attach PoC to evidence bundle. Use "
                "with evidence_generate_report() to include PoC in formatted reports. "

                "**Budget impact:** LOW - Local template-based code generation, no HTTP requests. Completes in "
                "<500ms including template rendering and safety checks. Does NOT count against request budget. "
                "Does NOT execute generated code (no runtime testing). "

                "**Failure modes:** 'Invalid finding format' if finding object missing required fields (url, method). "
                "'Unsupported vulnerability type' for exotic vulnerabilities without templates (falls back to generic "
                "HTTP request template). 'Missing payload' if injection-type vulnerability lacks payload data (generates "
                "placeholder). All failures still produce basic PoC showing HTTP request structure. "

                "**Risk level:** SAFE - Template-based code generation only, no network activity or target interaction. "
                "Generated PoCs are PoC-level demonstrations (trigger vulnerability, observe response) NOT weaponized "
                "exploits. Safety classifier ensures PoCs don't include: credential harvesting, lateral movement, "
                "persistence, data exfiltration, destructive actions. Safe for client delivery and internal documentation. "

                "**Returns:** PoC package with: poc_type (vulnerability class), safety_level (demonstration_only/"
                "safe_poc), description (what the PoC demonstrates), curl_command (ready-to-run curl), script "
                "(Python code with comments), language (python), optional browser_url (for XSS/client-side). "
                "curl format for quick manual testing, Python format for automation and integration. Both include "
                "comments explaining expected behavior. Use with evidence_add_artifact() to attach to findings. "
                "Include in client reports to demonstrate vulnerabilities are real and reproducible."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID for reference",
                    },
                    "finding": {
                        "type": "object",
                        "description": (
                            "Finding details (vuln_type, url, method, parameter, "
                            "payload, title, headers, request, response)"
                        ),
                        "additionalProperties": True,
                    },
                    "format": {
                        "type": "string",
                        "enum": ["curl", "python", "both"],
                        "description": "PoC output format (default: both)",
                    },
                },
                "required": ["finding_id", "finding"],
            },
        ),
    ]


# ---------------------------------------------------------------------------
# Tool handler dispatch
# ---------------------------------------------------------------------------

async def handle_risk_tool(
    name: str,
    arguments: dict,
    mcp_service: Any = None,
) -> List[TextContent]:
    """Dispatch a risk tool call to the appropriate handler."""
    try:
        if name == "risk_score":
            return await _handle_risk_score(arguments, mcp_service)
        elif name == "risk_assess":
            return await _handle_risk_assess(arguments, mcp_service)
        elif name == "poc_generate":
            return await _handle_poc_generate(arguments, mcp_service)
    except Exception as exc:
        logger.error("Risk tool %s failed: %s", name, exc, exc_info=True)
        return _error_content(f"Error in {name}: {exc}")

    return _error_content(f"Unknown risk tool: {name}")


# ---------------------------------------------------------------------------
# Individual handlers
# ---------------------------------------------------------------------------

async def _handle_risk_score(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle risk_score - calculate unified risk score for a finding."""
    finding_id = arguments.get("finding_id")
    if not finding_id or not isinstance(finding_id, str):
        return _error_content("finding_id is required and must be a string")

    cvss_vector = arguments.get("cvss_vector")
    if not cvss_vector or not isinstance(cvss_vector, str):
        return _error_content("cvss_vector is required and must be a string")

    confidence = arguments.get("confidence")
    if confidence is None or not isinstance(confidence, (int, float)):
        return _error_content("confidence is required and must be a number (0.0-1.0)")

    from lib.risk_engine import CVSSv31, BusinessImpact, RiskScorer, calculate_epss

    # Parse CVSS
    try:
        cvss = CVSSv31(cvss_vector)
        cvss_score = cvss.base_score()
        cvss_info = cvss.to_dict()
    except ValueError as e:
        return _error_content(f"Invalid CVSS vector: {e}")

    # Business impact
    asset_type = arguments.get("asset_type", "web_app")
    data_classification = arguments.get("data_classification", "internal")
    compliance_frameworks = arguments.get("compliance_frameworks") or []

    bi = BusinessImpact()
    impact = bi.calculate(
        asset_type=asset_type,
        data_classification=data_classification,
        compliance_frameworks=compliance_frameworks,
    )

    # EPSS
    cve_id = arguments.get("cve_id")
    epss = calculate_epss(cve_id=cve_id, cvss_score=cvss_score)

    # Unified risk score
    scorer = RiskScorer()
    risk = scorer.score(
        cvss_score=cvss_score,
        confidence=float(confidence),
        business_impact=impact["overall"],
        epss_score=epss,
    )

    return _json_content({
        "success": True,
        "finding_id": finding_id,
        "cvss": cvss_info,
        "business_impact": impact,
        "epss": epss,
        "risk": risk,
        "message": (
            f"Risk score: {risk['risk_score']} ({risk['risk_level']}) - "
            f"Priority {risk['priority']}"
        ),
    })


async def _handle_risk_assess(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle risk_assess - batch risk assessment for all confirmed findings."""
    if mcp_service is None or mcp_service.current_assessment_id is None:
        return _error_content(
            "No assessment loaded. Use 'load_assessment' first."
        )

    from lib.world_model_db import get_world_model_db
    from lib.risk_engine import CVSSv31, BusinessImpact, RiskScorer, calculate_epss

    db = await get_world_model_db(mcp_service.current_assessment_id)

    # Query all confirmed/draft findings
    findings = await db.query(
        table="findings",
        filters={"status": "confirmed"},
        limit=500,
    )
    # Also include draft findings
    draft_findings = await db.query(
        table="findings",
        filters={"status": "draft"},
        limit=500,
    )
    findings.extend(draft_findings)

    if not findings:
        return _json_content({
            "success": True,
            "count": 0,
            "results": [],
            "message": "No confirmed or draft findings to assess.",
        })

    # Default parameters
    asset_type = arguments.get("asset_type", "web_app")
    data_classification = arguments.get("data_classification", "internal")

    bi = BusinessImpact()
    impact = bi.calculate(asset_type=asset_type, data_classification=data_classification)
    scorer = RiskScorer()

    assessed = []
    for finding in findings:
        metadata = finding.get("metadata", {})
        cvss_vector = metadata.get("cvss_vector") or metadata.get("cvss")
        confidence = finding.get("confidence", 0.5)

        if cvss_vector:
            try:
                cvss = CVSSv31(cvss_vector)
                cvss_score = cvss.base_score()
            except ValueError:
                cvss_score = _severity_to_cvss(finding.get("severity", "medium"))
        else:
            cvss_score = _severity_to_cvss(finding.get("severity", "medium"))

        cve_id = metadata.get("cve_id")
        epss = calculate_epss(cve_id=cve_id, cvss_score=cvss_score)

        risk = scorer.score(
            cvss_score=cvss_score,
            confidence=float(confidence),
            business_impact=impact["overall"],
            epss_score=epss,
        )

        assessed.append({
            "finding_id": finding["id"],
            "title": finding.get("title", ""),
            "severity": finding.get("severity", ""),
            "confidence": confidence,
            "cvss_score": cvss_score,
            "risk_score": risk["risk_score"],
            "risk_level": risk["risk_level"],
            "priority": risk["priority"],
        })

    # Sort by priority (1=critical first), then by risk_score descending
    assessed.sort(key=lambda x: (x["priority"], -x["risk_score"]))

    return _json_content({
        "success": True,
        "count": len(assessed),
        "results": assessed,
        "message": f"Assessed {len(assessed)} findings. Top priority: {assessed[0]['title'] if assessed else 'none'}",
    })


def _severity_to_cvss(severity: str) -> float:
    """Convert a severity string to an approximate CVSS score."""
    mapping = {
        "critical": 9.5,
        "high": 7.5,
        "medium": 5.5,
        "low": 3.0,
        "info": 1.0,
    }
    return mapping.get(severity.lower(), 5.0)


async def _handle_poc_generate(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle poc_generate - generate PoC for a confirmed finding."""
    finding_id = arguments.get("finding_id")
    if not finding_id or not isinstance(finding_id, str):
        return _error_content("finding_id is required and must be a string")

    finding = arguments.get("finding")
    if not finding or not isinstance(finding, dict):
        return _error_content("finding is required and must be an object")

    from lib.poc_generator import PoCGenerator

    generator = PoCGenerator()
    poc = generator.generate(finding)

    # Apply format filter
    fmt = arguments.get("format", "both")
    result = {
        "success": True,
        "finding_id": finding_id,
        "poc_type": poc["poc_type"],
        "safety_level": poc["safety_level"],
        "description": poc["description"],
    }

    if fmt in ("curl", "both"):
        result["curl_command"] = poc["curl_command"]
    if fmt in ("python", "both"):
        result["script"] = poc["script"]
        result["language"] = poc["language"]
    if "browser_url" in poc:
        result["browser_url"] = poc["browser_url"]

    result["message"] = f"PoC generated for {poc['poc_type']} ({poc['safety_level']})"

    return _json_content(result)
