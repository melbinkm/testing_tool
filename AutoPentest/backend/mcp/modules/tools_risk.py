"""
Risk Tools - risk_score, risk_assess, poc_generate.

New tool module providing risk scoring, batch assessment, and PoC generation.
"""

from __future__ import annotations

import json
import logging
from typing import Any, Dict, List

from mcp.types import Tool, TextContent

logger = logging.getLogger("autopentest-mcp")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _json_content(data: Any) -> List[TextContent]:
    """Return a single-element TextContent list with *data* as JSON."""
    return [TextContent(type="text", text=json.dumps(data, indent=2, default=str))]


def _error_content(message: str) -> List[TextContent]:
    """Return a JSON error object wrapped in TextContent."""
    return [TextContent(type="text", text=json.dumps({"success": False, "error": message}, indent=2))]


# ---------------------------------------------------------------------------
# Tool definitions
# ---------------------------------------------------------------------------

def get_risk_tools() -> List[Tool]:
    """Return the three risk tools."""
    return [
        # 1 ---- risk_score -------------------------------------------------
        Tool(
            name="risk_score",
            description=(
                "Calculate a unified risk score for a finding using CVSS v3.1, "
                "confidence, business impact, and EPSS."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID for reference",
                    },
                    "cvss_vector": {
                        "type": "string",
                        "description": (
                            "CVSS v3.1 vector string "
                            "(e.g. 'CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H')"
                        ),
                    },
                    "confidence": {
                        "type": "number",
                        "minimum": 0,
                        "maximum": 1,
                        "description": "Finding confidence (0.0-1.0)",
                    },
                    "asset_type": {
                        "type": "string",
                        "enum": ["web_app", "api", "database", "infrastructure", "iot"],
                        "description": "Type of target asset (for business impact)",
                    },
                    "data_classification": {
                        "type": "string",
                        "enum": ["public", "internal", "confidential", "restricted"],
                        "description": "Data sensitivity level (for business impact)",
                    },
                    "compliance_frameworks": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Applicable compliance frameworks (e.g. ['pci-dss', 'gdpr'])",
                    },
                    "cve_id": {
                        "type": "string",
                        "description": "CVE ID for EPSS lookup (optional)",
                    },
                },
                "required": ["finding_id", "cvss_vector", "confidence"],
            },
        ),

        # 2 ---- risk_assess ------------------------------------------------
        Tool(
            name="risk_assess",
            description=(
                "Run risk assessment on all confirmed findings in the world model. "
                "Returns a prioritized list with risk scores."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "asset_type": {
                        "type": "string",
                        "enum": ["web_app", "api", "database", "infrastructure", "iot"],
                        "description": "Default asset type for business impact",
                    },
                    "data_classification": {
                        "type": "string",
                        "enum": ["public", "internal", "confidential", "restricted"],
                        "description": "Default data classification",
                    },
                },
            },
        ),

        # 3 ---- poc_generate -----------------------------------------------
        Tool(
            name="poc_generate",
            description=(
                "Generate a proof-of-concept script for a confirmed finding. "
                "PoC-level only - demonstrates the vulnerability exists. "
                "No deep exploitation or secret extraction."
            ),
            inputSchema={
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Finding ID for reference",
                    },
                    "finding": {
                        "type": "object",
                        "description": (
                            "Finding details (vuln_type, url, method, parameter, "
                            "payload, title, headers, request, response)"
                        ),
                        "additionalProperties": True,
                    },
                    "format": {
                        "type": "string",
                        "enum": ["curl", "python", "both"],
                        "description": "PoC output format (default: both)",
                    },
                },
                "required": ["finding_id", "finding"],
            },
        ),
    ]


# ---------------------------------------------------------------------------
# Tool handler dispatch
# ---------------------------------------------------------------------------

async def handle_risk_tool(
    name: str,
    arguments: dict,
    mcp_service: Any = None,
) -> List[TextContent]:
    """Dispatch a risk tool call to the appropriate handler."""
    try:
        if name == "risk_score":
            return await _handle_risk_score(arguments, mcp_service)
        elif name == "risk_assess":
            return await _handle_risk_assess(arguments, mcp_service)
        elif name == "poc_generate":
            return await _handle_poc_generate(arguments, mcp_service)
    except Exception as exc:
        logger.error("Risk tool %s failed: %s", name, exc, exc_info=True)
        return _error_content(f"Error in {name}: {exc}")

    return _error_content(f"Unknown risk tool: {name}")


# ---------------------------------------------------------------------------
# Individual handlers
# ---------------------------------------------------------------------------

async def _handle_risk_score(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle risk_score - calculate unified risk score for a finding."""
    finding_id = arguments.get("finding_id")
    if not finding_id or not isinstance(finding_id, str):
        return _error_content("finding_id is required and must be a string")

    cvss_vector = arguments.get("cvss_vector")
    if not cvss_vector or not isinstance(cvss_vector, str):
        return _error_content("cvss_vector is required and must be a string")

    confidence = arguments.get("confidence")
    if confidence is None or not isinstance(confidence, (int, float)):
        return _error_content("confidence is required and must be a number (0.0-1.0)")

    from lib.risk_engine import CVSSv31, BusinessImpact, RiskScorer, calculate_epss

    # Parse CVSS
    try:
        cvss = CVSSv31(cvss_vector)
        cvss_score = cvss.base_score()
        cvss_info = cvss.to_dict()
    except ValueError as e:
        return _error_content(f"Invalid CVSS vector: {e}")

    # Business impact
    asset_type = arguments.get("asset_type", "web_app")
    data_classification = arguments.get("data_classification", "internal")
    compliance_frameworks = arguments.get("compliance_frameworks") or []

    bi = BusinessImpact()
    impact = bi.calculate(
        asset_type=asset_type,
        data_classification=data_classification,
        compliance_frameworks=compliance_frameworks,
    )

    # EPSS
    cve_id = arguments.get("cve_id")
    epss = calculate_epss(cve_id=cve_id, cvss_score=cvss_score)

    # Unified risk score
    scorer = RiskScorer()
    risk = scorer.score(
        cvss_score=cvss_score,
        confidence=float(confidence),
        business_impact=impact["overall"],
        epss_score=epss,
    )

    return _json_content({
        "success": True,
        "finding_id": finding_id,
        "cvss": cvss_info,
        "business_impact": impact,
        "epss": epss,
        "risk": risk,
        "message": (
            f"Risk score: {risk['risk_score']} ({risk['risk_level']}) - "
            f"Priority {risk['priority']}"
        ),
    })


async def _handle_risk_assess(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle risk_assess - batch risk assessment for all confirmed findings."""
    if mcp_service is None or mcp_service.current_assessment_id is None:
        return _error_content(
            "No assessment loaded. Use 'load_assessment' first."
        )

    from lib.world_model_db import get_world_model_db
    from lib.risk_engine import CVSSv31, BusinessImpact, RiskScorer, calculate_epss

    db = await get_world_model_db(mcp_service.current_assessment_id)

    # Query all confirmed/draft findings
    findings = await db.query(
        table="findings",
        filters={"status": "confirmed"},
        limit=500,
    )
    # Also include draft findings
    draft_findings = await db.query(
        table="findings",
        filters={"status": "draft"},
        limit=500,
    )
    findings.extend(draft_findings)

    if not findings:
        return _json_content({
            "success": True,
            "count": 0,
            "results": [],
            "message": "No confirmed or draft findings to assess.",
        })

    # Default parameters
    asset_type = arguments.get("asset_type", "web_app")
    data_classification = arguments.get("data_classification", "internal")

    bi = BusinessImpact()
    impact = bi.calculate(asset_type=asset_type, data_classification=data_classification)
    scorer = RiskScorer()

    assessed = []
    for finding in findings:
        metadata = finding.get("metadata", {})
        cvss_vector = metadata.get("cvss_vector") or metadata.get("cvss")
        confidence = finding.get("confidence", 0.5)

        if cvss_vector:
            try:
                cvss = CVSSv31(cvss_vector)
                cvss_score = cvss.base_score()
            except ValueError:
                cvss_score = _severity_to_cvss(finding.get("severity", "medium"))
        else:
            cvss_score = _severity_to_cvss(finding.get("severity", "medium"))

        cve_id = metadata.get("cve_id")
        epss = calculate_epss(cve_id=cve_id, cvss_score=cvss_score)

        risk = scorer.score(
            cvss_score=cvss_score,
            confidence=float(confidence),
            business_impact=impact["overall"],
            epss_score=epss,
        )

        assessed.append({
            "finding_id": finding["id"],
            "title": finding.get("title", ""),
            "severity": finding.get("severity", ""),
            "confidence": confidence,
            "cvss_score": cvss_score,
            "risk_score": risk["risk_score"],
            "risk_level": risk["risk_level"],
            "priority": risk["priority"],
        })

    # Sort by priority (1=critical first), then by risk_score descending
    assessed.sort(key=lambda x: (x["priority"], -x["risk_score"]))

    return _json_content({
        "success": True,
        "count": len(assessed),
        "results": assessed,
        "message": f"Assessed {len(assessed)} findings. Top priority: {assessed[0]['title'] if assessed else 'none'}",
    })


def _severity_to_cvss(severity: str) -> float:
    """Convert a severity string to an approximate CVSS score."""
    mapping = {
        "critical": 9.5,
        "high": 7.5,
        "medium": 5.5,
        "low": 3.0,
        "info": 1.0,
    }
    return mapping.get(severity.lower(), 5.0)


async def _handle_poc_generate(arguments: dict, mcp_service: Any = None) -> List[TextContent]:
    """Handle poc_generate - generate PoC for a confirmed finding."""
    finding_id = arguments.get("finding_id")
    if not finding_id or not isinstance(finding_id, str):
        return _error_content("finding_id is required and must be a string")

    finding = arguments.get("finding")
    if not finding or not isinstance(finding, dict):
        return _error_content("finding is required and must be an object")

    from lib.poc_generator import PoCGenerator

    generator = PoCGenerator()
    poc = generator.generate(finding)

    # Apply format filter
    fmt = arguments.get("format", "both")
    result = {
        "success": True,
        "finding_id": finding_id,
        "poc_type": poc["poc_type"],
        "safety_level": poc["safety_level"],
        "description": poc["description"],
    }

    if fmt in ("curl", "both"):
        result["curl_command"] = poc["curl_command"]
    if fmt in ("python", "both"):
        result["script"] = poc["script"]
        result["language"] = poc["language"]
    if "browser_url" in poc:
        result["browser_url"] = poc["browser_url"]

    result["message"] = f"PoC generated for {poc['poc_type']} ({poc['safety_level']})"

    return _json_content(result)
